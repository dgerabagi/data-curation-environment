# Artifact A94: DCE - Connecting to a Local LLM Guide
# Date Created: C35
# Author: AI Model & Curator
# Updated on: C36 (Align with new multi-modal settings UI)

- **Key/Value for A0:**
- **Description:** A step-by-step guide on how to configure the DCE extension to use a local LLM with an OpenAI-compatible API via the new settings panel.
- **Tags:** guide, setup, llm, vllm, configuration, local

## 1. Overview & Goal

This guide explains how to configure the Data Curation Environment (DCE) extension to communicate with a locally hosted Large Language Model (LLM), such as the one set up via the `A92. DCE - vLLM Setup Guide`.

The goal is to switch the extension from its default "Manual" mode to one of the automated modes that can make API calls directly to your local model, streamlining the development workflow.

## 2. Step-by-Step Configuration

### Step 1: Open the Settings Panel
- Open the Command Palette (`Ctrl+Shift+P` or `Cmd+Shift+P`).
- Run the command: **`DCE: Open Settings & Help`**. This will open the settings panel in a new editor tab.

### Step 2: Navigate to the Settings Section
- In the settings panel, find and expand the **"Settings"** section.

### Step 3: Select Your Connection Mode
You will see a list of connection modes. Choose the one that matches your setup.

#### Option A: Demo Mode (Recommended for `aiascent.game` users)
This is the simplest option if you are using the pre-configured `aiascent.game` proxy.
-   Select the radio button for **"Demo Mode (Local vLLM via `aiascent.game`)"**.
-   The endpoint is pre-configured. No other steps are needed.

#### Option B: API Mode (URL)
Use this option if you are running your own vLLM server (or another OpenAI-compatible service) and want to connect to it directly without a proxy.
-   Select the radio button for **"API (URL)"**.
-   An input field will appear. Enter the full API endpoint URL. For a standard vLLM server, this will be `http://localhost:8000/v1`.
    -   **Important:** If your LLM server is on a different machine, replace `localhost` with that machine's local network IP address (e.g., `http://192.168.1.100:8000/v1`).
-   Save the settings.

## 4. Next Steps

The DCE extension is now configured to send its API requests to your local LLM server. You can now use the "Generate Responses" button (once implemented) in the Parallel Co-Pilot Panel to automatically populate the response tabs, completing the automated workflow. To switch back to the manual copy/paste method, simply re-open the settings and select **"Free Mode (Manual Copy/Paste)"**.