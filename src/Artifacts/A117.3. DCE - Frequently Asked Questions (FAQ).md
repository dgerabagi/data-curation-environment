# Artifact A117.3: DCE - Frequently Asked Questions (FAQ)
# Date Created: C117
# Author: AI Model & Curator

- **Key/Value for A0:**
- **Description:** A comprehensive list of frequently asked questions about the Data Curation Environment (DCE) to be used as a knowledge base for the new promotional website.
- **Tags:** documentation, faq, knowledge base, guide, onboarding

## 1. General / What is DCE?

**Q: What is the Data Curation Environment (DCE)?**

**A:** The Data Curation Environment (DCE) is a VS Code extension designed to streamline and accelerate AI-assisted development. It provides a suite of tools to help developers and curators precisely select, manage, and package the code and documents (the "context") they provide to Large Language Models (LLMs). Its core feature is a "Parallel Co-Pilot Panel" that allows users to manage, compare, and test multiple AI-generated responses simultaneously.

**Q: Who is DCE for?**

**A:** DCE is for any developer, researcher, or project manager who uses Large Language Models as part of their workflow. It's particularly useful for those working on complex projects who need to provide large, multi-file contexts to an AI and want a more structured, efficient, and auditable process than manually copying and pasting into a chat window.

**Q: What problem does DCE solve?**

**A:** DCE solves the "context problem" in AI-assisted development. Manually selecting files, copying their content, and managing the prompt you send to an AI is tedious, error-prone, and not easily repeatable. DCE automates the process of gathering and packaging this context. It also solves the "single-threaded" nature of AI interaction by allowing you to work with multiple AI responses in parallel, dramatically speeding up the iterative cycle of testing and refining AI-generated code.

**Q: Is DCE a replacement for GitHub Copilot?**

**A:** No, DCE is a complementary tool. While Copilot excels at inline code completion and chat-based assistance, DCE is focused on the higher-level workflow of managing large contexts and orchestrating multiple, complex, multi-file responses from an AI. You can use DCE to generate a prompt, get responses from your preferred AI (including those you might get from a tool like Copilot Chat), and then use DCE's panel to manage and test those responses.

## 2. Core Concepts & Workflow

**Q: What is the "artifact-driven workflow"?**

**A:** This is the core philosophy of DCE, summarized as "Documentation First." Before writing code, you and your AI partner first create or update a documentation "Artifact" that describes the plan. These artifacts (like Project Vision, Requirements, etc.) serve as the "source of truth" for the project, ensuring that both human and AI are aligned. DCE's onboarding experience helps you bootstrap this process.

**Q: What is a "Cycle"?**

**A:** A "Cycle" is the fundamental unit of work in the DCE workflow. A typical cycle involves:
1.  Writing your plan for the cycle (the "Cycle Context").
2.  Generating a complete `prompt.md` file that includes your plan, project history, and all relevant code.
3.  Getting multiple responses from an AI.
4.  Pasting those responses into the Parallel Co-Pilot Panel.
5.  Parsing, comparing, and selecting the best response.
6.  Accepting the AI's changes into your codebase and testing them.
7.  Starting the next cycle.

**Q: What is the "Parallel Co-Pilot Panel" (PCPP)?**

**A:** The PCPP is the main UI of the DCE. It's a multi-tabbed panel inside VS Code where you can paste, parse, compare, and test multiple AI-generated responses in parallel. It includes features like a cycle navigator to review history, an integrated diff viewer, and a Git-powered "Baseline/Restore" workflow for safe testing.

**Q: What does "Flatten Context" mean?**

**A:** "Flattening" is the process of taking all the files and folders you've selected in the File Tree View and concatenating their content into a single, large text file (`flattened_repo.md`). This file, combined with your project's history and plans, becomes the `prompt.md` that you send to the LLM, giving it a comprehensive view of your project.

## 3. Features & Functionality

**Q: What kind of files can DCE handle?**

**A:** DCE is designed to handle a wide variety of text-based files, including source code in any language. It also has specialized support for extracting text from `.pdf`, `.docx` (Microsoft Word), and `.xlsx` / `.csv` (Excel/CSV) files, converting their content into a format that an LLM can understand. For binary files like images, it includes metadata (path, size) instead of raw content.

**Q: How does the Git-integrated testing work?**

**A:** The PCPP includes "Baseline (Commit)" and "Restore Baseline" buttons.
*   **Baseline:** Creates a Git commit of your current workspace state, giving you a safe restore point.
*   **Accept:** You can then "Accept" an AI's proposed file changes, which overwrites your local files.
*   **Test & Restore:** You can test the new code. If it doesn't work, a single click on "Restore Baseline" uses `git restore` to instantly revert all changes, allowing you to cleanly test a different AI response without manual cleanup.

**Q: Can I use DCE with my own local LLM?**

**A:** Yes. DCE is designed for this. The "Demo Mode" connects to a local vLLM instance with an OpenAI-compatible API out of the box. You can also configure the extension in the settings to point to any custom URL, allowing you to use other local model servers like Ollama or LM Studio, as long as they expose an OpenAI-compatible endpoint.

**Q: What is the "Animated Workflow Guide"?**

**A:** To help new users learn the process, DCE features an optional animated guide. It places a subtle "pulsing glow" on the UI element that represents the next logical step in the workflow (e.g., after pasting responses, the "Parse All" button will glow).

## 4. Local LLM / Demo Mode

**Q: What is "Demo Mode"?**

**A:** "Demo Mode" is a pre-configured setting that allows DCE to connect to a locally running LLM that exposes an OpenAI-compatible API (like vLLM). When in this mode, the "Generate prompt.md" button is replaced with a "Generate responses" button, which fully automates the process of creating the prompt, sending it to the local LLM, and streaming the responses back into the PCPP.

**Q: What is vLLM and why do you recommend it?**

**A:** vLLM is a high-throughput serving engine for LLMs. We recommend it for local use because of its performance and its support for parallel processing ("continuous batching"). This allows vLLM to generate multiple responses simultaneously with very high speed (tokens/second), which pairs perfectly with DCE's parallel response panel.

**Q: Do I have to use vLLM?**

**A:** No. While the "Demo Mode" is pre-configured with vLLM in mind, you can use the "API (URL)" mode in the settings to point DCE to any OpenAI-compatible API endpoint, including those provided by other tools like Ollama, LM Studio, or a custom server.

## 5. Troubleshooting & Common Issues

**Q: Why are my newly created files showing up with a red 'âœ—' in the "Associated Files" list?**

**A:** This usually happens due to a slight delay between when the file is written to disk and when the UI receives the update. If it persists, a simple refresh of the panel or ensuring the file is saved should resolve it. The "Link" feature can also be used to manually associate the AI's response with the correct file path if needed.

**Q: I'm seeing data loss when I navigate between cycles quickly.**

**A:** This can happen if you navigate away from a cycle while it is in the middle of an auto-save operation. The UI includes a save status indicator (a checkmark that turns into a caution or spinning icon). To prevent this, wait for the indicator to return to a green checkmark before navigating to a different cycle. The navigation buttons are automatically disabled during the saving process to help prevent this.

**Q: The File Tree View (FTV) keeps flashing or refreshing.**

**A:** This is often caused by a file watcher reacting to frequent file changes. A common culprit is the DCE's own history file (`.vscode/dce_history.json`). Ensuring that the `.vscode` directory is added to your project's `.gitignore` file can often resolve this issue, as it signals to the file watcher to ignore changes within that directory.