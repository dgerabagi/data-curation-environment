# Artifact A11: DCE - Regression Case Studies
# Date Created: C16
# Author: AI Model & Curator
# Updated on: C130 (Add non-functional workflow buttons case)

## 1. Purpose

This document serves as a living record of persistent or complex bugs. By documenting the root cause analysis (RCA) and the confirmed solution for each issue, we create a "source of truth" to prevent the same mistakes from being reintroduced into the codebase.

## 2. Case Studies

---

### Case Study 024: Workflow Buttons Non-Functional After Centralization

-   **Artifacts Affected:** `view.tsx`, `WorkflowToolbar.tsx`
-   **Cycles Observed:** C130
-   **Symptom:** The "Baseline (Commit)" and "Restore Baseline" buttons in the centralized `WorkflowToolbar` were visible and animated correctly but did nothing when clicked.
-   **Root Cause Analysis (RCA):** When the buttons were moved from the main `view.tsx` component to the `WorkflowToolbar` child component, the event handlers (`handleBaseline`, `handleRestore`) were not implemented in the parent. Instead, empty placeholder functions (`() => {}`) were passed as props, severing the connection between the UI and the IPC logic.
-   **Codified Solution & Best Practice:** When refactoring or moving UI components, always verify that the event handlers passed as props are fully implemented in the parent container. Ensure that critical logic (like IPC calls) is not lost during the move.

---

### Case Study 023: Native Module Build & ABI Mismatch (Consolidated)

-   **Artifacts Affected:** `node_modules`, `package.json`, `webpack.config.js`
-   **Cycles Observed:** C119-C123
-   **Symptom:** The extension fails to activate, hangs on build, or throws errors like `NODE_MODULE_VERSION 130. This version of Node.js requires NODE_MODULE_VERSION 136` when using native modules like `better-sqlite3`.
-   **Root Cause Analysis (RCA):**
    1.  **Webpack Bundling:** Webpack cannot bundle binary files (`.node`). They must be treated as external dependencies.
    2.  **ABI Mismatch:** VS Code runs on a specific version of Electron, which uses a specific Node.js ABI (e.g., 136). Standard `npm install` compiles for the system's Node.js version (e.g., 127), causing a mismatch.
    3.  **Electron Version Detection:** `electron-rebuild` sometimes fails to detect the correct target version if `electron` is not explicitly listed in `devDependencies`.
    4.  **Compiler Standards:** Newer Electron versions (v33+) require C++20, which older native modules may not support.
-   **Codified Solution & Best Practice:**
    1.  **Webpack:** Add native modules to the `externals` section in `webpack.config.js` (e.g., `'better-sqlite3': 'commonjs better-sqlite3'`).
    2.  **Dependencies:** Ensure `electron` (matching the target VS Code version) and `@electron/rebuild` are in `devDependencies`.
    3.  **Rebuild Script:** Use a robust rebuild command: `electron-rebuild -f -w better-sqlite3`.
    4.  **Force Version:** If mismatches persist (especially with custom VS Code builds), identify the runtime Electron version from logs and force the rebuild target: `npm run rebuild -- -v <VERSION> -f`.

---

### Case Study 022: Parallel Requests Fail with ETIMEDOUT (Regression)

-   **Artifacts Affected:** `src/backend/services/llm.service.ts`
-   **Cycles Observed:** C113, C115, C116
-   **Symptom:** When the backend attempts to make multiple parallel `fetch` requests to the same host (e.g., generating 4 responses simultaneously), some of the requests fail with a `connect ETIMEDOUT` error. This results in only one or two responses being generated successfully.
-   **Root Cause Analysis (RCA):** The default Node.js `http.Agent` (used by `node-fetch`) has a limited pool of sockets for concurrent connections to a single origin. When the application tries to open several long-lived streaming connections at once, the later requests can time out while waiting for a socket to become available. This is a recurring issue, indicating that previous fixes were not consistently applied.
-   **Codified Solution & Best Practice:**
    1.  When an application needs to make a high number of concurrent, long-lived HTTP/HTTPS requests to a single host from a Node.js backend, do not rely on the default agent.
    2.  Use a dedicated agent library like `agentkeepalive` to create a single, shared `HttpsAgent` instance at the module level.
    3.  Configure this agent with a high `maxSockets` value (e.g., 100) to ensure a large enough connection pool is available.
    4.  **Crucially, ensure this custom agent is passed to *all* relevant `fetch` calls within the service to guarantee it is used for every request.**

---

### Case Study 021: Incorrect Un-escaping of Double-Escaped JSON String Content

-   **Artifacts Affected:** `src/client/utils/response-parser.ts`
-   **Cycles Observed:** C115
-   **Symptom:** When parsing a JSON response from the vLLM, the final content in the UI is corrupted with extra backslashes. For example, newlines appear as `\` instead of being processed, and quotes appear as `\"` or `\\"`.
-   **Root Cause Analysis (RCA):** The LLM, when generating a JSON object as a string, sometimes "double-escapes" characters within its string values to ensure they are valid. For example, a newline becomes `\\n` and a quote becomes `\\\"`. The parser's logic for handling this was flawed. `JSON.parse` correctly handles the first level of escaping, but the subsequent manual `.replace()` calls in the hybrid parser were too simplistic and did not correctly handle the remaining escape sequences, leading to the visual artifacts.
-   **Codified Solution & Best Practice:**
    1.  When processing string values from an LLM-generated JSON, assume they may be double-escaped.
    2.  Implement a robust, multi-step un-escaping sequence. The correct order is to first replace `\\\\` with `\\` (to handle literal backslashes), then replace `\\n` with a newline, `\\t` with a tab, and finally `\\"` with `"`.
    3.  This sequence, applied after the main JSON structure is parsed, correctly reduces the escape levels and produces a clean, readable string for the UI.

---

### Case Study 020: Parallel Onboarding Requests Fail with ETIMEDOUT

-   **Artifacts Affected:** `llm.service.ts`, `OnboardingView.tsx`, `useGeneration.ts`, `view.tsx`
-   **Cycles Observed:** C113, C115 (Regression)
-   **Symptom:** When clicking "Generate Initial Responses" from the onboarding view with the number of responses set to > 1, only one response is successfully generated. The other requests fail with `connect ETIMEDOUT` errors in the logs.
-   **Root Cause Analysis (RCA):** This is a complex issue with two contributing factors.
    1.  **State Mismatch:** The `OnboardingView.tsx` component managed its own local state for the `responseCount`. This was separate from the `tabCount` state managed by the main PCPP view. While the value was correctly passed to the backend, this state divergence made the system harder to debug and reason about.
    2.  **Connection Pooling:** The underlying issue is the `ETIMEDOUT` error, which indicates a client-side bottleneck in establishing concurrent connections to the proxy server, despite a previous fix (`agentkeepalive`) intended to solve this. Unifying the state is a prerequisite to ensure the correct parameters are being sent before further debugging of the connection pooling issue can be effective.
-   **Codified Solution & Best Practice:**
    1.  Avoid state divergence for critical parameters. The number of responses should be a single piece of state managed by a higher-order component or hook (`view.tsx` or `useGeneration.ts`). This state should be passed down as props to any child component that needs to read or modify it, ensuring a single source of truth.
    2.  The `ETIMEDOUT` error points to a persistent issue with Node.js connection pooling in the extension host environment. The `agentkeepalive` solution needs to be re-verified or a different strategy for managing parallel long-lived connections may be required.

---

### Case Study 019: Backend SSE Parser Fails on Fragmented Data Chunks

-   **Artifacts Affected:** `src/backend/services/llm.service.ts`
-   **Cycles Observed:** C108, C109, C110, C114
-   **Symptom:** The DCE output log is flooded with `Could not parse JSON object from stream` warnings during response generation. The final response content is often corrupted or incomplete.
-   **Root Cause Analysis (RCA):** The stream consumer in `llm.service.ts` was not correctly buffering incoming data from the vLLM server. It processed each `data` event from the stream as if it contained one or more complete, newline-terminated messages. However, a single logical SSE message from the server can be fragmented and sent across multiple TCP packets, resulting in the `data` event firing with an incomplete piece of a message. The parser would then attempt to parse this incomplete fragment, which is invalid JSON, leading to the error.
-   **Codified Solution & Best Practice:**
    1.  Stream consumers for protocols like SSE must be designed to handle fragmented messages. They cannot assume that each `data` event contains a complete message.
    2.  The correct implementation is to maintain a persistent buffer outside the `stream.on('data')` handler.
    3.  Each incoming chunk should be appended to this buffer.
    4.  The buffer should then be processed in a loop, searching for the standard SSE message terminator (`\n\n`).
    5.  Only the complete messages found before the terminator should be extracted and parsed. Any remaining text after the last terminator is an incomplete message and must be kept in the buffer to be prepended to the next incoming chunk.

---

### Case Study 018: Parallel Fetch Requests Fail with ETIMEDOUT

-   **Artifacts Affected:** `src/backend/services/llm.service.ts`
-   **Cycles Observed:** C113
-   **Symptom:** When the backend attempts to make multiple parallel `fetch` requests to the same host (e.g., generating 4 responses simultaneously), some of the requests fail with a `connect ETIMEDOUT` error. This results in only one or two responses being generated successfully.
-   **Root Cause Analysis (RCA):** The default Node.js `http.Agent` (used by `node-fetch`) has a pool of sockets for connections. While the default `maxSockets` is technically `Infinity`, in practice, factors within the execution environment (like VS Code's extension host) can lead to exhaustion or delays in acquiring new sockets for concurrent requests to the same origin. When the application tries to open several connections at once, the later requests can time out while waiting for a socket to become available.
-   **Codified Solution & Best Practice:**
    1.  When an application needs to make a high number of concurrent, long-lived HTTP/HTTPS requests to a single host from a Node.js backend, do not rely on the default `http.Agent`.
    2.  Use a dedicated agent library like `agentkeepalive` to create a custom `HttpsAgent` instance.
    3.  Configure this agent with a high `maxSockets` value (e.g., 100) to ensure a large enough connection pool is available.
    4.  Pass this custom agent to all relevant `fetch` calls. This provides robust and performant connection pooling, preventing timeout errors caused by socket exhaustion.