# Artifact A11: DCE - Regression Case Studies
# Date Created: C16
# Author: AI Model & Curator
# Updated on: C74 (Add navigation failure case study)

## 1. Purpose

This document serves as a living record of persistent or complex bugs that have recurred during development. By documenting the root cause analysis (RCA) and the confirmed solution for each issue, we create a "source of truth" that can be referenced to prevent the same mistakes from being reintroduced into the codebase.

**This artifact is the primary log for new and recent case studies.** Older, resolved issues are archived in `A11.1 DCE - New Regression Case Studies.md` to keep this document concise and focused on currently relevant issues.

## 2. Case Studies

---

### Case Study 042: Failure to Navigate to New Cycle on Generation

-   **Artifacts Affected:** `src/client/views/parallel-copilot.view/view.tsx`, `src/common/ipc/channels.type.ts`, `src/backend/services/history.service.ts`
-   **Cycles Observed:** C74
-   **Symptom:** After the initial onboarding, when the user clicks "Generate responses" for Cycle 1, the backend correctly creates a new placeholder for Cycle 2 and starts the LLM generation. However, the frontend UI remains on Cycle 1 and does not display the generation progress UI.
-   **Root Cause Analysis (RCA):** The "Create-Then-Generate" workflow relies on the backend telling the frontend to navigate to the new placeholder cycle. The `StartGenerationUI` message correctly provides the `newCycleId`, but the frontend's navigation logic (`handleCycleChange`) has a guard clause that prevents navigation to a cycle ID that is greater than its current `maxCycle` state. The `maxCycle` state was not being updated on the frontend before the navigation was attempted, causing the navigation to be silently ignored.
-   **Codified Solution & Best Practice:**
    1.  Any backend message that instructs the frontend to navigate to a newly created cycle **must** also include the new maximum cycle count in its payload (e.g., `{ newCycleId, newMaxCycle }`).
    2.  The frontend message handler must update its `maxCycle` state *before* attempting to call its navigation function. This ensures the guard clauses in the navigation logic have the most up-to-date state and will permit the view switch.

---

### Case Study 041: PCPP View State Lost on Tab Switch

-   **Artifacts Affected:** `src/client/views/parallel-copilot.view/view.tsx`, `src/common/types/vscode-webview.d.ts`
-   **Cycles Observed:** C67, C72
-   **Symptom:** When the user is viewing a specific UI state within the Parallel Co-Pilot Panel (e.g., the "Generation Progress" view), and they switch to another VS Code tab and then return, the panel's view resets to its default state (the main response pane). The user's intended view is lost.
-   **Root Cause Analysis (RCA):** VS Code webviews can be destroyed when they become hidden to conserve resources. When the user returns, the webview is completely re-initialized. Any UI state managed solely within React's `useState` is therefore lost. The correct way to persist UI-specific state for a webview is to use the `acquireVsCodeApi()`'s `getState()` and `setState()` methods, which are managed by the VS Code host and survive the webview's destruction.
-   **Codified Solution & Best Practice:**
    1.  Identify any transient UI state that needs to be persisted (e.g., `activeView: 'main' | 'progress'`).
    2.  Add this state to the `ViewState` interface in `vscode-webview.d.ts`.
    3.  On component mount, use a `useEffect` hook to call `vscode.getState()` to retrieve and restore the persisted UI state.
    4.  Use another `useEffect` hook that listens for changes to that state variable and calls `vscode.setState()` to save it whenever it changes. This ensures the view state is always preserved by the VS Code host.

---

### Case Study 040: Stale Prompt Context in Automated Generation Workflow

-   **Artifacts Affected:** `src/backend/services/prompt.service.ts`, `src/client/views/parallel-copilot.view/on-message.ts`, `src/client/views/parallel-copilot.view/view.tsx`
-   **Cycles Observed:** C67, C71
-   **Symptom:** When using the "Generate responses" button for a new cycle (e.g., Cycle 2), the responses received from the LLM are based on the context of a much older cycle (e.g., Cycle 0), completely ignoring the new information provided by the user in the current cycle (e.g., Cycle 1). Additionally, the UI fails to automatically navigate to the new cycle after generation is complete.
-   **Root Cause Analysis (RCA):** This is a critical workflow failure with two main causes:
    1.  **Stale Data:** The `prompt.service.ts` was not correctly combining the fresh, in-memory `cycleData` (for Cycle `N`) sent from the frontend with the full history read from disk. A logic error caused it to ignore the new `cycleContext` and build the prompt using only the older, persisted data for Cycle `N`.
    2.  **Navigation Failure:** The frontend's message handler for `SendBatchGenerationComplete` was not reliably triggering the navigation to the new cycle (`N+1`), leaving the user on the old cycle view.
-   **Codified Solution & Best Practice:**
    1.  The backend handler for `RequestNewCycleAndGenerate` must use the `cycleData` from the client as the absolute source of truth for the current cycle.
    2.  The `prompt.service.ts` must ensure its logic correctly overwrites any stale data from the history file with the fresh data from the client before assembling the prompt.
    3.  As a best practice for transparency, the generated prompt string should be written to `prompt.md` in the workspace before being sent to the LLM.
    4.  The frontend's `SendBatchGenerationComplete` handler must reliably call the navigation logic to switch the view to the `newCycleId`.

---

### Case Study 039: vLLM Responses Truncated at Stop Token

-   **Artifacts Affected:** `A90. AI Ascent - server.ts (Reference).md`, `src/backend/services/llm.service.ts`
-   **Cycles Observed:** C44
-   **Symptom:** When generating batch responses from the vLLM server, the AI-generated text is cut off prematurely, often right before it would have written `