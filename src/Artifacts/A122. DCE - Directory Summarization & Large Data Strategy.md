# Artifact A122: DCE - Directory Summarization & Large Data Strategy
# Date Created: C127
# Author: AI Model & Curator

- **Key/Value for A0:**
- **Description:** A strategy to manage token bloat by summarizing large asset directories and truncating massive data files.
- **Tags:** strategy, optimization, tokens, d-info, truncation, large files

## 1. Problem Statement

As projects grow, they often accumulate large numbers of asset files (images, audio) or massive data definition files. Including these in the AI context "raw" leads to significant token bloat.
1.  **Asset Directories:** A folder with 2,000 images generates 2,000 entries in the flattened context. Even if the content is skipped, the file paths and metadata headers consume thousands of tokens.
2.  **Data Files:** Large TypeScript data files (e.g., item definitions, RPG stats) can consume tens of thousands of tokens while providing low "structural" value to the AI, which often only needs to know the *shape* of the data.

## 2. Strategy 1: Directory Summarization (`d-info`)

**Goal:** Replace the verbose listing of hundreds of individual files with a concise summary of the directory's contents.

**Mechanism:**
*   **Trigger:** When the Flattener Service processes the selected files, it groups them by their parent directory. If the number of selected files in a single directory exceeds a threshold (e.g., **50 files**), the "Summarization Mode" is triggered for that directory.
*   **Action:** The individual file entries are removed from the flattening queue. They are replaced by a single, virtual file entry named `d-info.md` within that directory.
*   **Content:** The virtual `d-info.md` file contains:
    *   Total file count.
    *   Directory location relative to the project root.
    *   A concise list of the filenames.

**Output Format:**
```markdown
<d-info.md (directory info)>
File Count: 150
Directory Located at: packages/ag-client/public/assets/icons/items/
Files:
1. icon_001.png
2. icon_002.png
...
</d-info.md (directory info)>
```

## 3. Strategy 2: Large Data Truncation (Planned)

**Goal:** Provide the AI with the *structure* (schema) of large data files without burdening it with the *volume* of the data.

**Mechanism (Future Implementation):**
*   **Detection:** Identify large `.ts` or `.json` files that primarily contain arrays of objects or large dictionaries.
*   **Truncation:** Generate a temporary `.local.ts` version of the file.
*   **Logic:**
    *   Keep the file header (imports, variable declarations).
    *   Keep the first entry of the array/object (to show the schema/structure).
    *   Insert a comment `// ... [X items truncated] ...`.
    *   Keep the last entry (to show the closing syntax).
*   **Context:** The system will prefer the `.local.ts` version for the context window, while the original file remains untouched on disk.

## 4. Benefits

*   **Token Efficiency:** Drastically reduces the overhead of asset-heavy projects.
*   **Context Clarity:** Reduces noise, allowing the AI to focus on code logic rather than file lists.
*   **Performance:** Faster flattening and prompt generation.