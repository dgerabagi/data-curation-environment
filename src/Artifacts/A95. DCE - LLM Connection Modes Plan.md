# Artifact A95: DCE - LLM Connection Modes Plan
# Date Created: C36
# Author: AI Model & Curator

- **Key/Value for A0:**
- **Description:** Outlines the plan for a multi-modal settings UI to allow users to switch between manual copy/paste, a pre-configured demo mode, and user-provided API URLs or Keys.
- **Tags:** feature plan, settings, ui, ux, llm, configuration, api

## 1. Overview & Goal

To maximize the utility and accessibility of the DCE extension, users need a flexible way to connect to different LLM backends. This plan details the implementation of a multi-modal settings UI that allows users to seamlessly switch between different connection methods, from a simple manual workflow to advanced, automated API integrations.

This plan refines and supersedes the original `A85. DCE - Model Card Management Plan.md` by focusing on a more user-friendly, mode-based approach rather than a complex card management system.

## 2. User Stories

| ID | User Story | Acceptance Criteria |
|---|---|---|
| P3-CM-01 | **Use Manual Mode** | As a new user, I want the extension to default to a "Free (Manual)" mode, so I can use the core features by copying and pasting without any setup. | - The default setting is "Free Mode". <br> - In this mode, no API calls are made, and no configuration is required. |
| P3-CM-02 | **Use Demo Mode** | As a demo user, I want to select a "Demo Mode" that automatically connects to a pre-configured local vLLM endpoint, so I can experience the full automated workflow with minimal setup. | - A "Demo Mode" option is available. <br> - When selected, it displays the pre-configured endpoint (`https://aiascent.game/api/dce/proxy`) but does not allow editing. |
| P3-CM-03 | **Use Custom URL** | As an advanced user running my own LLM, I want to select an "API (URL)" mode and provide my own OpenAI-compatible endpoint, so I can use my own models. | - An "API (URL)" option is available. <br> - When selected, it shows a text input field for the endpoint URL. <br> - The entered URL is saved and used for API calls. |
| P3-CM-04 | **Use API Key** | As a user of a cloud service, I want to select an "API (KEY)" mode, choose my provider, and securely enter my API key, so I can use services like OpenAI. | - An "API (KEY)" option is available. <br> - When selected, it shows a dropdown for the provider and a secure input for the API key. <br> - The key is stored securely using VS Code's `SecretStorage`. |

## 3. UI/UX Design (Settings Panel)

The "Settings" section of the settings panel will be redesigned as follows:

```
[ Settings ]
----------------------------------------------------------------------
LLM Connection Mode:

(â€¢) Free Mode (Manual Copy/Paste)
    | Use the extension by manually copying and pasting responses.

( ) Demo Mode (Local vLLM via aiascent.game)
    | Connects to a pre-configured, high-performance local vLLM
    | instance via the aiascent.game proxy. Requires setup from A92.
    | Endpoint: https://aiascent.game/api/dce/proxy

( ) API (URL)
    | Connect to your own self-hosted OpenAI-compatible endpoint.
    |
    | [ API Endpoint URL: http://localhost:8000/v1           ]

( ) API (KEY)
    | Connect to a cloud provider using an API key.
    |
    | Provider: [ OpenAI v ]
    | API Key:  [ sk-................................... ]

----------------------------------------------------------------------
```

-   **Radio Buttons:** A group of radio buttons controls the active mode.
-   **Conditional Rendering:** The input fields for `API (URL)` and `API (KEY)` only appear when their respective modes are selected.

## 4. Technical Implementation Plan

### 4.1. Frontend (`settings.view.tsx`)
-   **State:** A new state variable, `connectionMode`, will be added to manage which radio button is selected.
-   **UI Logic:** The component will use conditional rendering (`{connectionMode === 'URL' && ...}`) to show/hide the input fields.
-   **IPC:** New IPC channels will be created to save and load these settings.

### 4.2. Backend (`SettingsService` - New)
-   A new `SettingsService` will be created to handle the persistence of these settings.
-   **Storage:**
    -   The active `connectionMode` and the `apiUrl` will be stored in the standard VS Code workspace settings using `vscode.workspace.getConfiguration`.
    -   The `apiKey` will be stored securely using `vscode.ExtensionContext.secrets` (the `SecretStorage` API).
-   **Methods:** The service will expose methods like `getActiveMode()`, `getApiUrl()`, `getApiKey()`, `saveSettings(...)`, etc.

### 4.3. Backend (`LlmService` - New)
-   A new `LlmService` will be created to handle outgoing API calls.
-   When a request is made, it will first query the `SettingsService` to determine the active mode.
-   **Logic:**
    -   If mode is `Manual` or `Demo`, it will construct the request for the appropriate endpoint (the `aiascent.game` proxy for demo).
    -   If mode is `URL`, it will use the user-provided URL.
    -   If mode is `KEY`, it will retrieve the secret key and use the appropriate provider's base URL.
-   This service will contain all the `fetch` logic for making the actual API calls.