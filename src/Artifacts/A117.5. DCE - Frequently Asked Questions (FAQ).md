# Artifact A117.5: DCE - Frequently Asked Questions (FAQ)
# Date Created: C117
# Author: AI Model & Curator

- **Key/Value for A0:**
- **Description:** A comprehensive list of frequently asked questions about the Data Curation Environment (DCE) to serve as a knowledge base for the promotional website.
- **Tags:** documentation, faq, knowledge base, rag, onboarding, support

## 1. Purpose

This document serves as the primary knowledge base for the Data Curation Environment (DCE) VS Code extension. Its purpose is to provide clear, concise answers to common questions that new and existing users may have. This FAQ is a core component of the embedding file used for the Retrieval-Augmented Generation (RAG) feature on the `aiascent.dev` website.

## 2. Frequently Asked Questions

### I. General & Core Concepts

**Q: What is the Data Curation Environment (DCE)?**
A: The DCE is a Visual Studio Code extension designed to streamline and enhance AI-assisted development. It solves the problem of manually managing the context (code files, documents, etc.) you provide to Large Language Models (LLMs). It provides an integrated toolset for selecting context, managing multiple AI responses in parallel, and testing AI-generated code efficiently.

**Q: What core problem does DCE solve?**
A: It solves the "context problem." Effective AI assistance requires providing the right background information (the "context"). Manually collecting files, copying their content, and pasting them into a prompt is tedious, error-prone, and inefficient. DCE automates this entire process, allowing you to manage your AI context with a few clicks.

**Q: What is an "Artifact" in the DCE workflow?**
A: An "Artifact" is a formal, written document that serves as a "source of truth" for your project. These are your blueprints, plans, and requirements documents (like this FAQ). The core philosophy of DCE is "Documentation First"—planning in artifacts before writing code.

**Q: What are "Cycles"?**
A: A "Cycle" represents one complete iteration of the development loop: you define a task, generate a prompt, get responses from an AI, and integrate the chosen solution. The DCE organizes your entire project history into these numbered cycles, creating a navigable "knowledge graph" of your project's evolution.

**Q: What does "Flattening Context" mean?**
A: "Flattening" is the process where the DCE takes all the files and folders you've selected, reads their content, and combines them into a single, large text file (`flattened_repo.md`). This file, along with your cycle history and instructions, is then used to create the final `prompt.md` that you send to the AI.

### II. Phase 1: The Context Chooser (File Tree View)

**Q: How do I select files to include in my AI prompt?**
A: The DCE adds a custom view to your VS Code activity bar (with a spiral icon). This view contains a file tree of your entire workspace. Simply click the checkbox next to any file or folder to include it in your context for the AI.

**Q: What do the token and file counts next to folders mean?**
A: The DCE automatically calculates and displays statistics for your project. Next to each folder, you'll see the total number of files within it and the approximate token count of all the text-based files. This helps you manage the size of your context to fit within your AI model's context window.

**Q: What are "Selection Sets"?**
A: If you frequently use the same group of files for different tasks, you can save your current selection as a named "Selection Set." This allows you to quickly load a specific context without having to manually re-select all the files.

### III. Phase 2: The Parallel Co-Pilot Panel (PCPP)

**Q: What is the Parallel Co-Pilot Panel?**
A: The PCPP is the main interface for managing the iterative development workflow. It's a custom panel that opens in the main editor area and allows you to manage multiple AI responses side-by-side in a tabbed view.

**Q: How does the workflow in the PCPP work?**
A: The workflow is a guided, multi-step process:
1.  **Paste & Parse:** You paste the raw responses from your AI into the different response tabs and click "Parse All."
2.  **Review & Select:** The DCE parses the responses, showing you a summary, a course of action, and a list of "Associated Files" for each. You review them and "Select" the best one.
3.  **Test:** You can use the integrated "Accept Selected Files" button to write the AI's proposed code directly into your workspace for testing.
4.  **Baseline & Restore:** Using Git integration, you can create a "Baseline" (a commit) before testing and "Restore" your workspace with one click if the AI's code doesn't work.
5.  **Iterate:** Once you're satisfied, you write your notes for the next task in the "Cycle Context" field and generate the prompt for the next cycle.

**Q: What is the "Associated Files" list?**
A: When the DCE parses an AI response, it detects all the files the AI intends to create or modify. This list is displayed in the "Associated Files" section. The extension cross-references this list with your workspace, showing you with a checkmark (`✓`) or an 'x' (`✗`) whether each file exists. This helps you immediately spot AI "hallucinations" (references to non-existent files).

**Q: What is the integrated Diff Viewer?**
A: You can click an "Open Changes" button next to any file in the "Associated Files" list. This will open VS Code's native, side-by-side diff viewer, showing you the exact changes the AI is proposing compared to your current file.

### IV. Local LLM / Demo Mode

**Q: Can I use DCE with my own local Large Language Model?**
A: Yes. The DCE supports connecting to any local LLM that provides an OpenAI-compatible API endpoint (e.g., models run with vLLM, Ollama, or LM Studio). You can enter the URL of your local server in the DCE settings panel.

**Q: What is "Demo Mode"?**
A: "Demo Mode" is a pre-configured setting that connects the DCE to a specific local vLLM setup. When in this mode, the "Generate prompt.md" button is replaced with a "Generate responses" button. This automates the entire workflow: the DCE generates the prompt, sends it to the local LLM in a batch request, and streams the responses directly back into the PCPP, complete with a progress UI.

**Q: What is the Response Progress UI?**
A: When using an automated mode like "Demo Mode," a special UI appears while the AI is generating responses. It shows real-time progress bars for each parallel response, token counts, generation speed (tokens/second), and elapsed time.

### V. Troubleshooting

**Q: Why are my cycles getting wiped or my data being lost?**
A: This was a critical bug in early versions related to a "race condition" during the auto-save process. The issue has been resolved by implementing a "navigation locking" feature. The UI now displays a save status indicator (a checkmark, a caution sign, or a spinner), and navigation between cycles is disabled until all changes are safely saved to the `dce_history.json` file.

**Q: Why is the parser failing on my AI's response?**
A: The parser expects the AI's response to follow a specific format (using tags like `<summary>` and `<file path="...">`). While the parser has fallbacks for common model errors, a severely malformed response can cause it to fail. When using "Demo Mode" with a supported local model, the DCE requests a structured JSON output, which is much more reliable and less prone to parsing failures.

**Q: Why does the File Tree View (FTV) sometimes flash or refresh?**
A: The FTV automatically refreshes when it detects changes to your workspace files. In some cases, frequent auto-saves (like the extension saving its own history file) could trigger this. This has been largely mitigated by adding specific exclusions to the file watcher, but if you experience this, ensuring `.vscode/` is in your `.gitignore` file can help.