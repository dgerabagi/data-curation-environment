# Artifact A34: DCE - Phase 2 - Parallel Co-Pilot Panel - Vision & Requirements
# Date Created: C69
# Author: AI Model
# Updated on: C71 (Incorporate feedback on terminology, annotation, and context management)

- **Key/Value for A0:**
- **Description:** Outlines the high-level vision and user stories for the Phase 2 multi-tabbed editor panel, designed for comparing and managing multiple AI-generated responses. Includes plans for response annotation and a "Cycles Context" field.
- **Tags:** feature plan, phase 2, co-pilot, multi-tab, ui, ux, requirements, annotation

## 1. Vision & Goal

Phase 2 of the Data Curation Environment aims to solve the "single-threaded" nature of interacting with AI assistants. The current workflow for developers often involves sending the same prompt to multiple models or conversations, copying the results to separate text files, and then manually integrating them into their project to test. This is inefficient and cumbersome.

The goal of the **Parallel Co-Pilot Panel** is to create an integrated environment within VS Code specifically for managing, comparing, and testing multiple AI-generated code responses. It will function as a temporary "workbench" for AI outputs before they are committed to the source code.

## 2. Core Concepts

1.  **Multi-Tab Editor:** A new webview panel that presents a simple, multi-tabbed text editor interface.
2.  **Manual & API Ingestion:** The user can manually copy-paste AI responses into tabs. The architecture will also support direct ingestion from LLM APIs (local or remote) via a configured API key/URL.
3.  **Live Testing via "Swap":** The core innovation is a "swap" feature. The user can, with a single click, exchange the content of a tab with its corresponding source file in the workspace. This allows for immediate testing of the AI-generated code.
4.  **Accepting a Response:** A clear, explicit action to "Accept Response" will permanently overwrite the source file with the tab's content, distinct from the temporary "Swap" for testing.
5.  **Annotation & History:** Each response can be rated and commented on. This feedback, along with the responses themselves, is saved as part of a navigable "Cycle History," creating a rich knowledge graph of the project's evolution.

## 3. User Stories

| ID | User Story | Acceptance Criteria |
|---|---|---|
| P2-US-01 | **Manage Multiple Responses** | As a developer, I want a panel with multiple tabs (from 1 to 8) where I can place different AI-generated code responses, so I can keep them organized and view them side-by-side. | - A new view/panel is available in VS Code. <br> - The panel contains a slider or input to select the number of visible tabs (1-8). <br> - Each tab is a fully functional text editor. |
| P2-US-02 | **See Response Metadata** | As a developer, I want to see metadata for the code in each tab, such as token count and line count, so I can quickly assess its size and complexity. | - Each tab displays the token count and line count of its current content. <br> - The panel also shows the token/line count of the corresponding original file in the workspace for easy comparison. |
| P2-US-03 | **Test Response with "Swap"** | As a developer, I want to click a button to temporarily swap the code from a tab with the actual source file in my project, so I can immediately see if the new code works and compiles correctly. | - Each tab has a "Swap with Source" button. <br> - Clicking it replaces the content of the source file on disk with the content of the tab. <br> - Simultaneously, the original content of the source file is loaded into the tab. <br> - The VS Code editor and Problems view update instantly. |
| P2-US-04 | **Accept a Response** | As a developer, after testing a swapped response and confirming it is correct, I want to click an "Accept Response" button to permanently adopt the new code, so my project is updated. | - Each tab has an "Accept Response" button. <br> - Clicking it overwrites the source file with the tab's content. <br> - The original content in the tab is cleared or marked as accepted. |
| P2-US-05 | **Annotate & Rate Responses** | As a developer, I want to rate each AI response (e.g., thumbs up/down) and add comments to specific lines of code, so I can remember my evaluation and provide feedback for future cycles. | - Each tab has UI controls for rating (e.g., üëç/üëé). <br> - A feature exists to highlight a section of code in the tab and attach a text comment. <br> - These annotations are saved as part of the cycle's history. |
| P2-US-06 | **Manage Temporary Context** | As a developer, I want a separate "Cycles Context" text area where I can paste temporary information like error logs for the current cycle, so I can provide it to the AI without permanently cluttering my main prompt history. | - A dedicated, multi-line text input field labeled "Cycles Context" is present in the UI. <br> - Its content is included in the prompt for the current cycle but is not automatically carried over to the next cycle's main prompt. |
| P2-US-07 | **Use Intent Buttons** | As a developer, I want to have clear buttons for common AI intents (e.g., "Refactor Selection," "Add Documentation"), so I can perform common tasks quickly without typing slash commands. | - A configurable set of buttons is available in the UI. <br> - Clicking a button sends a pre-defined instruction to the LLM along with the relevant code context. |