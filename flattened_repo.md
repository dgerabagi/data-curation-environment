<!--
  File: flattened_repo.md
  Source Directory: c:\Projects\DCE
  Date Generated: 2025-12-04T14:13:38.578Z
  ---
  Total Files: 222
  Approx. Tokens: 375074
-->

<!-- Top 10 Text Files by Token Count -->
1. src\Artifacts\reportContent.json (51215 tokens)
2. GPT-OSS-HARMONY-REFERENCE-REPO\harmony_vllm_app.py (15557 tokens)
3. GPT-OSS-HARMONY-REFERENCE-REPO\harmony_educational_demo.html (14154 tokens)
4. GPT-OSS-HARMONY-REFERENCE-REPO\python_d20_response.json (9910 tokens)
5. src\Artifacts\A0. DCE Master Artifact List.md (9485 tokens)
6. src\client\views\parallel-copilot.view\view.scss (7573 tokens)
7. src\backend\services\prompt.service.ts (5232 tokens)
8. src\client\views\parallel-copilot.view\view.tsx (5014 tokens)
9. src\backend\services\file-operation.service.ts (4932 tokens)
10. src\client\components\tree-view\TreeView.tsx (4422 tokens)

<!-- Full File List -->
1. src\Artifacts\A0. DCE Master Artifact List.md - Lines: 548 - Chars: 37940 - Tokens: 9485
2. src\Artifacts\A1. DCE - Project Vision and Goals.md - Lines: 41 - Chars: 3995 - Tokens: 999
3. src\Artifacts\A2. DCE - Phase 1 - Context Chooser - Requirements & Design.md - Lines: 20 - Chars: 3329 - Tokens: 833
4. src\Artifacts\A3. DCE - Technical Scaffolding Plan.md - Lines: 55 - Chars: 3684 - Tokens: 921
5. src\Artifacts\A4. DCE - Analysis of The-Creator-AI Repo.md - Lines: 56 - Chars: 5722 - Tokens: 1431
6. src\Artifacts\A5. DCE - Target File Structure.md - Lines: 67 - Chars: 1977 - Tokens: 495
7. src\Artifacts\A7. DCE - Development and Testing Guide.md - Lines: 47 - Chars: 3075 - Tokens: 769
8. src\Artifacts\A8. DCE - Phase 1 - Selection Sets Feature Plan.md - Lines: 65 - Chars: 6043 - Tokens: 1511
9. src\Artifacts\A9. DCE - GitHub Repository Setup Guide.md - Lines: 88 - Chars: 4916 - Tokens: 1229
10. src\Artifacts\A10. DCE - Metadata and Statistics Display.md - Lines: 53 - Chars: 7286 - Tokens: 1822
11. src\Artifacts\A12. DCE - Logging and Debugging Guide.md - Lines: 80 - Chars: 5766 - Tokens: 1442
12. src\Artifacts\A13. DCE - Phase 1 - Right-Click Context Menu.md - Lines: 45 - Chars: 6068 - Tokens: 1517
13. src\Artifacts\A14. DCE - Ongoing Development Issues.md - Lines: 64 - Chars: 4324 - Tokens: 1081
14. src\Artifacts\A15. DCE - Phase 1 - Multi-Select & Sorting Feature Plan.md - Lines: 43 - Chars: 7263 - Tokens: 1816
15. src\Artifacts\A16. DCE - Phase 1 - UI & UX Refinements Plan.md - Lines: 24 - Chars: 4349 - Tokens: 1088
16. src\Artifacts\A17. DCE - Phase 1 - Advanced Tree View Features.md - Lines: 47 - Chars: 3888 - Tokens: 972
17. src\Artifacts\A18. DCE - Phase 1 - Active File Sync Feature Plan.md - Lines: 46 - Chars: 4548 - Tokens: 1137
18. src\Artifacts\A19. DCE - Phase 1 - Double-Click & Quick-Remove Feature Plan.md - Lines: 42 - Chars: 4603 - Tokens: 1151
19. src\Artifacts\A20. DCE - Phase 1 - Advanced UX & Automation Plan.md - Lines: 47 - Chars: 7268 - Tokens: 1817
20. src\Artifacts\A21. DCE - Phase 1 - Feature Drift Analysis vs. VS Code Explorer.md - Lines: 48 - Chars: 7385 - Tokens: 1847
21. src\Artifacts\A22. DCE - Phase 1 - Search & Filter Feature Plan.md - Lines: 58 - Chars: 3663 - Tokens: 916
22. src\Artifacts\A23. DCE - Phase 1 - Advanced Interactions (Keyboard & Drag-Drop) Plan.md - Lines: 37 - Chars: 5504 - Tokens: 1376
23. src\Artifacts\A24. DCE - Selection Paradigm Terminology.md - Lines: 57 - Chars: 3330 - Tokens: 833
24. src\Artifacts\A25. DCE - Phase 1 - Git & Problems Integration Plan.md - Lines: 48 - Chars: 5004 - Tokens: 1251
25. src\Artifacts\A26. DCE - Phase 1 - File System Traversal & Caching Strategy.md - Lines: 42 - Chars: 3593 - Tokens: 899
26. src\Artifacts\A27. DCE - Phase 1 - Undo-Redo Feature Plan.md - Lines: 55 - Chars: 5701 - Tokens: 1426
27. src\Artifacts\A28. DCE - Packaging and Distribution Guide.md - Lines: 95 - Chars: 4366 - Tokens: 1092
28. src\Artifacts\A29. DCE - Phase 1 - Binary and Image File Handling Strategy.md - Lines: 81 - Chars: 4217 - Tokens: 1055
29. src\Artifacts\A30. DCE - Phase 1 - PDF Handling and Virtualization Strategy.md - Lines: 44 - Chars: 4431 - Tokens: 1108
30. src\Artifacts\A31. DCE - Phase 2 - Multimodal Content Extraction (PDF Images).md - Lines: 44 - Chars: 4035 - Tokens: 1009
31. src\Artifacts\A32. DCE - Phase 1 - Excel and CSV Handling Strategy.md - Lines: 44 - Chars: 4295 - Tokens: 1074
32. src\Artifacts\A33. DCE - Phase 1 - Copy-Paste Feature Plan.md - Lines: 42 - Chars: 4456 - Tokens: 1114
33. src\Artifacts\A34. DCE - Phase 2 - Parallel Co-Pilot Panel - Vision & Requirements.md - Lines: 45 - Chars: 6849 - Tokens: 1713
34. src\Artifacts\A35. DCE - Phase 2 - UI Mockups and Flow.md - Lines: 54 - Chars: 3584 - Tokens: 896
35. src\Artifacts\A36. DCE - Phase 2 - Technical Implementation Plan.md - Lines: 56 - Chars: 3621 - Tokens: 906
36. src\Artifacts\A37. DCE - Phase 2 - Cycle Navigator & Knowledge Graph - Vision.md - Lines: 28 - Chars: 3242 - Tokens: 811
37. src\Artifacts\A38. DCE - Phase 2 - Cycle Navigator - UI Mockup.md - Lines: 69 - Chars: 4621 - Tokens: 1156
38. src\Artifacts\A39. DCE - Phase 2 - Cycle Navigator - Technical Plan.md - Lines: 84 - Chars: 4595 - Tokens: 1149
39. src\Artifacts\A40. DCE - Phase 2 - Parallel Co-Pilot - Target File Structure.md - Lines: 66 - Chars: 3659 - Tokens: 915
40. src\Artifacts\A40.1. DCE - Phase 2 - Competitive Analysis & Feature Ideas.md - Lines: 43 - Chars: 4784 - Tokens: 1196
41. src\Artifacts\A41. DCE - Phase 2 - API Key Management - Feature Plan.md - Lines: 47 - Chars: 4542 - Tokens: 1136
42. src\Artifacts\A41.1. DCE - Phase 2 - Advanced Features & Integrations Plan.md - Lines: 44 - Chars: 3946 - Tokens: 987
43. src\Artifacts\A41.2. DCE - Phase 2 - Feature Ideation & Competitive Analysis.md - Lines: 40 - Chars: 4566 - Tokens: 1142
44. src\Artifacts\A42. DCE - Phase 2 - Initial Scaffolding Deployment Script.md - Lines: 246 - Chars: 8264 - Tokens: 2066
45. src\Artifacts\A43. DCE - Phase 2 - Implementation Roadmap.md - Lines: 69 - Chars: 4694 - Tokens: 1174
46. src\Artifacts\A44. DCE - Phase 1 - Word Document Handling Strategy.md - Lines: 45 - Chars: 4626 - Tokens: 1157
47. src\Artifacts\A45. DCE - Phase 2 - Pop-out Co-Pilot Window - Feature Plan.md - Lines: 49 - Chars: 4156 - Tokens: 1039
48. src\Artifacts\A46. DCE - Phase 2 - Paste and Parse Response - Feature Plan.md - Lines: 38 - Chars: 3587 - Tokens: 897
49. src\Artifacts\A47. DCE - Phase 2 - Prompt Amalgamation Feature Plan.md - Lines: 42 - Chars: 3499 - Tokens: 875
50. src\Artifacts\A48. DCE - Phase 2 - Advanced Syntax Highlighting Plan.md - Lines: 49 - Chars: 4044 - Tokens: 1011
51. src\Artifacts\A49. DCE - Phase 2 - File Association & Diffing Plan.md - Lines: 42 - Chars: 4285 - Tokens: 1072
52. src\Artifacts\A50. DCE - Phase 2 - UI Component Plan (Resizable Panes & Inner Editors).md - Lines: 51 - Chars: 5128 - Tokens: 1282
53. src\Artifacts\A51. DCE - A-B-C Testing Strategy for UI Bugs.md - Lines: 81 - Chars: 5490 - Tokens: 1373
54. src\Artifacts\A52. DCE - Interaction Schema Refinement.md - Lines: 66 - Chars: 3444 - Tokens: 861
55. src\Artifacts\A52.1 DCE - Parser Logic and AI Guidance.md - Lines: 123 - Chars: 5850 - Tokens: 1463
56. src\Artifacts\A52.2 DCE - Interaction Schema Source.md - Lines: 59 - Chars: 10311 - Tokens: 2578
57. src\Artifacts\A53. DCE - Phase 2 - Token Count and Similarity Analysis.md - Lines: 43 - Chars: 3500 - Tokens: 875
58. src\Artifacts\A55. DCE - FSService Refactoring Plan.md - Lines: 77 - Chars: 4022 - Tokens: 1006
59. src\Artifacts\A57. DCE - Phase 2 - Cycle Management Plan.md - Lines: 46 - Chars: 3849 - Tokens: 963
60. src\Artifacts\A59. DCE - Phase 2 - Debugging and State Logging.md - Lines: 40 - Chars: 3737 - Tokens: 935
61. src\Artifacts\A60. DCE - Phase 2 - Cycle 0 Onboarding Experience.md - Lines: 35 - Chars: 4177 - Tokens: 1045
62. src\Artifacts\A61. DCE - Phase 2 - Cycle History Management Plan.md - Lines: 45 - Chars: 3559 - Tokens: 890
63. src\Artifacts\A65. DCE - Universal Task Checklist.md - Lines: 93 - Chars: 5650 - Tokens: 1413
64. src\Artifacts\A67. DCE - PCPP View Refactoring Plan.md - Lines: 47 - Chars: 3583 - Tokens: 896
65. src\Artifacts\A68. DCE - PCPP Context Pane UX Plan.md - Lines: 37 - Chars: 3347 - Tokens: 837
66. src\Artifacts\A69. DCE - Animated UI Workflow Guide.md - Lines: 68 - Chars: 3772 - Tokens: 943
67. src\Artifacts\A70. DCE - Git-Integrated Testing Workflow Plan.md - Lines: 61 - Chars: 6827 - Tokens: 1707
68. src\Artifacts\A71. Sample M0 Prompt.md - Lines: 76 - Chars: 10822 - Tokens: 2706
69. src\Artifacts\A72. DCE - README for Artifacts.md - Lines: 55 - Chars: 2867 - Tokens: 717
70. src\Artifacts\A73. DCE - GitService Plan.md - Lines: 44 - Chars: 2548 - Tokens: 637
71. src\Artifacts\A74. DCE - Per-Input Undo-Redo Feature Plan.md - Lines: 49 - Chars: 3624 - Tokens: 906
72. src\Artifacts\A75. DCE - Text Area Component A-B-C Test Plan.md - Lines: 50 - Chars: 4761 - Tokens: 1191
73. src\Artifacts\A76. DCE - Word Wrap Line Numbering Challenges.md - Lines: 61 - Chars: 4895 - Tokens: 1224
74. src\Artifacts\A77. DCE - Whitepaper Generation Plan.md - Lines: 74 - Chars: 8731 - Tokens: 2183
75. src\Artifacts\A78. DCE - VSIX Packaging and FTV Flashing Bug.md - Lines: 50 - Chars: 3687 - Tokens: 922
76. src\Artifacts\A79. DCE - Autosave and Navigation Locking Plan.md - Lines: 49 - Chars: 4291 - Tokens: 1073
77. src\Artifacts\A80. DCE - Settings Panel Plan.md - Lines: 39 - Chars: 3592 - Tokens: 898
78. src\Artifacts\A81. DCE - Curator Activity Plan.md - Lines: 34 - Chars: 2346 - Tokens: 587
79. src\Artifacts\A82. DCE - Advanced Exclusion Management Plan.md - Lines: 40 - Chars: 3010 - Tokens: 753
80. src\Artifacts\A85. DCE - Phase 3 - Model Cards Feature Plan.md - Lines: 53 - Chars: 4197 - Tokens: 1050
81. src\Artifacts\A86. DCE - PCPP Workflow Centralization and UI Persistence Plan.md - Lines: 74 - Chars: 5931 - Tokens: 1483
82. src\Artifacts\A87. VCPG - vLLM High-Throughput Inference Plan.md - Lines: 56 - Chars: 4251 - Tokens: 1063
83. src\Artifacts\A88. DCE - Native Diff Integration Plan.md - Lines: 43 - Chars: 4053 - Tokens: 1014
84. src\Artifacts\A89. DCE - vLLM Integration and API Proxy Plan.md - Lines: 61 - Chars: 3736 - Tokens: 934
85. src\Artifacts\A90. AI Ascent - server.ts (Reference).md - Lines: 377 - Chars: 16856 - Tokens: 4214
86. src\Artifacts\A91. AI Ascent - Caddyfile (Reference).md - Lines: 54 - Chars: 2305 - Tokens: 577
87. src\Artifacts\A92. DCE - vLLM Setup Guide.md - Lines: 100 - Chars: 4302 - Tokens: 1076
88. src\Artifacts\A93. DCE - vLLM Encryption in Transit Guide.md - Lines: 65 - Chars: 3811 - Tokens: 953
89. src\Artifacts\A94. DCE - Connecting to a Local LLM Guide.md - Lines: 42 - Chars: 2565 - Tokens: 642
90. src\Artifacts\A95. DCE - LLM Connection Modes Plan.md - Lines: 54 - Chars: 4725 - Tokens: 1182
91. src\Artifacts\A96. DCE - Harmony-Aligned Response Schema Plan.md - Lines: 33 - Chars: 2660 - Tokens: 665
92. src\Artifacts\A97. DCE - vLLM Response Progress UI Plan.md - Lines: 63 - Chars: 7578 - Tokens: 1895
93. src\Artifacts\A149. Local LLM Integration Plan.md - Lines: 99 - Chars: 6208 - Tokens: 1552
94. src\Artifacts\A189. Number Formatting Reference Guide.md - Lines: 118 - Chars: 4938 - Tokens: 1235
95. src\Artifacts\DCE_README.md - Lines: 47 - Chars: 3127 - Tokens: 782
96. src\backend\commands\commands.ts - Lines: 110 - Chars: 4507 - Tokens: 1127
97. src\backend\commands\register-commands.ts - Lines: 11 - Chars: 456 - Tokens: 114
98. src\backend\providers\ResponseContentProvider.ts - Lines: 24 - Chars: 1160 - Tokens: 290
99. src\backend\services\action.service.ts - Lines: 71 - Chars: 2444 - Tokens: 611
100. src\backend\services\content-extraction.service.ts - Lines: 148 - Chars: 7681 - Tokens: 1921
101. src\backend\services\file-operation.service.ts - Lines: 411 - Chars: 19728 - Tokens: 4932
102. src\backend\services\file-tree.service.ts - Lines: 287 - Chars: 14796 - Tokens: 3699
103. src\backend\services\flattener.service.ts - Lines: 296 - Chars: 15044 - Tokens: 3761
104. src\backend\services\git.service.ts - Lines: 130 - Chars: 6332 - Tokens: 1583
105. src\backend\services\highlighting.service.ts - Lines: 77 - Chars: 3788 - Tokens: 947
106. src\backend\services\history.service.ts - Lines: 309 - Chars: 12471 - Tokens: 3118
107. src\backend\services\llm.service.ts - Lines: 276 - Chars: 13767 - Tokens: 3442
108. src\backend\services\logger.service.ts - Lines: 38 - Chars: 1078 - Tokens: 270
109. src\backend\services\prompt.service.ts - Lines: 393 - Chars: 20928 - Tokens: 5232
110. src\backend\services\selection.service.ts - Lines: 133 - Chars: 5410 - Tokens: 1353
111. src\backend\services\services.ts - Lines: 51 - Chars: 2436 - Tokens: 609
112. src\backend\services\settings.service.ts - Lines: 44 - Chars: 1713 - Tokens: 429
113. src\backend\types\git.ts - Lines: 79 - Chars: 1944 - Tokens: 486
114. src\client\components\file-tree\FileTree.tsx - Lines: 176 - Chars: 11127 - Tokens: 2782
115. src\client\components\file-tree\FileTree.utils.ts - Lines: 134 - Chars: 4721 - Tokens: 1181
116. src\client\components\tree-view\TreeView.tsx - Lines: 395 - Chars: 17687 - Tokens: 4422
117. src\client\components\tree-view\TreeView.utils.ts - Lines: 13 - Chars: 333 - Tokens: 84
118. src\client\components\Checkbox.tsx - Lines: 25 - Chars: 814 - Tokens: 204
119. src\client\components\ContextMenu.tsx - Lines: 72 - Chars: 3353 - Tokens: 839
120. src\client\components\LocationPane.tsx - Lines: 28 - Chars: 776 - Tokens: 194
121. src\client\components\SelectedFilesView.tsx - Lines: 276 - Chars: 13123 - Tokens: 3281
122. src\client\utils\logger.ts - Lines: 19 - Chars: 744 - Tokens: 186
123. src\client\views\context-chooser.view\index.ts - Lines: 7 - Chars: 184 - Tokens: 46
124. src\client\views\context-chooser.view\on-message.ts - Lines: 78 - Chars: 5167 - Tokens: 1292
125. src\client\views\context-chooser.view\view.scss - Lines: 630 - Chars: 14830 - Tokens: 3708
126. src\client\views\context-chooser.view\view.tsx - Lines: 151 - Chars: 16129 - Tokens: 4033
127. src\client\views\parallel-copilot.view\components\CodeViewer.tsx - Lines: 33 - Chars: 1284 - Tokens: 321
128. src\client\views\parallel-copilot.view\components\ContextInputs.tsx - Lines: 70 - Chars: 3089 - Tokens: 773
129. src\client\views\parallel-copilot.view\components\CycleNavigator.tsx - Lines: 83 - Chars: 3346 - Tokens: 837
130. src\client\views\parallel-copilot.view\components\HighlightedTextarea.tsx - Lines: 89 - Chars: 3521 - Tokens: 881
131. src\client\views\parallel-copilot.view\components\ParsedView.tsx - Lines: 204 - Chars: 13097 - Tokens: 3275
132. src\client\views\parallel-copilot.view\components\ResponsePane.tsx - Lines: 72 - Chars: 2948 - Tokens: 737
133. src\client\views\parallel-copilot.view\components\ResponseTabs.tsx - Lines: 117 - Chars: 5154 - Tokens: 1289
134. src\client\views\parallel-copilot.view\components\WorkflowToolbar.tsx - Lines: 95 - Chars: 4136 - Tokens: 1034
135. src\client\views\parallel-copilot.view\index.ts - Lines: 9 - Chars: 238 - Tokens: 60
136. src\client\views\parallel-copilot.view\on-message.ts - Lines: 179 - Chars: 8997 - Tokens: 2250
137. src\client\views\parallel-copilot.view\OnboardingView.tsx - Lines: 131 - Chars: 6049 - Tokens: 1513
138. src\client\views\parallel-copilot.view\view.scss - Lines: 1326 - Chars: 30292 - Tokens: 7573
139. src\client\views\parallel-copilot.view\view.tsx - Lines: 355 - Chars: 20055 - Tokens: 5014
140. src\client\views\settings.view\index.ts - Lines: 8 - Chars: 281 - Tokens: 71
141. src\client\views\settings.view\on-message.ts - Lines: 27 - Chars: 1222 - Tokens: 306
142. src\client\views\settings.view\view.scss - Lines: 115 - Chars: 2285 - Tokens: 572
143. src\client\views\settings.view\view.tsx - Lines: 134 - Chars: 7159 - Tokens: 1790
144. src\client\views\index.ts - Lines: 39 - Chars: 1928 - Tokens: 482
145. src\common\ipc\channels.enum.ts - Lines: 116 - Chars: 6612 - Tokens: 1653
146. src\common\ipc\channels.type.ts - Lines: 130 - Chars: 9922 - Tokens: 2481
147. src\common\ipc\client-ipc.ts - Lines: 44 - Chars: 1588 - Tokens: 397
148. src\common\ipc\get-vscode-api.ts - Lines: 12 - Chars: 239 - Tokens: 60
149. src\common\ipc\server-ipc.ts - Lines: 42 - Chars: 1562 - Tokens: 391
150. src\common\types\file-node.ts - Lines: 16 - Chars: 487 - Tokens: 122
151. src\common\types\pcpp.types.ts - Lines: 57 - Chars: 1582 - Tokens: 396
152. src\common\types\vscode-webview.d.ts - Lines: 15 - Chars: 435 - Tokens: 109
153. src\common\utils\formatting.ts - Lines: 141 - Chars: 4606 - Tokens: 1152
154. src\common\utils\similarity.ts - Lines: 36 - Chars: 1188 - Tokens: 297
155. src\common\utils\view-html.ts - Lines: 37 - Chars: 1314 - Tokens: 329
156. src\common\view-types.ts - Lines: 8 - Chars: 175 - Tokens: 44
157. src\extension.ts - Lines: 174 - Chars: 7202 - Tokens: 1801
158. src\Artifacts\A52.3 DCE - Harmony Interaction Schema Source.md - Lines: 74 - Chars: 3856 - Tokens: 964
159. src\Artifacts\A78. DCE - Whitepaper - Process as Asset.md - Lines: 108 - Chars: 9820 - Tokens: 2455
160. src\Artifacts\A98. DCE - Harmony JSON Output Schema Plan.md - Lines: 88 - Chars: 4228 - Tokens: 1057
161. src\Artifacts\A99. DCE - Response Regeneration Workflow Plan.md - Lines: 44 - Chars: 5381 - Tokens: 1346
162. src\client\utils\response-parser.ts - Lines: 171 - Chars: 7819 - Tokens: 1955
163. src\client\views\parallel-copilot.view\components\GenerationProgressDisplay.tsx - Lines: 170 - Chars: 8339 - Tokens: 2085
164. src\Artifacts\A100. DCE - Model Card & Settings Refactor Plan.md - Lines: 46 - Chars: 5168 - Tokens: 1292
165. src\Artifacts\A11. DCE - Regression Case Studies.md - Lines: 98 - Chars: 10336 - Tokens: 2584
166. src\Artifacts\A101. DCE - Asynchronous Generation and State Persistence Plan.md - Lines: 45 - Chars: 4498 - Tokens: 1125
167. src\Artifacts\A103. DCE - Consolidated Response UI Plan.md - Lines: 65 - Chars: 4866 - Tokens: 1217
168. src\Artifacts\A105. DCE - vLLM Performance and Quantization Guide.md - Lines: 57 - Chars: 4079 - Tokens: 1020
169. src\Artifacts\A105. DCE - PCPP View Refactoring Plan for Cycle 76.md - Lines: 55 - Chars: 5342 - Tokens: 1336
170. src\Artifacts\A106. DCE - vLLM Performance and Quantization Guide.md - Lines: 45 - Chars: 4360 - Tokens: 1090
171. src\Artifacts\A66. DCE - Cycle 1 - Task Tracker.md - Lines: 25 - Chars: 1830 - Tokens: 458
172. src\client\views\parallel-copilot.view\hooks\useCycleManagement.ts - Lines: 131 - Chars: 5672 - Tokens: 1418
173. src\client\views\parallel-copilot.view\hooks\useFileManagement.ts - Lines: 101 - Chars: 4347 - Tokens: 1087
174. src\client\views\parallel-copilot.view\hooks\useGeneration.ts - Lines: 85 - Chars: 3834 - Tokens: 959
175. src\client\views\parallel-copilot.view\hooks\usePcppIpc.ts - Lines: 215 - Chars: 9851 - Tokens: 2463
176. src\client\views\parallel-copilot.view\hooks\useTabManagement.ts - Lines: 180 - Chars: 7363 - Tokens: 1841
177. src\client\views\parallel-copilot.view\hooks\useWorkflow.ts - Lines: 84 - Chars: 2898 - Tokens: 725
178. src\Artifacts\A110. DCE - Response UI State Persistence and Workflow Plan.md - Lines: 82 - Chars: 5020 - Tokens: 1255
179. src\Artifacts\A111. DCE - New Regression Case Studies.md - Lines: 108 - Chars: 11535 - Tokens: 2884
180. GPT-OSS-HARMONY-REFERENCE-REPO\builtin_tool_instructions.py - Lines: 122 - Chars: 3044 - Tokens: 761
181. GPT-OSS-HARMONY-REFERENCE-REPO\custom_python_instruction.py - Lines: 59 - Chars: 1605 - Tokens: 402
182. GPT-OSS-HARMONY-REFERENCE-REPO\harmony_educational_demo.html - Lines: 1323 - Chars: 56615 - Tokens: 14154
183. GPT-OSS-HARMONY-REFERENCE-REPO\harmony_vllm_app.py - Lines: 1396 - Chars: 62225 - Tokens: 15557
184. GPT-OSS-HARMONY-REFERENCE-REPO\official_python_instruction.py - Lines: 10 - Chars: 742 - Tokens: 186
185. GPT-OSS-HARMONY-REFERENCE-REPO\python_d20_response.json - Lines: 1989 - Chars: 39640 - Tokens: 9910
186. GPT-OSS-HARMONY-REFERENCE-REPO\python_function_wrapper.py - Lines: 103 - Chars: 3444 - Tokens: 861
187. GPT-OSS-HARMONY-REFERENCE-REPO\python_tool_wrapper.py - Lines: 164 - Chars: 6624 - Tokens: 1656
188. GPT-OSS-HARMONY-REFERENCE-REPO\README.md - Lines: 157 - Chars: 3863 - Tokens: 966
189. src\Artifacts\A112. DCE - Per-Cycle Connection Mode Plan.md - Lines: 38 - Chars: 3424 - Tokens: 856
190. src\Artifacts\A50. DCE - UI Component Plan (Resizable Panes & Inner Editors).md - Lines: 50 - Chars: 5005 - Tokens: 1252
191. src\Artifacts\reportContent.json - Lines: 1550 - Chars: 204858 - Tokens: 51215
192. src\Artifacts\A113. AI Ascent Dev - Universal Task Checklist.md - Lines: 74 - Chars: 3960 - Tokens: 990
193. src\Artifacts\A114. AI Ascent - Dual Domain Hosting Guide.md - Lines: 89 - Chars: 4264 - Tokens: 1066
194. src\Artifacts\A115. DCE - Porting Guide for aiascent.dev.md - Lines: 41 - Chars: 2972 - Tokens: 743
195. src\Artifacts\aiascent-dev-A0-Master-Artifact-List.md - Lines: 39 - Chars: 2213 - Tokens: 554
196. src\Artifacts\aiascent-dev-A1-Project-Vision-and-Goals.md - Lines: 42 - Chars: 2806 - Tokens: 702
197. src\Artifacts\aiascent-dev-A2-Phase1-Requirements.md - Lines: 32 - Chars: 2690 - Tokens: 673
198. src\Artifacts\aiascent-dev-A3-Technical-Scaffolding-Plan.md - Lines: 62 - Chars: 2734 - Tokens: 684
199. src\Artifacts\aiascent-dev-A7-Development-and-Testing-Guide.md - Lines: 48 - Chars: 1658 - Tokens: 415
200. src\Artifacts\aiascent-dev-A9-GitHub-Repository-Setup-Guide.md - Lines: 68 - Chars: 2465 - Tokens: 617
201. src\Artifacts\A117. DCE - FAQ for aiascent.dev Knowledge Base.md - Lines: 164 - Chars: 12446 - Tokens: 3112
202. webpack.config.js - Lines: 113 - Chars: 3039 - Tokens: 760
203. tsconfig.json - Lines: 27 - Chars: 632 - Tokens: 158
204. README.md - Lines: 28 - Chars: 2456 - Tokens: 614
205. package.json - Lines: 174 - Chars: 5715 - Tokens: 1429
206. LICENSE - Lines: 21 - Chars: 1092 - Tokens: 273
207. CHANGELOG.md - Lines: 49 - Chars: 3665 - Tokens: 917
208. src\Artifacts\A118. DCE - Database Integration Plan.md - Lines: 98 - Chars: 5862 - Tokens: 1466
209. src\backend\services\database.service.ts - Lines: 332 - Chars: 16325 - Tokens: 4082
210. src\Artifacts\A119. DCE - Universal Task Checklist for Cycle 122+.md - Lines: 39 - Chars: 2026 - Tokens: 507
211. src\Artifacts\A120. DCE - Database Maintenance Guide.md - Lines: 67 - Chars: 3388 - Tokens: 847
212. src\Artifacts\A121. DCE - Master Artifact List Automation Plan.md - Lines: 56 - Chars: 2821 - Tokens: 706
213. external_context\personal-project\altered-galaxy\scripts\fix-shared-imports.js - Lines: 65 - Chars: 2128 - Tokens: 532
214. external_context\personal-project\altered-galaxy\scripts\generate-d-info.js - Lines: 96 - Chars: 3496 - Tokens: 874
215. external_context\personal-project\altered-galaxy\scripts\migrate-items.js - Lines: 56 - Chars: 2216 - Tokens: 554
216. external_context\personal-project\altered-galaxy\scripts\README.md - Lines: 37 - Chars: 2012 - Tokens: 503
217. external_context\personal-project\altered-galaxy\scripts\rename-files.js - Lines: 61 - Chars: 1987 - Tokens: 497
218. external_context\personal-project\altered-galaxy\scripts\requirements.txt - Lines: 2 - Chars: 23 - Tokens: 6
219. external_context\personal-project\altered-galaxy\scripts\scrape_wiki.py - Lines: 155 - Chars: 7716 - Tokens: 1929
220. external_context\personal-project\altered-galaxy\scripts\simulate-movement.js - Lines: 161 - Chars: 5945 - Tokens: 1487
221. external_context\personal-project\altered-galaxy\scripts\truncate-data-files.js - Lines: 112 - Chars: 4084 - Tokens: 1021
222. src\Artifacts\A122. DCE - Directory Summarization & Large Data Strategy.md - Lines: 57 - Chars: 3129 - Tokens: 783

<file path="src/Artifacts/A0. DCE Master Artifact List.md">
# Artifact A0: DCE Master Artifact List
# Date Created: C1
# Author: AI Model & Curator
# Updated on: C127 (Add A122)

## 1. Purpose

# This file serves as the definitive, parseable list of all documentation artifacts for the "Data Curation Environment" (DCE) VS Code Extension project.

## 2. Formatting Rules for Parsing

# *   Lines beginning with `#` are comments and are ignored.
# *   `##` denotes a major category header and is ignored.
# *   `###` denotes an artifact entry. The text following it is the artifact's full name and ID.
# *   Lines beginning with `- **Description:**` provide context for the project.
# *   Lines beginning with `- **Tags:**` provide keywords for Inference.

## 3. Artifacts List

## I. Project Planning & Design

### A1. DCE - Project Vision and Goals
- **Description:** High-level overview of the DCE VS Code extension, its purpose, and the three-phase development plan.
- **Tags:** project vision, goals, scope, phase 1, phase 2, phase 3, vs code extension

### A2. DCE - Phase 1 - Context Chooser - Requirements & Design
- **Description:** Detailed functional and technical requirements for Phase 1, focusing on the file tree with checkboxes and the flattening functionality.
- **Tags:** requirements, design, phase 1, context chooser, tree view, checkbox, flatten, vs code api

### A3. DCE - Technical Scaffolding Plan
- **Description:** Outlines the proposed file structure, technologies, and key VS Code API components for the extension, based on the `The-Creator-AI-main` reference repo.
- **Tags:** technical plan, scaffolding, file structure, typescript, vs code extension, api

### A4. DCE - Analysis of The-Creator-AI Repo
- **Description:** Provides a detailed analysis of the `The-Creator-AI-main` reference repository, its architecture, and its mapping to the Data Curation Environment project goals.
- **Tags:** analysis, repository, architecture, vscode-extension, project-planning

### A5. DCE - Target File Structure
- **Description:** A text-based representation of the target file structure for the DCE extension, outlining the layout of directories and key files.
- **Tags:** file structure, architecture, project layout, scaffolding

### A6. DCE - Initial Scaffolding Deployment Script (DEPRECATED)
- **Description:** (Deprecated) Contains a Node.js script that creates the initial directory structure. This is obsolete as the AI now generates files directly.
- **Tags:** deployment, script, scaffolding, bootstrap, nodejs, automation, deprecated

### A7. DCE - Development and Testing Guide
- **Description:** A step-by-step guide explaining how to run, debug, and test the DCE extension within VS Code using the Extension Development Host.
- **Tags:** development, testing, debugging, workflow, vs code extension, f5

### A8. DCE - Phase 1 - Selection Sets Feature Plan
- **Description:** A plan outlining the user stories, UI/UX, and technical implementation for saving, loading, and persisting different sets of selected files (selection profiles).
- **Tags:** feature plan, selection sets, profiles, context management, persistence, phase 1

### A9. DCE - GitHub Repository Setup Guide
- **Description:** A step-by-step guide with the necessary git commands to initialize the project as a local repository and push it to a new remote repository on GitHub.
- **Tags:** git, github, version control, setup, repository

### A10. DCE - Metadata and Statistics Display
- **Description:** Outlines the requirements and design for displaying live metadata (total selected files, total tokens) and for showing aggregate statistics (token and file counts) for folders in the file tree.
- **Tags:** feature plan, metadata, statistics, token count, ui, ux

### A11. DCE - Regression Case Studies
- **Description:** Documents recurring bugs, their root causes, and codified solutions to prevent future regressions during development.
- **Tags:** bugs, regression, troubleshooting, development, best practices

### A12. DCE - Logging and Debugging Guide
- **Description:** Explains how to access and use the integrated logging solution for debugging the extension's backend and frontend components.
- **Tags:** logging, debugging, troubleshooting, development, output channel

### A13. DCE - Phase 1 - Right-Click Context Menu
- **Description:** A plan for implementing standard file explorer context menu actions (e.g., Rename, Delete, Copy Path) in the custom file tree.
- **Tags:** feature plan, context menu, right-click, file operations, ux, phase 1

### A14. DCE - Ongoing Development Issues
- **Description:** A tracking document for recurring or persistent issues that need to be monitored across development cycles until they are confirmed as resolved.
- **Tags:** bugs, tracking, issues, logging, node_modules, performance

### A15. DCE - Phase 1 - Multi-Select & Sorting Feature Plan
- **Description:** Details the requirements for multi-selection (click, Ctrl, Shift) in both the main file tree and the "Selected Items" panel, and multi-level column sorting.
- **Tags:** feature plan, multi-select, sorting, list view, ux, phase 1

### A16. DCE - Phase 1 - UI & UX Refinements Plan
- **Description:** Covers visual and usability improvements like fixing panel layouts, resolving overflow bugs, adding loading indicators, and improving scrollbar visibility.
- **Tags:** feature plan, ui, ux, layout, bug fix, loading indicator, phase 1

### A17. DCE - Phase 1 - Advanced Tree View Features
- **Description:** Outlines the plan for advanced tree view interactions, specifically the implementation of scrollable, self-contained views for large, expanded folders.
- **Tags:** feature plan, tree view, ux, scrollable, phase 1

### A18. DCE - Phase 1 - Active File Sync Feature Plan
- **Description:** Details the requirements and implementation for automatically revealing and highlighting the active editor's file in the custom Data Curation file tree.
- **Tags:** feature plan, active file, sync, reveal, tree view, ux, phase 1

### A19. DCE - Phase 1 - File Interaction Plan (Click & Remove)
- **Description:** Details the requirements for opening files by single-clicking them and quickly removing single files from the selection list via a mouse-over action.
- **Tags:** feature plan, single-click, open file, quick remove, ux, phase 1

### A20. DCE - Phase 1 - Advanced UX & Automation Plan
- **Description:** Details plans for several UX enhancements, including auto-revealing the flattened file, showing selected counts in folder stats, and providing an option to auto-add new files to the selection.
- **Tags:** feature plan, ux, automation, reveal, statistics, auto-add, phase 1

### A21. DCE - Phase 1 - Feature Drift Analysis vs. VS Code Explorer
- **Description:** A comparative analysis documenting the functional and behavioral differences between the DCE custom file view and the native VS Code Explorer to guide future development and feature parity.
- **Tags:** feature plan, analysis, drift, ux, vs code explorer, parity

### A22. DCE - Phase 1 - Search & Filter Feature Plan
- **Description:** Outlines the requirements and implementation for a search bar to filter the main file tree view by file or folder name.
- **Tags:** feature plan, search, filter, tree view, ux, phase 1

### A23. DCE - Phase 1 - Advanced Interactions (Keyboard & Drag-Drop) Plan
- **Description:** Details the requirements for implementing full keyboard navigation and drag-and-drop file/folder operations within the main file tree.
- **Tags:** feature plan, keyboard navigation, drag and drop, file operations, accessibility, ux, phase 1

### A24. DCE - Selection Paradigm Terminology
- **Description:** A document to clarify the terminology used within the project to distinguish between different types of user selections (e.g., "checking" for flattening vs. "selecting" for actions).
- **Tags:** documentation, terminology, selection, checking, design

### A25. DCE - Phase 1 - Git & Problems Integration Plan
- **Description:** Outlines the user stories and technical approach for integrating Git status indicators and VS Code Problem Diagnostics into the custom file tree.
- **Tags:** feature plan, git, problems, diagnostics, ux, phase 1

### A26. DCE - Phase 1 - File System Traversal & Caching Strategy
- **Description:** Documents the root cause of the folder visibility bug and outlines the new strategy of using recursive directory traversal instead of `findFiles` to build a complete and accurate file system map.
- **Tags:** bug fix, file system, traversal, refresh, cache, architecture

### A27. DCE - Phase 1 - Undo-Redo Feature Plan
- **Description:** Details the requirements for implementing an undo/redo stack for file system operations (move, delete) performed within the DCE view, to achieve parity with the native explorer's Ctrl+Z functionality.
- **Tags:** feature plan, undo, redo, ctrl+z, file operations, ux, phase 1

### A28. DCE - Packaging and Distribution Guide
- **Description:** Provides a step-by-step guide on how to package the extension into a `.vsix` file for beta testing and distribution.
- **Tags:** packaging, distribution, vsix, vsce, deployment

### A29. DCE - Phase 1 - Binary and Image File Handling Strategy
- **Description:** Defines the strategy for handling binary files; they can be checked, but only their metadata (path, size) is included in the flattened output, not their content.
- **Tags:** feature plan, binary, image, metadata, flatten, phase 1

### A30. DCE - Phase 1 - PDF Handling and Virtualization Strategy
- **Description:** Defines the strategy for handling PDF files. Text is extracted on-demand and cached in memory for flattening, creating a "virtual" markdown file without modifying the user's workspace.
- **Tags:** feature plan, pdf, text extraction, virtualization, cache, phase 1

### A31. DCE - Phase 2 - Multimodal Content Extraction (PDF Images)
- **Description:** A plan for a future feature to extract images from PDF files and use a multimodal LLM to generate rich, textual descriptions for inclusion in the context.
- **Tags:** feature plan, multimodal, image to text, pdf, llm, phase 2

### A32. DCE - Phase 1 - Excel and CSV Handling Strategy
- **Description:** Defines the strategy for handling tabular data files (.xlsx, .xls, .csv) by converting them to Markdown tables on-demand and caching them in memory for flattening.
- **Tags:** feature plan, excel, csv, text extraction, virtualization, cache, phase 1

### A33. DCE - Phase 1 - Copy-Paste Feature Plan
- **Description:** Details the requirements and implementation for copying and pasting files and folders within the DCE file tree using standard keyboard shortcuts (Ctrl+C, Ctrl+V).
- **Tags:** feature plan, copy, paste, file operations, keyboard shortcuts, ux, phase 1

### A34. DCE - Phase 2 - Parallel Co-Pilot Panel - Vision & Requirements
- **Description:** Outlines the high-level vision and user stories for the Phase 2 multi-tabbed editor panel, designed for comparing and managing multiple AI-generated responses.
- **Tags:** feature plan, phase 2, co-pilot, multi-tab, ui, ux, requirements

### A35. DCE - Phase 2 - UI Mockups and Flow
- **Description:** Provides a detailed textual description and flow diagram for the user interface of the Parallel Co-Pilot Panel, including tab management and the "swap" interaction.
- **Tags:** feature plan, phase 2, ui, ux, mockup, workflow

### A36. DCE - Phase 2 - Technical Implementation Plan
- **Description:** Details the technical approach for building the Parallel Co-Pilot Panel, including the new webview provider, state management, IPC channels, and backend logic for file content swapping.
- **Tags:** feature plan, phase 2, technical plan, architecture, webview, ipc

### A37. DCE - Phase 2 - Cycle Navigator & Knowledge Graph - Vision
- **Description:** Outlines the vision for a cycle-based navigation system to browse the history of AI-generated responses and project states, creating a navigable knowledge graph.
- **Tags:** feature plan, phase 2, knowledge graph, history, cycle navigator, ui, ux

### A38. DCE - Phase 2 - Cycle Navigator - UI Mockup
- **Description:** Provides a textual mockup and interaction flow for the Cycle Navigator UI, including the cycle counter and navigation controls within the Parallel Co-Pilot Panel.
- **Tags:** feature plan, phase 2, ui, ux, mockup, workflow, cycle navigator

### A39. DCE - Phase 2 - Cycle Navigator - Technical Plan
- **Description:** Details the technical approach for implementing the Cycle Navigator, including data structures for storing cycle-specific responses and the state management for historical navigation.
- **Tags:** feature plan, phase 2, technical plan, architecture, state management, data model

### A40. DCE - Phase 2 - Parallel Co-Pilot - Target File Structure
- **Description:** A text-based representation of the target file structure for the new Phase 2 Parallel Co-Pilot panel, outlining the layout of new directories and key files.
- **Tags:** file structure, architecture, project layout, scaffolding, phase 2

### A40.1. DCE - Phase 2 - Competitive Analysis & Feature Ideas
- **Description:** An analysis of existing tools and extensions for managing multiple AI responses, with a list of potential features to incorporate into the Parallel Co-Pilot panel.
- **Tags:** feature plan, phase 2, research, competitive analysis, co-pilot

### A41. DCE - Phase 2 - API Key Management - Feature Plan
- **Description:** Outlines the user stories and technical plan for a settings UI where users can securely input and manage their API keys for various LLM services.
- **Tags:** feature plan, phase 2, settings, api key, configuration, security

### A41.1. DCE - Phase 2 - Advanced Features & Integrations Plan
- **Description:** Explores future enhancements for the Parallel Co-Pilot, such as applying AI responses as diff patches and integrating with Git for direct commits.
- **Tags:** feature plan, phase 2, ideation, diff, patch, git, workflow

### A41.2. DCE - Phase 2 - Feature Ideation & Competitive Analysis
- **Description:** An analysis of similar AI coding assistant tools (e.g., Cursor.sh, Copilot Chat) and a brainstorm of potential advanced features for the Parallel Co-Pilot panel.
- **Tags:** feature plan, phase 2, research, competitive analysis, ideation, roadmap

### A42. DCE - Phase 2 - Initial Scaffolding Deployment Script
- **Description:** Contains a Node.js script that, when executed, creates the file and directory structure for the Phase 2 Parallel Co-Pilot panel.
- **Tags:** deployment, script, scaffolding, bootstrap, nodejs, automation, phase 2

### A43. DCE - Phase 2 - Implementation Roadmap
- **Description:** Provides a step-by-step implementation plan for building the Phase 2 features, including the Parallel Co-Pilot panel and the integrated Diff Tool.
- **Tags:** feature plan, phase 2, roadmap, project plan, diff tool

### A44. DCE - Phase 1 - Word Document Handling Strategy
- **Description:** Defines the strategy for handling Word document files (.docx) by converting them to text on-demand and caching them in memory for flattening.
- **Tags:** feature plan, docx, text extraction, virtualization, cache, phase 1

### A45. DCE - Phase 2 - Pop-out Co-Pilot Window - Feature Plan
- **Description:** Outlines the technical strategy to allow the Parallel Co-Pilot panel to be "popped out" into a separate window by re-implementing it as a main editor WebviewPanel.
- **Tags:** feature plan, phase 2, pop-out, window, webview, ux

### A46. DCE - Phase 2 - Paste and Parse Response - Feature Plan
- **Description:** Details the plan for allowing users to paste a full AI response into a tab, which the extension will then parse to identify file paths referenced within XML tags.
- **Tags:** feature plan, phase 2, paste, parse, workflow, automation

### A48. DCE - Phase 2 - Advanced Syntax Highlighting Plan
- **Description:** Outlines the strategy to replace the plain textarea in response tabs with a proper code editor component to provide rich syntax highlighting for Markdown and embedded code.
- **Tags:** feature plan, phase 2, ui, ux, syntax highlighting, monaco, codemirror

### A49. DCE - Phase 2 - File Association & Diffing Plan
- **Description:** Plans the UI and backend logic to visually link file blocks in an AI response to workspace files and sets the stage for an integrated diff tool.
- **Tags:** feature plan, phase 2, ui, ux, diff, file association

### A50. DCE - Phase 2 - UI Component Plan (Resizable Panes & Inner Editors)
- **Description:** Documents the plan for advanced UI components like resizable panes and nested, scrollable editors within the Parallel Co-Pilot panel.
- **Tags:** feature plan, phase 2, ui, ux, resizable, scrollable, editor

### A51. DCE - A-B-C Testing Strategy for UI Bugs
- **Description:** Outlines a development pattern for creating parallel, isolated test components to diagnose and resolve persistent UI bugs, such as event handling or rendering issues.
- **Tags:** process, debugging, troubleshooting, ui, ux, react

### A52. DCE - Interaction Schema Refinement
- **Description:** Proposes a set of refined rules for the AI's output format to improve the reliability and consistency of automated parsing within the Parallel Co-Pilot Panel.
- **Tags:** documentation, process, parsing, interaction schema, roadmap

### A52.1 DCE - Parser Logic and AI Guidance
- **Description:** Provides the literal source code for the response parser and explicit instructions to the AI on how to format its output to ensure successful parsing.
- **Tags:** documentation, process, parsing, metainterpretability, source of truth

### A52.2 DCE - Interaction Schema Source
- **Description:** The canonical source text for the M3. Interaction Schema, which is injected into all generated prompts.
- **Tags:** documentation, process, interaction schema, source of truth

### A52.3 DCE - Harmony Interaction Schema Source
- **Description:** The canonical source text for the M3. Interaction Schema, adapted for use with Harmony-based models like GPT-OSS. This version is injected into prompts when "Demo Mode" is active.
- **Tags:** documentation, process, interaction schema, source of truth, harmony, gpt-oss

### A53. DCE - Phase 2 - Token Count and Similarity Analysis
- **Description:** Details the plan to implement token counting for raw and parsed responses, and to calculate a similarity score between AI-generated files and their workspace originals.
- **Tags:** feature plan, phase 2, token count, similarity, metrics, ui, ux

### A54. starry-night Readme
- **Description:** A copy of the readme.md file for the `@wooorm/starry-night` syntax highlighting library, providing a reference for available languages and API usage.
- **Tags:** documentation, library, syntax highlighting, starry-night

### A55. DCE - FSService Refactoring Plan
- **Description:** Outlines a strategic plan to refactor the monolithic `FSService` into smaller, more focused services to improve modularity, maintainability, and reduce token count.
- **Tags:** refactor, architecture, technical debt, services

### A56. DCE - Phase 2 - Advanced Diff Viewer Plan
- **Description:** Details the plan to enhance the integrated diff viewer with background coloring for changes and WinMerge-like navigation controls to jump between differences.
- **Tags:** feature plan, phase 2, ui, ux, diff, navigation, side-by-side

### A57. DCE - Phase 2 - Cycle Management Plan
- **Description:** Details the plan for adding critical cycle management features to the Parallel Co-Pilot panel, including deleting the current cycle and resetting the entire history.
- **Tags:** feature plan, phase 2, ui, ux, history, cycle management

### A59. DCE - Phase 2 - Debugging and State Logging
- **Description:** Documents the plan for a "Log State" button that outputs critical state information (cycle history, current inputs) to the debug channel to accelerate troubleshooting.
- **Tags:** feature plan, phase 2, ui, ux, debugging, logging, state management

### A60. DCE - Phase 2 - Cycle 0 Onboarding Experience
- **Description:** Documents the plan for a special "Cycle 0" mode to guide new users in setting up their project by generating an initial set of planning documents.
- **Tags:** feature plan, phase 2, onboarding, first-run, project setup

### A61. DCE - Phase 2 - Cycle History Management Plan
- **Description:** Outlines the plan to allow users to save and load their entire cycle history (`dce_history.json`), enabling them to manage multiple development threads or back up their work.
- **Tags:** feature plan, phase 2, history, import, export, cycle management

### A65. DCE - Universal Task Checklist
- **Description:** A universal checklist for organizing development tasks by file, focusing on complexity in terms of token count and estimated cycles for completion.
- **Tags:** process, checklist, task management, planning, workflow

### A67. DCE - PCPP View Refactoring Plan
- **Description:** A plan to refactor the large `parallel-copilot.view.tsx` into smaller, more manageable components to improve maintainability.
- **Tags:** refactor, architecture, technical debt, pcpp

### A68. DCE - PCPP Context Pane UX Plan
- **Description:** A plan to enhance the UX of the cycle context and ephemeral context text areas with features like token counts and line numbers.
- **Tags:** feature plan, ui, ux, pcpp, context

### A69. DCE - Animated UI Workflow Guide
- **Description:** A plan for a guided user workflow that uses animated UI highlighting to indicate the next logical step in the process.
- **Tags:** feature plan, ui, ux, workflow, animation, guidance

### A70. DCE - Git-Integrated Testing Workflow Plan
- **Description:** Outlines the plan for `Baseline (Commit)` and `Restore Baseline` buttons to streamline the testing of AI-generated code by leveraging Git.
- **Tags:** feature plan, workflow, git, testing, automation

### A71. Sample M0 Prompt.md
- **Description:** An example of a fully-formed `prompt.md` file generated by the Cycle 0 onboarding experience.
- **Tags:** example, cycle 0, onboarding, prompt

### A72. DCE - README for Artifacts
- **Description:** The content for the `README.md` file that is automatically created in a new project's `src/Artifacts` directory, explaining the purpose of the extension and the artifact-driven workflow.
- **Tags:** documentation, onboarding, readme, source of truth

### A73. DCE - GitService Plan
- **Description:** A plan for a dedicated backend service to encapsulate all interactions with the Git command line for features like baselining and restoring.
- **Tags:** plan, architecture, backend, git, service

### A74. DCE - Per-Input Undo-Redo Feature Plan
- **Description:** A plan to implement a separate undo/redo history for each major text input in the PCPP to provide a more intuitive editing experience.
- **Tags:** feature plan, ui, ux, undo, redo, state management

### A75. DCE - Text Area Component A-B-C Test Plan
- **Description:** A plan to create a test harness for the `NumberedTextarea` component to diagnose and fix persistent scrolling and alignment bugs.
- **Tags:** plan, process, debugging, troubleshooting, ui, ux, react

### A76. DCE - Word Wrap Line Numbering Challenges
- **Description:** Explains the technical complexity of implementing line numbers that accurately reflect visual word wrapping in a textarea component.
- **Tags:** documentation, technical debt, ui, ux, word wrap, line numbers

### A77. DCE - Monaco Editor Replacement Plan
- **Description:** Documents the failure of the Monaco Editor integration and the new plan to switch to a lighter-weight, non-worker-based editor component.
- **Tags:** plan, refactor, ui, ux, monaco, codemirror, technical debt

### A78. DCE - VSIX Packaging and FTV Flashing Bug
- **Description:** Documents the root cause and solution for the bloated VSIX package and the persistent File Tree View flashing bug in the packaged extension.
- **Tags:** bug fix, packaging, vsix, vscodeignore, file watcher, git

### A79. DCE - Autosave and Navigation Locking Plan
- **Description:** Outlines the plan to fix the cycle data loss bug by implementing a UI-driven autosave status indicator and locking navigation controls while there are unsaved changes.
- **Tags:** bug fix, data integrity, race condition, autosave, ui, ux

### A80. DCE - Settings Panel Plan
- **Description:** A plan for a new settings panel, accessible via a help icon, to house changelogs, settings, and other informational content.
- **Tags:** feature plan, settings, ui, ux, changelog

### A81. DCE - Curator Activity Plan
- **Description:** A plan to introduce a new `<curator_activity>` section to the AI response format, allowing for explicit instructions to the human curator.
- **Tags:** documentation, process, interaction schema, workflow

### A82. DCE - Advanced Exclusion Management Plan
- **Description:** A plan for a feature allowing users to right-click files or folders and add them to a persistent exclusion list, preventing them from being automatically selected or flattened.
- **Tags:** feature plan, context menu, exclusion, ignore, ux

### A85. DCE - Model Card Management Plan
- **Description:** A plan for an enhanced settings panel where users can create and manage "model cards" to easily switch between different LLM providers and configurations.
- **Tags:** feature plan, settings, ui, ux, llm, configuration, model management

### A86. DCE - PCPP Workflow Centralization and UI Persistence Plan
- **Description:** A plan to centralize the main workflow buttons in the PCPP, make the animated workflow highlight persistent, and fix the broken cost calculation.
- **Tags:** feature plan, ui, ux, workflow, refactor, bug fix

### A87. VCPG - vLLM High-Throughput Inference Plan
- **Description:** A research and planning document analyzing the potential of using vLLM for high-throughput, low-latency inference for JANE, particularly for batched tool calling.
- **Tags:** guide, research, planning, ai, jane, llm, vllm, inference, performance

### A88. DCE - Native Diff Integration Plan
- **Description:** A plan to integrate VS Code's native diff viewer (`vscode.diff`) for comparing AI-generated file content against the current workspace file, leveraging a TextDocumentContentProvider for in-memory content.
- **Tags:** feature plan, ui, ux, diff, vscode api, virtual document

### A89. DCE - Phase 3 - Hosted LLM & vLLM Integration Plan
- **Description:** Outlines the architecture and roadmap for integrating the DCE extension with a remote, high-throughput vLLM backend via a secure proxy server.
- **Tags:** feature plan, phase 3, llm, vllm, inference, performance, architecture, proxy

### A90. AI Ascent - server.ts (Reference)
- **Description:** A reference copy of the `server.ts` file from the `aiascent.game` project, used as a baseline for implementing the DCE LLM proxy.
- **Tags:** reference, source code, backend, nodejs, express

### A91. AI Ascent - Caddyfile (Reference)
- **Description:** A reference copy of the `Caddyfile` from the `aiascent.game` project, used for configuring the web server proxy.
- **Tags:** reference, configuration, caddy, proxy

### A92. DCE - vLLM Setup Guide
- **Description:** A step-by-step guide for setting up the vLLM inference server with an OpenAI-compatible API endpoint for use with the DCE.
- **Tags:** guide, setup, vllm, llm, inference, performance, openai

### A93. DCE - vLLM Encryption in Transit Guide
- **Description:** Explains the standard architectural pattern of using a reverse proxy to provide HTTPS encryption for the vLLM API endpoint.
- **Tags:** guide, security, encryption, https, proxy, caddy, vllm

### A94. DCE - Connecting to a Local LLM Guide
- **Description:** A step-by-step guide on how to configure the DCE extension to use a local LLM with an OpenAI-compatible API.
- **Tags:** guide, setup, llm, vllm, model card, configuration, local

### A95. DCE - LLM Connection Modes Plan
- **Description:** Outlines the plan for a multi-modal settings UI to allow users to switch between manual copy/paste, a pre-configured demo mode, and user-provided API URLs or Keys.
- **Tags:** feature plan, settings, ui, ux, llm, configuration, api

### A96. DCE - Harmony-Aligned Response Schema Plan
- **Description:** An analysis of the `openai_harmony` library and a proposed plan for migrating the DCE's vLLM interaction schema from XML tags to a more robust, token-based structured format.
- **Tags:** plan, architecture, interaction schema, parsing, llm, vllm, harmony

### A97. DCE - vLLM Response Progress UI Plan
- **Description:** A plan and textual mockup for a UI to display the progress of incoming vLLM responses, including progress bars and a tokens/second metric.
- **Tags:** feature plan, ui, ux, vllm, progress indicator, metrics

### A98. DCE - Harmony JSON Output Schema Plan
- **Description:** A plan to migrate the vLLM interaction schema from XML-based parsing to a structured JSON object output, leveraging the `response_format` parameter in OpenAI-compatible APIs.
- **Tags:** plan, architecture, interaction schema, parsing, llm, vllm, harmony, json

### A99. DCE - Response Regeneration Workflow Plan
- **Description:** Details the user stories and technical implementation for the "Regenerate" button in the PCPP, including logic for regenerating empty tabs, all tabs, and a new per-tab refresh feature.
- **Tags:** feature plan, ui, ux, workflow, regeneration

### A100. DCE - Model Card & Settings Refactor Plan
- **Description:** A plan to implement a user-configurable "Model Card" system in the settings panel. This includes a UI for managing different LLM configurations and a feature to query a vLLM server's `/v1/models` endpoint to auto-populate model details.
- **Tags:** feature plan, settings, ui, ux, llm, configuration, model management

### A101. DCE - Asynchronous Generation and State Persistence Plan
- **Description:** Documents the new, more robust workflow for generating responses. This involves creating a new cycle with a "generating" status first, which provides a persistent state container for the asynchronous LLM call, making the UI state recoverable on reload.
- **Tags:** plan, architecture, workflow, persistence, asynchronous, state management

### A103. DCE - Consolidated Response UI Plan
- **Description:** Details the user flow where generating responses navigates to a new cycle, and selecting any tab in that "generating" cycle displays the progress UI.
- **Tags:** feature plan, ui, ux, workflow, refactor

### A105. DCE - PCPP View Refactoring Plan for Cycle 76
- **Description:** Provides a detailed plan for refactoring the monolithic `parallel-copilot.view/view.tsx` component into smaller, more manageable sub-components to improve maintainability and reduce token count.
- **Tags:** plan, refactor, architecture, technical debt, pcpp

### A106. DCE - vLLM Performance and Quantization Guide
- **Description:** A guide explaining the performance warnings from the vLLM logs and detailing the various model quantization options available.
- **Tags:** guide, vllm, performance, quantization, llm

### A110. DCE - Response UI State Persistence and Workflow Plan
- **Description:** A plan to fix the response UI state loss by expanding the data model to include generation metrics and refactoring the UI to be driven by a per-response status.
- **Tags:** plan, bug fix, persistence, state management, ui, ux

### A111. DCE - New Regression Case Studies
- **Description:** Documents new, complex bugs and their codified solutions to prevent future regressions.
- **Tags:** bugs, regression, troubleshooting, development, best practices

### A112. DCE - Per-Cycle Connection Mode Plan
- **Description:** A plan for a dropdown in the PCPP to allow users to select a generation mode for the current cycle, overriding the global default from the settings panel.
- **Tags:** feature plan, ui, ux, llm, configuration

### A117. DCE - FAQ for aiascent.dev Knowledge Base
- **Description:** A comprehensive, consolidated Frequently Asked Questions (FAQ) document to serve as the primary knowledge base for the `aiascent.dev` website's RAG chatbot, Ascentia.
- **Tags:** documentation, faq, knowledge base, rag, user guide

### A118. DCE - Database Integration Plan
- **Description:** A plan to transition from the brittle `dce_history.json` file to a robust SQLite database for managing cycle history, solving data loss issues.
- **Tags:** plan, architecture, database, sqlite, persistence, data integrity

### A119. DCE - Universal Task Checklist for Cycle 122+
- **Description:** A structured checklist for the next phase of development, focusing on stabilizing the new SQLite database integration.
- **Tags:** checklist, planning, database, sqlite

### A120. DCE - Database Maintenance Guide
- **Description:** A guide for developers on how to maintain, migrate, and debug the SQLite database used by the DCE extension.
- **Tags:** guide, database, sqlite, maintenance, migration, debugging

### A121. DCE - Master Artifact List Automation Plan
- **Description:** A plan to automate the maintenance of the Master Artifact List (A0) by programmatically scanning artifact files for metadata tags.
- **Tags:** plan, automation, documentation, maintenance, a0

### A122. DCE - Directory Summarization & Large Data Strategy
- **Description:** A strategy to manage token bloat by summarizing large asset directories and truncating massive data files.
- **Tags:** strategy, optimization, tokens, d-info, truncation, large files

### A200. Cycle Log
- **Description:** A log of all development cycles for historical reference and context.
- **Tags:** history, log, development process, cycles

## II. Standalone Utilities & Guides

### A149. Local LLM Integration Plan
- **Description:** The technical plan for integrating a locally hosted LLM into the game via a secure backend proxy.
- **Tags:** llm, integration, plan, backend, api

### A189. Number Formatting Reference Guide
- **Description:** A standalone guide and utility script for formatting large numbers with K/M/B/T suffixes and dynamic decimal place adjustment for clean UI presentation.
- **Tags:** utility, script, formatting, numbers, ui, ux, javascript, typescript

## III. Cycle 0 Static Content Templates

### T1. Template - Master Artifact List
- **Description:** A generic template for a Master Artifact List, to be used as static context in the Cycle 0 prompt.
- **Tags:** template, cycle 0, documentation, project setup

### T2. Template - Project Vision and Goals
- **Description:** A generic template for a Project Vision and Goals document.
- **Tags:** template, cycle 0, documentation, project setup

### T3. Template - Phase 1 Requirements & Design
- **Description:** A generic template for a requirements and design document.
- **Tags:** template, cycle 0, documentation, project setup

### T4. Template - Technical Scaffolding Plan
- **Description:** A generic template for a technical scaffolding plan.
- **Tags:** template, cycle 0, documentation, project setup

### T5. Template - Target File Structure
- **Description:** A generic template for a target file structure document.
- **Tags:** template, cycle 0, documentation, project setup

### T6. Template - Initial Scaffolding Deployment Script (DEPRECATED)
- **Description:** (Deprecated) A generic template for a scaffolding deployment script. This is obsolete.
- **Tags:** template, cycle 0, documentation, project setup, deprecated

### T7. Template - Development and Testing Guide
- **Description:** A generic template for a development and testing guide.
- **Tags:** template, cycle 0, documentation, project setup

### T8. Template - Regression Case Studies
- **Description:** A generic template for a regression case studies document, promoting development best practices.
- **Tags:** template, cycle 0, documentation, project setup

### T9. Template - Logging and Debugging Guide
- **Description:** A generic template for a logging and debugging guide.
- **Tags:** template, cycle 0, documentation, project setup

### T10. Template - Feature Plan Example
- **Description:** A generic template for a feature plan, using a right-click context menu as an example.
- **Tags:** template, cycle 0, documentation, project setup

### T11. Template - Implementation Roadmap
- **Description:** A generic template for an implementation roadmap document, guiding the development process.
- **Tags:** template, cycle 0, documentation, project setup, roadmap

### T12. Template - Competitive Analysis
- **Description:** A generic template for a competitive analysis document, used for feature ideation.
- **Tags:** template, cycle 0, documentation, project setup, research

### T13. Template - Refactoring Plan
- **Description:** A generic template for a refactoring plan, guiding users to consider constraints like token count.
- **Tags:** template, cycle 0, documentation, project setup, refactor

### T14. Template - GitHub Repository Setup Guide
- **Description:** A generic template for a guide on setting up a new project with Git and GitHub.
- **Tags:** template, cycle 0, git, github, version control

### T15. Template - A-B-C Testing Strategy for UI Bugs
- **Description:** A generic template for a guide on using the A-B-C testing pattern to diagnose UI bugs.
- **Tags:** template, cycle 0, process, debugging, troubleshooting

### T16. Template - Developer Environment Setup Guide
- **Description:** A generic template for a guide on setting up a new project's development environment, including OS, tools, and installation steps.
- **Tags:** template, cycle 0, documentation, project setup, environment

### T17. Template - Universal Task Checklist
- **Description:** A generic template for a universal task checklist, designed to organize work by file and complexity.
- **Tags:** template, process, checklist, task management, planning
</file_artifact>

<file path="src/Artifacts/A1. DCE - Project Vision and Goals.md">
# Artifact A1: DCE - Project Vision and Goals
# Date Created: Cycle 1
# Author: AI Model
# Updated on: C87 (Shifted Diff Tool to Phase 2, defined Phase 3 as LLM Integration)

## 1. Project Vision

The vision of the Data Curation Environment (DCE) is to create a seamless, integrated toolset within VS Code that streamlines the workflow of interacting with large language models. The core problem this project solves is the manual, cumbersome process of selecting, packaging, and managing the context (code files, documents, etc.) required for effective AI-assisted development.

## 2. High-Level Goals & Phases

The project will be developed in three distinct phases.

**Note on Reference Repository:** The discovery of the `The-Creator-AI-main` repository in Cycle 2 has provided a significant head-start, especially for Phase 1 and 2. The project's focus shifts from building these components from the ground up to adapting and extending the powerful, existing foundation.

### Phase 1: The Context Chooser

The goal of this phase is to eliminate the manual management of a `files_list.txt`. Users should be able to intuitively select files and folders for their AI context directly within the VS Code file explorer UI.

-   **Core Functionality:** Implement a file explorer view with checkboxes for every file and folder.
-   **Action:** A "Flatten Context" button will take all checked items and generate a single `flattened_repo.md` file in the project root.
-   **Outcome:** A user can curate a complex context with simple mouse clicks, completely removing the need to edit a text file.
-   **Status:** Largely complete.

### Phase 2: The Parallel Co-Pilot Panel & Integrated Diff Tool

This phase addresses the limitation of being locked into a single conversation with an AI assistant and brings the critical "diffing" workflow directly into the extension. The goal is to enable multiple, parallel interactions and to create a navigable record of the AI-driven development process.

-   **Core Functionality (Parallel Co-Pilot):** Create a custom panel within VS Code that hosts a multi-tabbed text editor. Users can manually paste or have the extension ingest different AI-generated code responses into each tab for side-by-side comparison.
-   **Key Feature ("Swap & Test"):** A button on each tab allows the user to "swap" the content of that tab with the corresponding source file in their workspace. This provides an immediate, low-friction way to test a given AI response.
-   **Core Functionality (Integrated Diff):** The panel will include a built-in diff viewer to compare the content of any two tabs, or a tab and the source file. This eliminates the need for external tools like WinMerge.
-   **Core Functionality (Cycle Navigator):** Integrate a UI element to navigate back and forth between development cycles. Each cycle will be associated with the set of AI responses generated during that cycle.
-   **Outcome:** A user can efficiently manage, compare, and test multiple AI solutions, and also review the historical evolution of the code by navigating through past cycles and their corresponding AI suggestions, creating a powerful "knowledge graph" of the project's development.

### Phase 3: Advanced AI & Local LLM Integration

This phase focuses on deeper integration with AI services and providing support for local models.

-   **Core Functionality:** Implement direct API calls to various LLM providers (e.g., Gemini, OpenAI, Anthropic) from within the Parallel Co-Pilot panel, populating the tabs automatically. This requires building a secure API key management system.
-   **Local LLM Support:** Allow users to configure an endpoint URL for a locally hosted LLM (e.g., via LM Studio, Ollama), enabling fully offline and private AI-assisted development.
-   **Outcome:** The DCE becomes a fully-featured AI interaction environment, supporting both cloud and local models, and automating the entire prompt-to-test workflow.
</file_artifact>

<file path="src/Artifacts/A2. DCE - Phase 1 - Context Chooser - Requirements & Design.md">
# Artifact A2: DCE - Phase 1 - Context Chooser - Requirements & Design
# Date Created: Cycle 1
# Author: AI Model
# Updated on: C46 (Remove requirement for ignoring binary files, per A29)

## 1. Overview

This document outlines the requirements for Phase 1 of the Data Curation Environment (DCE) project. The primary goal of this phase is to replace the manual, error-prone process of managing context via a `files_list.txt` with an intuitive, UI-driven approach within VS Code.

**Major Update (Cycle 2):** The analysis of the `The-Creator-AI-main` repository revealed an existing, highly-functional file tree component (`src/client/components/file-tree/FileTree.tsx`) with checkbox selection. The project requirements have been updated to reflect a shift from *building* this component from scratch to *analyzing, adapting, and integrating* the existing solution.

## 2. Functional Requirements

| ID | Requirement | User Story | Acceptance Criteria | Update (Cycle 2) |
|---|---|---|---|---|
| FR-01 | **Analyze Existing File Tree** | As a developer, I want to understand the capabilities of the `FileTree.tsx` component | - Analyze the component's props and state. <br> - Document its dependencies on other frontend components and backend services (`FSService`). <br> - Determine how checkbox state is managed and communicated. | **New** |
| FR-02 | **Display File Tree in View** | As a user, I want to see a tree of all files and folders in my workspace within a dedicated VS Code view. | - The view should accurately reflect the workspace's file system structure. <br> - It should respect `.gitignore` rules to hide irrelevant files. | **Adaptation.** The `FileTree.tsx` component and `FSService` already provide this. We need to ensure it's correctly instantiated in our extension's view. |
| FR-03 | **Checkbox Selection** | As a user, I want to select and deselect files and folders for my context using checkboxes. | - Every file and folder in the tree has a checkbox. <br> - Checking a folder checks all its children. <br> - Unchecking a folder unchecks all its children. <br> - A folder shows an "indeterminate" state if only some of its children are checked. | **Adaptation.** The reference component appears to support this logic. We must verify and adapt its state management (`selectedFiles` array). |
| FR-04 | **Flatten Selected Context** | As a user, I want a single button to package all my selected files into one context file. | - A "Flatten Context" button is present in the view. <br> - Clicking it triggers a process that reads the content of all checked files. <br> - The contents are concatenated into a single `flattened_repo.md` file in the project root. | **Implementation.** The logic for this will need to be implemented, using the state from the `FileTree` component as input for our enhanced `bootstrap-flattener.js` logic. |
| FR-05 | **Handle Binary Files** | As a user, I want to be able to select binary/image files to include their metadata in the context, without including their raw content. | - All files, including binary and image files, are selectable via their checkbox. <br> - When a binary/image file is selected and flattened, only its metadata (path, size, type) is included in `flattened_repo.md`. <br> - See `A29` for the full strategy. | **Revised (C46)** |
</file_artifact>

<file path="src/Artifacts/A3. DCE - Technical Scaffolding Plan.md">
# Artifact A3: DCE - Technical Scaffolding Plan
# Date Created: Cycle 1
# Author: AI Model
# Updated on: Cycle 2 (Adopted architecture from `The-Creator-AI-main` repository)

## 1. Overview

This document outlines the technical scaffolding and file structure for the Data Curation Environment (DCE) VS Code extension.

**Major Update (Cycle 2):** The initial plan for a simple file structure has been superseded. We are officially adopting the mature and robust architecture of the `The-Creator-AI-main` reference repository as our project's blueprint. This provides a proven, scalable foundation for all three project phases.

## 2. Adopted File Structure

The project will adhere to the following directory structure, derived directly from the reference repository:

```
.
 public/                     # Static assets for webviews (icons, css)
 src/
    backend/                # Extension Host code (Node.js environment)
       commands/           # Command definitions and registration
       repositories/       # Data persistence logic (workspace state)
       services/           # Core backend services (LLM, FS, Git, etc.)
       types/              # TypeScript types for the backend
       utils/              # Utility functions for the backend
   
    client/                 # Webview code (Browser environment)
       components/         # Generic, reusable React components (FileTree, Modal)
       modules/            # Feature-specific modules (Context, Plan)
       store/              # Global state management for webviews (RxJS)
       views/              # Entry points for each webview panel
   
    common/                 # Code shared between backend and client
       constants/
       ipc/                # IPC channel definitions and managers
       types/              # Shared TypeScript types (FileNode)
       utils/              # Shared utility functions (parse-json)
   
    extension.ts            # Main entry point for the VS Code extension

 package.json                # Extension manifest, dependencies, and scripts
 tsconfig.json               # TypeScript configuration
 webpack.config.js           # Webpack configuration for bundling client/server code
 ... (config files like .eslintrc.json, .gitignore)
```

## 3. Key Architectural Concepts

-   **Separation of Concerns:** The structure strictly separates backend (Node.js) logic from frontend (React/webview) logic.
-   **Shared Code:** The `src/common/` directory is critical for sharing types and IPC definitions, ensuring type safety and consistency between the extension host and the webview.
-   **Service-Oriented Backend:** The `src/backend/services/` directory promotes modularity. Each service has a single responsibility (e.g., `FSService` for file operations, `LlmService` for AI interaction), making the system easier to maintain and test.
-   **Dependency Injection:** The `Services.ts` class acts as a simple injector, managing the instantiation and provision of backend services.
-   **Modular Frontend:** The `src/client/modules/` directory allows for building complex UIs by composing smaller, feature-focused modules.
-   **Component-Based UI:** The `src/client/components/` directory holds the fundamental building blocks of the UI, promoting reusability.
-   **Typed IPC Communication:** The use of `channels.enum.ts` and `channels.type.ts` in `src/common/ipc/` provides a strongly-typed and well-documented contract for communication between the webview and the extension host, reducing runtime errors.
</file_artifact>

<file path="src/Artifacts/A4. DCE - Analysis of The-Creator-AI Repo.md">
# Artifact A4: DCE - Analysis of The-Creator-AI Repo
# Date Created: Cycle 2
# Author: AI Model
- **Description:** Provides a detailed analysis of the `The-Creator-AI-main` reference repository, its architecture, and its mapping to the Data Curation Environment project goals.
- **Tags:** analysis, repository, architecture, vscode-extension, project-planning

## 1. Overview

The `The-Creator-AI-main` repository is a comprehensive and well-structured VS Code extension that functions as a sophisticated AI coding assistant. It utilizes a modern tech stack including TypeScript, React for webviews, and TailwindCSS for styling. Its architecture is service-oriented on the backend (extension host) and modular on the frontend (webview). The discovery of this repository provides a massive head-start for our project, as it contains pre-built solutions for many of our planned features.

## 2. Backend Architecture (Extension Host)

The backend, located primarily in `src/backend/`, follows a clean, service-oriented architecture.

-   **`extension.ts`**: The main entry point. It initializes services and registers the commands and webview providers.
-   **`services/`**: A directory containing distinct services for handling specific concerns:
    -   `LlmService.ts`: Manages interactions with multiple AI models (Gemini, OpenAI). It includes logic for API key management and prompt construction.
    -   `FSService.ts`: Handles all file system operations, including reading files, creating a file tree, and respecting `.gitignore`.
    -   `CodeService.ts`: Contains logic for applying code changes, parsing diffs, and generating code.
    -   `GitService.ts`: Provides an interface for Git operations, like committing changes.
    -   `MessageService.ts`: Orchestrates the flow of messages between the frontend and the LLM service.
    -   `PlanExImService.ts`: Manages exporting and importing of "Change Plans".
    -   `Services.ts`: A dependency injection container that initializes and provides access to all other services.
-   **`repositories/`**: Manages data persistence within the VS Code workspace state (e.g., `PersistentStoreRepository.ts`, `SettingsRepository.ts`).
-   **`commands/`**: Defines all the commands exposed by the extension in `package.json`.

## 3. Frontend Architecture (Webview)

The frontend, located in `src/client/`, is a React application bundled with Webpack.

-   **`views/`**: The application is divided into distinct views, each with its own entry point, state management, and logic (e.g., `change-plan.view`).
-   **`modules/`**: Contains reusable UI/logic modules that are composed into the main view, such as:
    -   `context.module/Context.tsx`: Renders the file explorer.
    -   `plan.module/Plan.tsx`: Handles displaying the AI-generated plan and user input.
-   **`components/`**: A collection of generic, reusable React components:
    -   `file-tree/FileTree.tsx`: A fully functional file tree component with checkbox selection, expansion state, and active file highlighting. This is directly applicable to our Phase 1 goal.
    -   `AutoResizingTextarea.tsx`, `Modal.tsx`, `ProgressSteps.tsx`: Other useful UI components.
-   **State Management**: Each view appears to have its own local store (`store/`), using RxJS `BehaviorSubject` for reactivity. This is a simple yet effective approach for managing state within a contained webview.
-   **IPC**: Communication with the backend is handled via a robust `ClientPostMessageManager` (`src/common/ipc/`) which defines clear channels for client-server interaction.

## 4. Mapping to DCE Project Goals

The reference repository provides solutions or strong foundations for all three of our project phases.

-   **Phase 1 (Context Chooser):** **Largely Complete.** The `FileTree.tsx` component in `src/client/components/file-tree/` combined with `FSService.ts` on the backend already provides the core functionality of a checkbox-based file explorer for context selection. Our work shifts from building this from scratch to adapting and integrating this existing, powerful component.

-   **Phase 2 (Parallel 'Co-pilot' Panel):** **Partially Complete.** The "Change Plan" view (`src/client/views/change-plan.view/`) is essentially a single "co-pilot" panel. It allows a user to describe a change, get an AI-generated plan, and interact with it. Our goal of *parallel* panels is not implemented, but the foundation for a single panel is incredibly strong.

-   **Phase 3 (Diff Tool):** **Not Present.** There is no integrated diff-viewing tool like WinMerge. However, the `CodeService.ts` *does* contain logic for parsing and applying diffs in a custom `<<<<<<< SEARCH` format, and the extension can trigger VS Code's native diff viewer (`git.openChange`).

## 5. Recommendations & Path Forward

1.  **Adopt the Architecture:** We should officially adopt the architecture of `The-Creator-AI-main` as the blueprint for our project. It is robust, scalable, and well-organized.
2.  **Focus on Adaptation:** Our immediate efforts for Phase 1 should be to isolate the `FileTree` component and its backend dependencies (`FSService.ts`) and ensure they can be used to generate the `flattened_repo.md` as originally specified.
3.  **De-risk Phase 2:** The "Change Plan" functionality is a perfect starting point for our parallel co-pilot. We should analyze its state management and IPC communication to understand how we might instantiate multiple, independent instances of it.
4.  **Update All Documentation:** All planning artifacts (`A1`, `A2`, `A3`) must be updated immediately to reflect this new context. Our plan has evolved from "build" to "analyze, adapt, and extend".
</file_artifact>

<file path="src/Artifacts/A5. DCE - Target File Structure.md">
# Artifact A5: DCE - Target File Structure
# Date Created: Cycle 3
# Author: AI Model

- **Description:** A text-based representation of the target file structure for the DCE extension, outlining the layout of directories and key files.
- **Tags:** file structure, architecture, project layout, scaffolding

## 1. Overview

This document provides a visual representation of the file structure that the `A6. DCE - Initial Scaffolding Deployment Script` will create. It is based on the robust and scalable architecture of the `The-Creator-AI-main` reference repository, as detailed in `A3. DCE - Technical Scaffolding Plan`.

## 2. File Tree

```
DCE/
 .gitignore
 .vscodeignore
 package.json
 tsconfig.json
 webpack.config.js
 public/
    spiral.svg
 src/
     backend/
        commands/
           commands.ts
           register-commands.ts
        repositories/
           persistent-store.repository.ts
        services/
           fs.service.ts
           services.ts
           flattener.service.ts
        types/
            storage-keys.enum.ts
    
     client/
        components/
           file-tree/
               FileTree.tsx
               FileTree.utils.ts
        views/
           context-chooser.view/
              index.ts
              on-message.ts
              view.scss
              view.tsx
           index.ts
        store/
            store.ts
            useStore.ts
    
     common/
        ipc/
           channels.enum.ts
           channels.type.ts
           client-ipc.ts
           get-vscode-api.ts
           server-ipc.ts
        types/
           file-node.ts
           vscode-webview.d.ts
        utils/
            view-html.ts
    
     extension.ts
```
</file_artifact>

<file path="src/Artifacts/A7. DCE - Development and Testing Guide.md">
# Artifact A7: DCE - Development and Testing Guide
# Date Created: Cycle 7
# Author: AI Model
# Updated on: Cycle 9 (Revised workflow to use integrated debugger configuration)

- **Description:** A step-by-step guide explaining how to run, debug, and test the DCE extension within VS Code using the Extension Development Host.
- **Tags:** development, testing, debugging, workflow, vs code extension, f5, launch.json

## 1. Purpose

This guide provides the correct and simplified procedure for running and testing the Data Curation Environment (DCE) extension locally. Following these steps is crucial to see your changes and the extension's UI in action.

## 2. The Core Concept: The Extension Development Host

You cannot see the extension's UI (like the spiral icon or the custom panel) in the same VS Code window where you are writing the code. Instead, you must launch a special, separate VS Code window called the **Extension Development Host**. This new window has your extension installed and running, allowing you to test it as a user would.

Our project now includes the necessary `.vscode/launch.json` and `.vscode/tasks.json` files to make this process seamless.

## 3. Step-by-Step Workflow

Follow these steps every time you want to test the extension:

### Step 1: Open the "Run and Debug" View

In your main project window (e.g., `C:\Projects\DCE`), navigate to the "Run and Debug" panel in the activity bar on the left. The icon looks like a play button with a bug on it.

### Step 2: Launch the Extension

At the top of the "Run and Debug" panel, you will see a dropdown menu. It should already have **"Run Extension"** selected.

Simply press the **F5** key or click the green play button next to the "Run Extension" dropdown.

This single action will now:
1.  Automatically start the `npm run watch` task in the background to compile your code.
2.  Launch the new **"[Extension Development Host]"** VS Code window.

### Step 3: Find the Extension UI

In the newly opened **Extension Development Host** window, look at the activity bar on the far left. You should now see our spiral icon. Clicking this icon will open the "Context Chooser" panel, where you'll see the file tree with checkboxes.

### Step 4: Making and Viewing Changes

1.  **Make Code Changes:** Edit the source code in your **original** project window.
2.  **Auto-Compile:** When you save a file, the `npm run watch` task (which was started automatically) will recompile it. You can see its progress in the terminal panel of your original window.
3.  **Reload the Host:** To see your changes, go to the **Extension Development Host** window (the one you launched with F5) and reload it. The easiest way is to open the Command Palette (`Ctrl+Shift+P` or `Cmd+Shift+P`) and run the command **`Developer: Reload Window`**.

You only need to stop the debugger (Shift+F5) and restart it (F5) if you make changes to configuration files like `package.json`. For all other code changes, simply reloading the host window is sufficient and much faster.
</file_artifact>

<file path="src/Artifacts/A8. DCE - Phase 1 - Selection Sets Feature Plan.md">
# Artifact A8: DCE - Phase 1 - Selection Sets Feature Plan
# Date Created: Cycle 11
# Author: AI Model
# Updated on: C23 (Add requirement for selection persistence)

- **Key/Value for A0:**
- **Description:** A plan outlining the user stories, UI/UX, and technical implementation for saving, loading, and persisting different sets of selected files (selection profiles).
- **Tags:** feature plan, selection sets, profiles, context management, persistence, phase 1

## 1. Overview & Goal

The goal of the "Selection Sets" feature is to address the user feedback regarding the need to save and switch between different file selections, and to ensure the current selection is not lost during a session. Users often work on multiple tasks or projects concurrently, each requiring a different context. Manually re-selecting files is tedious and losing the current selection when switching tabs is a critical usability flaw. This feature will allow users to save a named "set" of their current selections, quickly load it back later, and have their current selection state persist automatically.

## 2. User Stories

| ID | User Story | Acceptance Criteria |
|---|---|---|
| US-01 | **Selection Persistence** | As a user, I expect my current selection of checked files to remain active when I switch to another VS Code tab and then return, so my work is not lost. | - The current array of selected file paths is automatically saved to the webview's persistent state whenever it changes. <br> - When the webview is re-activated (e.g., tab is clicked), it restores the last saved selection state. |
| US-02 | **Save Current Selection** | As a developer, I want to save my currently checked files as a named set, so I don't have to re-select them manually when I switch tasks. | - A UI element (e.g., button or menu item) exists to "Save current selection". <br> - Clicking it prompts me to enter a name for the selection set. <br> - After providing a name, the current list of selected file paths is saved. <br> - I receive a confirmation that the set was saved. |
| US-03 | **Load a Saved Selection** | As a developer, I want to load a previously saved selection set, so I can quickly restore a specific context. | - A UI element (e.g., a dropdown menu) lists all saved selection sets by name. <br> - Selecting a set from the list immediately updates the file tree, checking all the files and folders from that set. <br> - Any previously checked files that are not part of the loaded set become unchecked. |
| US-04 | **Delete a Saved Selection** | As a developer, I want to delete a selection set that I no longer need, so I can keep my list of saved sets clean. | - A UI element exists to manage or delete saved sets. <br> - I can select a set to delete from a list. <br> - I am asked to confirm the deletion. <br> - Upon confirmation, the set is removed from the list of saved sets. |

## 3. Proposed UI/UX

The functionality will be consolidated into the `view-header` of our Context Chooser panel for easy access.

1.  **Header Controls:**
    *   A dropdown menu and/or a set of dedicated toolbar buttons for managing selection sets.
    *   Example: A "Save" icon button and a "Load" icon button.
    *   Clicking "Save" would trigger the save workflow.
    *   Clicking "Load" would open a Quick Pick menu of saved sets.

2.  **Saving a Set:**
    *   Clicking the "Save" button will execute the `dce.saveSelectionSet` command.
    *   This command will trigger a VS Code input box (`vscode.window.showInputBox`).
    *   The user will enter a name (e.g., "API Feature", "Frontend Refactor").
    *   On submission, the backend saves the current `selectedFiles` array under that name.

3.  **Loading a Set:**
    *   Clicking the "Load" button will execute the `dce.loadSelectionSet` command.
    *   This command shows a Quick Pick list (`vscode.window.showQuickPick`) of all saved sets.
    *   Selecting a set triggers an IPC message (`ApplySelectionSet`) to the frontend with the array of file paths for that set.
    *   The frontend updates its `selectedFiles` state, causing the tree to re-render with the new selections.

## 4. Technical Implementation Plan

1.  **State Persistence (`view.tsx`):**
    *   Define a state type in `vscode-webview.d.ts`: `interface ViewState { selectedFiles: string[] }`.
    *   In the main `App` component in `view.tsx`, use a `useEffect` hook that triggers whenever the `selectedFiles` state changes. Inside this effect, call `vscode.setState({ selectedFiles })`.
    *   On initial component mount, retrieve the persisted state using `const savedState = vscode.getState();` and if it exists, use it to initialize the `selectedFiles` state: `useState<string[]>(savedState?.selectedFiles || [])`.

2.  **Data Storage (`selection.service.ts`):**
    *   Selection sets will continue to be stored in the VS Code `workspaceState`. This is a key-value store specific to the current workspace.
    *   A single key, e.g., `dce.selectionSets`, will hold an object where keys are the set names and values are the `string[]` of absolute file paths.

3.  **IPC Channels & Commands (`commands.ts`):**
    *   The existing commands (`dce.saveSelectionSet`, `dce.loadSelectionSet`, `dce.deleteSelectionSet`) are suitable.
    *   The backend `loadSelectionSet` command will trigger the `ApplySelectionSet` IPC message to the client with the file paths.

4.  **Frontend Logic (`view.tsx`):**
    *   Add state to store the map of selection sets: `const [selectionSets, setSelectionSets] = useState({});`
    *   On mount, request the list of sets from the backend to populate any UI elements.
    *   Implement an effect to listen for `ApplySelectionSet` and call `setSelectedFiles()` with the new paths.
    *   Render the new "Save" and "Load" buttons in the header toolbar.
    *   The `onClick` handler for the "Save" button will trigger an IPC message that executes the `dce.saveSelectionSet` command, passing the current `selectedFiles` state.
</file_artifact>

<file path="src/Artifacts/A9. DCE - GitHub Repository Setup Guide.md">
# Artifact A9: DCE - GitHub Repository Setup Guide
# Date Created: Cycle 12
# Author: AI Model
# Updated on: C160 (Add sample workflow with `git restore`)

- **Description:** A step-by-step guide with the necessary git commands to initialize the project as a local repository and push it to a new remote repository on GitHub, including a sample workflow for testing AI responses.
- **Tags:** git, github, version control, setup, repository, workflow

## 1. Overview

This guide provides the necessary commands to turn your local project folder into a Git repository and link it to a new, empty repository on GitHub. It also describes a sample workflow for using Git to efficiently test multiple AI-generated responses.

## 2. Prerequisites

*   You have `git` installed on your machine.
*   You have a GitHub account.

## 3. Step-by-Step Setup

### Step 1: Create a New Repository on GitHub

1.  Go to [github.com](https://github.com) and log in.
2.  In the top-right corner, click the `+` icon and select **"New repository"**.
3.  **Repository name:** A good name would be `data-curation-environment` or `vscode-dce-extension`.
4.  **Description:** (Optional) "A VS Code extension for curating context for Large Language Models."
5.  Choose **"Private"** or **"Public"** based on your preference.
6.  **IMPORTANT:** Do **not** initialize the repository with a `README`, `.gitignore`, or `license`. We will be pushing our existing files, and this will prevent conflicts.
7.  Click **"Create repository"**.

GitHub will now show you a page with several command-line instructions. We will use the section titled **"...or push an existing repository from the command line"**.

### Step 2: Initialize Git in Your Local Project

Open a terminal (like the one integrated into VS Code) and navigate to your project's root directory (e.g., `C:\Projects\DCE`). Then, run the following commands one by one.

1.  **Initialize the repository:** This creates a new `.git` subdirectory in your project folder.
    ```bash
    git init
    ```

2.  **Add all existing files to the staging area:** The `.` adds all files in the current directory and subdirectories.
    ```bash
    git add .
    ```

3.  **Create the first commit:** This saves the staged files to the repository's history.
    ```bash
    git commit -m "Initial commit"
    ```

4.  **Rename the default branch to `main`:** This is the modern standard, replacing the older `master`.
    ```bash
    git branch -M main
    ```

### Step 3: Link and Push to GitHub

Now, you will link your local repository to the empty one you created on GitHub.

1.  **Add the remote repository:** Replace the URL with the one from your GitHub repository page. It should look like the example below.
    ```bash
    git remote add origin https://github.com/dgerabagi/data-curation-environment.git
    ```

2.  **Push your local `main` branch to GitHub:** The `-u` flag sets the upstream remote so that in the future, you can simply run `git push`.
    ```bash
    git push -u origin main
    ```

After these commands complete, refresh your GitHub repository page. You should see all of your project files. You have successfully created and linked your repository.

## 4. Sample Workflow for Testing AI Responses

Once your project is set up with Git, you can leverage it to create a powerful and non-destructive testing workflow with the DCE.

1.  **Start with a Clean State:** Make sure your working directory is clean. You can check this with `git status`. If you have any uncommitted changes, either commit them or stash them.
2.  **Generate Responses:** Use the DCE to generate a `prompt.md` file and get several responses from your AI. Paste these into the Parallel Co-Pilot Panel and parse them.
3.  **Accept a Response:** Choose the response you want to test (e.g., "Resp 1"). Select its files in the "Associated Files" list and click "Accept Selected Files". This will overwrite the files in your workspace.
4.  **Test the Changes:** Run your project's build process (`npm run watch`), check for errors, and test the functionality in the VS Code Extension Development Host.
5.  **Revert and Test the Next One:**
    *   If you're not satisfied with the changes from "Resp 1," you can instantly and safely revert all the changes by running a single command in your terminal:
        ```bash
        git restore .
        ```
    *   This command discards all uncommitted changes in your working directory, restoring your files to the state of your last commit.
6.  **Repeat:** Your workspace is now clean again. You can go back to the Parallel Co-Pilot Panel, accept the files from "Resp 2," and repeat the testing process.

This workflow allows you to rapidly test multiple complex, multi-file changes from different AI responses without the risk of permanently breaking your codebase.
</file_artifact>

<file path="src/Artifacts/A10. DCE - Metadata and Statistics Display.md">
# Artifact A10: DCE - Metadata and Statistics Display
# Date Created: Cycle 14
# Author: AI Model
# Updated on: C40 (Clarify file counter label and tooltip)

- **Key/Value for A0:**
- **Description:** Outlines the requirements and design for displaying live metadata (total selected files, total tokens) and for showing aggregate statistics (token and file counts) for folders in the file tree.
- **Tags:** feature plan, metadata, statistics, token count, ui, ux

## 1. Overview & Goal

To enhance the data curation process, it is critical for the user to have immediate, quantitative feedback on their selections. This feature will provide at-a-glance statistics at both the folder level and the overall selection level. The goal is to empower the user to make informed decisions about context size and composition without needing to perform manual calculations.

## 2. User Stories

| ID | User Story | Acceptance Criteria |
|---|---|---|
| US-01 | **Folder Statistics** | As a data curator, I want to see the total token count and the total number of files contained within each folder, so I can quickly assess the size and complexity of different parts of my project. | - Next to each folder name in the file tree, a token count is displayed. <br> - This token count is the recursive sum of all tokens from all non-image files within that folder and its subfolders. <br> - Next to the token count, a file count is also displayed, formatted with commas (e.g., "1,234"). <br> - These numbers are calculated on the backend and provided with the initial file tree data. |
| US-02 | **Live Selection Summary** | As a data curator, I want to see a live summary of my total selection as I check and uncheck files, so I can monitor the total size of my context in real-time. | - A dedicated summary panel/footer is visible in the UI. <br> - This panel displays "X files" and "Y tokens". <br> - **(C40 Update)** The label for the file count is "Selected Files". The tooltip reads: "Total number of individual files selected for flattening. This does not include empty directories." <br> - "X" is the total count of all individual files included in the current selection, formatted with commas. <br> - "Y" is the sum of all token counts for those selected non-image files. <br> - These values update instantly whenever a checkbox is changed. |
| US-03 | **Readable Numbers & Icons** | As a data curator, I want large token counts to be formatted in a compact and readable way (e.g., 1,234 becomes "1.2K"), and for icons to visually represent the data, so I can easily parse the information. | - All token counts use K/M/B suffixes for numbers over 1,000. <br> - All file counts use commas for thousands separators. <br> - An icon is displayed next to the token count and file count for visual distinction. <br> - The statistics are right-justified in the file tree for better readability. |
| US-04 | **Image File Handling** | As a data curator, I want to see the file size for images instead of a token count, so I can understand their contribution to storage/transfer size rather than context length. | - The backend identifies common image file types (png, jpg, etc.). <br> - For image files, the token count is treated as 0. <br> - In the file tree, instead of a token count, the human-readable file size is displayed (e.g., "15.2 KB", "2.1 MB"). |
| US-05 | **Selected Token Count in Folders** | As a data curator, I want to see how many tokens are selected within a folder, so I can understand the composition of my selection without expanding the entire directory. | - Next to a folder's total token count, a secondary count in parentheses `(x)` appears. <br> - `x` is the recursive sum of tokens from all selected files within that folder. <br> - The display format is `TotalTokens (SelectedTokens)`, e.g., `347K (13K)`. <br> - This count only appears if selected tokens are > 0 and less than the total tokens. |
| US-06 | **Visual Cue for Selected Tokens** | As a curator, I want a clear visual indicator on the token count itself when an item is included in the selection, so I can confirm its inclusion without looking at the checkbox. | - When an individual file is checked, its token count is wrapped in parentheses, e.g., `(168)`. <br> - When a folder is checked, and *all* of its children are included in the selection, its total token count is wrapped in parentheses, e.g., `(336)`. <br> - This complements the `Total (Selected)` format for partially selected folders. |

## 3. Technical Implementation Plan

1.  **Backend (`fs.service.ts`):**
    *   The `FileNode` interface in `src/common/types/file-node.ts` will be updated to include `isImage: boolean` and `sizeInBytes: number`.
    *   The backend service will maintain a list of image file extensions.
    *   When building the tree, it will check each file's extension.
    *   If it's an image, it will use `fs.stat` to get the `sizeInBytes`, set `isImage: true`, and set `tokenCount: 0`.
    *   If it's not an image, it will calculate the `tokenCount` and get the `sizeInBytes`.
    *   The recursive sum logic for folders will aggregate `tokenCount`, `fileCount`, and `sizeInBytes` from their children.
    *   The `vscode.workspace.findFiles` call will be updated to exclude the `node_modules` directory.

2.  **Frontend - Formatting (`formatting.ts`):**
    *   A new `formatBytes(bytes)` utility will be created to convert bytes to KB, MB, etc.
    *   A new `formatNumberWithCommas(number)` utility will be created.

3.  **Frontend - File Tree (`FileTree.tsx` & `view.scss`):**
    *   The `FileTree.tsx` component will be updated to render the new data.
    *   It will conditionally display either a formatted token count (using `formatLargeNumber`) or a formatted file size (using `formatBytes`) based on the `isImage` flag.
    *   It will display folder file counts using `formatNumberWithCommas`.
    *   **Selected Token Calculation:** A new memoized, recursive function will be created within `FileTree.tsx` to calculate the selected token count for a given directory node by checking its descendants against the `selectedFiles` prop.
    *   The rendering logic will be updated to display the `(SelectedTokens)` value conditionally.
    *   **Parenthesis Logic (US-06):** The rendering logic will be further updated. For files, it will check if the file's path is in the `selectedFiles` list. For folders, it will compare the calculated `selectedTokensInDir` with the `node.tokenCount`. Based on these checks, it will conditionally wrap the output string in parentheses.
    *   It will incorporate icons from `react-icons/vsc` for tokens and file counts.
    *   The stylesheet (`view.scss`) will be updated to right-align all statistics, pushing them to the end of the file/folder row.

4.  **Frontend - Live Summary Panel (`context-chooser.view.tsx`):**
    *   The `useMemo` hook that calculates the summary will be updated to correctly sum the total number of files and total tokens from the selected items. It will continue to ignore image sizes for the token total to avoid mixing units.
    *   The rendered output will use the new formatting utilities and icons.
    *   **(C40)** The label and title attribute will be updated for clarity.
</file_artifact>

<file path="src/Artifacts/A12. DCE - Logging and Debugging Guide.md">
# Artifact A12: DCE - Logging and Debugging Guide
# Date Created: Cycle 19
# Author: AI Model & Curator
# Updated on: C185 (Mandate truncated logging for large data)

- **Key/Value for A0:**
- **Description:** Explains how to access and use the integrated logging solution for debugging the extension's backend and frontend components.
- **Tags:** logging, debugging, troubleshooting, development, output channel

## 1. Purpose

This document provides instructions on how to access and use the logging features built into the Data Curation Environment (DCE) extension. Effective logging is crucial for diagnosing performance issues, tracking down bugs, and understanding the extension's behavior during development.

## 2. Two Primary Log Locations

There are two separate places to look for logs, depending on where the code is running.

### Location 1: The "Debug Console" (For `console.log`)

This is where you find logs from the **backend** (the extension's main Node.js process).

-   **What you'll see here:** `console.log()` statements from files in `src/backend/` and `src/extension.ts`. This is useful for debugging the extension's core activation and services *before* the UI is even visible.
-   **Where to find it:** In your **main development window** (the one where you press `F5`), look in the bottom panel for the **"DEBUG CONSOLE"** tab.

    ```
    -----------------------------------------------------------------------------------
    | PROBLEMS    OUTPUT    DEBUG CONSOLE    TERMINAL                                 |
    |---------------------------------------------------------------------------------|
    |                                                                                 |
    |  > Congratulations, your extension "Data Curation Environment" is now active!   |
    |  > FSService watcher initialized.                                               |
    |  ...                                                                            |
    -----------------------------------------------------------------------------------
    ```

### Location 2: The "Output" Channel (For Centralized Logging)

This is the primary, centralized log for the entire extension, including messages from the **frontend (WebView)**.

-   **What you'll see here:** Formatted log messages from both the backend (`LoggerService`) and the frontend (`logger.ts`). All messages are prefixed with a level (`[INFO]`, `[WARN]`, `[ERROR]`) and a timestamp. Frontend messages are also prefixed with `[WebView]`.
-   **Where to find it:** In the **"[Extension Development Host]" window** (the new window that opens after you press `F5`), follow these steps:
    1.  **Open the Panel:** Press `Ctrl+J` (or `Cmd+J` on Mac).
    2.  **Navigate to the "OUTPUT" Tab.**
    3.  In the dropdown menu on the right, select **`Data Curation Environment`**.

    ```
    -----------------------------------------------------------------------------------
    | PROBLEMS    OUTPUT    DEBUG CONSOLE    TERMINAL                                 |
    |---------------------------------------------------------------------------------|
    |                                                 [Data Curation Environment v]   |
    |                                                                                 |
    |  [INFO] [2:30:00 PM] Services initialized.                                      |
    |  [INFO] [2:30:01 PM] Received request for workspace files.                      |
    |  [INFO] [2:30:01 PM] [WebView] Initializing view and requesting workspace files.|
    |  [INFO] [2:30:01 PM] Scanning for files with exclusion pattern: ...             |
    |  ...                                                                            |
    -----------------------------------------------------------------------------------
    ```

## 3. Tactical Debugging with Logs (C93)

When a feature is not working as expected, especially one that involves communication between the frontend and backend, the most effective debugging technique is to add **tactical logs** at every step of the data's journey.

### Case Study: Fixing the "Associated Files" Parser (Cycle 93)

-   **Problem:** The UI was incorrectly reporting that files from a parsed AI response did not exist in the workspace.
-   **Data Flow:**
    1.  **Frontend (`view.tsx`):** User clicks "Parse All".
    2.  **Frontend (`response-parser.ts`):** Raw text is parsed into a list of relative file paths (e.g., `src/main.ts`).
    3.  **IPC (`RequestFileExistence`):** The list of relative paths is sent to the backend.
    4.  **Backend (`fs.service.ts`):** The backend receives the list and compares it against its own list of known workspace files, which are stored as absolute paths (e.g., `c:/project/src/main.ts`). The comparison fails.

## 4. Truncated Logging for Large Content (C185)

To prevent the output channel from becoming overwhelmed with large blocks of text (e.g., entire file contents or full AI responses), a logging utility has been implemented to truncate long strings.

-   **Behavior:** When a service logs a large piece of content (like a code block for syntax highlighting or the entire application state), it **must** use the `truncateCodeForLogging` utility.
-   **Format:** If a string is longer than a set threshold, it will be displayed in the logs in a format like this:
    `[First 15 lines]...// (content truncated) ...[Last 15 lines]`
-   **Benefit:** This keeps the logs clean and readable, allowing you to see that a large piece of data was processed without having its entire content flood the output. You can still see the beginning and end of the content to verify its identity.
</file_artifact>

<file path="src/Artifacts/A13. DCE - Phase 1 - Right-Click Context Menu.md">
# Artifact A13: DCE - Phase 1 - Right-Click Context Menu
# Date Created: C19
# Author: AI Model
# Updated on: C131 (Add Create File action for non-existent associated files)

- **Key/Value for A0:**
- **Description:** A plan for implementing standard file explorer context menu actions (e.g., Rename, Delete, Copy Path) in the custom file tree and other UI lists.
- **Tags:** feature plan, context menu, right-click, file operations, ux, phase 1

## 1. Overview & Goal

To enhance the user experience and make the Data Curation Environment a more complete replacement for the native VS Code explorer, this feature adds standard right-click context menus. The goal is to provide essential file and list management operations directly within our extension's view, reducing the need for users to switch contexts for common tasks.

This plan covers three distinct context menus: one for the main file tree, one for the "Selected Items" list, and one for the "Associated Files" list in the Parallel Co-Pilot Panel.

## 2. Main File Tree Context Menu

| ID | User Story | Acceptance Criteria |
|---|---|---|
| US-01 | **Copy Path** | As a user, I want to right-click a file or folder and copy its absolute or relative path to my clipboard, so I can easily reference it elsewhere. | - Right-clicking a node in the file tree opens a context menu. <br> - The menu contains "Copy Path" and "Copy Relative Path" options. <br> - Selecting an option copies the corresponding path string to the system clipboard. |
| US-02 | **Rename File/Folder** | As a user, I want to right-click a file or folder and rename it, so I can correct mistakes or refactor my project structure. | - The context menu contains a "Rename" option. <br> - Selecting it turns the file/folder name into an editable input field. <br> - Pressing Enter or clicking away saves the new name. <br> - The underlying file/folder is renamed on the file system. <br> - The file tree updates to reflect the change. |
| US-03 | **Delete File/Folder** | As a user, I want to right-click a file or folder and delete it, so I can remove unnecessary files from my project. | - The context menu contains a "Delete" option. <br> - Selecting it shows a confirmation dialog to prevent accidental deletion. <br> - Upon confirmation, the file or folder (and its contents, recursively) is moved to the trash/recycling bin. <br> - The file tree updates to reflect the change. |
| US-04 | **Reveal in OS Explorer** | As a user, I want to right-click a file or folder and have it revealed in the native OS file explorer, so I can interact with it outside of VS Code. | - The context menu contains a "Reveal in File Explorer" (or "Reveal in Finder" on macOS) option. <br> - Selecting it opens the parent directory of the item in the **operating system's default file manager** (e.g., Windows File Explorer) with the item selected. This should not simply switch to the VS Code Explorer tab. |
| US-05 | **New File/Folder** | As a user, I want to create new files and folders from the toolbar or context menu in the correct location, so I can build out my project structure without leaving the view. | - The header toolbar has "New File" and "New Folder" buttons. <br> - Clicking either prompts for a name. <br> - The new file/folder is created in the directory of the currently *active/highlighted* item in the tree. <br> - If the active item is a file, the new item is created in that file's parent directory. <br> - If no item is active, it defaults to the workspace root. <br> - The file tree automatically refreshes. |

## 3. "Selected Items" Panel Context Menu

| ID | User Story | Acceptance Criteria |
|---|---|---|
| US-06 | **Select All/Deselect All** | As a user, I want to right-click in the "Selected Items" panel to quickly select or deselect all items in the list, so I can perform batch removal operations more efficiently. | - Right-clicking anywhere within the list of selected files opens a context menu. <br> - The menu contains a "Select All" option. <br> - Clicking "Select All" highlights every item in the list, updating the "Remove selected" button count. <br> - The menu also contains a "Deselect All" option. <br> - Clicking "Deselect All" clears all selections in the list. |

## 4. "Associated Files" List Actions (C131)

| ID | User Story | Acceptance Criteria |
|---|---|---|
| US-07 | **Create Missing File** | As a developer, when an AI response refers to a file that doesn't exist, I want an easy way to create it directly from the "Associated Files" list, so I can quickly implement the AI's suggestion for a new file. | - In the "Associated Files" list, a file that does not exist is marked with an ''. <br> - When I hover over this item, a "Create File" button appears next to it. <br> - Clicking the button creates a new, empty file at that path in the workspace. <br> - The file tree and the "Associated Files" list automatically refresh, and the indicator changes to a ''. |

## 5. Technical Implementation Plan

-   **Main Tree Menu:** Implemented in `TreeView.tsx` and `ContextMenu.tsx` using an `onContextMenu` event handler and state management to control visibility and position.
-   **"Selected Items" Menu (C37):** Implemented in `SelectedFilesView.tsx` with its own context menu state and handlers for "Select All" / "Deselect All".
-   **"Create Missing File" Action (C131):**
    1.  **IPC:** Create a new `ClientToServerChannel.RequestCreateFile` channel with a payload of `{ filePath: string }`.
    2.  **Backend (`file-operation.service.ts`):** Implement `handleCreateFileRequest`. It will receive the relative path, resolve it to an absolute path, and use `vscode.workspace.fs.writeFile` with an empty `Uint8Array` to create the file. The file watcher will trigger a refresh.
    3.  **Frontend (`view.tsx`):** In the "Associated Files" list rendering logic, if a file does not exist (`!fileExistenceMap.get(file)`), render a "Create File" button. The button will be visible on hover. Its `onClick` handler will send the new IPC message.
</file_artifact>

<file path="src/Artifacts/A14. DCE - Ongoing Development Issues.md">
# Artifact A14: DCE - Ongoing Development Issues
# Date Created: C20
# Author: AI Model & Curator
# Updated on: C23 (Add issues for selection persistence and remove button)

- **Key/Value for A0:**
- **Description:** A tracking document for recurring or persistent issues that need to be monitored across development cycles until they are confirmed as resolved.
- **Tags:** bugs, tracking, issues, logging, node_modules, performance

## 1. Purpose

This artifact serves as a centralized list to track ongoing and recurring issues during the development of the Data Curation Environment (DCE) extension. This ensures that persistent problems are not forgotten and are actively monitored across cycles until a definitive solution is implemented and verified.

## 2. Active Issues

---

### Issue #5: Selection State is Not Persistent

-   **Symptom:** When the user makes selections in the "Data Curation" view, then switches to another VS Code tab and back, all selections are lost.
-   **First Reported:** Cycle 23
-   **Status (C23):** **Active.** The frontend state for `selectedFiles` is not being persisted in the VS Code `workspaceState`.
-   **Next Steps (C23):** Implement a mechanism to save the `selectedFiles` array to `workspaceState` on every change and load it when the view is initialized. This will involve both frontend (`view.tsx`) and backend (`selection.service.ts`) changes.

---

### Issue #6: "Remove selected" Button is Non-Functional

-   **Symptom:** In the "Selected Items" view, selecting one or more files and clicking the "Remove selected" button does not remove them from the list or from the main selection. It also causes the file tree in the main view to collapse.
-   **First Reported:** Cycle 23
-   **Status (C23):** **Active.** The logic in `removePathsFromSelected` or the way its result is being used to update the state is flawed. The tree collapsing indicates an improper state update is causing a major re-render.
-   **Next Steps (C23):** Debug the `removePathsFromSelected` function in `FileTree.utils.ts`. Add logging to the `onClick` handler in `SelectedFilesView.tsx` to trace the data flow. Fix the state update to prevent the side-effect of collapsing the tree.

---

### Issue #1: Logging Visibility

-   **Symptom:** The custom "Data Curation Environment" output channel is not visible in the "OUTPUT" tab's dropdown menu in the Extension Development Host window. This prevents the primary logging mechanism from being used for debugging.
-   **First Reported:** Cycle 19
-   **Status (C23):** **Resolved (C21).** The issue was caused by an early-exit error during extension activation. Adding robust `try...catch` blocks around service initializations in `extension.ts` allowed the extension to fully load, making the output channel visible.

---

### Issue #2: `node_modules` Exclusion and Performance

-   **Symptom:** The `node_modules` directory is included in file tree scans, leading to incorrect file and token counts and a significant performance delay.
-   **First Reported:** Cycle 15 (and earlier)
-   **Status (C23):** **Resolved (C20).** The `vscode.workspace.findFiles` call in `fs.service.ts` was updated with a more robust glob pattern `'{**/node_modules/**,**/dist/**,**/out/**,**/.git/**,**/flattened_repo.md}'` which now correctly excludes these directories.

---

### Issue #3: Incorrect Image Token Counting

-   **Symptom:** Image files are being assigned a token count instead of displaying their file size.
-   **First Reported:** Cycle 18
-   **Status (C23):** **Resolved (C20).** The logic in `fs.service.ts` was corrected to identify images by extension, set `tokenCount` to 0, and get their `sizeInBytes`. The frontend (`FileTree.tsx`) now uses an `isImage` flag to display the formatted byte size instead of tokens.

---

### Issue #4: File Tree Caching and Refresh Behavior

-   **Symptom:** The file tree reloaded from scratch on every tab switch and did not auto-update on file changes.
-   **First Reported:** Cycle 19
-   **Status (C23):** **Resolved (C20).** A frontend cache was implemented by changing the `useEffect` dependency array. A backend `FileSystemWatcher` was implemented in `fs.service.ts` to detect changes and push updates to the client, triggering a refresh.
</file_artifact>

<file path="src/Artifacts/A15. DCE - Phase 1 - Multi-Select & Sorting Feature Plan.md">
# Artifact A15: DCE - Phase 1 - Multi-Select & Sorting Feature Plan
# Date Created: Cycle 22
# Author: AI Model
# Updated on: C40 (Documented RCA and fix for batch removal bug)

- **Key/Value for A0:**
- **Description:** Details the requirements for multi-selection (click, Ctrl, Shift) in both the main file tree and the "Selected Items" panel, and multi-level column sorting.
- **Tags:** feature plan, multi-select, sorting, list view, ux, phase 1

## 1. Overview & Goal

To elevate the Data Curation Environment beyond basic functionality, this plan introduces advanced list-interaction features common in modern applications. The goal is to provide users with powerful and intuitive tools for managing their file selections, mirroring the behavior of native operating system file explorers. This includes robust multi-selection capabilities in both the main file tree and the "Selected Items" panel, and comprehensive sorting for the "Selected Items" list.

## 2. User Stories

| ID | User Story | Acceptance Criteria |
|---|---|---|
| US-01 | **"Selected Items" Multi-Selection** | As a curator, after selecting a large folder, I want to quickly remove a small group of unwanted files from the "Selected Items" list using standard Shift-click and Ctrl-click, so I don't have to uncheck them one by one in the main tree. | - Clicking a single item in the "Selected Items" list selects it and deselects all others. <br> - Ctrl-clicking an item toggles its selection state without affecting other items. <br> - Shift-clicking an item selects the range of items between the last-clicked anchor item and the current one. The anchor is set by the last non-Shift click. <br> - A "Remove Selected" button acts on all currently selected items in this list. |
| US-02 | **"Selected Items" Column Sorting** | As a curator, I want to sort the "Selected Items" list by file name or token count, so I can easily find specific files or identify the largest contributors to my context. | - The "Selected Items" panel has a header row with clickable "File" and "Tokens" labels. <br> - Clicking a column header sorts the list by that column. <br> - Clicking the same header again reverses the sort direction (ascending/descending). <br> - A visual indicator (e.g., an arrow) shows the current sort column and direction. <br> - The default, initial sort is by Token Count, descending. |
| US-03 | **"Selected Items" Multi-Layer Sorting** | As a curator, I want to apply a secondary sort, so I can group my selected files by type and then see the largest files within each group. | - The sorting mechanism supports at least two levels of sorting. <br> - The UI provides a way to define a primary and secondary sort key (e.g., Shift-clicking a second column header). <br> - The list first organizes by the primary key, then sorts items within those groups by the secondary key. For example, sort by Type (asc), then by Token Count (desc). |
| US-04 | **Main Tree Multi-Selection** | As a user, I want to select multiple files and folders in the main "Data Curation" file tree using standard OS conventions (Ctrl/Shift click), so I can perform context menu actions (like Delete) on multiple items at once. | - Standard multi-selection is implemented in the main file tree. <br> - This selection is a separate state from the checkbox state and is used for contextual actions, not for flattening. <br> - Right-clicking on any item within a multi-selected group opens a context menu that applies its actions to all selected items. <br> - **(Bug C31):** Ctrl-click is non-functional. Shift-click is inconsistent and difficult to use. |
| US-05 | **"As-Is" Sorting** | As a user, I want to be able to revert the "Selected Items" list to its default sort order, so I can see the files as they appear in the native VS Code explorer. | - A sort option for "Default" or "As-Is" is available. <br> - Selecting it sorts the items based on their original file system order (folders first, then files, all alphabetized). |

## 3. Technical Implementation Plan

1.  **`SelectedFilesView.tsx` Refactor:**
    *   **State Management:** Introduce new state variables to manage selection, sorting, and multi-selection.
        *   `const [selection, setSelection] = useState<Set<string>>(new Set());`
        *   `const [selectionAnchor, setSelectionAnchor] = useState<string | null>(null);` // For stable shift-click
        *   `const [sortConfig, setSortConfig] = useState<{ key: string; direction: 'asc' | 'desc' }[]>([{ key: 'tokenCount', direction: 'desc' }]);`
    *   **Event Handling:** Implement a comprehensive `onClick` handler for list items that inspects `event.ctrlKey` and `event.shiftKey`. A non-modifier click will set both the `selection` and the `selectionAnchor`. A shift-click will select from the `selectionAnchor` to the current item.
    *   **Sorting Logic:** The `useMemo` hook that sorts the `selectedFileNodes` prop will be updated to handle an array of `sortConfig` objects. It will perform a stable sort, iterating through the sort criteria until a non-zero comparison result is found. A new "Type" column will be added, requiring a utility to extract the file extension.

2.  **Batch Removal Logic (`FileTree.utils.ts`):**
    *   **Root Cause of C40 Bug:** The `removePathsFromSelected` function was buggy. It iterated through the list of files to remove, calling the single-item removal utility (`addRemovePathInSelectedFiles`) on each. This created a race condition where the first removal would perform a "subtractive uncheck" (e.g., removing `src` and adding back all its other children), drastically changing the selection state that subsequent iterations of the loop were relying on.
    *   **Codified Solution (C40):** The `removePathsFromSelected` function will be rewritten to be non-iterative and set-based. It will calculate the final desired state in a single pass by determining the full set of effectively selected files, removing the unwanted files from that set, and then "compressing" the remaining set of files back into the most efficient list of parent directories and individual files. This atomic approach is more robust and avoids the state mutation bug.

3.  **`FileTree.tsx` & `TreeView.tsx` (Main Tree Multi-Select):**
    *   This is a more complex task that mirrors the `SelectedFilesView` implementation but within a recursive tree structure.
    *   A new selection state for contextual actions (`const [contextSelection, setContextSelection] = useState<Set<string>>(new Set())`) will be managed at the top level (`view.tsx`).
    *   The selection state and handler functions will need to be passed down through `FileTree` to `TreeView`.
    *   **(Fix for C31):** The `handleNodeClick` event handler in `TreeView.tsx` must be corrected. The anchor for shift-click (`lastClickedPath`) must only be updated on a click *without* the Shift key pressed. The logic for Ctrl-click must be revised to correctly toggle a path's inclusion in the selection set without clearing other selections.
    *   The `onContextMenu` handler will need to be updated to check if the right-clicked node is part of the current `contextSelection` and pass the entire selection to the backend if an action is chosen.
</file_artifact>

<file path="src/Artifacts/A16. DCE - Phase 1 - UI & UX Refinements Plan.md">
# Artifact A16: DCE - Phase 1 - UI & UX Refinements Plan
# Date Created: Cycle 22
# Author: AI Model
# Updated on: C187 (Add Associated Files animation glitch)

- **Key/Value for A0:**
- **Description:** Covers visual and usability improvements like fixing panel layouts, resolving overflow bugs, adding loading indicators, and improving scrollbar visibility.
- **Tags:** feature plan, ui, ux, layout, bug fix, loading indicator, phase 1

## 1. Overview & Goal

This document outlines a series of user interface (UI) and user experience (UX) refinements identified during playtesting. The goal is to address layout bugs, provide better visual feedback to the user, and improve the overall professional feel of the extension. These changes focus on fixing immediate usability problems and making the extension more intuitive to operate.

## 2. User Stories & Issues

| ID | User Story / Issue | Acceptance Criteria |
|---|---|---|
| UI-01 | **Header Layout Bug** | As a user, I want the header of the "Data Curation" panel to be compact, without the extra vertical space between the title and the toolbar buttons, so it looks clean and professional. | - The vertical gap between the view title row and the toolbar button row is removed. <br> - The header area takes up minimal vertical space. <br> - This is a CSS fix, likely involving adjusting `padding`, `margin`, or `gap` in the flex container. |
| UI-02 | **"Selected Items" Overflow Bug** | As a user, when I select many files, I want the "Selected Items" list to scroll within its panel instead of running off the screen behind the "Flatten Context" footer, so I can see and manage all my selections. | - The "Selected Items" panel has a defined `max-height`. <br> - When the content exceeds this height, a vertical scrollbar appears. <br> - The panel never overlaps or pushes the footer out of view. <br> - This is a CSS fix involving `flex-grow`, `flex-shrink`, `min-height: 0` on the file tree container, and `overflow-y: auto` on the list container. |
| UI-03 | **Resizable "Selected Items" Panel** | As a user, I want to be able to vertically resize the "Selected Items" panel, so I can see more or fewer items as needed for my current task. | - A draggable handle or resizer element is added to the top border of the "Selected Items" panel. <br> - Clicking and dragging this handle adjusts the `height` or `max-height` of the panel. <br> - The main file tree above it resizes accordingly to fill the remaining space. |
| UI-04 | **Visible Loading State** | As a user, when I perform a slow action like renaming a file or refreshing the explorer, I want to see a loading indicator, so I have clear feedback that the system is working and not frozen. | - A loading state (e.g., `isLoading`) is added to the main view's state. <br> - This state is set to `true` when a file system scan begins (e.g., on initial load or refresh). <br> - A loading indicator (e.g., a spinning icon) is displayed in the UI (e.g., in the header toolbar) while `isLoading` is true. <br> - The state is set to `false` when the file data is received from the backend. |
| UI-05 | **Improved Scrollbar Gutter** | As a user, I find it difficult to distinguish between the extension's internal scrollbar and the main VS Code scrollbar when they are side-by-side. I want a clearer visual separation between them. | - A subtle vertical border (`border-right`) is added to the main file tree container. <br> - This creates a persistent, visible dividing line between the two scrollable areas, making it easier to position the mouse. |
| UI-06 | **Expand All Button** | As a user, I want an "Expand All" button in the toolbar, so I can quickly see all files in the project without manually clicking every folder. | - An "Expand All" button is added to the main header toolbar. <br> - Clicking it expands every collapsed folder in the file tree. <br> - The button complements the existing "Collapse All" button. |
| UI-07 | **Associated Files Animation Glitch** | As a user, I want the animated highlight on the "Associated Files" panel to be fully visible, so the guided workflow is clear. | - The top and left edges of the pulsing blue highlight are currently slightly obscured. <br> - A small `margin` will be added to the `.collapsible-section-inner` class to provide space for the `box-shadow` to render completely. |
</file_artifact>

<file path="src/Artifacts/A17. DCE - Phase 1 - Advanced Tree View Features.md">
# Artifact A17: DCE - Phase 1 - Advanced Tree View Features
# Date Created: Cycle 22
# Author: AI Model

- **Key/Value for A0:**
- **Description:** Outlines the plan for advanced tree view interactions, specifically the implementation of scrollable, self-contained views for large, expanded folders.
- **Tags:** feature plan, tree view, ux, scrollable, phase 1

## 1. Overview & Goal

The current file tree view expands vertically, which can create a poor user experience when a folder containing hundreds of files is opened. The entire view becomes excessively long, forcing the user to scroll a great distance to see files or folders below the expanded one. The goal of this feature is to innovate on the traditional tree view by containing the contents of a large expanded folder within a scrollable, "inline" window, preventing the main view from becoming unmanageable.

## 2. User Story

| ID | User Story | Acceptance Criteria |
|---|---|---|
| TV-01 | **Contained Folder Expansion** | As a user, when I expand a folder with a large number of children, I want its contents to appear in a scrollable sub-panel within the tree instead of pushing all subsequent items down, so I can browse the folder's contents without losing my place in the main file tree. | - When a folder is expanded, the extension checks the number of direct children. <br> - If the child count exceeds a certain threshold (e.g., 50), the children are rendered inside a nested, scrollable `div`. <br> - This `div` has a fixed `max-height`. <br> - A small 'x' icon is visible within this sub-panel. Clicking it closes the sub-panel and reverts the folder to the standard, fully expanded view for that session. |

## 3. Technical Implementation Plan

This is a significant UI/UX enhancement and will require careful implementation within the React component hierarchy.

1.  **Component (`TreeView.tsx`):**
    *   The core logic will reside in the `renderTreeNodes` function.
    *   **Threshold Check:** When rendering a directory node, check `if (node.children && node.children.length > FOLDER_CONTENT_THRESHOLD)`. The threshold will be a configurable constant.
    *   **State Management:** A new state variable will be needed to track which "large" folders have been reverted to the standard view by the user clicking the 'x' button. `const [standardViewFolders, setStandardViewFolders] = useState<Set<string>>(new Set());`
    *   **Conditional Rendering:**
        *   If the folder is expanded (`isExpanded`) AND its path is **not** in `standardViewFolders` AND it exceeds the threshold, render the children inside a special container:
            ```jsx
            <div className="large-folder-container" style={{ maxHeight: '300px', overflowY: 'auto' }}>
              <button onClick={() => setStandardViewFolders(prev => new Set(prev).add(node.absolutePath))}>X</button>
              <ul>{renderTreeNodes(node.children)}</ul>
            </div>
            ```
        *   Otherwise, render the children normally as is currently done:
            ```jsx
            <ul className="treenode-children">{renderTreeNodes(node.children)}</ul>
            ```

2.  **Styling (`view.scss`):**
    *   Create styles for `.large-folder-container`.
    *   It will need `position: relative`, a subtle `border` or `background-color` to distinguish it from the rest of the tree.
    *   The close button will need to be positioned appropriately within the container.

3.  **Performance Considerations:**
    *   This approach avoids virtualizing the entire tree, which is much more complex. It only contains the content of single, large folders.
    *   Rendering hundreds of nodes within the scrollable container might still have a minor performance impact on initial render, but it will be contained and will not affect the performance of the main tree's scrolling.
</file_artifact>

<file path="src/Artifacts/A18. DCE - Phase 1 - Active File Sync Feature Plan.md">
# Artifact A18: DCE - Phase 1 - Active File Sync Feature Plan
# Date Created: Cycle 24
# Author: AI Model
# Updated on: C44 (Add logic for suppressing auto-reveal after file operations)

- **Key/Value for A0:**
- **Description:** Details the requirements and implementation for automatically revealing and highlighting the active editor's file in the custom Data Curation file tree.
- **Tags:** feature plan, active file, sync, reveal, tree view, ux, phase 1

## 1. Overview & Goal

To create a more seamless and integrated experience, the Data Curation Environment's file tree should stay in sync with the user's focus in the main editor. Currently, selecting a file in the editor does not reflect in our custom view. The goal of this feature is to replicate the behavior of the native VS Code Explorer, where the active file is automatically revealed and highlighted in the file tree.

## 2. User Story

| ID | User Story | Acceptance Criteria |
|---|---|---|
| UX-01 | **Sync with Active Editor** | As a user, when I click on a file in the VS Code editor tabs or the native Explorer, I want the "Data Curation" file tree to automatically scroll to and highlight that file, so I can easily see its location in the project hierarchy and interact with its checkbox without manually searching for it. | - When the active text editor changes in VS Code, the new file is highlighted in the "Data Curation" tree view. <br> - All parent folders of the active file are automatically expanded to ensure it is visible. <br> - The file tree view scrolls so that the active file item is visible on the screen. |
| UX-02 | **Preserve View State** | As a user, after I perform an action that collapses the tree (e.g., "Collapse All") and then perform a file operation (e.g., drag-and-drop), I do not want the tree to automatically re-expand to reveal the active file, so my intended view state is respected. | - After a file operation (move, delete, rename, new file) triggers a refresh, the "Sync with Active Editor" feature is temporarily suppressed for the next event. <br> - This prevents the tree from re-expanding against the user's will. |

## 3. Technical Implementation Plan

1.  **Backend Listener (`extension.ts`):**
    *   Utilize the `vscode.window.onDidChangeActiveTextEditor` event listener in the `activate` function.
    *   This event provides the `TextEditor` object, from which `editor.document.uri.fsPath` can be extracted.
    *   When the event fires and an editor is present, the backend will normalize the file path (to use forward slashes) and send an IPC message to the webview containing the active file's path.

2.  **IPC Channel:**
    *   The existing `ServerToClientChannel.SetActiveFile` will be used.
    *   **(C44 Update)** The `ServerToClientChannel.ForceRefresh` channel's payload is updated from `{}` to `{ reason?: 'fileOp' | 'manual' }`.

3.  **Frontend View Logic (`TreeView.tsx`):**
    *   A `useEffect` hook in the `TreeView` component triggers whenever the `activeFile` prop changes.
    *   This effect is responsible for "revealing" the file by calculating all parent directory paths, adding them to the `expandedNodes` state, and then calling `scrollIntoView()` on the file's element ref.

4.  **Auto-Reveal Suppression Logic (C44):**
    *   **Backend (`fs.service.ts`):** The file watcher, upon detecting a change, will now send the `ForceRefresh` message with a payload: `{ reason: 'fileOp' }`.
    *   **Frontend (`view.tsx`):**
        *   A `useRef` flag (`suppressActiveFileReveal`) is used to track the suppression state.
        *   The message handler for `ForceRefresh` checks for the `fileOp` reason and sets the suppression flag to `true`, with a timeout to reset it.
        *   The message handler for `SetActiveFile` checks the flag. If `true`, it ignores the event, resets the flag, and prevents the `activeFile` state from being updated, thus preventing the reveal.

## 5. Debugging Notes & Regression Prevention

-   **Root Cause of C30 Regression:** The feature failed because of a path normalization mismatch. The `editor.document.uri.fsPath` property from the VS Code API returns paths with **backslashes (`\`)** on Windows. The frontend webview components, however, exclusively use and expect **forward slashes (`/`)** for path comparisons and manipulations.
-   **Codified Solution:** The path from the `onDidChangeActiveTextEditor` event **must** be normalized to use forward slashes *before* it is sent to the frontend via the IPC channel.
</file_artifact>

<file path="src/Artifacts/A19. DCE - Phase 1 - Double-Click & Quick-Remove Feature Plan.md">
# Artifact A19: DCE - Phase 1 - File Interaction Plan (Click & Remove)
# Date Created: Cycle 26
# Author: AI Model
# Updated on: C28 (Changed interaction model from double-click to single-click to open files)

- **Key/Value for A0:**
- **Description:** Details the requirements for opening files by single-clicking them and quickly removing single files from the selection list via a mouse-over action.
- **Tags:** feature plan, single-click, open file, quick remove, ux, phase 1

## 1. Overview & Goal

To further align the Data Curation Environment with standard, intuitive user workflows, this plan introduces two high-impact interaction enhancements. The first is the ability to **single-click** any file to open it in the main editor, mimicking the native VS Code Explorer behavior. The second is a "quick-remove" feature in the "Selected Items" panel, allowing for rapid, single-click removal of files. The goal is to reduce friction and increase the speed at which a user can curate their context.

## 2. User Stories

| ID | User Story | Acceptance Criteria |
|---|---|---|
| UX-01 | **Single-Click to Open (Main Tree)** | As a user, I want to be able to single-click on a file in the main "Data Curation" file tree and have it open in the editor, so I can quickly view its contents just like in the native Explorer. | - A single click on a file item (not a folder) in the main file tree opens that file in the main VS Code editor pane. <br> - If the file is already open in a tab, the editor switches focus to that tab. <br> - A single click on a folder still expands or collapses it. |
| UX-02 | **Single-Click to Open (Selected List)** | As a user, I want to single-click a file in the "Selected Items" list to open it, so I can easily inspect the files that are contributing the most tokens to my context. | - A single click on a file item in the "Selected Items" list opens that file in the main VS Code editor pane. <br> - If the file is already open, focus is switched to its tab. |
| UX-03 | **Quick Remove from Selection** | As a user, after selecting a large folder, I want to quickly remove a single file from the "Selected Items" list with one click, so I don't have to select it and then click the "Remove Selected" button. | - In the "Selected Items" list, when I mouse over a file row, the row number (in the `#` column) is replaced by an 'X' icon. <br> - Clicking the 'X' icon immediately removes that single file from the selection. <br> - This action is equivalent to selecting only that file and clicking "Remove Selected". <br> - The mouse leaving the row restores the row number. |

## 3. Technical Implementation Plan

1.  **IPC Channel (`channels.enum.ts`, `channels.type.ts`):**
    *   The existing `ClientToServerChannel.RequestOpenFile` is sufficient.
    *   The `ChannelBody` remains `{ path: string }`.

2.  **Backend Handler (`on-message.ts`, `fs.service.ts`):**
    *   The existing handler for `RequestOpenFile` in `fs.service.ts` is sufficient. It uses `vscode.workspace.openTextDocument` and `vscode.window.showTextDocument`.

3.  **Frontend - Single-Click (`TreeView.tsx`, `SelectedFilesView.tsx`):**
    *   In `TreeView.tsx`, the main `onClick` handler (`handleToggleNode`) will be modified. It will now check if the clicked node is a file or a directory.
        *   If it's a file, it will call `clientIpc.sendToServer(ClientToServerChannel.RequestOpenFile, ...)`.
        *   If it's a directory, it will perform the existing expand/collapse logic.
    *   In `SelectedFilesView.tsx`, the `onDoubleClick` handler will be removed and the `onClick` handler will be simplified to *only* open the file, as the multi-selection logic is handled by checking for modifier keys (`ctrlKey`, `shiftKey`).

4.  **Frontend - Quick Remove (`SelectedFilesView.tsx`, `view.scss`):**
    *   **State:** A state variable will track the hovered item's path: `const [hoveredPath, setHoveredPath] = useState<string | null>(null);`.
    *   **Event Handlers:** Add `onMouseEnter` and `onMouseLeave` to the `<li>` element to update the hover state.
    *   **Conditional Rendering:** In the JSX for the index column, render conditionally: if the row is hovered, show an 'X' icon with an `onClick` handler; otherwise, show the row number.
    *   **Styling:** Add styles for the `.quick-remove` class in `view.scss` to ensure it's clickable and has appropriate hover effects.
    *   The `onClick` handler for the 'X' icon will call the existing `onRemove` prop and use `stopPropagation` to prevent the click from also selecting the row.
</file_artifact>

<file path="src/Artifacts/A20. DCE - Phase 1 - Advanced UX & Automation Plan.md">
# Artifact A20: DCE - Phase 1 - Advanced UX & Automation Plan
# Date Created: C27
# Author: AI Model
# Updated on: C73 (Adjust token count color scheme to make red the highest risk)

- **Key/Value for A0:**
- **Description:** Details plans for several UX enhancements, including auto-revealing the flattened file, showing selected counts in folder stats, and providing an option to auto-add new files to the selection.
- **Tags:** feature plan, ux, automation, reveal, statistics, auto-add, phase 1

## 1. Overview & Goal

This document outlines a series of advanced user experience (UX) and automation features designed to further streamline the data curation workflow. The goal is to reduce manual steps, provide more insightful contextual information, and make the extension's UI more flexible and powerful.

## 2. User Stories

| ID | User Story | Acceptance Criteria |
|---|---|---|
| UXA-01 | **Auto-Reveal Flattened File** | As a user, after I click "Flatten Context," I want the newly created `flattened_repo.md` file to be automatically selected and revealed in the file tree, so I can immediately open it without searching. | - After the `flattened_repo.md` file is created or updated, it becomes the `activeFile` in the Data Curation view. <br> - The tree view automatically expands and scrolls to show the `flattened_repo.md` file. |
| UXA-02 | **Contextual Selected Count** | As a user, when I have files selected inside a folder, I want to see a count of how many files are selected within that folder, displayed next to the folder's total file count, so I can understand my selection density at a glance. | - Next to a folder's total file count, a secondary count in parentheses `(x)` appears. <br> - `x` represents the number of files within that folder (recursively) that are part of the current selection. <br> - This count only appears if `x` is greater than 0 and less than the folder's total file count. |
| UXA-03 | **Minimize Selection Panel** | As a user, once I've made my selection, I want to minimize the "Selected Items" list to reclaim vertical space while keeping the "Flatten Context" button accessible, so I can focus on the main file tree. | - A minimize/expand button is present in the "Selected Items" panel header. <br> - Clicking it collapses the list of selected files, but the panel's header, toolbar, and the main footer (with the Flatten button) remain visible. <br> - Clicking it again expands the list to its previous state. |
| UXA-04 | **Auto-Add New Files** | As a user, I want to enable an "auto-add" mode where any new file I create in the workspace is automatically added to my current selection, so I don't have to break my coding flow to manually check the new file. | - A toggle button or checkbox exists in the UI to enable/disable "Auto-Add New Files" mode. <br> - When enabled, any file created in the workspace is automatically added to the `selectedFiles` list. <br> - The file system watcher is responsible for detecting file creation and triggering this logic. <br> - The state of this toggle is persisted in the workspace state. |
| UXA-05 | **Resizable Panels** | As a user, I want to be able to click and drag the divider between the main file tree and the "Selected Items" panel to vertically resize them, so I can customize the layout to my needs. | - The horizontal divider between the two main panels is a draggable handle. <br> - Dragging it up or down resizes both panels accordingly, while respecting their minimum and maximum height constraints. |
| UXA-06 | **Token Count Color Coding** | As a user, I want the items in the "Selected Items" list to be color-coded based on their token count, so I can immediately identify potentially problematic large files. | - List items have a background color that corresponds to their token count. <br> - **(C73 Update)** The color scheme indicates increasing risk: <br> - **0-8k tokens:** Green (Low risk). <br> - **8k-10k tokens:** Yellow (Slight risk). <br> - **10k-12k tokens:** Orange (Moderate risk). <br> - **12k+ tokens:** Red (High risk). <br> - A tooltip explains the color coding and associated risk. |
| UXA-07 | **Auto-Uncheck Empty Folder** | As a user, when I remove the last selected file from a folder via the "Selected Items" panel, I want the parent folder to become unchecked in the main file tree, so the UI state remains consistent. | - When a file removal action is processed, the logic checks if any sibling files of the removed file are still selected. <br> - If no siblings remain selected under a parent folder that was previously checked, that parent folder is also removed from the selection. |


## 3. Technical Implementation Plan

-   **Auto-Reveal (UXA-01):**
    -   Create a new IPC channel `ServerToClientChannel.FocusFile`.
    -   Backend (`flattener.service.ts`): After writing the file, send the `FocusFile` message with the file's absolute path. A small delay might be needed to allow the file watcher to trigger a UI refresh first.
    -   Frontend (`view.tsx`): Listen for `FocusFile` and call `setActiveFile` with the received path. The existing `useEffect` in `TreeView.tsx` will handle the reveal.
-   **Selected Count (UXA-02):**
    -   Frontend (`FileTree.tsx`): Implement a memoized recursive function that traverses a `FileNode`'s children and checks against the `selectedFiles` list to calculate the selected count. Render this count conditionally in the `renderFileNodeContent` function. This is a frontend-only calculation.
-   **Minimize Panel (UXA-03):**
    -   Frontend (`view.tsx`): Add a new state, `isSelectionListMinimized`.
    -   Frontend (`SelectedFilesView.tsx`): Add a button to the header that calls a prop function to toggle this state. Conditionally render the `<ul>` based on the state.
-   **Auto-Add Files (UXA-04):**
    -   Frontend (`view.tsx`): Add a toggle button and a state for this mode. When toggled, send an IPC message to the backend to update its persisted state.
    -   Backend (`selection.service.ts`): Store the toggle's state in `workspaceState`.
    -   Backend (`fs.service.ts`): The `onDidCreate` handler in the file watcher will check this state. If true, it will get the current selection, add the new file's path, and save it back using `selection.service.ts` before triggering the UI refresh.
-   **Token Count Coloring (UXA-06):**
    -   Frontend (`SelectedFilesView.tsx`): Create a helper function `getTokenBackgroundColor(tokenCount)` that returns an HSL color string based on the specified token ranges.
    -   Apply the returned color to the `<li>` element's `style` prop.
    -   Add a `title` attribute to the `<li>` to explain the risk associated with the token count.
-   **Auto-Uncheck Folder (UXA-07):**
    -   Frontend (`FileTree.utils.ts`): The `removePathsFromSelected` function will be enhanced. After calculating the new effective selection set, it will need to perform a check. For each removed path, it can traverse up the tree to find its parent directories. For each parent, it can check if any of its other children are still in the effective selection set. If not, the parent should not be included in the final compressed path list. This is complex and requires careful state calculation.
</file_artifact>

<file path="src/Artifacts/A21. DCE - Phase 1 - Feature Drift Analysis vs. VS Code Explorer.md">
# Artifact A21: DCE - Phase 1 - Feature Drift Analysis vs. VS Code Explorer
# Date Created: C28
# Author: AI Model
# Updated on: C39 (Update Keyboard Nav status to Complete)

- **Key/Value for A0:**
- **Description:** A comparative analysis documenting the functional and behavioral differences between the DCE custom file view and the native VS Code Explorer to guide future development and feature parity.
- **Tags:** feature plan, analysis, drift, ux, vs code explorer, parity

## 1. Overview & Goal

The primary goal of the Data Curation Environment (DCE) is to enhance, not replace, the core developer workflow. To minimize friction and maximize adoption, its custom file view must achieve a high degree of feature parity with the native VS Code Explorer. This document analyzes the "drift," or the set of features present in the native Explorer that are currently missing from the DCE view. This analysis will serve as a backlog and prioritization guide for future development cycles.

## 2. Feature Comparison Matrix

| Feature Category            | Native VS Code Explorer         | DCE (as of C39)        | Status & Notes                                                                                                                                              |
| --------------------------- | ------------------------------- | ---------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **File Display**            |                                 |                        |                                                                                                                                                             |
| Hierarchical Tree           |                               |                      | **Complete.** Core functionality is present.                                                                                                                |
| File/Folder Icons           |                               |                      | **Complete.** Icons match file types.                                                                                                                       |
| Active File Highlighting    |                               |                      | **Complete.**                                                                                                                                               |
| Problems/Git Status         |  (Colors, badges)             |                      | **Complete.** Displays Git status colors/badges and problem indicators.                                                                                     |
| **Selection**               |                                 |                        |                                                                                                                                                             |
| Single-Click (Files)        |  Opens file                   |  Opens & Selects file| **Complete.** Aligns with native behavior.                                                                                                                  |
| Single-Click (Folders)      |  Expands/Collapses            |  Expands/Collapses   | **Complete.** |
| Multi-Select (Ctrl)         |                               |                      | **Complete.**                                                                                                                                               |
| Multi-Select (Shift)        |  (Selects rows)               |  (Selects rows)      | **Complete.**                                                                                                                                               |
| Select All (Ctrl+A)         |  (In focused list)            |                      | **Complete.** The focus-stealing bug is now resolved, making `Ctrl+A` in the "Selected Items" list reliable.                                           |
| **Interaction**             |                                 |                        |                                                                                                                                                             |
| Drag and Drop               |  (Move files/folders)         |                      | **Complete.**                                                                                                                                               |
| Right-Click Context Menu    |  (Extensive options)          |  (Basic + List actions) | **Partial.** DCE has basic file ops. Added "Select All" for lists in C37. Missing advanced options like `Open in Integrated Terminal`, `Compare...`.       |
| Keyboard Navigation         |  (Arrows, Enter, Space)       |                      | **Complete (C39).** Arrow keys, Enter, and Spacebar now function as expected. The focus-stealing bug has been resolved.                                   |
| Inline Rename               |  (F2 or slow double-click)    |                      | **Complete.** |
| **File Operations**         |                                 |                        |                                                                                                                                                             |
| New File / Folder           |                               |                      | **Complete.** |
| Delete (to Trash)           |                               |                      | **Complete.** |
| Cut / Copy / Paste          |                               |                      | **Missing.** Standard file system operations are not yet implemented.                                                                                       |
| Undo / Redo (Ctrl+Z)        |                               |                      | **Missing.** A critical feature for parity. Requires an action stack to reverse moves/deletes. Planned in A27.                                            |
| **Search & Filter**         |                                 |                        |                                                                                                                                                             |
| Filter by Name              |  (Start typing)               |                      | **Complete.**                                                                                                                                               |

## 3. High-Priority Features for Future Cycles

Based on the analysis, the following features represent the most significant gaps in user experience and should be prioritized:

1.  **Undo / Redo (Ctrl+Z):** The ability to undo a file move or deletion is a fundamental expectation for any file manager and its absence is a major point of friction.
2.  **Cut / Copy / Paste:** Adding standard clipboard operations for files is a key missing piece of basic file management.
3.  **Expanded Context Menu:** Adding more of the native right-click options, especially `Open in Integrated Terminal` and `Compare Selected`, would significantly reduce the need for users to switch back to the native Explorer.
</file_artifact>

<file path="src/Artifacts/A22. DCE - Phase 1 - Search & Filter Feature Plan.md">
# Artifact A22: DCE - Phase 1 - Search & Filter Feature Plan
# Date Created: C29
# Author: AI Model

- **Key/Value for A0:**
- **Description:** Outlines the requirements and implementation for a search bar to filter the main file tree view by file or folder name.
- **Tags:** feature plan, search, filter, tree view, ux, phase 1

## 1. Overview & Goal

To improve navigation and usability in large projects, this feature introduces a search and filter capability to the Data Curation Environment. The goal is to allow users to quickly find specific files or folders by typing a part of their name, mirroring the incremental filtering behavior of the native VS Code Explorer.

## 2. User Story

| ID | User Story | Acceptance Criteria |
|---|---|---|
| SF-01 | **Filter File Tree** | As a user working in a large repository, I want to type in a search bar to filter the file tree in real-time, so I can quickly locate the files and folders I need without extensive scrolling. | - A search icon/button is present in the main header toolbar. <br> - Clicking the icon reveals a text input field. <br> - As I type into the input field, the file tree dynamically updates to show only the files and folders whose names match the search string. <br> - All parent directories of a matching file are also shown to preserve the tree structure. <br> - The search is case-insensitive. <br> - Clearing the search input restores the full, unfiltered tree. |

## 3. Technical Implementation Plan

1.  **Frontend - UI (`view.tsx`, `view.scss`):**
    *   Add a new state variable to the main `App` component: `const [filterTerm, setFilterTerm] = useState('');`.
    *   Add a search icon (`VscSearch`) to the header toolbar. A second state, `isSearchVisible`, can be used to toggle the visibility of the input field when the icon is clicked.
    *   The search `<input>` element's `value` will be bound to `filterTerm`, and its `onChange` handler will call `setFilterTerm`.

2.  **Frontend - Filtering Logic (`FileTree.tsx`):**
    *   The `FileTree` component will receive the `filterTerm` as a new prop.
    *   A `useMemo` hook will be used to compute the filtered tree whenever the source `data` or the `filterTerm` changes.
    *   This hook will call a new recursive filtering function:
        ```typescript
        function filterTree(nodes: FileNode[], term: string): FileNode[] {
            if (!term) return nodes;
            const lowerCaseTerm = term.toLowerCase();

            return nodes.reduce((acc, node) => {
                if (node.name.toLowerCase().includes(lowerCaseTerm)) {
                    // If the node itself matches, include it and all its children
                    acc.push(node);
                    return acc;
                }

                if (node.children) {
                    // If the node is a directory, filter its children
                    const filteredChildren = filterTree(node.children, term);
                    if (filteredChildren.length > 0) {
                        // If any children match, include the parent with its filtered children
                        acc.push({ ...node, children: filteredChildren });
                    }
                }
                return acc;
            }, [] as FileNode[]);
        }
        ```
    *   The `TreeView` component will then be rendered with this new, filtered data.

3.  **State Management:**
    *   The filtering is a pure frontend operation. No backend changes or IPC communication are required for this feature.
    *   The search term is transient UI state and does not need to be persisted.
</file_artifact>

<file path="src/Artifacts/A23. DCE - Phase 1 - Advanced Interactions (Keyboard & Drag-Drop) Plan.md">
# Artifact A23: DCE - Phase 1 - Advanced Interactions (Keyboard & Drag-Drop) Plan
# Date Created: C29
# Author: AI Model
# Updated on: C71 (Add Delete key functionality)

- **Key/Value for A0:**
- **Description:** Details the requirements for implementing full keyboard navigation and drag-and-drop file/folder operations within the main file tree.
- **Tags:** feature plan, keyboard navigation, drag and drop, file operations, accessibility, ux, phase 1

## 1. Overview & Goal

To achieve true feature parity with the native VS Code Explorer and cater to power users, the Data Curation Environment must support advanced interactions. This plan outlines the requirements for two major features: full keyboard navigation for accessibility and speed, and drag-and-drop functionality for intuitive file system manipulation.

## 2. User Stories

| ID | User Story | Acceptance Criteria |
|---|---|---|
| AI-01 | **Keyboard Navigation** | As a power user, I want to navigate the file tree using only my keyboard, so I can find, select, and manage files without taking my hands off the keyboard. | - Arrow Up/Down keys move the focus between visible nodes. <br> - Arrow Right on a collapsed folder expands it. <br> - Arrow Left on an open folder collapses it. <br> - `Enter` key opens the focused file or toggles expansion. <br> - `Spacebar` toggles the checkbox of the focused node. <br> - **(Bug C68):** When a file within a checked parent folder is focused, pressing spacebar incorrectly de-selects a higher-level directory instead of just the single file. |
| AI-02 | **Internal Drag-and-Drop** | As a user, I want to be able to drag a file or folder and drop it into another folder within the DCE view to move it, so I can reorganize my project intuitively. | - Clicking and dragging a file or folder initiates a drag operation. <br> - Dragging over a folder highlights it as a potential drop target. <br> - Dropping a file/folder onto another folder moves the dragged item. <br> - **Validation:** A folder cannot be dropped into itself or one of its own descendants. |
| AI-03 | **External Drag-and-Drop** | As a user, I want to drag a file (e.g., a PDF) from my computer's file explorer or the VS Code Explorer and drop it into a folder in the DCE view to add it to my project, so I can quickly incorporate new assets. | - Dragging a file from the OS or VS Code Explorer and dropping it onto a folder in the DCE view copies that file into the target folder in the workspace. <br> - The file tree automatically refreshes to show the newly added file. |
| AI-04 | **Delete Key** | As a user, I want to press the `Delete` key on my keyboard when an item is focused in the file tree to delete it, so I can manage files quickly without using the mouse. | - Focusing an item in the main file tree and pressing `Delete` initiates the delete workflow. <br> - It uses the same backend logic as the context menu, including the confirmation dialog and moving the item to the trash. |
| AI-05 | **Copy & Paste** | As a user, I want to use `Ctrl+C` and `Ctrl+V` to copy and paste files/folders within the tree, so I can use standard keyboard shortcuts for file duplication. | - `Ctrl+C` on a focused item copies its path to an internal clipboard. <br> - `Ctrl+V` on another item pastes the copied item into that location. <br> - Handles name collisions gracefully (e.g., `file-copy.ts`). |
| AI-06 | **Hover to Expand Folder** | As a user dragging a file, when I hover over a collapsed folder for a moment, I want it to automatically expand, so I can drop the file into a nested subdirectory without having to cancel the drag operation. | - During a drag operation, hovering over a collapsed folder for ~500ms triggers its expansion. <br> - Moving the mouse away from the folder before the timer completes cancels the expansion. |

## 3. Implementation Status & Notes

### Keyboard Navigation & Internal Drag-Drop
These features are stable and complete, with the exception of the noted spacebar bug.

### External Drag and Drop (De-Prioritized as of C61)

-   **Status:** **On Hold.**
-   **Summary of Attempts:** Multiple approaches were attempted between C54 and C60 to implement file drops from outside the webview (e.g., from the OS or the native VS Code Explorer).
    1.  **Standard HTML5 API (`dataTransfer.files`):** This worked for drops from the OS but failed for drops from the VS Code Explorer, as the `files` collection is empty for security reasons.
    2.  **VS Code URI-based API (`text/uri-list`):** This approach correctly captured the URI of the file being dropped from the VS Code Explorer. The URI was passed to the backend, which then used the `vscode.workspace.fs.copy()` API.
-   **Root Cause of Failure:** Despite correctly implementing the URI-based approach, the drag-and-drop events (`onDrop`, `onDragOver`) failed to fire reliably or at all when dragging from an external source into the webview. The root cause appears to be a complex interaction with VS Code's webview security model, event propagation, and possibly the Workspace Trust feature, which could not be resolved within a reasonable number of cycles.
-   **Path Forward:** This feature is now considered a **tertiary, long-term research goal**. The core functionality of the extension is not dependent on it. For now, users can add new files using the native VS Code Explorer, the "New File..." button in the DCE toolbar, or by simply creating the file, which will then appear on refresh.
</file_artifact>

<file path="src/Artifacts/A24. DCE - Selection Paradigm Terminology.md">
# Artifact A24: DCE - Selection Paradigm Terminology
# Date Created: C29
# Author: AI Model

- **Key/Value for A0:**
- **Description:** A document to clarify the terminology used within the project to distinguish between different types of user selections (e.g., "checking" for flattening vs. "selecting" for actions).
- **Tags:** documentation, terminology, selection, checking, design

## 1. Problem Statement

During development and feedback cycles, the term "select" has been used ambiguously, leading to confusion. It has been used to describe two distinct user actions with different purposes:
1.  Clicking a checkbox to include a file/folder in the context to be flattened.
2.  Clicking a file/folder row (with optional Ctrl/Shift modifiers) to highlight it for a contextual action (e.g., Rename, Delete).

This ambiguity makes feature requests and technical discussions difficult. The goal of this document is to establish clear, consistent terminology for use in all future artifacts, code, and discussions.

## 2. Defined Terminology

Henceforth, the following terms will be used to describe user interactions with the file tree:

### **Checking / Unchecking**

*   **Action:** Clicking the `checkbox` next to a file or folder item.
*   **Purpose:** To include or exclude an item from the set of files that will be processed by the **"Flatten Context"** action.
*   **UI State:** A visible checkmark (``), indeterminate mark (`-`), or empty state in the checkbox.
*   **State Variable (conceptual):** `checkedPaths: Set<string>`
*   **User Phrasing:** "I **checked** the `src` folder."

---

### **Selecting / Highlighting**

*   **Action:** Single-clicking a file/folder row. Using `Ctrl+Click` or `Shift+Click` to highlight multiple rows.
*   **Purpose:** To designate one or more items as the target for a contextual action, such as those in the **right-click context menu** (e.g., Rename, Delete, Copy Path). This is also used to identify the "active" item for operations like "New File".
*   **UI State:** A visual highlight on the entire row, typically matching the VS Code theme's selection color.
*   **State Variable (conceptual):** `selectedPaths: Set<string>`
*   **User Phrasing:** "I **selected** three files and then right-clicked to delete them."

---

### **Focusing**

*   **Action:** Navigating the tree with keyboard arrow keys.
*   **Purpose:** To move a visual indicator (a focus ring or subtle highlight) to an item, making it the active target for keyboard actions (`Enter` to open, `Spacebar` to check/uncheck).
*   **UI State:** A focus outline around the item row.
*   **State Variable (conceptual):** `focusedPath: string | null`
*   **User Phrasing:** "The `README.md` file is currently **focused**."

## 3. Summary Table

| Term | Action | Purpose | UI Cue | State Name |
| :--- | :--- | :--- | :--- | :--- |
| **Check** | Click checkbox | Include in Flatten Context | Checkmark | `checkedPaths` |
| **Select** | Click / Ctrl+Click / Shift+Click row | Target for Context Menu Actions | Row highlight | `selectedPaths` |
| **Focus** | Keyboard navigation | Target for Keyboard Actions | Focus ring | `focusedPath` |

By adhering to this terminology, we can ensure clarity in communication and precision in our technical implementation.
</file_artifact>

<file path="src/Artifacts/A25. DCE - Phase 1 - Git & Problems Integration Plan.md">
# Artifact A25: DCE - Phase 1 - Git & Problems Integration Plan
# Date Created: C30
# Author: AI Model
# Updated on: C184 (Reflect new decoration-based update architecture)

- **Key/Value for A0:**
- **Description:** Outlines the user stories and technical approach for integrating Git status indicators and VS Code Problem Diagnostics into the custom file tree.
- **Tags:** feature plan, git, problems, diagnostics, ux, phase 1

## 1. Overview & Goal

To achieve full feature parity with the native VS Code Explorer and provide critical context to the user, the Data Curation Environment (DCE) file tree must display information about a file's Git status and any associated problems (errors/warnings). The goal of this feature is to overlay this diagnostic and source control information directly onto the file tree, allowing users to make more informed decisions during context curation.

## 2. User Stories

| ID | User Story | Acceptance Criteria |
|---|---|---|
| GP-01 | **Git Status Coloring** | As a user, I want to see files and folders colored according to their Git status (e.g., green for new, yellow for modified, gray for ignored), so I can quickly identify changes in my workspace. | - The file/folder name text color in the tree view changes based on its Git status. <br> - Colors should align with the user's current VS Code theme for Git decorations. <br> - A new, untracked file is green. <br> - A modified file is yellow/orange. <br> - A deleted file (in some views) is red. <br> - An ignored file is gray. |
| GP-02 | **Git Status Badges** | As a user, I want to see a letter badge next to a file's name indicating its specific Git status (e.g., 'U' for untracked, 'M' for modified), so I have an unambiguous indicator of its state. | - A small, colored badge with a letter appears to the right of the file name. <br> - 'U' for Untracked. <br> - 'M' for Modified. <br> - 'D' for Deleted. <br> - 'A' for Added. <br> - 'C' for Conflicted. <br> - The badge has a tooltip explaining the status (e.g., "Modified"). |
| GP-03 | **Problem Indicator Badges** | As a user, I want to see a badge with a count of errors and warnings on files and their parent folders, so I can immediately identify parts of the codebase that have issues. | - A file with problems displays a badge with the number of errors (e.g., in red). <br> - A folder recursively aggregates the problem counts of its children and displays a summary badge. <br> - Tooltips on the badge provide a breakdown (e.g., "2 Errors, 3 Warnings"). <br> - The file name may also be colored (e.g., red for errors, yellow for warnings) to match the Problems panel. |

## 3. Technical Implementation Plan (C184 Revision)

### Phase 1: Data Gathering (Backend)
The backend is responsible for collecting Git and Problem data and sending it to the client.

-   **Git Status (`file-tree.service.ts`):** A `getGitStatusMap()` method builds a `Map<string, string>` of file paths to their status character by querying the Git API.
-   **Problems (`file-tree.service.ts`):** A `getProblemCountsMap()` method builds a map of file paths to their error/warning counts by querying `vscode.languages.getDiagnostics()`.

### Phase 2: Decoupled Refresh Architecture
To solve the FTV flashing bug, structural refreshes are now decoupled from decoration refreshes.

1.  **Structural Refresh (File Watcher):** The `FileSystemWatcher` is the sole trigger for a full tree rebuild (`ForceRefresh`). This is for file creations, deletions, and renames.
2.  **Decoration Refresh (Git API):** The overly sensitive `repo.state.onDidChange` listener no longer triggers a full refresh. Instead, it triggers a new, lightweight update.
    *   **New IPC Channel:** `ServerToClientChannel.UpdateDecorations` is created to carry the Git status map and the problem map to the client.
    *   **New Backend Method:** A `triggerDecorationsUpdate` method in `file-tree.service.ts` is called by the Git listener. It gathers the latest decoration data and sends it over the new channel.

### Phase 3: Rendering (Frontend)
The frontend receives the file tree structure and decoration data separately and combines them at render time.

-   **State Management (`context-chooser.view/view.tsx`):**
    *   The component maintains the `files` (tree structure), `problemMap`, and a new `gitStatusMap` in its state.
    *   A message handler for `UpdateDecorations` updates the `problemMap` and `gitStatusMap` state variables.
-   **Rendering (`FileTree.tsx`):**
    *   The component receives the `gitStatusMap` and `problemMap` as props.
    *   The `gitStatus` and `problemCounts` properties are **removed** from the `FileNode` type, as this data is no longer static.
    *   When rendering a file node, the component looks up the node's `absolutePath` in the `gitStatusMap` and `problemMap` props to get the most current decoration data.
    *   This allows the Git and problem indicators to update frequently without the expensive process of rebuilding the entire tree structure.
</file_artifact>

<file path="src/Artifacts/A26. DCE - Phase 1 - File System Traversal & Caching Strategy.md">
# Artifact A26: DCE - Phase 1 - File System Traversal & Caching Strategy
# Date Created: C31
# Author: AI Model
# Updated on: C152 (Update node_modules handling)

- **Key/Value for A0:**
- **Description:** Documents the root cause of the folder visibility bug and outlines the new strategy of using recursive directory traversal instead of `findFiles` to build a complete and accurate file system map. Also defines the performance-oriented handling of `node_modules`.
- **Tags:** bug fix, file system, traversal, refresh, cache, architecture, performance

## 1. Overview & Goal

This document addresses a critical bug where newly created empty folders do not appear in the Data Curation file tree. It also defines the strategy for handling large directories like `node_modules` to ensure the UI remains performant. The goal is to define a robust file system traversal strategy that guarantees an accurate and fast representation of the workspace.

## 2. Root Cause Analysis (RCA) - Folder Visibility

-   **Symptom:** Creating a new, empty folder in the workspace does not result in that folder appearing in the DCE file tree, even after a refresh.
-   **Root Cause:** The file discovery mechanism was using `vscode.workspace.findFiles("**/*", ...)`. This API is optimized to return a flat list of **files** and does **not** return directories, especially empty ones. When the tree was reconstructed from this file-only list, empty directories were invisible.

## 3. New Traversal Strategy

To resolve this, the reliance on `vscode.workspace.findFiles` for building the tree structure has been replaced with a manual, recursive directory traversal.

### 3.1. Technical Implementation Plan

1.  **Primary API:** The new strategy is centered around `vscode.workspace.fs.readDirectory(uri)`. This function returns an array of `[name, fileType]` tuples for all immediate children of a given directory.
2.  **Recursive Function:** A `private async _traverseDirectory(uri)` method in `file-tree.service.ts` implements the recursive scan. It iterates through directory contents, creating `FileNode` objects and recursively calling itself for subdirectories.

## 4. Performance Strategy for `node_modules` (C152)

-   **Problem:** Scanning `node_modules` for file and token counts is extremely slow and provides no value for context curation. However, completely hiding it can be confusing if a user needs to reference its structure.
-   **New Strategy:** The `node_modules` directory will be **visible but not counted**.
-   **Implementation (`_traverseDirectory`):**
    1.  When the traversal encounters a directory named `node_modules`, it will **not** skip it. It will create a `FileNode` for it.
    2.  However, it will **not** recursively call `_traverseDirectory` on its contents.
    3.  The `FileNode` for `node_modules` will be returned with an empty `children` array and `fileCount`/`tokenCount` set to 0.
-   **Benefit:** This approach makes the UI load instantly while still showing the `node_modules` folder in the tree, achieving the best of both worlds. The `flattener.service.ts` will continue to explicitly ignore this directory to prevent its inclusion in the flattened output.

## 5. Benefits of the New Approach

-   **Accuracy:** The method builds a true representation of the file system, including empty directories.
-   **Performance:** By special-casing `node_modules`, the initial tree scan remains fast and responsive.
-   **Control:** It gives us full control over the traversal, allowing for sophisticated filtering and caching.
</file_artifact>

<file path="src/Artifacts/A27. DCE - Phase 1 - Undo-Redo Feature Plan.md">
# Artifact A27: DCE - Phase 1 - Undo-Redo Feature Plan
# Date Created: C35
# Author: AI Model
# Updated on: C12 (Add requirement for preserving selection state)

- **Key/Value for A0:**
- **Description:** Details the requirements for implementing an undo/redo stack for file system operations (move, delete) performed within the DCE view, to achieve parity with the native explorer's Ctrl+Z functionality.
- **Tags:** feature plan, undo, redo, ctrl+z, file operations, ux, phase 1

## 1. Overview & Goal

A critical feature for achieving parity with the native VS Code Explorer is the ability to undo file system operations. Users expect to be able to press `Ctrl+Z` to revert an accidental file move or deletion. The goal of this feature is to implement a robust undo/redo stack for file operations initiated from within the Data Curation Environment view.

**Status (C10):** In Progress.

## 2. User Stories

| ID | User Story | Acceptance Criteria |
|---|---|---|
| UR-01 | **Undo File Move** | As a user, after I drag and drop a file to a new location, I want to be able to press `Ctrl+Z` to move it back to its original location, so I can easily correct mistakes. | - Performing a file/folder move pushes an "action" object onto an undo stack. <br> - Pressing `Ctrl+Z` while the DCE view is focused pops the last action and reverses it (moves the file back). <br> - The file tree updates to reflect the reversed move. |
| UR-02 | **Undo File Deletion** | As a user, after I delete a file or folder (to the trash), I want to be able to press `Ctrl+Z` to restore it, so I don't lose work accidentally. | - Deleting a file/folder pushes an "action" object onto the undo stack. <br> - Pressing `Ctrl+Z` reverses the deletion. Since we use `useTrash: true`, this might be handled by a native VS Code command, or we may need to implement a restore from trash mechanism if possible. |
| UR-03 | **Redo Operation** | As a user, after I undo an action, I want to be able to press `Ctrl+Y` (or `Ctrl+Shift+Z`) to redo the action, so I can toggle between states. | - Undoing an action moves it from the undo stack to a redo stack. <br> - Pressing `Ctrl+Y` pops the last action from the redo stack and re-applies it. <br> - The file tree updates accordingly. |
| UR-04 | **Preserve Selection State** | As a user, if I move a file that is *not* checked for flattening, and then I undo that move, I expect the file to still be unchecked when it returns to its original location, so its selection state is preserved. | - The "auto-add new files" feature must not incorrectly re-check a file that is being restored via an undo operation. |

## 3. Technical Implementation Plan

This feature will be implemented primarily on the backend to manage the file system state and the action history.

1.  **Action Stack Service (New Backend Service):**
    *   Create a new service, `action.service.ts`, to manage the undo and redo stacks.
    *   It will contain two arrays: `undoStack: Action[]` and `redoStack: Action[]`.
    *   An `Action` will be a typed object, e.g., `{ type: 'move', payload: { from: string, to: string } }` or `{ type: 'delete', payload: { path: string } }`.
    *   It will expose methods: `push(action: Action)`, `undo()`, and `redo()`.
        *   `push`: Adds an action to `undoStack` and clears `redoStack`.
        *   `undo`: Pops from `undoStack`, performs the reverse operation, and pushes the original action to `redoStack`.
        *   `redo`: Pops from `redoStack`, performs the original operation, and pushes it back to `undoStack`.

2.  **Integrate with `file-operation.service.ts`:**
    *   The `handleMoveFileRequest` and `handleFileDeleteRequest` methods in `file-operation.service.ts` will be updated.
    *   *Before* performing the file system operation, they will create the corresponding `Action` object.
    *   *After* the operation succeeds, they will call `Services.actionService.push(action)`.

3.  **IPC Channels and Commands:**
    *   Create two new `ClientToServerChannel` entries: `RequestUndo` and `RequestRedo`.
    *   The frontend (`TreeView.tsx`) will have a top-level `onKeyDown` handler. When `Ctrl+Z` or `Ctrl+Y` is detected, it will send the appropriate IPC message to the backend.
    *   Create two new backend commands, `dce.undo` and `dce.redo`, which will be called by the message handlers. These commands will simply call `Services.actionService.undo()` and `Services.actionService.redo()`.

4.  **Reverse Operations Logic (`action.service.ts`):**
    *   The `undo()` method will contain the logic to reverse actions.
    *   **Move:** To undo a move from `A` to `B`, it calls `vscode.workspace.fs.rename(B, A)`.
    *   **Delete:** Undoing a delete is more complex. Since we use `useTrash: true`, VS Code might not expose a direct API to "un-delete". Research is needed. The simplest approach might be to leverage a built-in command like `files.restoreFromTrash` if it can be targeted, or we may need to inform the user to use the native Explorer's undo for deletions. For a first pass, we might only support undo for **move** operations.
    *   **Selection State Preservation (UR-04):** Before performing the reverse `rename`, the `undo` method will call a new method on the `FileOperationService` to temporarily add the original file path to an "ignore" list for the "auto-add new files" feature. This prevents the file watcher from incorrectly re-checking the file when it reappears.

5.  **Frontend Focus:**
    *   The main `TreeView` component needs to be focusable (`tabIndex="0"`) to capture the keyboard shortcuts. The `onKeyDown` handler will check for `event.ctrlKey` and the specific key (`z` or `y`) and then send the IPC message.
</file_artifact>

<file path="src/Artifacts/A28. DCE - Packaging and Distribution Guide.md">
# Artifact A28: DCE - Packaging and Distribution Guide
# Date Created: C43
# Author: AI Model
# Updated on: C164 (Add critical step for including static assets)

- **Key/Value for A0:**
- **Description:** Provides a step-by-step guide on how to package the extension into a `.vsix` file for beta testing and distribution.
- **Tags:** packaging, distribution, vsix, vsce, deployment

## 1. Overview

This document provides instructions on how to package the Data Curation Environment (DCE) extension into a single `.vsix` file. This file is the standard format for distributing and installing VS Code extensions, making it easy to share with beta testers or submit to the official marketplace.

The primary tool used for this process is `vsce` (Visual Studio Code Extensions), the official command-line tool for managing extensions.

## 2. Prerequisites

1.  **Node.js and npm:** You must have Node.js and npm installed.
2.  **Install `vsce`:** If you haven't already, install `vsce` globally by running the following command in your terminal:
    ```bash
    npm install -g @vscode/vsce
    ```

## 3. Packaging the Extension

Follow these steps in your terminal from the root directory of the DCE project (e.g., `C:\Projects\DCE`):

### Step 0: Update `package.json` (Important!)

Before packaging, ensure your `package.json` file is complete. The `vsce` tool will warn you if important fields are missing. At a minimum, make sure the following fields are present and correct:

-   `publisher`: Your publisher ID from the VS Code Marketplace.
-   `repository`: An object pointing to your source code repository (e.g., on GitHub).
-   `homepage`: A link to your project's homepage.
-   `bugs`: A link to your project's issue tracker.
-   `version`: Increment the version number for each new release.

### Step 1: Verify Static Asset Handling (CRITICAL)

The extension's backend code runs from the compiled `dist` directory. Any static files that the backend needs to read at runtime (like our `T*` template artifacts in `src/Artifacts`) **must be copied into the `dist` directory** during the build process.

-   **Check `webpack.config.js`:** Ensure the `CopyPlugin` includes a rule to copy `src/Artifacts` to the `dist` folder.
    ```javascript
    // Example rule in CopyPlugin patterns:
    { from: "src/Artifacts", to: "Artifacts" }
    ```
-   **Check Backend Code:** Ensure any code that reads these files (e.g., `prompt.service.ts`) constructs the path relative to the final `dist` directory (e.g., `path.join(context.extensionPath, 'dist', 'Artifacts', ...)`).

### Step 2: Ensure Dependencies are Installed

Make sure your project's dependencies are up to date.

```bash
npm install
```

### Step 3: Create a Production Build

Before packaging, it's essential to create an optimized production build of the extension. Our `package.json` already has a script for this.

```bash
npm run package
```

This command runs webpack in `production` mode, which minifies the code and removes source maps, resulting in a smaller and faster extension. It will update the files in the `/dist` directory.

### Step 4: Run the Packaging Command

Once the production build is complete, you can run the `vsce` packaging command.

```bash
vsce package
```

This command will:
1.  Read the `package.json` manifest file.
2.  Gather all the necessary files, respecting the rules in `.vscodeignore`.
3.  Bundle everything into a single file named `data-curation-environment-X.X.X.vsix`, where `X.X.X` is the version number from `package.json`.

You will see the `.vsix` file in the root of your project directory.

## 4. Sharing and Installing the `.vsix` File

### For Beta Testers:

1.  **Share the File:** You can send the generated `.vsix` file directly to your testers (e.g., via email, Slack, or a shared drive).

2.  **Installation Instructions:** Your testers can install it in VS Code by following these steps:
    *   Open VS Code.
    *   Go to the **Extensions** view (Ctrl+Shift+X).
    *   Click the **...** (More Actions) button at the top of the Extensions view.
    *   Select **"Install from VSIX..."**.
    *   In the file dialog that opens, navigate to and select the `.vsix` file you provided.
    *   VS Code will install the extension and prompt for a reload.
</file_artifact>

<file path="src/Artifacts/A29. DCE - Phase 1 - Binary and Image File Handling Strategy.md">
# Artifact A29: DCE - Phase 1 - Binary and Image File Handling Strategy
# Date Created: C46
# Author: AI Model
# Updated on: C47 (Richer metadata format and JSON output)

- **Key/Value for A0:**
- **Description:** Defines the strategy for handling binary files; they can be checked, but only their metadata (path, size) is included in the flattened output, not their content.
- **Tags:** feature plan, binary, image, metadata, flatten, phase 1

## 1. Overview & Goal

During beta testing, a use case emerged for including information about binary files (like images) in the flattened context without including their raw, unreadable content. The goal of this strategy is to allow users to select *any* file, but to intelligently handle non-text files during the flattening process to prevent corrupting the output while still capturing useful metadata.

## 2. Problem Statement

-   **Initial Problem:** Flattening a folder containing images (`.png`, `.gif`) resulted in binary gibberish being written to `flattened_repo.md`.
-   **Initial Solution (C43):** Prevent selection of binary files by disabling their checkboxes.
-   **Refined Requirement (C46):** The user realized they *do* want to capture the existence and properties of these files (e.g., path, size) as part of the context, just not their content.
-   **Refined Requirement (C47):** The metadata should be richer, including name, directory, dimensions, and file type, and be presented in a structured format.

## 3. The New Strategy

The extension will now adopt a "metadata-only" approach for a predefined list of binary and image file types.

### 3.1. User Experience

1.  **Selection is Always Allowed:** All files in the file tree, regardless of type, will have an enabled checkbox. The user is free to check any file or folder.
2.  **File Opening:** Clicking on any file in the tree view will open it using VS Code's default viewer for that file type (e.g., text editor for `.ts`, image preview for `.png`).
3.  **Flattening Behavior is Differentiated:**
    *   When a **text file** is checked and the "Flatten Context" button is pressed, its full content is read and included in `flattened_repo.md`.
    *   When a **binary or image file** is checked, its content is **not** read. Instead, the flattener service will gather its metadata and include a structured, human-readable entry for it in `flattened_repo.md`.

### 3.2. Output Format for Binary Files

When a binary file is included, its entry in the `<files content>` section of `flattened_repo.md` will contain a `<metadata>` tag with a JSON object. Dimensions will be included on a best-effort basis for common formats (PNG, JPG, GIF).

**Example (with dimensions):**
```xml
<file path="public/images/logo.png">
<metadata>
{
  "name": "logo.png",
  "directory": "public/images",
  "fileType": "PNG",
  "sizeInBytes": 12345,
  "dimensions": {
    "width": 256,
    "height": 256
  }
}
</metadata>
</file>
```

**Example (without dimensions):**
```xml
<file path="assets/archive.zip">
<metadata>
{
  "name": "archive.zip",
  "directory": "assets",
  "fileType": "ZIP",
  "sizeInBytes": 102400
}
</metadata>
</file>
```

## 4. Technical Implementation Plan

1.  **File Opening (`fs.service.ts`):**
    *   The `handleOpenFileRequest` method will be updated to use `vscode.commands.executeCommand('vscode.open', uri)`. This delegates opening to VS Code, which correctly selects the appropriate viewer for any file type.

2.  **Backend Flattener Logic (`flattener.service.ts`):**
    *   A constant set of binary/image extensions will be defined.
    *   A new private method, `_parseImageMetadata`, will be added. It will read a file's buffer and attempt to parse dimensions for PNG, JPG, and GIF files, adapting logic from `flattenv2.js`.
    *   The `getFileStatsAndContent` method will be updated. When it encounters a binary file, it will:
        *   Call `_parseImageMetadata`.
        *   Collect the name, directory, type, size, and (if available) dimensions.
        *   Construct the formatted JSON string.
        *   Return a `FileStats` object where `content` is this JSON string, and `tokens` is 0.
</file_artifact>

<file path="src/Artifacts/A30. DCE - Phase 1 - PDF Handling and Virtualization Strategy.md">
# Artifact A30: DCE - Phase 1 - PDF Handling and Virtualization Strategy
# Date Created: C49
# Author: AI Model

- **Key/Value for A0:**
- **Description:** Defines the strategy for handling PDF files. Text is extracted on-demand and cached in memory for flattening, creating a "virtual" markdown file without modifying the user's workspace.
- **Tags:** feature plan, pdf, text extraction, virtualization, cache, phase 1

## 1. Overview & Goal

Users need to include the textual content of PDF documents in their flattened context. However, creating physical `.md` files for each PDF in the user's workspace is undesirable as it clutters their project. The goal of this strategy is to implement a "virtual file" system for PDFs. The extension will extract text from PDF files on demand and hold it in an in-memory cache, using this virtual content during the flattening process without ever writing new files to the user's disk.

## 2. User Stories

| ID | User Story | Acceptance Criteria |
|---|---|---|
| PDF-01 | **Include PDF Text in Context** | As a user, when I check a `.pdf` file in the DCE view, I want its textual content to be included in the `flattened_repo.md` file, so I can use documents and papers as context. | - Checking a `.pdf` file is allowed. <br> - The token count displayed for the PDF reflects its extracted text content, not its binary size. <br> - When flattened, the text from the PDF is included within a `<file>` tag, just like a normal text file. <br> - No `.md` file is ever created in the user's workspace. |
| PDF-02 | **Drag-Drop PDF to Add** | As a user, I want to drag a PDF from my computer's file explorer and drop it into the DCE view, so I can quickly add it to my project and include it in my context. | - Dropping a PDF file into a folder in the DCE view copies the PDF into that workspace directory. <br> - The new PDF immediately appears in the file tree. <br> - The user can then check it to include its text content for flattening. |

## 3. Technical Implementation Plan

1.  **Dependency:**
    *   The `pdf-parse` library will be added as a dependency to `package.json` to handle text extraction from PDF buffers.

2.  **Backend (`fs.service.ts`):**
    *   **In-Memory Cache:** A new private cache will be added: `private pdfTextCache = new Map<string, { text: string; tokenCount: number }>();`. This will store the extracted text and calculated token count, keyed by the PDF's absolute path.
    *   **New IPC Handler (`RequestPdfToText`):**
        *   This handler will receive a file path for a PDF.
        *   It will first check the `pdfTextCache`. If the content is present, it will return the cached data.
        *   If not cached, it will read the PDF file into a buffer, use `pdf-parse` to extract the text, calculate the token count, store the result in the cache, and then return it.
        *   It will send a `UpdateNodeStats` message back to the client with the new token count.

3.  **Frontend (`view.tsx`):**
    *   **On-Demand Extraction:** The `updateCheckedFiles` function will be modified. When a path that ends in `.pdf` is being checked for the first time, it will send a `RequestPdfToText` message to the backend.
    *   **Dynamic Stats Update:** A new IPC listener for `UpdateNodeStats` will be added. When it receives a message, it will find the corresponding `FileNode` in the `files` state and update its `tokenCount` property, causing the UI to re-render with the correct information.

4.  **Backend (`flattener.service.ts`):**
    *   **Virtual Content Retrieval:** The `getFileStatsAndContent` method will be updated.
    *   If it encounters a file path ending in `.pdf`, it will **not** attempt to read the file from the disk.
    *   Instead, it will call a new method on the `FSService` (e.g., `getVirtualPdfContent(filePath)`) to retrieve the text from the `pdfTextCache`.
    *   It will then use this cached text to generate the `FileStats` object, effectively treating the PDF as if it were a markdown file. If the content is not in the cache (e.g., the file was never checked), it will be flattened with empty content.

5.  **External Drag-and-Drop:**
    *   This will be handled by the generic "External Drag-and-Drop" feature planned in `A23`. The implementation will read the file buffer and send it to the backend for creation, which works for PDFs just as it does for any other file type.
</file_artifact>

<file path="src/Artifacts/A31. DCE - Phase 2 - Multimodal Content Extraction (PDF Images).md">
# Artifact A31: DCE - Phase 2 - Multimodal Content Extraction (PDF Images)
# Date Created: C49
# Author: AI Model

- **Key/Value for A0:**
- **Description:** A plan for a future feature to extract images from PDF files and use a multimodal LLM to generate rich, textual descriptions for inclusion in the context.
- **Tags:** feature plan, multimodal, image to text, pdf, llm, phase 2

## 1. Overview & Goal

Building on the PDF text extraction in Phase 1, this plan outlines a powerful Phase 2 enhancement: making the visual information within PDFs accessible to language models. Many technical papers, reports, and documents rely on diagrams, charts, and images to convey critical information. The goal of this feature is to extract these images from a PDF and use a multimodal vision-language model (VLM) to generate rich, textual descriptions. These descriptions can then be included in the flattened context, allowing an LLM to "understand" the visual elements of the document.

## 2. User Story

| ID | User Story | Acceptance Criteria |
|---|---|---|
| MM-01 | **Understand PDF Images** | As a data curator, when I include a PDF containing charts and diagrams in my context, I want the extension to generate textual descriptions of those images, so the LLM I'm prompting can reason about the visual data. | - When a PDF is processed, the extension identifies and extracts embedded images. <br> - For each extracted image, the extension sends it to a configured multimodal LLM API (e.g., Gemini). <br> - The LLM API returns a detailed textual description of the image's content. <br> - These descriptions are inserted into the virtual markdown content of the PDF at the appropriate locations (e.g., `[Image: A bar chart showing user growth from 2022 to 2024...]`). <br> - This feature can be enabled/disabled in the extension's settings to manage API costs. |

## 3. Technical Implementation Plan (High-Level)

This is a complex feature that will require new services and dependencies, likely as part of the project's Phase 2.

1.  **PDF Image Extraction Library:**
    *   **Research:** The first step is to research and select a robust Node.js library capable of extracting raw image data (e.g., as buffers) from a PDF file. `pdf-lib` or native command-line tools like `pdfimages` (wrapped in a Node.js process) are potential candidates.
    *   **Implementation:** A new method in `fs.service.ts`, `_extractImagesFromPdf(buffer)`, will be created to handle this process.

2.  **New Service: `ImageDescriptionService`:**
    *   A new backend service, `ImageDescriptionService`, will be created.
    *   This service will be responsible for communicating with a multimodal LLM provider (e.g., Google's Gemini API).
    *   It will have a method like `describeImage(imageBuffer: Buffer): Promise<string>`.
    *   This method will handle the API request, sending the image data and receiving the text description.
    *   It will require API key management, likely extending the existing settings infrastructure.

3.  **Integration with PDF Processing:**
    *   The `RequestPdfToText` handler in `fs.service.ts` will be significantly enhanced.
    *   After parsing the text with `pdf-parse`, it would ideally also call the new image extraction method.
    *   It would then iterate through the extracted images, call the `ImageDescriptionService` for each, and intelligently weave the resulting descriptions back into the main text content to create a comprehensive markdown representation of the entire PDF.
    *   This process would be computationally expensive and time-consuming, requiring clear user feedback (e.g., progress indicators) in the UI.

4.  **Configuration:**
    *   New settings will be added to `package.json` and managed via a settings service to allow the user to:
        *   Enable/disable this feature.
        *   Configure their multimodal API provider and key.
        *   Potentially set a budget or limit on the number of images to process per document.
</file_artifact>

<file path="src/Artifacts/A32. DCE - Phase 1 - Excel and CSV Handling Strategy.md">
# Artifact A32: DCE - Phase 1 - Excel and CSV Handling Strategy
# Date Created: C62
# Author: AI Model
# Updated on: C67 (Revert to xlsx and custom Markdown converter for stability)

- **Key/Value for A0:**
- **Description:** Defines the strategy for handling tabular data files (.xlsx, .xls, .csv) by converting them to Markdown tables on-demand and caching them in memory for flattening.
- **Tags:** feature plan, excel, csv, text extraction, virtualization, cache, phase 1

## 1. Overview & Goal

Following the successful implementation of PDF virtualization, users now require a similar capability for tabular data files, specifically Microsoft Excel (`.xlsx`, `.xls`) and Comma-Separated Values (`.csv`). The goal is to extract the content from these files and represent it as clean, readable Markdown tables within the flattened context. This will be achieved using the same on-demand, in-memory caching strategy to avoid creating temporary files in the user's workspace.

## 2. User Stories

| ID | User Story | Acceptance Criteria |
|---|---|---|
| XLS-01 | **Include Tabular Data in Context** | As a user, when I check an Excel or CSV file, I want its data to be converted to Markdown tables and included in the `flattened_repo.md`, so I can use structured data as context for the LLM. | - Checking `.xlsx`, `.xls`, and `.csv` files is allowed. <br> - The token count displayed for the file reflects its Markdown table content. <br> - When flattened, the content is included within a `<file>` tag. <br> - For Excel files with multiple sheets, each sheet is converted to a separate named Markdown table. <br> - No temporary `.md` files are created in the user's workspace. |

## 3. Technical Implementation Plan (C67 Update)

1.  **Dependency:**
    *   After encountering critical parsing bugs and format limitations with `exceljs`, the project has reverted to using the more robust **`xlsx` (SheetJS)** library. This will be the sole dependency for parsing tabular data.
    *   **Vulnerability Note:** The `xlsx` package has a known high-severity vulnerability. While a direct fix from the library maintainers is not yet available, our implementation mitigates risk by using it only for its core data parsing and implementing our own logic for converting that data to Markdown, rather than using the library's more complex and less-audited utility functions.

2.  **Backend (`fs.service.ts`):**
    *   **In-Memory Cache:** A private cache will be maintained: `private excelMarkdownCache = new Map<string, { markdown: string; tokenCount: number }>();`.
    *   **IPC Handler (`RequestExcelToText`):**
        *   This handler will receive a file path. It will first check the cache.
        *   If not cached, it will read the file buffer.
        *   It will use `XLSX.read(buffer)` to parse the file into a workbook object. This works for `.xlsx`, `.xls`, and `.csv`.
        *   It will iterate through each sheet name in the `workbook.SheetNames`.
        *   For each sheet, it will call a **custom private helper method, `_sheetToMarkdown`**.
    *   **Custom Markdown Converter (`_sheetToMarkdown`):**
        *   This new function will take a worksheet object from `xlsx` as input.
        *   It will use `XLSX.utils.sheet_to_json(worksheet, { header: 1 })` to get an array-of-arrays representation of the sheet.
        *   It will then manually iterate over these arrays to construct a Markdown table string, creating the header row (`| Col1 | Col2 |`), the separator line (`|---|---|`), and all data rows.
        *   This custom implementation provides stability and avoids potential bundling issues with the library's own `sheet_to_markdown` utility.
        *   The final Markdown string (including headers for each sheet) will be concatenated, its token count calculated, and the result stored in the cache.
        *   It will then send an `UpdateNodeStats` message back to the client with the new token count.

3.  **Frontend & Flattener Integration:**
    *   The frontend (`view.tsx`) will continue to trigger the `RequestExcelToText` message on-demand.
    *   The backend (`flattener.service.ts`) will continue to retrieve the virtual Markdown content from the `FSService`'s cache. No changes are needed in these files.
</file_artifact>

<file path="src/Artifacts/A33. DCE - Phase 1 - Copy-Paste Feature Plan.md">
# Artifact A33: DCE - Phase 1 - Copy-Paste Feature Plan
# Date Created: C68
# Author: AI Model

- **Key/Value for A0:**
- **Description:** Details the requirements for implementing copy-paste functionality (Ctrl+C, Ctrl+V) for files and folders within the DCE view, including handling name collisions.
- **Tags:** feature plan, copy, paste, file operations, ux, phase 1

## 1. Overview & Goal

To achieve greater feature parity with the native VS Code Explorer and improve workflow efficiency, this plan outlines the implementation of standard copy-paste functionality for files and folders. Users expect to be able to use `Ctrl+C` and `Ctrl+V` to duplicate items within the file tree. The goal is to provide this intuitive and essential file management feature, complete with robust handling of name collisions to prevent accidental file overwrites.

## 2. User Stories

| ID | User Story | Acceptance Criteria |
|---|---|---|
| CP-01 | **Copy and Paste File/Folder** | As a user, I want to select a file or folder, press `Ctrl+C`, then select a destination folder and press `Ctrl+V` to create a duplicate, so I can quickly copy assets or boilerplate code within my project. | - `Ctrl+C` on a focused file/folder in the DCE view copies its path to an internal clipboard. <br> - `Ctrl+V` pastes the copied item into the currently focused folder. <br> - If a file is focused, the paste occurs in its parent directory. <br> - Pasting a folder also copies its entire contents recursively. |
| CP-02 | **Handle Name Collisions** | As a user, when I paste a file named `file.txt` into a folder that already contains a `file.txt`, I expect the new file to be automatically renamed to `file-copy.txt` (or similar), so I don't accidentally overwrite my work. | - If a file with the same name exists at the destination, the pasted file is renamed. <br> - The renaming scheme is `[original]-copy.[ext]`. <br> - If `[original]-copy.[ext]` also exists, the scheme becomes `[original]-copy-2.[ext]`, `[original]-copy-3.[ext]`, and so on, until a unique name is found. <br> - This applies to both files and folders. |

## 3. Technical Implementation Plan

1.  **IPC Channels (`channels.enum.ts`, `channels.type.ts`):**
    *   Create a new `ClientToServerChannel.RequestCopyFile` channel.
    *   The payload will be `{ sourcePath: string; destinationDir: string; }`.

2.  **Frontend State & Logic (`view.tsx`, `TreeView.tsx`):**
    *   **Clipboard State (`view.tsx`):** Add a new state variable to the main `App` component to act as the internal clipboard: `const [clipboard, setClipboard] = useState<{ path: string; type: 'copy' } | null>(null);`.
    *   **Keyboard Event Handler (`TreeView.tsx`):** Update the `handleKeyDown` function.
        *   It will now listen for `e.key === 'c'` and `e.key === 'v'` when `e.ctrlKey` (or `e.metaKey`) is true.
        *   **On `Ctrl+C`:** It will call a prop function (`onCopy`) passed down from `view.tsx`, which will update the `clipboard` state with the `focusedNodePath`.
        *   **On `Ctrl+V`:** It will check if the `clipboard` state is populated. If so, it will determine the destination directory from the `focusedNodePath` (if the focused node is a folder, use its path; if it's a file, use its parent's path). It will then send the `RequestCopyFile` message to the backend.

3.  **Backend File Operation (`fs.service.ts`):**
    *   **New Handler:** Create a new `async handleCopyFileRequest({ sourcePath, destinationDir })` method.
    *   **Name Collision Logic:**
        *   This handler will contain a private helper function, `private async _findAvailableCopyName(destinationPath: string): Promise<string>`.
        *   This helper will parse the `destinationPath` into its directory, base name, and extension.
        *   It will check if the original path exists using `vscode.workspace.fs.stat`.
        *   If it exists, it will enter a loop, checking for `...-copy.[ext]`, then `...-copy-2.[ext]`, `...-copy-3.[ext]`, etc., until `fs.stat` throws an `ENOENT` error, indicating a free name.
        *   It will return the first available unique path.
    *   **File Copy:** The main handler will call `_findAvailableCopyName` to get the final target path and then use `vscode.workspace.fs.copy(sourceUri, targetUri)` to perform the recursive copy.
    *   The existing file system watcher will automatically detect the new file/folder and trigger a UI refresh.
</file_artifact>

<file path="src/Artifacts/A34. DCE - Phase 2 - Parallel Co-Pilot Panel - Vision & Requirements.md">
# Artifact A34: DCE - Phase 2 - Parallel Co-Pilot Panel - Vision & Requirements
# Date Created: C69
# Author: AI Model
# Updated on: C133 (Add requirement for visual feedback on selection)

- **Key/Value for A0:**
- **Description:** Outlines the high-level vision and user stories for the Phase 2 multi-tabbed editor panel, designed for comparing and managing multiple AI-generated responses. Includes plans for response annotation and a "Cycles Context" field.
- **Tags:** feature plan, phase 2, co-pilot, multi-tab, ui, ux, requirements, annotation, persistence, diff, parsing

## 1. Vision & Goal

Phase 2 of the Data Curation Environment aims to solve the "single-threaded" nature of interacting with AI assistants. The current workflow for developers often involves sending the same prompt to multiple models or conversations, copying the results to separate text files, and then manually integrating them into their project to test. This is inefficient and cumbersome.

The goal of the **Parallel Co-Pilot Panel** is to create an integrated, **persistent** environment within VS Code specifically for managing, comparing, diffing, and testing multiple AI-generated code responses.

**Core Workflow (C91 Update):** The primary interaction model is now **parse-centric** and **globally controlled**. The user pastes raw AI responses into simple text areas in each tab. A single, global "Parse All" button then processes the raw text in all tabs simultaneously, transforming their UIs into a structured, read-only view. This view separates the AI's plan from its code artifacts and includes a new "Associated Files" list for at-a-glance validation.

## 2. Core Concepts

1.  **Dedicated View Container:** The panel has its own icon in the Activity Bar, providing a distinct, full-height space for its UI.
2.  **Stateful & Persistent:** The content of all tabs, context fields, the current cycle number, and the **selected response** are automatically saved. The state persists across sessions and when moving the panel to a new window.
3.  **Global Parse-on-Demand:** A single "Parse All Responses" button in the main header controls the view mode for all tabs.
4.  **Structured, Readable View:** After parsing, each tab's `textarea` is replaced by a static, read-only view that:
    *   Renders the AI's summary and plan as **formatted Markdown**.
    *   Uses **collapsible sections** for the main UI areas (Cycle Info, Summary, etc.) to manage screen real estate.
    *   Displays an **"Associated Files" list** with indicators (``/``) showing if the files exist in the workspace.
    *   Displays individual, **syntax-highlighted** code blocks for each file.
5.  **Live Testing via "Accept":** The core innovation is an "accept" feature. The user can, with a single click, overwrite the content of a workspace file with the AI-generated version.
6.  **Integrated Diffing:** Users can click on a file in the "Associated Files" list to see an immediate diff view comparing the AI's suggestion against the current workspace file.
7.  **Cycle Navigator:** A UI to navigate back and forth through the history of development cycles, loading the corresponding AI responses for each cycle.
8.  **Metadata Display:** Each response tab will display key metadata, such as token counts and similarity scores, to help the user quickly evaluate the AI's output.

## 3. User Stories

| ID | User Story | Acceptance Criteria |
|---|---|---|
| P2-US-01 | **Manage Multiple Responses** | As a developer, I want a dedicated panel with multiple tabs where I can place different AI-generated code responses, so I can keep them organized. | - A new icon in the Activity Bar opens the Parallel Co-Pilot panel. <br> - The panel contains a slider or input to select the number of visible tabs. <br> - Each tab initially contains a large text input area. |
| P2-US-02 | **Parse All Responses** | As a developer, after pasting responses into multiple tabs, I want to click a single button to parse all of them into a structured view, so I can easily review them without repetitive clicking. | - A global "Parse All Responses" button exists in the panel's header. <br> - Clicking it processes the raw text in every tab. <br> - Each tab's UI transforms to show distinct sections for summary, action plan, and file blocks. <br> - A corresponding "Un-Parse All" button reverts all tabs to their raw text view. |
| P2-US-03 | **View Formatted Text** | As a developer, I want the AI's summary and plan to be rendered as formatted Markdown, so I can easily read lists, bolded text, and other formatting. | - The summary and course of action sections correctly render Markdown syntax. |
| P2-US-04 | **Manage UI Space** | As a developer, I want to be able to collapse the main sections of the UI, so I can focus on the code blocks without excessive scrolling. | - The Cycle Info, Summary, Course of Action, and Associated Files sections have collapsible headers. |
| P2-US-05 | **Verify Response Validity** | As a developer, I want to see a list of all files an AI response intends to modify, with a clear indicator of whether those files exist in my project, so I can immediately spot hallucinations or new file suggestions. | - After parsing, a list of "Associated Files" is displayed. <br> - A checkmark (``) appears next to files that exist in the workspace. <br> - An 'x' (``) appears next to files that do not exist. |
| P2-US-06 | **Persistent State** | As a developer, I want all the text I've entered and the response I've selected to be saved automatically, so I don't lose my work if I close the panel, move it, or restart VS Code. | - All raw text content and the ID of the selected response is saved to a history file (`.vscode/dce_history.json`). <br> - When the panel is reopened, it loads the state from the most recent cycle. |
| P2-US-07 | **Review Changes with Diff** | As a developer, I want to click on any file in the "Associated Files" list to see a diff, so I can review the exact changes before testing. | - Clicking a file path in the list opens a diff view comparing the workspace version with the AI's version. |
| P2-US-08 | **Navigate Cycle History** | As a developer, I want to navigate backward and forward through my project's development cycles, so I can review past AI suggestions. | - UI controls exist to move between cycles. <br> - Navigating to a past cycle loads its saved raw responses into the panel. |
| P2-US-09 | **Visual Feedback on Selection** | As a user, when I select a response that is ready to be used for the next cycle, I want clear visual feedback, so I know I can proceed with confidence. | - When a response is selected (and other conditions like having a cycle title are met), the current cycle's tab and the selected response's tab turn a distinct color (e.g., green). |
</file_artifact>

<file path="src/Artifacts/A35. DCE - Phase 2 - UI Mockups and Flow.md">
# Artifact A35: DCE - Phase 2 - UI Mockups and Flow
# Date Created: C69
# Author: AI Model
# Updated on: C158 (Add "Project Plan" button for navigation to Cycle 0)

## 1. Overview

This document describes the user interface (UI) and interaction flow for the Parallel Co-Pilot Panel. The design is centered around a two-stage workflow: **Input**, followed by a global **Parse** that transforms the entire panel into a **Review & Act** mode.

## 2. UI Mockup (Textual Description)

### 2.1. Main Header & Cycle Section
The main header contains global actions.

```
|-------------------------------------------------------------------------------------------------|
| [ Project Plan ] [ Generate prompt.md ] [ Log State ] [ Parse All ] [ Sort by Tokens ] [ Resp: [ 4 ] ] |
|-------------------------------------------------------------------------------------------------|
| [v] CYCLE & CONTEXT (C158: Review and Implement Feedback)                                       |
| |---------------------------------------------------------------------------------------------| |
| | Cycle: [ < ] [ C158 ] [ > ] [ + ] [ Title Input... ] [Delete] [Reset]                       | |
| | [ Cycle Context Text Area... ]                                                              | |
| | [ Ephemeral Context Text Area... ]                                                          | |
|-------------------------------------------------------------------------------------------------|
```
*   **`[ Project Plan ]` (New):** A new button in the main header. Clicking it navigates the user back to the Cycle 0 "Onboarding View," allowing them to view and edit their master project scope.

### 2.2. Response Tabs
The tabs now display metadata when in parsed mode.

```
|=================================================================================================|
| [ Resp 1 (5 files, 2.1K tk) ] [ Resp 2 (4 files, 1.8K tk) ] [ Resp 3 ] [ Resp 4 ]                |
|-------------------------------------------------------------------------------------------------|
```
*   **Tab Metadata:** When parsed, each tab will show the number of files detected in its response and the total token count of those files.

### 2.3. Parsed View (Non-Diff Mode)
(No changes from C134)

### 2.4. Diff View
(No changes from C133)

## 3. User Interaction Flow

1.  **Edit Project Scope:** The user is on Cycle 158 and realizes they need to update their high-level project plan.
    *   They click the new **`[ Project Plan ]`** button.
    *   The PCPP view changes to the "Onboarding View" (Cycle 0), displaying the large text area with their current project scope.
    *   A "Return to Cycles" button is now visible.
    *   The user edits their project scope and the changes are auto-saved.
    *   They click "Return to Cycles" and are taken back to their latest cycle (Cycle 158). The next time they click "Generate prompt.md," the updated scope will be used.
2.  **Paste & Parse:** User pastes responses and clicks "Parse All". The tabs update to show metadata (e.g., "Resp 1 (5 files, 2.1K tk)").
3.  **Sort Responses:** The user notices "Resp 2" has a higher token count than "Resp 1". They click the **"Sort by Tokens"** button. The order of the tabs in the tab bar immediately changes to `[ Resp 2 ] [ Resp 1 ] [ Resp 4 ] [ Resp 3 ]` (based on their respective token counts). The user can now review the longest, likely most detailed, response first.
4.  **Select & Accept:** The rest of the workflow for selecting and accepting files remains the same.
</file_artifact>

<file path="src/Artifacts/A36. DCE - Phase 2 - Technical Implementation Plan.md">
# Artifact A36: DCE - Phase 2 - Technical Implementation Plan
# Date Created: C69
# Author: AI Model
# Updated on: C137 (Add selectedFilesForReplacement to persisted state)

- **Key/Value for A0:**
- **Description:** Details the technical approach for building the Parallel Co-Pilot Panel, including the new webview provider, state management, IPC channels, and backend logic for file content swapping.
- **Tags:** feature plan, phase 2, technical plan, architecture, webview, ipc, parsing, markdown, diff

## 1. Overview

This document outlines the technical implementation strategy for the Parallel Co-Pilot Panel. The plan is updated to reflect several UI/UX fixes and new features from recent cycles.

## 2. Core Components

### 2.1. Frontend State Management (`view.tsx`)

The component state will be expanded to manage the new UI features.

```typescript
// State within the view.tsx component
interface PcppState {
  // ... existing state
  selectedFilesForReplacement: Set<string>; // This state must be persisted per-cycle
  fileExistenceMap: Map<string, boolean>;
}```
*   **`selectedFilesForReplacement`**: This state must be explicitly cleared when the user navigates to a new or different cycle to prevent "state bleeding." It must also be saved as part of the `PcppCycle` object.
*   **`fileExistenceMap`**: This state must be updated after a file is successfully created via the "Accept" functionality to provide immediate UI feedback.

### 2.2. Robust "New Cycle" Button Logic

*   **Goal:** The `[ + ]` (New Cycle) button must be disabled until all required precursor data from the *previous* cycle is present.
*   **Implementation (`view.tsx`):** The `isNewCycleButtonDisabled` memoized boolean will be updated. It must now check:
    1.  That the `cycleTitle` of the *current* cycle is non-default and not empty.
    2.  That the `cycleContext` of the *current* cycle is not empty.
    3.  That a `selectedResponseId` has been set for the *current* cycle.
    *   This ensures that a user cannot create an orphaned "Cycle 2" before they have finished providing all the necessary inputs for "Cycle 1".

### 2.3. Clearing Selection State on Navigation
*   **Goal:** Fix the bug where checked files from one cycle remain checked when viewing another cycle.
*   **Implementation (`view.tsx`):** The `handleCycleChange` and `handleNewCycle` functions will explicitly reset the `selectedFilesForReplacement` state to `new Set()` on every navigation.

### 2.4. IPC Channel Updates

*   **`ServerToClientChannel.FilesWritten`:** A channel to provide direct feedback from the backend to the PCPP frontend after a file write operation.
*   **`RequestLogState`:** A channel to facilitate the "Log State" feature.

### 2.5. Backend State Synchronization (`file-operation.service.ts`, `on-message.ts`)

*   **Goal:** Fix the UI desynchronization bug where a newly created file still shows a red ``.
*   **Implementation:** The `handleBatchFileWrite` method in `file-operation.service.ts` will return the paths of successfully written files. The `on-message.ts` handler will then send a `FilesWritten` message back to the frontend, which will update its `fileExistenceMap` state.

### 2.6. Backend State Logging (`prompt.service.ts`)

*   **Goal:** Implement the logic for the "Log State" button.
*   **Implementation:** A new method, `generateStateLog`, will be added to `PromptService`. It will receive the frontend state, construct a comprehensive log message including a JSON dump and the generated `<M6. Cycles>` block, and send it to the `LoggerService`.
</file_artifact>

<file path="src/Artifacts/A37. DCE - Phase 2 - Cycle Navigator & Knowledge Graph - Vision.md">
# Artifact A37: DCE - Phase 2 - Cycle Navigator & Knowledge Graph - Vision
# Date Created: C70
# Author: AI Model

- **Key/Value for A0:**
- **Description:** Outlines the vision for a cycle-based navigation system to browse the history of AI-generated responses and project states, creating a navigable knowledge graph.
- **Tags:** feature plan, phase 2, knowledge graph, history, cycle navigator, ui, ux

## 1. Vision & Goal

As the Data Curation Environment matures, the interaction history with the AI becomes a valuable asset in itself. Currently, this history is ephemeral, existing only within the context of a single session. The vision for the **Cycle Navigator & Knowledge Graph** is to capture this history and make it a persistent, navigable, and core feature of the development workflow.

The goal is to transform the series of AI interactions from a linear conversation into a structured, explorable history of the project's evolution. This creates a "knowledge graph" where each node is a development cycle, and the edges are the AI-generated solutions that led from one cycle to the next.

## 2. Core Concepts

1.  **Cycle-Based History:** The fundamental unit of history is the "Cycle." Every time the curator sends a prompt and receives responses, that entire transaction is associated with a unique Cycle ID (e.g., `C70`).
2.  **Persistent Response Storage:** All AI-generated responses (the content that would be pasted into the Parallel Co-Pilot tabs) are saved and tagged with their corresponding Cycle ID.
3.  **UI for Navigation:** A simple, non-intrusive UI will be added to the Parallel Co-Pilot panel, allowing the user to step backward and forward through the cycles.
4.  **Historical Context Loading:** As the user navigates to a past cycle (e.g., from `C70` to `C69`), the Parallel Co-Pilot panel will automatically load the set of AI responses that were generated during that cycle.

## 3. User Stories

| ID | User Story | Acceptance Criteria |
|---|---|---|
| P2-US-06 | **Navigate Project History** | As a developer, I want to navigate backward and forward through my project's development cycles, so I can review past decisions and the AI suggestions that prompted them. | - A UI control (e.g., left/right arrows and a cycle number display) is present in the Parallel Co-Pilot panel. <br> - Clicking the arrows changes the currently viewed cycle. |
| P2-US-07 | **View Historical Responses** | As a developer, when I navigate to a previous cycle, I want the Parallel Co-Pilot tabs to automatically populate with the AI-generated responses from that specific cycle, so I can see exactly what options I was considering at that time. | - Navigating to a cycle loads the associated set of AI responses into the tabs. <br> - The metadata (token counts, etc.) for these historical responses is also displayed. |
| P2-US-08 | **Preserve Interaction Context** | As a developer, I want every AI response to be automatically saved and associated with the current cycle, so a complete and accurate history of the project is built over time. | - A mechanism exists to automatically persist all AI responses received. <br> - Each response is tagged with a Cycle ID and a unique response UUID. |
</file_artifact>

<file path="src/Artifacts/A38. DCE - Phase 2 - Cycle Navigator - UI Mockup.md">
# Artifact A38: DCE - Phase 2 - Cycle Navigator - UI Mockup
# Date Created: C70
# Author: AI Model

- **Key/Value for A0:**
- **Description:** Provides a textual mockup and interaction flow for the Cycle Navigator UI, including the cycle counter and navigation controls within the Parallel Co-Pilot Panel.
- **Tags:** feature plan, phase 2, ui, ux, mockup, workflow, cycle navigator

## 1. Overview

This document describes the proposed user interface (UI) for the Cycle Navigator. The design prioritizes simplicity and integration, placing the navigation controls directly within the Parallel Co-Pilot Panel, reinforcing the connection between the cycle history and the AI responses.

## 2. UI Mockup (Textual Description)

The Cycle Navigator will be a new UI element added to the top of the Parallel Co-Pilot Panel, positioned just below the main header and above the tab configuration slider.

```
+-----------------------------------------------------------------+
| [Parallel Co-Pilot] [Settings Icon]                             |
|-----------------------------------------------------------------|
| Cycle: [ < ] [ C70 ] [ > ]                                      |
|-----------------------------------------------------------------|
| Number of Tabs: [Slider: 1 to 8]  (Current: 4)                  |
|=================================================================|
| [ Tab 1 (active) ] [ Tab 2 ] [ Tab 3 ] [ Tab 4 ] [ + ]           |
|-----------------------------------------------------------------|
|                                                                 |
|   [Swap with Source]                                            |
|                                                                 |
|   Source: src/services/user.service.ts                          |
|   ------------------------------------------------------------  |
|   |          | Original Source      | This Tab (Response 1) |  |
|   | Lines    | 150                  | 165                   |  |
|   | Tokens   | 2.1K                 | 2.4K                  |  |
|   |----------|----------------------|-----------------------|  |
|   | Similarity Score: 85%                                   |  |
|   ------------------------------------------------------------  |
|                                                                 |
|   [Text editor area where user pastes AI-generated code...]     |
|   |                                                         |   |
|   | export class UserService {                              |   |
|   |   // ... AI generated code ...                           |   |
|   | }                                                       |   |
|   |                                                         |   |
|                                                                 |
+-----------------------------------------------------------------+
```

### 2.1. UI Components Breakdown

1.  **Cycle Navigator Bar:**
    *   A new horizontal bar containing the navigation controls.
    *   **Label:** "Cycle:".
    *   **Previous Button (`<`):** A button with a left-arrow icon. Clicking it navigates to the previous cycle (e.g., `C69`). The button is disabled if the user is at the very first recorded cycle.
    *   **Cycle Display (`C70`):** A read-only (or potentially editable) text field showing the ID of the currently viewed cycle.
    *   **Next Button (`>`):** A button with a right-arrow icon. Clicking it navigates to the next cycle (e.g., `C71`). The button is disabled if the user is at the most recent cycle.

## 3. User Interaction Flow

1.  **Initial State:** The user is working on Cycle 70. The Cycle Display shows `C70`. The `>` button is disabled. The Parallel Co-Pilot tabs show the AI responses generated for Cycle 70.
2.  **Navigate Back:**
    *   The user clicks the **`<`** button.
    *   **Action:** The extension's state updates to the previous cycle, `C69`.
    *   **UI Update:** The Cycle Display changes to `C69`.
    *   **Data Load:** The Parallel Co-Pilot panel fetches the historical data for Cycle 69. The tabs are cleared and re-populated with the AI responses that were generated during that cycle. The metadata and similarity scores all update to reflect this historical data. Both `<` and `>` buttons are now enabled.
3.  **Navigate Forward:**
    *   The user is viewing Cycle 69 and clicks the **`>`** button.
    *   **Action:** The state moves forward to `C70`.
    *   **UI Update & Data Load:** The UI returns to the state described in step 1. The `>` button becomes disabled again.
</file_artifact>

<file path="src/Artifacts/A39. DCE - Phase 2 - Cycle Navigator - Technical Plan.md">
# Artifact A39: DCE - Phase 2 - Cycle Navigator - Technical Plan
# Date Created: C70
# Author: AI Model
# Updated on: C92 (Revise initialization flow to fix persistence issues)

- **Key/Value for A0:**
- **Description:** Details the technical approach for implementing the Cycle Navigator, including data structures for storing cycle-specific responses and the state management for historical navigation.
- **Tags:** feature plan, phase 2, technical plan, architecture, state management, data model

## 1. Overview

This document outlines the technical strategy for implementing the Cycle Navigator and PCPP persistence. The implementation will require a structured data format for storing historical data, enhancements to the frontend state management, new IPC channels, and robust backend logic for data persistence. The key change in this revision is a new initialization flow to make the backend the single source of truth, resolving state loss on reload or window pop-out.

## 2. Data Structure and Persistence

A structured approach to storing the historical data is critical. A simple JSON file stored within the workspace's `.vscode` directory is a suitable starting point.

### 2.1. `dce_history.json` (Example)

```json
{
  "version": 1,
  "cycles": [
    {
      "cycleId": 91,
      "timestamp": "2025-08-20T12:30:00Z",
      "title": "Initial implementation",
      "cycleContext": "Long-term notes...",
      "ephemeralContext": "<console_log>...</console_log>",
      "responses": {
        "1": { "content": "<src/client/views/view.tsx>...</file>" },
        "2": { "content": "..." },
        "3": { "content": "" }
      }
    },
    {
      "cycleId": 92,
      "timestamp": "2025-08-21T10:00:00Z",
      "title": "Persistence fix",
      "cycleContext": "Focus on fixing state loss.",
      "ephemeralContext": "",
      "responses": {
        "1": { "content": "" }, "2": { "content": "" }, "3": { "content": "" }, "4": { "content": "" }
      }
    }
  ]
}
```

*   **Backend (`history.service.ts`):** This service will manage reading from and writing to `dce_history.json`. It will handle file locking to prevent race conditions and provide methods like `getCycle(cycleId)`, `saveCycle(cycleData)`, `getCycleList()`, and a new `getLatestCycle()`.

## 3. Frontend State Management & Initialization Flow (C92 Revision)

### 3.1. Initialization
1.  **Problem:** Previously, the frontend managed its own state and only requested pieces of data, leading to state loss when the webview was re-initialized (e.g., on reload or pop-out).
2.  **Solution:** The new flow makes the backend the single source of truth.
    *   On component mount, the frontend sends a single new IPC message: `RequestLatestCycleData`.
    *   The backend's `HistoryService` finds the cycle with the highest `cycleId` in `dce_history.json`. If the file is empty, it creates a default "Cycle 1" object.
    *   The backend sends this complete `PcppCycle` object back to the client via `SendLatestCycleData`.
    *   The frontend's message handler uses this single object to populate its *entire* initial state: `currentCycleId`, `maxCycleId`, `cycleTitle`, `cycleContext`, `ephemeralContext`, and all `tabs` content. This guarantees the UI always starts with the latest saved data.

### 3.2. State Management (`parallel-copilot.view.tsx`)
```typescript
interface PcppState {
  currentCycleId: number;
  maxCycleId: number;
  cycleTitle: string;
  // ... other state
}
```
*   The state remains largely the same, but it is now initialized from a single backend message.
*   A "New Cycle" button (`+`) will be added. Its handler will increment `maxCycleId`, set `currentCycleId = maxCycleId`, clear the UI fields, and trigger a `saveCycleData` call to create the new empty cycle record.

## 4. IPC Communication

*   **REMOVED:** `RequestCycleHistoryList`.
*   **NEW:** `ClientToServerChannel.RequestLatestCycleData`:
    *   **Payload:** `{}`
    *   **Action:** Frontend requests the full data object for the most recent cycle.
*   **NEW:** `ServerToClientChannel.SendLatestCycleData`:
    *   **Payload:** `{ cycleData: PcppCycle }`
    *   **Action:** Backend sends the complete, latest cycle data to the frontend for initialization.
*   `ClientToServerChannel.RequestCycleData`: Still used for navigating to *older* cycles.
*   `ClientToServerChannel.SaveCycleData`: Unchanged. It sends the entire state of the *current* cycle to the backend to be persisted. It's critical that the `cycleId` in the payload is correct.
</file_artifact>

<file path="src/Artifacts/A40. DCE - Phase 2 - Parallel Co-Pilot - Target File Structure.md">
# Artifact A40: DCE - Phase 2 - Parallel Co-Pilot - Target File Structure
# Date Created: C71
# Author: AI Model

- **Key/Value for A0:**
- **Description:** A text-based representation of the new files and components required to build the Phase 2 Parallel Co-Pilot and Cycle Navigator features.
- **Tags:** file structure, architecture, project layout, scaffolding, phase 2

## 1. Overview

This document outlines the new files and directories that will be created to support the development of the Phase 2 features: the Parallel Co-Pilot Panel and the Cycle Navigator. This structure is designed to be modular and integrate cleanly with our existing architecture. This artifact also serves as the "pre-computation" plan requested in C71, allowing for a script to be created to scaffold these files when development begins.

## 2. New File Tree for Phase 2

This tree shows only the **new** files and directories to be added. Existing directories will be modified to import and use these new components.

```
src/
 backend/
    services/
        history.service.ts      # New: Manages reading/writing dce_history.json

 client/
     components/
        DiffViewer.tsx          # New (for Phase 3, but can be stubbed): A component for side-by-side text diffing.
        Slider.tsx              # New: A simple reusable slider component for the tab count.
        TabbedEditor.tsx        # New: The core multi-tab editor component.
    
     views/
        parallel-copilot.view/  # New View for Phase 2
            index.ts
            on-message.ts
            view.scss
            view.tsx            # Main React component for the Parallel Co-Pilot panel
    
     utils/
         string-similarity.ts    # New: A lightweight utility for calculating string similarity scores.

.vscode/
 dce_history.json                # New (auto-generated): Stores the cycle history and AI responses.
```

## 3. Component & Service Descriptions

### Backend

-   **`src/backend/services/history.service.ts`:**
    -   **Responsibility:** Solely responsible for abstracting the file I/O for the `dce_history.json` file.
    -   **Methods:** `getCycleHistory()`, `getCycleData(cycleId)`, `saveResponseToCycle(...)`. This keeps the main `fs.service.ts` clean from business logic.

### Frontend Components

-   **`src/client/views/parallel-copilot.view/`:**
    -   This new directory will contain everything needed for the new panel, following the same structure as our existing `context-chooser.view`.
    -   `view.tsx` will be the main component, managing the state for all tabs, the current cycle, and orchestrating IPC communication.
-   **`src/client/components/TabbedEditor.tsx`:**
    -   A component that will manage the tab bar and the content of each tab editor, receiving the array of tab data as props.
-   **`src/client/components/Slider.tsx`:**
    -   A simple, reusable slider component to control the number of tabs. This extracts UI logic from the main view.
-   **`src/client/utils/string-similarity.ts`:**
    -   Will contain a function to calculate the similarity between two strings, likely implementing the Dice Coefficient or a similar algorithm. This keeps the calculation logic separate and testable.

### Root Directory

-   **`.vscode/dce_history.json`:**
    -   This file will be automatically created and managed by the `HistoryService`. Storing it in `.vscode` is standard practice for workspace-specific extension data that should not typically be checked into source control. It will be added to `.gitignore`.
</file_artifact>

<file path="src/Artifacts/A40.1. DCE - Phase 2 - Competitive Analysis & Feature Ideas.md">
# Artifact A40.1: DCE - Phase 2 - Competitive Analysis & Feature Ideas
# Date Created: C71
# Author: AI Model
# Updated on: C71 (Incorporate user feedback and consolidate ideas)

- **Key/Value for A0:**
- **Description:** An analysis of existing tools and extensions for managing multiple AI responses, with a list of potential features to incorporate into the Parallel Co-Pilot panel.
- **Tags:** feature plan, phase 2, research, competitive analysis, co-pilot

## 1. Overview

As requested in Cycle 71, this document summarizes research into existing tools that address the problem of managing and comparing multiple AI-generated code responses. The goal is to identify common features, discover innovative ideas, and ensure our Phase 2 "Parallel Co-Pilot Panel" is a best-in-class solution.

## 2. Research Summary

A search for "VS Code extensions for comparing AI responses" reveals that while many extensions integrate a single AI chat (like GitHub Copilot Chat), very few are designed for the specific workflow of managing *multiple, parallel* responses to the *same* prompt. [1, 3] This represents a significant opportunity for our project. The "AI Toolkit for Visual Studio Code" is a notable exception, offering features to run prompts against multiple models simultaneously and compare the results, validating our core concept. [1, 2]

Most developers still use a manual process involving external tools:
1.  Pasting responses into separate tabs in a text editor (Notepad++, Sublime Text).
2.  Using a dedicated diff tool (WinMerge, Beyond Compare, VS Code's native diff) to compare two responses at a time.

The key pain point is the friction of moving text between applications and the lack of an integrated testing loop, which our "swap" feature directly addresses.

## 3. Existing Tools & Inspirations

| Tool / Extension | Relevant Features | How It Inspires DCE |
| :--- | :--- | :--- |
| **AI Toolkit for VS Code** | - "Bulk Run" executes a prompt across multiple models simultaneously. [1] <br> - "Compare" view for side-by-side model responses. [2] <br> - Model evaluation with metrics like similarity and relevance. [2] | This extension is the closest conceptually to our goal. It validates the need for parallel prompting and comparison. Our "swap" feature for live testing remains a key differentiator. |
| **Cursor.sh (IDE)** | - A fork of VS Code built around an AI-first workflow. <br> - "Auto-debug" feature attempts to fix errors. <br> - Inline diffing for AI-suggested changes. | Cursor's deep integration is a long-term inspiration. An "Auto-fix TS Errors" button in our panel could be a powerful feature, where we send the code + errors back to the AI. |
| **Continue.dev** | - Open-source and customizable. <br> - Strong concept of "Context Providers," very similar to our Phase 1. | Their flexible context system is a good model. A future DCE feature could allow highlighting a specific function and sending *just that* to the Parallel Co-Pilot panel for iteration. |

## 4. New Feature Ideas for DCE Phase 2 (Refined with C71 Feedback)

Based on the analysis and our project goals, here are some new or refined feature ideas for the Parallel Co-Pilot Panel:

| Feature Idea | Description |
| :--- | :--- |
| **"Accept Response" Button** | As per user feedback, this is a more intuitive name than "Promote to Source". A button to overwrite the source file with the tab's content without swapping back. This signifies a permanent acceptance of the AI's suggestion for that cycle. |
| **One-Click Diff View** | A button that opens VS Code's native diff viewer, comparing the tab's content with the original source file. This is a great stepping stone to our fully integrated Phase 3 diff tool. |
| **AI-Powered Summary of Changes** | A button that sends the original code and the tab's code to an LLM with a prompt like "Summarize the key changes between these two code blocks." The summary would be displayed in the tab's metadata area. |
| **Response Annotation & Rating** | A feature the user liked: Allow adding thumbs up/down, tags (e.g., `refactor`, `bug-fix`), and comments to each response tab. This metadata would be saved with the cycle history, adding valuable context. |
| **Intent Buttons** | As per user feedback, instead of slash commands, provide clear buttons for common refinement tasks like "Add Documentation," "Find Bugs," or "Refactor for Readability." These would re-prompt the AI with the tab's content and the specific instruction. |
| **Ephemeral "Cycles Context" Field** | As per user feedback, add a separate text field for temporary context like error logs that are useful for the current cycle's prompt but should not be saved in the long-term cycle history to avoid token bloat. |
</file_artifact>

<file path="src/Artifacts/A41. DCE - Phase 2 - API Key Management - Feature Plan.md">
# Artifact A41: DCE - Phase 2 - API Key Management - Feature Plan
# Date Created: C71
# Author: AI Model

- **Key/Value for A0:**
- **Description:** Outlines the user stories and technical plan for a settings UI where users can securely input and manage their API keys for various LLM services or a local endpoint URL.
- **Tags:** feature plan, phase 2, settings, api key, configuration, security

## 1. Overview & Goal

As the DCE project moves into Phase 2, it will begin to make its own API calls to LLM providers. To do this securely and flexibly, the extension needs a dedicated interface for users to manage their API keys and specify a local LLM endpoint. The goal of this feature is to provide a simple, secure, and intuitive settings panel for managing these credentials.

This functionality is heavily inspired by the `ApiKeysManagement.tsx` module in the `The-Creator-AI-main` reference repository.

## 2. User Stories

| ID | User Story | Acceptance Criteria |
|---|---|---|
| P2-API-01 | **Configure API Key** | As a user, I want to add an API key for a specific cloud service (e.g., Gemini, OpenAI), so the extension can make API calls on my behalf. | - A UI is available to add a new API key. <br> - I can select the LLM provider from a dropdown list. <br> - I can paste my key into a text field. <br> - The key is stored securely using VS Code's `SecretStorage` API. |
| P2-API-02 | **Configure Local LLM Endpoint** | As a user with a local LLM (e.g., via LM Studio), I want to provide an API endpoint URL, so the extension can use my local model instead of a cloud service. | - The settings UI has a dedicated input field for a local LLM API URL. <br> - The URL is saved to the workspace settings. <br> - The extension prioritizes using this URL if it is set. |
| P2-API-03 | **View Saved Keys** | As a user, I want to see a list of my saved API keys (partially masked), so I can confirm which keys I have configured. | - The settings UI displays a list of all saved API keys. <br> - Keys are grouped by service. <br> - The key values are partially masked for security (e.g., `sk-xxxx...1234`). |
| P2-API-04 | **Delete an API Key** | As a user, I want to delete an API key that I no longer use, so I can manage my credentials. | - Each listed API key has a "Delete" button. <br> - Clicking "Delete" prompts for confirmation. <br> - Upon confirmation, the key is removed from the extension's secure storage. |
| P2-API-05 | **Secure Storage** | As a developer, I want API keys to be stored securely using VS Code's `SecretStorage` API, so sensitive user credentials are not exposed as plain text. | - API keys are not stored in plain text in `settings.json` or workspace state. <br> - The `SecretStorage` API is used to encrypt and store the keys, associating them with the extension. |

## 3. Technical Implementation Plan

1.  **New View / Command:**
    *   A new command, `dce.openApiSettings`, will be created. This command will open a new webview panel dedicated to API key management. This keeps the UI clean and separate from the main workflow panels.
    *   This can be triggered from a "Settings" icon within the Parallel Co-pilot view.

2.  **Backend (`settings.service.ts` - New):**
    *   A new `SettingsService` will be created to handle the logic for storing and retrieving secrets and settings.
    *   **API Key Storage:** It will use `vscode.ExtensionContext.secrets` (the `SecretStorage` API) for all API key operations.
    -   **Local URL Storage:** It will use the standard `vscode.workspace.getConfiguration` API to get/set the local LLM URL in the workspace `settings.json`.
    *   **Methods:** It will expose methods like `setApiKey(service: string, key: string)`, `getApiKeys()`, `deleteApiKey(service: string)`, `getLocalLlmUrl()`, and `setLocalLlmUrl(url: string)`. The `getApiKeys` method will return a structure with masked keys for the UI.

3.  **Frontend (New `api-settings.view.tsx`):**
    *   This new React view will render the UI for managing keys and the local endpoint URL.
    *   It will communicate with the backend `SettingsService` via new IPC channels.

4.  **IPC Channels:**
    *   `RequestApiKeys`: Frontend asks for the list of saved (masked) keys.
    *   `SendApiKeys`: Backend sends the list of keys.
    *   `SaveApiKey`: Frontend sends a new service and key to the backend.
    *   `DeleteApiKey`: Frontend requests the deletion of a specific key.
    *   `RequestLocalLlmUrl` / `SendLocalLlmUrl`
    *   `SaveLocalLlmUrl`
</file_artifact>

<file path="src/Artifacts/A41.1. DCE - Phase 2 - Advanced Features & Integrations Plan.md">
# Artifact A41.1: DCE - Phase 2 - Advanced Features & Integrations Plan
# Date Created: C71
# Author: AI Model

- **Key/Value for A0:**
- **Description:** Explores future enhancements for the Parallel Co-Pilot, such as applying AI responses as diff patches and integrating with Git for direct commits.
- **Tags:** feature plan, phase 2, ideation, diff, patch, git, workflow

## 1. Overview & Goal

This document explores potential high-impact features that could be built on top of the core Parallel Co-Pilot panel. The goal is to move beyond simple "swap" functionality and create a more powerful, integrated, and intelligent workflow for reviewing and applying AI-generated code. These ideas are intended for consideration and prioritization during Phase 2 development.

## 2. Proposed Advanced Features

### 2.1. Idea: Apply as Diff/Patch

-   **Problem:** The current "swap" feature is a blunt instrument. It replaces the entire file, which can be risky if the AI only intended to change a small part of it and made a mistake elsewhere. It also makes it hard to see exactly what changed.
-   **Proposed Solution:**
    1.  **Diff Generation:** When an AI response is pasted into a tab, the extension automatically generates a diff between the tab's content and the original source file.
    2.  **Inline Diff View:** The editor in the tab could be enhanced to show an inline diff view (similar to VS Code's source control view), highlighting added and removed lines.
    3.  **"Apply Patch" Button:** The "Swap" button is replaced with an "Apply Patch" button. Clicking it would attempt to apply only the identified changes to the source file, leaving the rest of the file untouched. This is a much safer and more precise way to integrate AI suggestions.
-   **Technical Notes:** This would require a diffing library (e.g., `diff-match-patch` or `jsdiff`) on the frontend or backend to generate and apply patches.

### 2.2. Idea: Integrated Git Workflow

-   **Problem:** After a developer tests and accepts an AI suggestion, the next step is almost always to commit the change. This requires leaving the co-pilot panel and using the source control view.
-   **Proposed Solution:**
    1.  **"Commit This Change" Button:** Add a new button to each tab in the Parallel Co-Pilot panel.
    2.  **Workflow:**
        *   The user swaps in the AI code and verifies it works.
        *   They click "Commit This Change".
        *   The extension automatically stages the modified file (`git add <file_path>`).
        *   The extension opens the Source Control commit input box.
        *   **Enhancement:** The commit message box could be pre-populated with a summary of the changes, potentially generated by another AI call based on the diff.
-   **Technical Notes:** This requires deeper integration with the `vscode.git` extension API to programmatically stage files and interact with the commit box.

### 2.3. Idea: Response Annotation and Rating

-   **Problem:** It's difficult to remember why a particular AI response was good or bad, especially when looking back at the history via the Cycle Navigator.
-   **Proposed Solution:**
    1.  **Rating/Annotation UI:** Add a small section to each tab allowing the user to give a thumbs up/down rating and add a short text note (e.g., "Works, but inefficient" or "Best solution, very clean"). This includes highlighting specific sections of code to associate with a comment.
    2.  **Persistence:** These annotations would be saved as part of the `dce_history.json` file, associated with that specific response.
    3.  **Benefit:** When navigating back through cycles, these notes would provide valuable context about the quality and outcome of each AI suggestion, enhancing the "knowledge graph" of the project.
-   **Technical Notes:** This requires extending the data model in `A39` and adding the corresponding UI elements and state management.
</file_artifact>

<file path="src/Artifacts/A41.2. DCE - Phase 2 - Feature Ideation & Competitive Analysis.md">
# Artifact A41.2: DCE - Phase 2 - Feature Ideation & Competitive Analysis
# Date Created: C71
# Author: AI Model
# Updated on: C71 (Incorporate user feedback from C71)

- **Key/Value for A0:**
- **Description:** An analysis of similar AI coding assistant tools (e.g., Cursor.sh, Copilot Chat) and a brainstorm of potential advanced features for the Parallel Co-Pilot panel.
- **Tags:** feature plan, phase 2, research, competitive analysis, ideation, roadmap

## 1. Overview & Goal

The core vision of the Parallel Co-Pilot panel is to solve the "single-threaded" limitation of current AI chat interfaces. As we plan its implementation, it's valuable to analyze existing tools to identify best-in-class features and brainstorm new ideas that could give our extension a unique advantage. The goal of this document is to explore this landscape and generate a backlog of potential enhancements for Phase 2 and beyond, incorporating feedback from Cycle 71.

## 2. Competitive Analysis (Incorporating Search Results [1, 2, 3, 4])

### 2.1. GitHub Copilot Chat & Similar Tools
-   **Strengths:** Deeply integrated, understands editor context, uses "slash commands" (`/fix`, `/doc`) for specific intents. [5]
-   **Weakness (Our Opportunity):** Fundamentally a linear, single-threaded chat. Comparing multiple responses to a single prompt is difficult and requires manual copy-pasting. Our parallel tabbed view is a direct solution to this.

### 2.2. Cursor.sh
-   **Strengths:** An "AI-first" fork of VS Code. Has an "AI-diff" feature that applies changes directly in the editor with an intuitive diff view.
-   **Weakness (Our Opportunity):** It's a separate application, not an extension. Users must leave their standard VS Code setup. Our tool integrates into the existing environment. The user has also specified a preference for a whole-file workflow over Cursor's chunk-based edits.

### 2.3. AI Toolkit for Visual Studio Code
-   **Strengths:** This is the most conceptually similar tool found. It explicitly supports a "Bulk Run" feature to execute prompts across multiple models simultaneously and a "Compare" view to see results side-by-side. [1, 2]
-   **Weakness (Our Opportunity):** While it excels at comparison, its workflow for *testing* the code within the user's live project is not as streamlined. Our "Swap" feature provides an immediate, integrated test loop that appears to be a unique advantage.

## 3. Brainstormed Feature Enhancements for DCE (Refined with C71 Feedback)

This is a backlog of potential features for the Parallel Co-Pilot panel, inspired by the analysis and our project's unique goals.

| Feature ID | Feature Name | Description | Priority |
| :--- | :--- | :--- | :--- |
| **P2-F01** | **Inline Diff View** | Instead of a blind "swap", clicking a button opens a diff view within the tab, comparing the AI response to the source file. The user can then accept the full change. | High |
| **P2-F02** | **AI Refinement Actions (Intent Buttons)** | Per user feedback, each tab will have a small toolbar with **buttons** like "Add Docs," "Find Bugs," or "Refactor." Clicking one sends the tab's content back to the LLM with that specific instruction, replacing the content with the refined response. | High |
| **P2-F03** | **Model Selection Per Tab** | Allow the user to select a different backend LLM (e.g., Gemini, Claude, Local URL) for each tab. This requires the API Key Management feature from `A41`. | Medium |
| **P2-F04** | **"Accept Response" Workflow** | Formalize the user's feedback. The "Swap" button is for temporary, iterative testing. A separate, explicit **"Accept Response"** button will permanently overwrite the source file, signifying the end of that iteration for that file. | High |
| **P2-F05** | **Response Annotation & Rating** | A feature the user liked: Add UI for thumbs up/down, short text notes, and tags (e.g., "works", "buggy"). This metadata is saved with the cycle history, enhancing the knowledge graph. | Medium |
| **P2-F06** | **Highlight-to-Context** | Allow a user to highlight a block of code in the main editor, right-click, and select "Send to Parallel Co-Pilot". This would open a new tab in the panel, pre-filled with the highlighted code. | Medium |
| **P2-F07** | **Ephemeral "Cycles Context" Field** | Per user feedback, add a separate text field for temporary context (e.g., error logs). This content is included in the prompt for the current cycle but is NOT saved to the permanent `dce_history.json` to prevent token bloat over time. | High |
</file_artifact>

<file path="src/Artifacts/A42. DCE - Phase 2 - Initial Scaffolding Deployment Script.md">
# Artifact A42: DCE - Phase 2 - Initial Scaffolding Deployment Script
# Date Created: C72
# Author: AI Model
# Updated on: C73 (Flesh out script with full placeholder content)

- **Key/Value for A0:**
- **Description:** Contains a Node.js script that, when executed, creates the file and directory structure for the Phase 2 Parallel Co-Pilot panel.
- **Tags:** deployment, script, scaffolding, bootstrap, nodejs, automation, phase 2

## 1. Overview

This artifact contains the `deploy_phase2_scaffold.js` script. Its purpose is to automate the creation of the new files and directories required for Phase 2, as outlined in `A40. DCE - Phase 2 - Parallel Co-Pilot - Target File Structure`. This ensures a consistent setup for starting development on the new features.

## 2. How to Use

1.  Save the code below as `deploy_phase2_scaffold.js` in your project's root directory (e.g., `C:\Projects\DCE\`).
2.  Open a terminal in that directory.
3.  Run the script using Node.js: `node deploy_phase2_scaffold.js`
4.  The script will create the new directories and placeholder files, logging its progress to the console.

## 3. Script: `deploy_phase2_scaffold.js`

```javascript
const fs = require('fs').promises;
const path = require('path');

// --- File Content Definitions ---

const filesToCreate = [
    {
        path: 'src/backend/services/history.service.ts',
        content: `// src/backend/services/history.service.ts
import * as vscode from 'vscode';
import { Services } from './services';

// Basic structure for history data
interface CycleResponse {
    responseId: string;
    model: string;
    content: string;
}

interface Cycle {
    cycleId: string;
    timestamp: string;
    prompt: string;
    responses: CycleResponse[];
}

interface HistoryFile {
    version: number;
    cycles: Cycle[];
}

export class HistoryService {
    private historyFilePath: string | undefined;

    constructor() {
        const workspaceFolders = vscode.workspace.workspaceFolders;
        if (workspaceFolders && workspaceFolders.length > 0) {
            this.historyFilePath = path.join(workspaceFolders.uri.fsPath, '.vscode', 'dce_history.json');
        }
    }

    private async _readHistoryFile(): Promise<HistoryFile> {
        if (!this.historyFilePath) return { version: 1, cycles: [] };
        try {
            const content = await vscode.workspace.fs.readFile(vscode.Uri.file(this.historyFilePath));
            return JSON.parse(Buffer.from(content).toString('utf-8'));
        } catch (error) {
            Services.loggerService.warn("dce_history.json not found or is invalid. A new one will be created.");
            return { version: 1, cycles: [] };
        }
    }

    private async _writeHistoryFile(data: HistoryFile): Promise<void> {
        if (!this.historyFilePath) return;
        const dir = path.dirname(this.historyFilePath);
        try {
            await vscode.workspace.fs.createDirectory(vscode.Uri.file(dir));
            const content = Buffer.from(JSON.stringify(data, null, 2), 'utf-8');
            await vscode.workspace.fs.writeFile(vscode.Uri.file(this.historyFilePath), content);
        } catch (error) {
            Services.loggerService.error(\`Failed to write to dce_history.json: \${error}\`);
        }
    }

    public async getCycleHistory() {
        Services.loggerService.log("HistoryService: getCycleHistory called.");
        const history = await this._readHistoryFile();
        return history.cycles.map(c => c.cycleId).sort(); // Return sorted list of cycle IDs
    }
}
`
    },
    {
        path: 'src/client/views/parallel-copilot.view/index.ts',
        content: `// src/client/views/parallel-copilot.view/index.ts
import { onMessage } from "./on-message";

export const viewConfig = {
    entry: "parallelCopilotView.js",
    type: "viewType.sidebar.parallelCopilot",
    handleMessage: onMessage,
};
`
    },
    {
        path: 'src/client/views/parallel-copilot.view/on-message.ts',
        content: `// src/client/views/parallel-copilot.view/on-message.ts
import { ServerPostMessageManager } from "@/common/ipc/server-ipc";
import { Services } from "@/backend/services/services";

export function onMessage(serverIpc: ServerPostMessageManager) {
    const loggerService = Services.loggerService;
    loggerService.log("Parallel Co-Pilot view message handler initialized.");

    // TODO: Add message handlers for Phase 2 features
    // e.g., serverIpc.onClientMessage(ClientToServerChannel.RequestSwapFileContent, ...)
}
`
    },
    {
        path: 'src/client/views/parallel-copilot.view/view.scss',
        content: `/* Styles for Parallel Co-Pilot View */
body {
    padding: 0;
    font-family: var(--vscode-font-family);
    font-size: var(--vscode-font-size);
    color: var(--vscode-editor-foreground);
    background-color: var(--vscode-sideBar-background);
}

.pc-view-container {
    padding: 8px;
    display: flex;
    flex-direction: column;
    height: 100vh;
    gap: 8px;
}

.cycle-navigator {
    display: flex;
    align-items: center;
    gap: 8px;
    padding-bottom: 8px;
    border-bottom: 1px solid var(--vscode-panel-border);
}

.tab-bar {
    display: flex;
    border-bottom: 1px solid var(--vscode-panel-border);
}

.tab {
    padding: 6px 12px;
    cursor: pointer;
    border-bottom: 2px solid transparent;
    color: var(--vscode-tab-inactiveForeground);
}

.tab.active {
    color: var(--vscode-tab-activeForeground);
    border-bottom-color: var(--vscode-tab-activeBorder);
}

.tab-content {
    padding-top: 8px;
}
`
    },
    {
        path: 'src/client/views/parallel-copilot.view/view.tsx',
        content: `// src/client/views/parallel-copilot.view/view.tsx
import * as React from 'react';
import * as ReactDOM from 'react-dom/client';
import './view.scss';
import { VscChevronLeft, VscChevronRight } from 'react-icons/vsc';

const App = () => {
    const [activeTab, setActiveTab] = React.useState(1);
    const tabCount = 4; // Example tab count

    return (
        <div className="pc-view-container">
            <div className="cycle-navigator">
                <span>Cycle:</span>
                <button><VscChevronLeft /></button>
                <span>C73</span>
                <button><VscChevronRight /></button>
            </div>
            
            <div className="tab-bar">
                {[...Array(tabCount)].map((_, i) => (
                    <div 
                        key={i} 
                        className={\`tab \${activeTab === i + 1 ? 'active' : ''}\`}
                        onClick={() => setActiveTab(i + 1)}
                    >
                        Response {i + 1}
                    </div>
                ))}
            </div>

            <div className="tab-content">
                {[...Array(tabCount)].map((_, i) => (
                    activeTab === i + 1 && <div key={i}>Content for Response {i + 1}</div>
                ))}
            </div>
        </div>
    );
};

const root = ReactDOM.createRoot(document.getElementById('root')!);
root.render(<App />);
`
    },
];

// --- Main Execution ---

async function deployScaffold() {
    console.log('Starting Phase 2 scaffold deployment...');
    const rootDir = process.cwd();

    for (const file of filesToCreate) {
        const fullPath = path.join(rootDir, file.path);
        const dir = path.dirname(fullPath);

        try {
            await fs.mkdir(dir, { recursive: true });
            await fs.writeFile(fullPath, file.content, 'utf-8');
            console.log(` Created: ${file.path}`);
        } catch (error) {
            console.error(` Failed to create ${file.path}: ${error.message}`);
        }
    }

    console.log('\\n Phase 2 scaffold deployment complete! ');
    console.log('Next steps:');
    console.log('1. Review and apply changes to package.json, webpack.config.js, src/client/views/index.ts, and src/common/view-types.ts.');
    console.log('2. Update services.ts to instantiate and provide the new HistoryService.');
}

deployScaffold();
```
</file_artifact>

<file path="src/Artifacts/A43. DCE - Phase 2 - Implementation Roadmap.md">
# Artifact A43: DCE - Phase 2 - Implementation Roadmap
# Date Created: C72
# Author: AI Model
# Updated on: C87 (Promote Persistence and Diffing, defer advanced UI)

- **Key/Value for A0:**
- **Description:** Provides a step-by-step implementation plan for building the Phase 2 features, including the Parallel Co-Pilot panel and the integrated Diff Tool.
- **Tags:** feature plan, phase 2, roadmap, project plan, diff tool

## 1. Overview & Goal

This document provides a clear, step-by-step roadmap for the implementation of Phase 2. The scope of Phase 2 is now defined as the **Parallel Co-Pilot Panel with state persistence and an integrated Diff Tool**. This roadmap breaks the large feature set into smaller, manageable, and testable steps. The goal is to build the functionality incrementally, ensuring a stable foundation at each stage.

## 2. Implementation Steps

### Step 1: Foundational UI & State Persistence (Highest Priority)

-   **Goal:** Create a functional UI for the PCPP where all user input is saved and restored reliably.
-   **Tasks:**
    1.  **Scaffolding & Config:** Ensure all files from `A42` are in place and correctly configured in `package.json`, `webpack.config.js`, etc.
    2.  **UI Development (`view.tsx`):**
        *   Build the static React components for the panel based on the updated mockup in `A35`.
        *   **Crucially, re-add the "Cycle Context" and "Ephemeral Context" text areas to fix the C87 regression.**
    3.  **Backend (`history.service.ts`):** Implement the core logic to read from and write to the `.vscode/dce_history.json` file.
    4.  **State Sync Loop:** Implement the full persistence loop. Changes in the frontend UI trigger a debounced `SaveCycleData` IPC message. The backend `HistoryService` updates the JSON file.
-   **Outcome:** A visible panel where any text typed into any field is saved and restored when the panel is closed and reopened or moved to a new window.

### Step 2: Cycle Navigator

-   **Goal:** Enable navigation through the persistent history created in Step 1.
-   **Tasks:**
    1.  **IPC:** Implement the `RequestCycleHistoryList` and `RequestCycleData` channels.
    2.  **Frontend (`view.tsx`):**
        *   On load, fetch the list of all cycle IDs to determine the valid range for navigation (`1` to `maxCycleId`).
        *   Wire the `<` and `>` buttons to change the `currentCycleId` state.
        *   Create a `useEffect` hook that listens for changes to `currentCycleId` and requests the corresponding data from the backend.
        *   The handler for `SendCycleData` will update the entire panel's state with the historical data.
-   **Outcome:** The user can click the back and forward buttons to load and view the complete state of the PCPP from previous cycles.

### Step 3: File Association and Diffing

-   **Goal:** Implement the ability to see a diff for any file mentioned in an AI response.
-   **Tasks:**
    1.  **Add Dependency:** Add the `diff` library to `package.json`.
    2.  **UI (`view.tsx`):**
        *   Implement the "Associated Files" list UI element. It will be populated by the `detectedFiles` state, which is already being parsed.
        *   Make each file in the list a clickable button.
    3.  **IPC:** Create a `RequestFileContent` channel.
    4.  **Backend (`fs.service.ts`):** Implement a handler that reads a file's content and sends it back.
    5.  **Component (`DiffViewer.tsx`):** Create a new component that takes two strings and renders a side-by-side or inline diff.
    6.  **Workflow:** Clicking a file in the list sends `RequestFileContent`. When the content arrives, the frontend shows the `DiffViewer` component (e.g., in a modal) with the original content and the content from the AI response.
-   **Outcome:** The user can paste a response and immediately get a clear, color-coded view of the changes being proposed for any file.

### Step 4: Core "Swap" Functionality

-   **Goal:** Implement the "Swap with Source" feature.
-   **Tasks:**
    1.  **IPC Channels:** Implement `RequestSwapFileContent`.
    2.  **Backend (`fs.service.ts`):** Implement the `handleSwapFileContentRequest` method.
    3.  **Frontend (`view.tsx`):** Wire up the "Swap" button to trigger the IPC message.
-   **Outcome:** The user can test AI-generated code in their workspace with a single click.

### Step 5: Advanced Features (Future Cycles)

-   **Goal:** Implement remaining features from the vision.
-   **Tasks:**
    *   Annotation and Rating (Comments, Thumbs Up/Down).
    *   Live API Integration (The new Phase 3).
    *   Advanced UI from `A50` (Resizable panes, inner editors).
</file_artifact>

<file path="src/Artifacts/A44. DCE - Phase 1 - Word Document Handling Strategy.md">
# Artifact A44: DCE - Phase 1 - Word Document Handling Strategy
# Date Created: C73
# Author: AI Model
# Updated on: C81 (Add handling for corrupted .docx files)

- **Key/Value for A0:**
- **Description:** Defines the strategy for handling Word document files (.docx) by converting them to text on-demand and caching them in memory for flattening.
- **Tags:** feature plan, docx, text extraction, virtualization, cache, phase 1

## 1. Overview & Goal

To further expand the data curation capabilities of the extension, users need to be able to include the content of Microsoft Word documents (`.docx`). Following the successful virtualization pattern used for PDFs and Excel files, the goal is to extract text from Word documents on-demand and hold it in an in-memory cache. This allows their content to be included in the flattened context without creating temporary files in the user's workspace.

## 2. Supported & Unsupported Formats

-   **Supported:** This strategy focuses exclusively on the modern, XML-based **`.docx`** format.
-   **Unsupported:** The legacy binary **`.doc`** format is significantly more complex to parse and is **not supported**. The extension will identify `.doc` files and insert a placeholder in the flattened output rather than attempting to process them.

## 3. User Stories

| ID | User Story | Acceptance Criteria |
|---|---|---|
| DOCX-01 | **Include Word Document Text in Context** | As a user, when I check a `.docx` file, I want its text content to be extracted and included in the `flattened_repo.md`, so I can use reports and documents as context for the LLM. | - Checking `.docx` files is allowed. <br> - The token count displayed for the file reflects its extracted text content. <br> - When flattened, the text from the document is included within a `<file>` tag. <br> - No temporary files are created in the user's workspace. |
| DOCX-02 | **Handle Unsupported `.doc` format** | As a user, when I check a legacy `.doc` file, I want the system to acknowledge it but inform me in the output that its content could not be processed, so I am not confused by missing data or corrupted text. | - Checking `.doc` files is allowed. <br> - The token count for `.doc` files remains 0. <br> - When flattened, a clear placeholder comment is included for the `.doc` file, stating that the format is unsupported. |
| DOCX-03 | **Handle Corrupted `.docx` files** | As a user, if I check a `.docx` file that is corrupted or invalid, I want the extension to fail gracefully and show me an error in the UI, so I know the file has a problem. | - The extension attempts to parse the `.docx` file. <br> - If parsing fails due to file corruption (e.g., it's not a valid zip archive), the token count is set to 0. <br> - An error message (e.g., "File may be corrupted") is displayed in the file's tooltip in the UI. <br> - The flattened output includes a comment indicating the failure. |

## 4. Technical Implementation Plan

1.  **Dependency:**
    *   The `mammoth` library will be added to `package.json`. It is a popular and effective library for converting `.docx` files to HTML and raw text.

2.  **Backend (`fs.service.ts`):**
    *   **In-Memory Cache:** A new private cache will be added: `private wordTextCache = new Map<string, { text: string; tokenCount: number }>();`.
    *   **New IPC Handler (`RequestWordToText`):**
        *   This handler will receive a file path. It will first check the cache.
        *   **If `.doc`:** It will cache an "Unsupported Format" message and a token count of 0, then notify the client.
        *   **If `.docx`:** It will read the file buffer and attempt to parse it with `mammoth.extractRawText()`.
        *   **Success:** On success, it will calculate the token count, store the result in the cache, and send the stats to the client.
        *   **Failure:** The `try...catch` block will inspect the error. If the error message indicates a corrupted file (e.g., from `jszip`), it will create a specific, user-friendly error message and send that to the client with a token count of 0.

3.  **Frontend (`view.tsx`):**
    *   **On-Demand Extraction:** The logic for handling checked files and restored selections will be updated to send a `RequestWordToText` message to the backend for `.docx` and `.doc` files.

4.  **Backend (`flattener.service.ts`):**
    *   **Virtual Content Retrieval:** The flattener will retrieve the text from the `wordTextCache` in the `FSService` instead of reading the binary file. It will correctly handle the "Unsupported Format" and "Corrupted File" messages from the cache.
</file_artifact>

<file path="src/Artifacts/A45. DCE - Phase 2 - Pop-out Co-Pilot Window - Feature Plan.md">
# Artifact A45: DCE - Phase 2 - Pop-out Co-Pilot Window - Feature Plan
# Date Created: C76
# Author: AI Model
# Updated on: C78 (Reflect implementation of WebviewPanel)

- **Key/Value for A0:**
- **Description:** Outlines the technical strategy to allow the Parallel Co-Pilot panel to be "popped out" into a separate window by re-implementing it as a main editor WebviewPanel.
- **Tags:** feature plan, phase 2, pop-out, window, webview, ux

## 1. Overview & Goal

The Parallel Co-Pilot panel is designed for intensive, side-by-side comparison of code, a task that benefits greatly from maximum screen real estate. Many developers use multiple monitors and would prefer to move this panel to a secondary display. The goal of this feature is to enable the user to "pop out" the Parallel Co-Pilot panel into its own floating window.

## 2. Problem & Proposed Solution

A direct `popOut()` API for a sidebar webview does not exist in the VS Code extension API. The most robust and user-friendly way to achieve this is to leverage a native VS Code feature: users can drag any editor tab into its own floating window.

Therefore, the proposed solution is to **re-architect the Parallel Co-Pilot from a sidebar view (`WebviewViewProvider`) into a main editor view (`WebviewPanel`)**.

### 2.1. User Experience Flow

1.  The user runs the `DCE: Open Parallel Co-Pilot` command from the Command Palette or clicks the icon in the Activity Bar.
2.  Instead of opening in the sidebar, the Parallel Co-Pilot panel opens as a new tab in the main editor group.
3.  The user can then click and drag this tab out of the main VS Code window, and it will become its own floating window, which can be moved to another monitor.

## 3. User Stories

| ID | User Story | Acceptance Criteria |
|---|---|---|
| P2-WIN-01 | **Open Co-Pilot in Main Editor**| As a developer, I want a command or button to open the Parallel Co-Pilot panel in a main editor tab, so I have more horizontal space to view and compare responses. | - A command `DCE: Open Parallel Co-Pilot` exists. <br> - An icon in the activity bar triggers this command. <br> - Executing the command opens a new editor tab containing the full Co-Pilot UI. <br> - If the panel is already open, the command brings it into focus. |
| P2-WIN-02 | **Move Co-Pilot to New Window** | As a developer with multiple monitors, after opening the Co-Pilot in an editor tab, I want to drag that tab out of my main VS Code window to turn it into a separate, floating window, so I can place it on my second monitor. | - The Co-Pilot editor tab behaves like any other editor tab. <br> - It can be dragged to create new editor groups or dragged outside the main window to create a new floating window. |

## 4. Technical Implementation Plan (C78)

This is a significant architectural change that has been implemented.

1.  **Remove Sidebar Contribution (`package.json`):**
    *   The `dce-parallel-copilot` entry in `contributes.viewsContainers.activitybar` still exists to provide an entry point icon, but the view is no longer directly registered under `contributes.views`.

2.  **Create a `WebviewPanel` (`extension.ts`):**
    *   A new command, `dce.openParallelCopilot`, is registered.
    *   A module-level variable (`private static parallelCopilotPanel: vscode.WebviewPanel | undefined;`) is used to track the panel's instance, ensuring only one can exist.
    *   When the command is executed, it checks if the panel already exists. If so, it calls `panel.reveal()`.
    *   If not, it calls `vscode.window.createWebviewPanel`. This creates the webview in an editor tab.
    *   The panel's `onDidDispose` event is used to clear the static instance variable.
    *   The logic for setting the webview's HTML, options, and message handlers is now managed within this command's callback.

3.  **State Management:**
    *   Because the panel is now created on-demand, its state (tab content, cycle number) must be managed in a backend service to be restored if the panel is closed and reopened. This is a future enhancement. For now, the state is ephemeral to the panel's lifecycle.
</file_artifact>

<file path="src/Artifacts/A46. DCE - Phase 2 - Paste and Parse Response - Feature Plan.md">
# Artifact A46: DCE - Phase 2 - Paste and Parse Response - Feature Plan
# Date Created: C76
# Author: AI Model

- **Key/Value for A0:**
- **Description:** Details the plan for allowing users to paste a full AI response into a tab, which the extension will then parse to identify file paths referenced within XML tags.
- **Tags:** feature plan, phase 2, paste, parse, workflow, automation

## 1. Overview & Goal

The manual workflow for using the Parallel Co-Pilot involves copying an entire AI response and pasting it into one of the response tabs. These responses often contain multiple file updates, each wrapped in XML-like tags (e.g., `<file path="...">...</file>`). The goal of this feature is to make the extension "intelligent" about this pasted content. It should automatically parse the text, identify the files being modified, and associate them with the response tab.

## 2. User Story

| ID | User Story | Acceptance Criteria |
|---|---|---|
| P2-PARSE-01 | **Parse Pasted Content** | As a developer, when I paste a full AI response into a tab, I want the extension to automatically detect the file paths mentioned in the `<file>` tags, so I can see a list of affected files and use them for "Swap" and "Diff" operations. | - Pasting text into a response tab's editor triggers a parsing event. <br> - The extension uses a regular expression to find all occurrences of `<file path="...">`. <br> - The extracted file paths are stored in the state for that tab. <br> - The UI for the tab is updated to display the list of detected files. |
| P2-PARSE-02 | **Set Primary Source File** | As a developer, after pasting a response with multiple files, I want the first file detected to be automatically set as the primary "source file" for the "Swap" and "Diff" actions, so I don't have to select it manually. | - After parsing, if the tab's `sourceFilePath` is not already set, it is automatically populated with the path of the first file found in the pasted content. <br> - The metadata table (comparing original vs. response) updates accordingly. |

## 3. Technical Implementation Plan

1.  **Frontend Logic (`parallel-copilot.view/view.tsx`):**
    *   **Event Handler:** An `onPaste` event handler will be added to the `<textarea>` or code editor component for each tab.
    *   **Parsing Function:** A new utility function, `parseFilePathsFromResponse(text: string): string[]`, will be created.
        *   It will use a regular expression: `/<file path="([^"]+)">/g`.
        *   It will execute this regex on the input text to extract all captured file paths.
    *   **State Update:**
        *   Inside the `onPaste` handler, it will call `event.clipboardData.getData('text')` to get the pasted content.
        *   It will pass this content to the `parseFilePathsFromResponse` function.
        *   The resulting array of paths will be stored in the state for the active tab (e.g., in a new `detectedFiles: string[]` property).
        *   If the tab's primary `sourceFilePath` is empty, it will be set to the first path in the array.

2.  **UI Update (`parallel-copilot.view/view.tsx`):**
    *   A new UI element will be added to each tab's content area.
    *   It will conditionally render if `detectedFiles` has items.
    *   It will display a list of the detected file paths, perhaps as clickable links that could set the active `sourceFilePath` for the tab.

3.  **No Backend Changes:** This feature is entirely a frontend concern, involving UI event handling, string parsing, and state management within the React component.
</file_artifact>

<file path="src/Artifacts/A47. DCE - Phase 2 - Prompt Amalgamation Feature Plan.md">
# Artifact A47: DCE - Phase 2 - Prompt Amalgamation Feature Plan
# Date Created: C82
# Author: AI Model

- **Key/Value for A0:**
- **Description:** Details the plan for a "Generate prompt.md" button that will assemble the static schemas, cycle history, and flattened code into a single, complete prompt file.
- **Tags:** feature plan, phase 2, prompt engineering, automation, workflow

## 1. Overview & Goal

The process of constructing the final `prompt.md` file is a core part of the curator's workflow. It involves manually assembling several distinct pieces of content: static schemas, the cycle history, and the dynamically generated `flattened_repo.md`. This is a repetitive and error-prone task. The goal of this feature is to automate this process with a single button click, generating a complete, perfectly formatted `prompt.md` file on demand.

## 2. User Story

| ID | User Story | Acceptance Criteria |
|---|---|---|
| P2-PROMPT-01 | **Generate Complete Prompt** | As a curator, I want to click a button to generate a complete `prompt.md` file that includes all my standard schemas, the project's cycle history, and the latest flattened code, so I can start my next development cycle with zero manual setup. | - A "Generate `prompt.md`" button is available in the Parallel Co-Pilot Panel UI. <br> - A "Cycle Title" input field is available next to the cycle navigator. <br> - Clicking the button creates or overwrites `prompt.md` in the workspace root. <br> - The generated file has the correct structure: static schemas, then the dynamic cycle overview, then the content of `flattened_repo.md`. <br> - The cycle overview is built from the `dce_history.json` file and includes the title from the new input field. |

## 3. Technical Implementation Plan

1.  **UI (`parallel-copilot.view/view.tsx`):**
    *   Add a "Generate `prompt.md`" button to the main header toolbar.
    *   Add a new state variable and a corresponding `<input type="text">` element for the "Cycle Title" next to the cycle navigator.
    *   The button's `onClick` handler will send a new IPC message to the backend.

2.  **IPC Channels:**
    *   `ClientToServerChannel.RequestCreatePromptFile`: Payload will be `{ cycleTitle: string, currentCycle: number }`.

3.  **Backend (New `prompt.service.ts`):**
    *   Create a new `PromptService` to encapsulate the logic.
    *   **Static Templates:** The service will contain private string constants holding the content for `<M1. artifact schema>`, `<M3. Interaction Schema>`, and `<M4. current project scope>`.
    *   **`generatePromptFile` Method:** This method will be the core of the service.
        1.  It will receive the `cycleTitle` and `currentCycle` from the IPC message.
        2.  It will read the `dce_history.json` file (using `HistoryService`) to build the `<M2. cycle overview>` section dynamically.
        3.  It will read the entire content of `flattened_repo.md`.
        4.  It will assemble these strings in the correct order into a single, large string.
        5.  It will write this final string to `prompt.md` in the workspace root using `vscode.workspace.fs.writeFile`.
        6.  It will show a `showInformationMessage` to confirm completion.

4.  **Integration:**
    *   The new `PromptService` will be instantiated in `services.ts`.
    *   A new handler for `RequestCreatePromptFile` will be added to the `on-message.ts` for the Parallel Co-Pilot view, which will call the `PromptService`.
</file_artifact>

<file path="src/Artifacts/A48. DCE - Phase 2 - Advanced Syntax Highlighting Plan.md">
# Artifact A48: DCE - Phase 2 - Advanced Syntax Highlighting Plan
# Date Created: C82
# Author: AI Model
# Updated on: C90 (Update plan to reflect implementation)

## 1. Overview & Goal

AI-generated responses are complex documents, containing both explanatory Markdown text and code blocks in various languages. A plain `<textarea>` element does not provide any syntax highlighting, making these responses difficult to read and analyze. The goal of this feature is to significantly enhance the readability of AI responses by replacing the textareas with a proper code editor component that can provide rich, language-aware syntax highlighting.

## 2. User Story

| ID | User Story | Acceptance Criteria |
|---|---|---|
| P2-SYNTAX-01 | **View Highlighted Responses** | As a developer, I want to see AI responses with full syntax highlighting inside the Parallel Co-Pilot tabs, so I can easily distinguish between comments, keywords, and code, just like in a real editor. | - The content area of each response tab renders with syntax highlighting. <br> - Standard Markdown elements (headers, lists, bold, italics, backticks) are formatted correctly. <br> - Code blocks (e.g., ` ```typescript ... ``` `) are highlighted with the correct grammar for the specified language. <br> - The highlighting should be theme-aware, matching the user's current VS Code theme. |

## 3. Technical Implementation Strategy (C90)

### 3.1. Chosen Library: `starry-night`

After research and consideration of alternatives like `refractor`, **`@wooorm/starry-night`** is the chosen library for syntax highlighting.

-   **Rationale (C85):**
    -   **High Fidelity:** It uses the same TextMate grammars as VS Code itself. This is the most important factor, as it ensures the highlighting in our panel will be a perfect visual match to the user's native editor experience.
    -   **Backend Architecture:** Our implementation performs highlighting on the backend (in the Node.js extension host) and sends pre-rendered HTML to the frontend webview. This means the primary drawback of `starry-night`its large bundle sizeis a non-issue for the client. The "heavy lifting" is done by the extension's server-side process, keeping the webview lightweight and performant.

### 3.2. Implementation Plan

1.  **Dependencies (`package.json`):**
    *   `@wooorm/starry-night` is the core backend dependency.
    *   `hast-util-to-html` is used to convert the abstract syntax tree to an HTML string.
    *   `react-markdown` is added as a frontend dependency to handle the rendering of non-code markdown content (lists, bold, etc.).

2.  **Backend (`fs.service.ts`):**
    *   The `handleSyntaxHighlightRequest({ code, lang, id })` method is implemented.
    *   It initializes `starry-night` with a set of common grammars.
    *   It uses `starryNight.highlight(code, scope)` where `scope` is determined from the language identifier (e.g., 'typescript' -> 'source.ts').
    *   It converts the resulting `hast` tree to an HTML string using `toHtml`.
    *   This HTML string is sent back to the client via the `SendSyntaxHighlight` IPC channel, including the `id` to match the request.

3.  **IPC Channels:**
    *   `ClientToServerChannel.RequestSyntaxHighlight`: Payload `{ code: string; lang: string, id: string }`.
    *   `ServerToClientChannel.SendSyntaxHighlight`: Payload `{ highlightedHtml: string, id: string }`.

4.  **Frontend (`parallel-copilot.view/view.tsx`):**
    *   After a response is parsed into `parsedContent`, the view iterates through `parsedContent.files`.
    *   For each file block, it sends a `RequestSyntaxHighlight` message to the backend.
    *   A state map (`highlightedCodeBlocks: Map<string, string>`) caches the HTML returned from the backend.
    *   The component that renders the file's code uses `dangerouslySetInnerHTML` to display the highlighted HTML.
    *   The `summary` and `courseOfAction` sections are rendered using the `<ReactMarkdown>` component to display formatted text.
</file_artifact>

<file path="src/Artifacts/A49. DCE - Phase 2 - File Association & Diffing Plan.md">
# Artifact A49: DCE - Phase 2 - File Association & Diffing Plan
# Date Created: C82
# Author: AI Model
# Updated on: C27 (Deprecate custom diff viewer in favor of native integration)

- **Key/Value for A0:**
- **Description:** Plans the UI and backend logic to visually link file blocks in an AI response to workspace files and sets the stage for an integrated diff tool.
- **Tags:** feature plan, phase 2, ui, ux, diff, file association

## 1. Overview & Goal

To make the Parallel Co-Pilot Panel's workflow trustworthy and intuitive, users need a clear visual confirmation of which local file an AI-generated code block is intended to modify. This feature introduces a "file association" mechanism that parses AI responses, verifies the existence of the mentioned files, and displays this status to the user.

**Update (C27):** The custom, integrated diff viewer has been **deprecated**. It is being replaced by an integration with VS Code's native diff viewer (`vscode.diff`), as detailed in `A88. DCE - Native Diff Integration Plan.md`. This provides a superior user experience with all the features of the native editor.

## 2. User Stories

| ID | User Story | Acceptance Criteria |
|---|---|---|
| P2-ASSOC-01 | **See Affected Files** | As a developer, when I parse an AI response, I want the extension to automatically show me a list of all the file paths it intends to modify, so I can understand the scope of the proposed changes. | - After parsing, a collapsible "Associated Files" section appears in the tab's UI. <br> - This section displays a list of all file paths found in the response. |
| P2-ASSOC-02 | **Verify File Existence** | As a developer, for each file listed, I want to see a visual indicator of whether that file already exists in my workspace, so I can spot potential errors or new files proposed by the AI. | - Next to each listed file path, an icon is displayed. <br> - A green checkmark (``) indicates the file exists at that path. <br> - A red cross (``) indicates the file does not exist. |
| P2-ASSOC-03 | **Preview Changes with Native Diff** | As a developer, I want an "Open Changes" button to see a side-by-side comparison of the original file and the AI's proposed changes in a native VS Code diff tab, so I can review the exact changes before accepting them. | - An "Open Changes" icon appears on hover for each existing file in the "Associated Files" list. <br> - Clicking it opens a new editor tab showing the native VS Code diff view. <br> - The right side shows the current content of the workspace file. <br> - The left side shows the AI-generated content from the response tab. |
| P2-ASSOC-04 | **Accept Changes** | As a developer, I want to be able to accept changes from the AI response into my workspace, either for a single file or for a batch of selected files. | - An "Accept this file" button replaces the content of the workspace file with the AI's version. <br> - A separate "Accept Selected Files" button performs a bulk replacement for all files checked in the "Associated Files" list. <br> - This is a one-way copy from the AI response to the workspace. |

## 3. Technical Implementation Plan

1.  **Frontend - Parsing (`response-parser.ts`):**
    *   **Status:** **Complete.**

2.  **Backend - Verification & Highlighting (`file-operation.service.ts`, `highlighting.service.ts`):**
    *   **Status:** **Complete.** The `handleFileExistenceRequest` and `handleSyntaxHighlightRequest` handlers are working.

3.  **Frontend - UI & State (`view.tsx`):**
    *   **Status:** **In Progress.**
    *   **File List & Native Diff:** Implement the "Associated Files" list. An "Open Changes" button on each item will trigger the new native diff workflow as outlined in `A88`.
    *   **Selection State:** Manage a `Set<string>` of `selectedFilesForReplacement` to track which files are checked.
    *   **Accept/Replace Logic:**
        *   The "Accept this file" button will trigger a `RequestWriteFile` IPC message.
        *   The "Accept Selected Files" button will trigger a `RequestBatchFileWrite` IPC message with an array of file paths and their new content.

4.  **Backend - File Writing (`file-operation.service.ts`):**
    *   **Status:** **Complete.** `handleWriteFileRequest` and `handleBatchFileWrite` are implemented.
</file_artifact>

<file path="src/Artifacts/A50. DCE - Phase 2 - UI Component Plan (Resizable Panes & Inner Editors).md">
# Artifact A50: DCE - Phase 2 - UI Component Plan (Resizable Panes & Inner Editors)
# Date Created: C87
# Author: AI Model
# Updated on: C112 (Prioritize resizable panes implementation)

- **Key/Value for A0:**
- **Description:** Documents the plan for advanced UI components like resizable panes and nested, scrollable editors within the Parallel Co-Pilot panel.
- **Tags:** feature plan, phase 2, ui, ux, resizable, scrollable, editor

## 1. Overview & Goal

As the Parallel Co-Pilot Panel (PCPP) becomes more feature-rich, its UI needs to be flexible and efficient. This document outlines the plan for two advanced UI components: a **resizable pane** for the summary/code view and a system of **nested, scrollable "inner editors"** for individual file blocks within a response. The goal is to create a highly readable and customizable interface that prevents "endless scrolling" and allows users to focus on the information that matters most to them.

## 2. User Stories

| ID | User Story | Acceptance Criteria |
|---|---|---|
| P2-UI-01 | **Resizable Panes** | As a developer, I want to be able to drag the vertical divider between the summary/file list pane and the code viewer pane, so I can give more space to the view that is most important for my current task. | - A draggable handle exists on the vertical divider between the two main panes in the parsed view. <br> - Clicking and dragging the handle adjusts the relative width of the two panes. <br> - The layout is responsive and does not break during resizing. <br> - The left pane should be collapsible. |
| P2-UI-02 | **Contained File Editors** | As a developer, when viewing a large AI response with multiple files, I want each file's code to be contained within its own fixed-height, scrollable text area, so I can quickly scroll past entire files without having to scroll through all of their content. | - The extension parses the AI response and identifies individual file blocks (e.g., content within `<file>` tags). <br> - Each file block is rendered inside its own container with a fixed `max-height` and `overflow-y: auto`. <br> - This allows the user to scroll through the list of files quickly, only scrolling within a specific file's content when needed. |
| P2-UI-03 | **File-Level Action Buttons** | As a developer, I want action buttons (like "Accept", "Diff", "Comment") to be associated with each individual file block within a response, so I can act on a single file at a time. | - In the "inner editor" view, each file container has its own set of action buttons. <br> - Clicking "Accept" on one file block only affects that specific file, not the entire response. |

## 3. Technical Implementation Plan

### 3.1. Resizable Panes (Priority for C112)

-   **Strategy:** Implement a custom, lightweight resizable pane component directly within `view.tsx`.
-   **Component Logic:**
    *   The main `.parsed-view-grid` will be the flex container.
    *   A new `div` element with a `.resizer` class will be added between the left and right panes to act as the draggable handle.
    *   **State:** A new state variable, `const [leftPaneWidth, setLeftPaneWidth] = useState(33);`, will manage the width of the left pane as a percentage.
    *   **Event Handling:**
        *   The resizer `div` will have an `onMouseDown` handler.
        *   This handler will attach `onMouseMove` and `onMouseUp` listeners to the `window`.
        *   The `onMouseMove` handler will calculate the new percentage width based on `event.clientX` and update the `leftPaneWidth` state, respecting min/max width constraints.
        *   The `onMouseUp` handler will remove the `mousemove` and `mouseup` listeners from the window.
-   **Integration:** The `style` attribute of the left pane will be bound to this state (e.g., `flex-basis: `${leftPaneWidth}%`).

### 3.2. Inner Editors / Contained File Blocks (Future Cycle)

-   **Strategy:** This requires a significant change to how the response content is rendered. Instead of treating the response as a single block of text to be rendered as Markdown, it must be parsed into a structured array of objects.
-   **Parsing Logic (`view.tsx`):**
    -   A new parsing function will take the raw response string and split it into an array of segments, e.g., `[{ type: 'markdown', content: '...' }, { type: 'file', path: '...', content: '...' }, ...]`.
-   **Rendering Logic (`view.tsx`):**
    -   The main render function will map over this array of segments.
    -   If `segment.type === 'markdown'`, it renders the content as before.
    -   If `segment.type === 'file'`, it renders a new component, e.g., `FileBlock.tsx`.
-   **`FileBlock.tsx` Component:**
    -   This component will be responsible for rendering a single file from the AI response.
    -   It will have a header displaying the file path and the file-specific action buttons (Accept, Diff, etc.).
    -   The main content area will be a `div` with CSS properties `max-height: 300px;` (or similar) and `overflow-y: auto;`.
    -   The code content within this `div` will be syntax-highlighted as before.
</file_artifact>

<file path="src/Artifacts/A51. DCE - A-B-C Testing Strategy for UI Bugs.md">
# Artifact A51: DCE - A-B-C Testing Strategy for UI Bugs
# Date Created: C102
# Author: AI Model & Curator
# Updated on: C103 (Refine to "Original-A-B-C" parallel testing model)

- **Key/Value for A0:**
- **Description:** Outlines a development pattern for creating parallel, isolated test components to diagnose and resolve persistent UI bugs, such as event handling or rendering issues.
- **Tags:** process, debugging, troubleshooting, ui, ux, react

## 1. Overview & Goal

When a user interface (UI) bug, particularly related to event handling (`onClick`, `onDrop`, etc.) or component rendering, proves resistant to conventional debugging, it often indicates a complex or non-obvious root cause. Continuously attempting small, incremental fixes on the main, complex component can be inefficient and can lead to regressions.

The goal of the **"Original-A-B-C" Testing Strategy** is to break this cycle by creating a test harness that runs the original, complex component in parallel with multiple, simplified, independent test components. Each test component attempts to solve the same basic problem using a slightly different technical approach, allowing for rapid diagnosis.

## 2. The Strategy

### 2.1. Core Principles
1.  **Preserve the Original:** Never gut or remove existing, working functionality to build a test case. The original component should remain available as the "control" in the experiment.
2.  **Isolate Variables:** Each test case should be as simple as possible, designed to test a single variable (e.g., raw event handling, local state updates, prop drilling).
3.  **Run in Parallel:** The original component and all test components should be accessible from the same UI, typically via a simple tab switcher, allowing for immediate comparison.

### 2.2. Steps
1.  **Identify the Core Problem:** Isolate the most fundamental action that is failing (e.g., "A click on a list item is not being registered").
2.  **Create Test Harness:** Refactor the main view to act as a "test harness."
    *   Introduce a top-level state to control which view is active (e.g., `activeView: 'Original' | 'TestA' | 'TestB'`).
    *   Create a simple tab bar UI to switch this state.
    *   Encapsulate the existing, complex component so it can be rendered when `activeView === 'Original'`.
3.  **Lift Necessary State:** Identify the minimum state required for the test components to function (e.g., `parsedContent`). Lift this state up to the test harness level. The "Original" component can then pass data up to the harness via a callback prop.
4.  **Implement Isolated Test Components:** Create new, simple components for each test case, which receive the shared state as props.
    *   **Test A (Barebones):** The simplest possible implementation. Use raw HTML elements with inline event handlers that only `logger.log()`.
    *   **Test B (Local State):** Introduce `useState` to test the component's ability to manage its own state and re-render on an event.
    *   **Test C (Prop-Driven):** Use a child component that calls a function passed down via props, testing the prop-drilling pattern.
5.  **Analyze Results:** Interact with each tab to see which implementation succeeds, thereby isolating the architectural pattern that is failing.

## 3. Cleanup Process

Once a working pattern is identified in a test component:
1.  **Codify Findings:** Document the successful pattern and the root cause of the failure in a relevant artifact (e.g., `A11. Regression Case Studies`).
2.  **Integrate Solution:** Refactor the "Original" component to use the successful pattern.
3.  **Remove Test Artifacts:**
    *   Remove the test harness tabs and view-switching logic from the main view component.
    *   Delete the temporary `TestPane*.tsx` component files.
    *   Remove any extra styling related to the test harness from the SCSS file.

## 4. Sample Test Data for Parser

To ensure consistent testing of the PCPP parser, use the following sample raw response. Paste this into a response tab in the "Original" view and click "Parse All".

```
I've analyzed the request and the provided context. The main goal is to add a new test harness to the Parallel Co-Pilot panel without removing the existing functionality. This involves refactoring `view.tsx` to support multiple, switchable views.

### Course of Action

1.  **Update Documentation:** I will first update `A51` to reflect the new "Original-A-B-C" parallel testing strategy.
2.  **Refactor `view.tsx`:** I will refactor the main component into a test harness that can switch between the original view and the new test panes.
3.  **Re-supply Test Panes:** I will provide the code for the three isolated test panes again.

### Files Updated This Cycle:
*   `A51. DCE - A-B-C Testing Strategy for UI Bugs.md` (Updated)
*   `src/client/views/parallel-copilot.view/view.tsx` (Updated)
*   `src/client/views/parallel-copilot.view/view.scss` (Updated)

<file path="src/client/views/parallel-copilot.view/view.tsx">
// This is a sample file content block.
// It will be parsed and displayed.
import * as React from 'react';

const TestComponent = () => {
    return <div>Hello, World!</div>;
};

export default TestComponent;
</file>
<file path="src/client/views/parallel-copilot.view/view.scss">
/* This is a sample SCSS file content block. */
.test-harness-tabs {
    display: flex;
    border-bottom: 1px solid var(--vscode-panel-border);
}
```
</file_artifact>

<file path="src/Artifacts/A52. DCE - Interaction Schema Refinement.md">
# Artifact A52: DCE - Interaction Schema Refinement
# Date Created: C110
# Author: AI Model & Curator
# Updated on: C154 (Switch to XML tags for summary and course of action)

- **Key/Value for A0:**
- **Description:** A set of refined rules and an explanation of the parsing logic for the AI's output format to improve the reliability and consistency of automated parsing within the Parallel Co-Pilot Panel.
- **Tags:** documentation, process, parsing, interaction schema, metainterpretability

## 1. Overview & Goal

The Parallel Co-Pilot Panel (PCPP) relies on parsing your output to provide features like file association, diffing, and syntax highlighting. To ensure this process is reliable, your responses must adhere to a strict and consistent format.

The goal of this document is to serve as a definitive guide for you, the AI, on how to structure your responses. It explains the "documentation first" principle we follow and details the exact logic the PCPP parser uses. By understanding how you are being interpreted, you can generate perfectly parsable output every time.

## 2. The "Documentation First" Principle

A core principle of this project is to **plan before coding**.
-   **Cycle 0 (Project Initialization):** Your first task for a new project is **always** to generate planning and documentation artifacts (e.g., A1 Project Vision, A2 Requirements), not code files. You should use the provided templates as a guide.
-   **Subsequent Cycles:** When a new feature is requested, your first step should be to update existing documentation or create new artifacts that describe the plan for that feature. You should only generate code *after* the plan has been documented.

## 3. How the PCPP Parser Works

The parser is designed to be simple and robust. It looks for specific tags to break your response into structured data.

### Step 1: Extract Summary / Plan
-   **Rule:** Your high-level summary, thoughts, or plan must be enclosed in `<summary>...</summary>` tags.
-   **Parser Logic:** The parser captures all text between the opening and closing `summary` tags.

### Step 2: Extract Course of Action
-   **Rule:** Your point-by-point plan must be enclosed in `<course_of_action>...</course_of_action>` tags.
-   **Parser Logic:** The parser captures all text between the opening and closing `course_of_action` tags.

### Step 3: Extract File Blocks
The parser's most important job is to find and extract all file blocks.
-   **Rule:** Every file you generate **must** be enclosed in `<file path="..."></file>` tags.
-   **Example:**
    ```xml
    <file path="src/main.ts">
    // ... content of main.ts
    </file>
    ```
-   **Parser Logic:** The parser looks for the literal string `<file path="` followed by a quoted path, then captures everything until it finds the literal closing string `</file>`. **Any other format will be ignored.**

## 4. Canonical Response Structure

To guarantee successful parsing, every response should follow this structure:

```
<summary>
[High-level summary and analysis of the request.]
</summary>

<course_of_action>
1.  [A detailed, point-by-point plan of the changes you are about to make.]
2.  [Another point in the plan.]
</course_of_action>

<file path="path/to/first/file.ts">
// Full content of the first file...
</file>

<file path="path/to/second/file.md">
# Full content of the second file...
</file>
```
</file_artifact>

<file path="src/Artifacts/A52.1 DCE - Parser Logic and AI Guidance.md">
# Artifact A52.1: DCE - Parser Logic and AI Guidance
# Date Created: C155
# Author: AI Model & Curator
# Updated on: C14 (Make file tag parsing more flexible)

- **Key/Value for A0:**
- **Description:** Provides the literal source code for the response parser and explicit instructions to the AI on how to format its output to ensure successful parsing.
- **Tags:** documentation, process, parsing, metainterpretability, source of truth

## 1. Overview & Goal (Metainterpretability)

This document is included in every prompt to provide you with direct insight into how your responses are parsed. By understanding the exact logic used to interpret your output, you can structure your responses to be perfectly machine-readable, ensuring a smooth and reliable workflow.

The goal is to eliminate parsing failures caused by unexpected formatting. Adhering to this guide is a critical part of the interaction schema.

## 2. The Parser's Source Code

The following TypeScript code is the complete and exact logic used by the Parallel Co-Pilot Panel to parse your responses. It looks for specific XML tags to separate the summary, course of action, and file blocks.

```typescript
// src/client/utils/response-parser.ts
import { ParsedResponse, ParsedFile } from '@/common/types/pcpp.types';

const SUMMARY_REGEX = /<summary>([\s\S]*?)<\/summary>/;
const COURSE_OF_ACTION_REGEX = /<course_of_action>([\s\S]*?)<\/course_of_action>/;
const CURATOR_ACTIVITY_REGEX = /<curator_activity>([\s\S]*?)<\/curator_activity>/;
// C14 Update: More flexible closing tag matching
const FILE_TAG_REGEX = /<file path="([^"]+)">([\s\S]*?)(?:<\/file_path>|<\/file>|<\/filepath>|<\/file_artifact>)/g;
const CODE_FENCE_START_REGEX = /^\s*```[a-zA-Z]*\n/;

export function parseResponse(rawText: string): ParsedResponse {
    const fileMap = new Map<string, ParsedFile>();
    let totalTokens = 0;

    let processedText = rawText.replace(/\\</g, '<').replace(/\\>/g, '>').replace(/\\_/g, '_');

    const tagMatches = [...processedText.matchAll(FILE_TAG_REGEX)];

    if (tagMatches.length === 0 && processedText.includes('<file path')) {
        const summary = `**PARSING FAILED:** Could not find valid \`<file path="...">...</file_artifact>\` (or similar) tags. The response may be malformed or incomplete. Displaying raw response below.\n\n---\n\n${processedText}`;
        return { summary, courseOfAction: '', filesUpdated: [], files: [], totalTokens: Math.ceil(processedText.length / 4) };
    }

    for (const match of tagMatches) {
        const path = (match?. ?? '').trim();
        let content = (match?. ?? '');

        if (path) {
            content = content.replace(CODE_FENCE_START_REGEX, '');
            // C14 Update: Add new tags to the removal list
            const patternsToRemove = [`</file_artifact>`, `</file_path>`, `</filepath>`, `</file>`, `</${path}>`, '```', '***'];
            let changed = true;
            while(changed) {
                const originalContent = content;
                for (const pattern of patternsToRemove) {
                    if (content.trim().endsWith(pattern)) {
                        content = content.trim().slice(0, -pattern.length);
                    }
                }
                if (content === originalContent) { changed = false; }
            }
            content = content.trim();
            const tokenCount = Math.ceil(content.length / 4);
            fileMap.set(path, { path, content, tokenCount });
        }
    }

    const finalFiles = Array.from(fileMap.values());
    totalTokens = finalFiles.reduce((sum, file) => sum + file.tokenCount, 0);

    const summaryMatch = processedText.match(SUMMARY_REGEX);
    const courseOfActionMatch = processedText.match(COURSE_OF_ACTION_REGEX);
    const curatorActivityMatch = processedText.match(CURATOR_ACTIVITY_REGEX);

    const summary = (summaryMatch?.[1] ?? 'Could not parse summary.').trim();
    const courseOfAction = (courseOfActionMatch?.[1] ?? 'Could not parse course of action.').trim();
    const curatorActivity = (curatorActivityMatch?.[1] ?? '').trim();
    
    const filesUpdatedList = finalFiles.map(f => f.path);

    if (finalFiles.length === 0 && !summaryMatch && !courseOfActionMatch && !curatorActivityMatch) {
        return { summary: processedText, courseOfAction: '', filesUpdated: [], files: [], totalTokens: Math.ceil(processedText.length / 4) };
    }

    return {
        summary,
        courseOfAction,
        curatorActivity,
        filesUpdated: [...new Set(filesUpdatedList)],
        files: finalFiles,
        totalTokens,
    };
}
```

## 3. Critical Instructions for Formatting Your Response

To guarantee successful parsing, every response **must** follow this structure:

1.  **Summary:** Your high-level analysis and plan must be enclosed in `<summary>...</summary>` tags.
2.  **Course of Action:** Your point-by-point plan must be enclosed in `<course_of_action>...</course_of_action>` tags.
3.  **File Blocks:** Every file you generate must be enclosed in `<file path="..."></file_artifact>` tags (or a similar valid closing tag). The parser uses a global regex (`/g`) to find all occurrences of this pattern. The closing tag can be `</file_artifact>`, `</file_path>`, `</filepath>`, or `</file>`.

### Canonical Example:

```
<summary>
I have analyzed the request. My course of action is to update the main component and its corresponding stylesheet.
</summary>

<course_of_action>
1.  **Update `view.tsx`:** Add a new state variable and a button.
2.  **Update `view.scss`:** Add styling for the new button.
</course_of_action>

<file path="src/client/views/my-view/view.tsx">
// (Canonical Example) Full content of the view.tsx file...
</file_artifact>

<file path="src/client/views/my-view/view.scss">
/* (Canonical Example) Full content of the view.scss file... */
</file_artifact>
```
</file_artifact>

<file path="src/Artifacts/A52.2 DCE - Interaction Schema Source.md">
# Artifact A52.2: DCE - Interaction Schema Source
# Date Created: C156
# Author: AI Model & Curator
# Updated on: C128 (Add DCE context sentence)

- **Key/Value for A0:**
- **Description:** The canonical source text for the M3. Interaction Schema, which is injected into all generated prompts.
- **Tags:** documentation, process, interaction schema, source of truth

## Interaction Schema Text

**Note:** This prompt is generated by the Data Curation Environment (DCE) extension within VS Code. When instructions refer to 'the IDE', 'curator activity', or 'accepting files', they refer to this specific environment and its workflow.

1.  Artifacts are complete, individual texts enclosed in `<xmltags>`. To ensure consistent parsing by the DCE extension, all file artifacts **must** be enclosed in `<file path="path/to/file.ts">...</file_artifact>` tags. The path must be relative to the workspace root. **The closing tag must be exactly `</file_artifact>`.** Do not use the file path in the closing tag (e.g., `</file path="...">` is incorrect). Do not write the closing tag as `</file>` or `</file_path>`. Only `</file_artifact>` will parse successfully.

2.  Our Document Artifacts serve as our `Source of Truth` throughout multiple cycles. As such, over time, as issues occur, or code repeatedly regresses in the same way, seek to align our `Source of Truth` such that the Root Cause of such occurances is codified so that it can be avoided on subsequent cycles visits to those Code artifacts.

3.  Please output entire Document or Code artifacts. Do not worry about Token length. If your length continues for too long, and you reach the 600 second timeout, I will simply incorporate the work you did complete, and we can simply continue from where you left off. Better to have half of a solution to get started with, than not to have it. **Preference is for larger, more complete updates over smaller, incremental ones to align with the human curator's parallel processing workflow.** The human curator often sends the same prompt to multiple AI instances simultaneously and selects the most comprehensive response as the primary base for the next cycle, using other responses as supplementary information. Providing more complete updates increases the likelihood of a response being selected as the primary base.

4.  Do not output artifacts that do not require updates in this cycle. (Eg. Do not do this: // Updated on: Cycle 1040 (No functional changes, only cycle header))

5.  **Critical: `flattened_repo_v2.txt` contains all project files. Output updated *individual* files that are part of it (like `<src/state/coreStore.ts>...`). However, do **NOT** output the surrounding Artifact container tags (`<flattened_repo_v2.txt>...</flattened_repo_v2.txt>`) or any auto-generated metadata sections within it (like the Total Files summary, Top 10 list, or the `<files list>` section) which are created by the `flatten.js` script.**
5.1. `flattened_repo_v2.txt` is a copy of the codebase, generated by a script; assume its an accurate representation of the existing codebase, but not necessarily a 'source of truth' like we treat our documents as, our codebase is a living artifact, documents, while we can update them, should be considered less transient.
5.2. **`.local` File Convention:** To manage token count, some large data files (e.g., `researchNodes.ts`) may be represented by a truncated `.local.ts` version in the context. This version contains the essential structure and a few examples. If the full content of a file is required for a task (e.g., a comprehensive data refactor or fixing a bug related to a specific entry), explicitly state this need in your summary of actions and request that the curator swap the `.local.ts` file with the full `.ts` version in the `files_list.txt` for the subsequent cycle.

6.  remember to output complete artifacts without placeholders, im taking your output, putting it in winmerge, and confirming we arent losing data in the update. when you provide placeholders, my cursory review turns into a meticulous file parsing, taking me from what is 5 seconds per artifact to upwards of 5 minutes, only to realize that the output is actually un-parseable, due to the nature of relativity, as the theory of relativity also applies to code. if you give me a code snippet, and do not give me the code surrounding that snippet, i do not know where that code should go. by providing the complete file, on the other hand, i can put it in a diff, see easily what was altered, and if anything was accidentally omitted or lost, i can be sure that it's retained.

7.  **Update documentation before writing code.** document artifacts are like our project readme files, our source of truth. they are our blueprints. they guide the code we write. when we realize we need to alter our approach or invent new game mechanics, we update the source of truth first, cause english is easy and flexible, then we codify that.

8.  this query is part of a larger software engineering project

9.  After you complete delivery on a code artifact, review it to make sure you did not miss any intermediary files. for instance, if we have a DevelopmentSystem.ts, using the componentData.ts, which is displaying on the ComponentProductionTab.tsx. But then theres also still a DevPanel.tsx file that is in-between that *could*, but shouldnt, get overlooked.

10. If you are deciding where to put a particular piece of code or function, and due to its nature, there are one or more candidate files that it could be placed in, choose the smaller file (in tokens).

11. Begin your response with a course of action and end with a review of your work, surface any self corrections in the summary of changes for the subsequent cycle.

12. do not underestimate how much you can accomplish in a given cycle; you'd only accomplish handicapping yourself. (Eg. you've authored this whole thing with just my guidance. good job, keep it up.)

13. Not as relevant for this project: **Log State Button:** The 'Log State' button in the `DevInfoOverlay` is a dynamic debugging tool. Modify the `triggerDebugLogs` action in `uiStore.ts` to output specific state information relevant to the current bug being investigated. **See A85 (Logging Guide) for usage details.**

14. Not as relevant for this project: **Regression Case Studies:** Use Artifact A106 to document persistent or complex bugs and their resolutions. Add entries *after* a fix is confirmed to codify the RCA and solution, preventing future regressions.

15. Include in your cycle summary, a short list of files you've updated. This makes it easy for my reviews.

16. if you seem to have spare time in a cycle, see if you can spot any particular file with excessive levels of comments or logging that seems extensive and for troubleshooting an error that has since been resolved, see to it to clean those files but preserve their functionalities. im just looking to shave off excess tokens wherever possible in the master_content.txt file.

17. if you see `(No change from C850)` such language, it's data loss. there was supposed to be actual language behind that placeholder, but in one iteration (C850, in this case) you had provided a placeholder, and i 'missed it' and did not capture the initial information. you either need to deliver the placeholder in such a way as i can easily press the left arrow instead of the rigth arrow in winmerge to not accept that part, but to also not have winmerge confuse it with the rest, otherwise i must manually parse the information. when the process is a single keystroke, i can manage it quickly enough. when we remove that ability because you provided me data in a format that has placeholders AND the placeholders do not parse within winmerge such that it removes the benefit winmerge is adding, then we have our problem. when you see this, try to correct it using whatever current relevant context you have.

18. basically, you should not worry about brevity, because when you go too long, your response gets interrupted by the system anyway. its better that the products you do deliver are all complete except for the last one, rather than you delivering all incomplete products, including the last one. does that make sense?

19. remember, do not stop outputting for the reason of preventing a potential artifact interruption mid-output. you actually end up stopping yourself from producting two or three additional files before you actually get interrupted. what i mean is, in the outputs where you do not do this, you produce for 500 seconds, producing 7-9 files, and only the last one is interrupted and unusable. compared to when you stop yourself prematurely, for the reason stated, and you produce for 180 seconds and provide maybe 3-4 files. even with the -1, producing as much as you can still outperforms the alternative.

20. This is a misaligned statement: `// (For full history, see master_content.txt)` because your changes get rolled into master_content.txt. therefore, if you remove the history, then when your updates are rolled in, they will remove the full history. understand? after a while, the history is not relevant and can be rolled out, for a while, it ought to stay. you can see what we're working on + the current cycle and make this determination.

21. Each time we create a new documentation artifact, lets also create the key/value pairs needed for me to add it into our Master Artifact List. they can simply be added into the new artifact itself and ill make the new entry in A0. this will solve for me manually generating a description and tag for each new documentation artifact. also, dont place `/` in the title/name of a documentation artifact. VSCode treats it as a folder separator.
21.1. when creating a new documentation artifact, also just update the master artifacts list itself.

22. **New: Curator Activity Section:** If you need the human curator to perform an action that you cannot (e.g., delete a file, run a specific command), include these instructions in a dedicated `<curator_activity>...</curator_activity>` section in your response. NOTE: the two `\` were added to the last sentence just to break the parser within the DCE itself; if you're 'in-situ', do be sure to NOT include them if you are attempting to instruct the 'in-situ' curator.
</file_artifact>

<file path="src/Artifacts/A53. DCE - Phase 2 - Token Count and Similarity Analysis.md">
# Artifact A53: DCE - Phase 2 - Token Count and Similarity Analysis
# Date Created: C112
# Author: AI Model & Curator
# Updated on: C144 (Mark feature as implemented)

- **Key/Value for A0:**
- **Description:** Details the plan to implement token counting for raw and parsed responses, and to calculate a similarity score between AI-generated files and their workspace originals.
- **Tags:** feature plan, phase 2, token count, similarity, metrics, ui, ux

## 1. Overview & Goal

To enhance the curator's decision-making process, the Parallel Co-Pilot Panel (PCPP) must provide quantitative metrics about the AI's responses. The goal of this feature is to display token counts for various pieces of content and a similarity score to gauge the extent of changes proposed by the AI. This allows the user to quickly assess response verbosity, parser effectiveness, and the magnitude of code modifications.

**Status (C144):** This feature is now fully implemented.

## 2. User Stories

| ID | User Story | Acceptance Criteria |
|---|---|---|
| P2-MET-01 | **Raw Response Token Count** | As a user, I want to see the total token count of the raw AI response I've pasted, so I can understand the overall size of the output. | - A token count is displayed for the raw content in each response tab. <br> - This count updates in real-time as I type or paste content. |
| P2-MET-02 | **Parsed vs. Original Token Count** | As a user, when viewing a parsed file, I want to see a comparison of the token count between the original workspace file and the AI's new version, so I can quickly see if the code is growing or shrinking. | - In the header of the code viewer pane, the token counts for both the original and new versions of the selected file are displayed (e.g., "Original: 4.1K | New: 4.2K"). |
| P2-MET-03 | **File Similarity Score** | As a user, along with the token counts, I want to see a percentage-based similarity score, so I can gauge how substantially the AI has altered the file. | - A similarity score (e.g., "Sim: 98%") is displayed in the code viewer header. <br> - A score of 100% indicates identical files. <br> - A low score indicates a major rewrite. |

## 3. Technical Implementation Plan

1.  **IPC Channel:**
    *   `ClientToServerChannel.RequestFileComparison` was created.
    *   Payload: `{ filePath: string; modifiedContent: string; }`.
    *   Response channel: `ServerToClientChannel.SendFileComparison`.
    *   Payload: `{ originalTokens: number; modifiedTokens: number; similarity: number; }`.

2.  **Backend (`file-operation.service.ts`):**
    *   `handleFileComparisonRequest` was implemented.
    *   It reads the content of the original `filePath` from the workspace.
    *   It calculates the token count for the original content and the `modifiedContent` received in the payload using `content.length / 4`.
    *   It computes a similarity score using the Srensen-Dice coefficient algorithm located in `src/common/utils/similarity.ts`.
    *   It sends the results back to the client via `SendFileComparison`.

3.  **Frontend (`parallel-copilot.view/view.tsx`):**
    *   When a file is selected for viewing (`setSelectedFilePath`), a `RequestFileComparison` message is sent.
    *   A state variable, `comparisonMetrics`, holds the returned results.
    *   The message handler for `SendFileComparison` updates this state.
    *   The UI in the code viewer header renders the live data from the `comparisonMetrics` state.
</file_artifact>

<file path="src/Artifacts/A55. DCE - FSService Refactoring Plan.md">
# Artifact A55: DCE - FSService Refactoring Plan
# Date Created: C113
# Author: AI Model & Curator
# Updated on: C114 (Mark refactor as complete)

- **Key/Value for A0:**
- **Description:** Outlines a strategic plan to refactor the monolithic `FSService` into smaller, more focused services to improve modularity, maintainability, and reduce token count.
- **Tags:** refactor, architecture, technical debt, services

## 1. Problem Statement

The `FSService` has become a "god object," handling a wide range of responsibilities beyond basic file system interactions and now violates the Single Responsibility Principle. Its large size (over 800 lines) makes it difficult to maintain, debug, and reason about. The service currently manages at least four distinct areas of concern:
1.  **Workspace State:** Building, caching, and watching the file tree.
2.  **File Operations:** Handling requests to create, move, delete, and modify files.
3.  **Content Virtualization:** Processing special file types like PDF, Word, and Excel into text.
4.  **Syntax Highlighting:** Managing the `starry-night` library and processing highlighting requests.

## 2. Refactoring Plan (Completed in C114)

The `FSService` has been successfully broken down into four new, more focused services. This has improved code organization, reduced the token count of individual files, and made the system more modular and maintainable.

### 2.1. New Service Structure

#### 1. `FileTreeService`
-   **Responsibility:** All "read" operations related to the workspace structure. This service is the source of truth for what the workspace looks like.
-   **Methods moved here:**
    -   `handleWorkspaceFilesRequest`
    -   `buildTreeFromTraversal`, `_traverseDirectory`, `_aggregateStats`
    -   `getFileStats`
    -   `getGitStatusMap`, `getProblemCountsMap`
    -   `initializeWatcher`, `triggerFullRefresh`, `triggerDiagnosticsUpdate`
    -   `fileTreeCache` property

#### 2. `FileOperationService`
-   **Responsibility:** All "write" or direct modification operations on the file system.
-   **Methods moved here:**
    -   `handleNewFileRequest`
    -   `handleNewFolderRequest`
    -   `handleFileRenameRequest`
    -   `handleMoveFileRequest`
    -   `handleFileDeleteRequest`, `handleBatchFileDeleteRequest`
    -   `handleCopyFileRequest`, `handleCopyFileFromUri`, `handleAddFileFromBuffer`
    -   `handleOpenFileRequest`
    -   `handleRevealInExplorerRequest`
    -   `handleCopyPathRequest`

#### 3. `ContentExtractionService`
-   **Responsibility:** Handling the on-demand parsing and virtualization of special, non-text file formats.
-   **Methods moved here:**
    -   `handlePdfToTextRequest`, `getVirtualPdfContent`, `pdfTextCache`
    -   `handleExcelToTextRequest`, `getVirtualExcelContent`, `excelMarkdownCache`
    -   `handleWordToTextRequest`, `getVirtualWordContent`, `wordTextCache`
    -   `_sheetToMarkdown` (private helper)

#### 4. `HighlightingService`
-   **Responsibility:** All logic related to syntax highlighting.
-   **Methods moved here:**
    -   `initializeStarryNight`
    -   `handleSyntaxHighlightRequest`
    -   `starryNight` property

### 2.2. Integration

-   The main `services.ts` container was updated to instantiate all four new services.
-   The `on-message.ts` handlers were updated to call the correct methods on the new, more specific services.
-   The original `fs.service.ts` file has been deleted.

## 3. Benefits Achieved

-   **Reduced Complexity:** Each service is now significantly smaller and easier to understand.
-   **Improved Maintainability:** Bugs or feature requests will be easier to implement in the correct, isolated service.
-   **Clear Separation of Concerns:** The architecture now follows best practices.
-   **Lower Token Count:** Splitting the large file into four smaller ones makes each file more manageable.

<Original fs.service.ts>
Removed after completing refactor.
</Original fs.service.ts>
</file_artifact>

<file path="src/Artifacts/A57. DCE - Phase 2 - Cycle Management Plan.md">
# Artifact A57: DCE - Phase 2 - Cycle Management Plan
# Date Created: C125
# Author: AI Model & Curator
# Updated on: C62 (Refine "Reset History" workflow)

- **Key/Value for A0:**
- **Description:** Outlines the user stories and technical implementation for deleting cycles and resetting the PCPP history.
- **Tags:** feature plan, phase 2, ui, ux, history, cycle management

## 1. Overview & Goal

As the number of development cycles increases, users need tools to manage their history within the Parallel Co-Pilot Panel (PCPP). The goal of this feature is to provide basic but essential management capabilities, allowing users to delete unwanted cycles and completely reset the history if needed. This keeps the history relevant and manageable.

## 2. User Stories

| ID | User Story | Acceptance Criteria |
|---|---|---|
| P2-CM-01 | **Delete a Cycle** | As a developer, I want to be able to delete a specific cycle from my history, so I can remove erroneous or irrelevant entries. | - A "Delete Cycle" button is available in the "Cycle & Context" section. <br> - Clicking it prompts for confirmation (e.g., "Are you sure you want to delete Cycle X?"). <br> - Upon confirmation, the specified cycle is removed from the `dce_history.json` file. <br> - The UI automatically navigates to the next available cycle (e.g., the previous one or the new latest one). |
| P2-CM-02 | **Reset All History** | As a developer, I want to be able to reset the entire PCPP history, so I can start a project fresh without old cycle data. | - A "Reset History" button is available. <br> - Clicking it shows a strong confirmation warning (e.g., "This will delete ALL cycles and cannot be undone."). <br> - Upon confirmation, the `dce_history.json` file is deleted. <br> - The UI reloads to the "Cycle 0" onboarding/welcome screen, allowing the user to re-initialize the project. |

## 3. Technical Implementation Plan

1.  **IPC Channels (`channels.enum.ts`, `channels.type.ts`):**
    *   Create `ClientToServerChannel.RequestDeleteCycle` with a payload of `{ cycleId: number }`.
    *   Create `ClientToServerChannel.RequestResetHistory` with an empty payload.

2.  **Backend (`history.service.ts`):**
    *   **`deleteCycle(cycleId: number)`:**
        *   Read the `dce_history.json` file.
        *   Filter the `cycles` array to remove the entry where `cycle.cycleId === cycleId`.
        *   If only one cycle remains, do not allow deletion, or handle it by resetting to a default state.
        *   Write the updated history file back to disk.
    *   **`resetHistory()`:**
        *   Use `vscode.workspace.fs.delete` to remove the `dce_history.json` file.
        *   Clear the `lastViewedCycleId` from the workspace state.
        *   The existing logic in `getInitialCycle` will automatically create a new, default "Cycle 0" the next time data is requested.

3.  **Frontend (`view.tsx`):**
    *   **UI Buttons:** Add "Delete Cycle" and "Reset History" icon buttons to the `cycle-navigator` div.
    *   **Event Handlers:**
        *   The `onClick` handler for "Delete Cycle" will call `vscode.window.showWarningMessage` to confirm. If the user confirms, it will send the `RequestDeleteCycle` IPC message with the `currentCycle` ID. After sending, it should trigger a request for the new latest cycle data to refresh the UI.
        *   The `onClick` handler for "Reset History" will do the same, but for the `RequestResetHistory` message. After the backend confirms the reset, the frontend will navigate to `cycleId: 0`.

4.  **Message Handling (`on-message.ts`):**
    *   Add handlers for the new IPC channels that call the corresponding methods in `HistoryService`.
    *   After a successful deletion or reset, the backend should send a message back to the client (e.g., a `ForceRefresh` or a new dedicated message) to trigger a full state reload.
</file_artifact>

<file path="src/Artifacts/A59. DCE - Phase 2 - Debugging and State Logging.md">
# Artifact A59: DCE - Phase 2 - Debugging and State Logging
# Date Created: C134
# Author: AI Model & Curator
# Updated on: C3 (Focus log output on cycle management state and truncate large data)

- **Key/Value for A0:**
- **Description:** Documents the plan for a "Log State" button that outputs critical state information (cycle history, current inputs) to the debug channel to accelerate troubleshooting.
- **Tags:** feature plan, phase 2, ui, ux, debugging, logging, state management

## 1. Overview & Goal

Debugging complex state interactions in the Parallel Co-Pilot Panel can be challenging, as it often requires the curator to manually describe the state of multiple text fields and selections. To accelerate this process, a dedicated debugging feature is required.

The goal of this feature is to add a **"Log State"** button to the PCPP's main header. When clicked, this button will generate a comprehensive, formatted log of the panel's current state and send it to the "Data Curation Environment" output channel. This allows the curator to easily copy and paste the exact state of the application into their feedback, eliminating ambiguity and speeding up bug resolution.

## 2. User Story

| ID | User Story | Acceptance Criteria |
|---|---|---|
| P2-LOG-01 | **Log Current State for Debugging** | As a curator encountering a bug, I want to click a "Log State" button that outputs the current state of the entire PCPP to the debug logs, so I can easily copy and paste this information for you to reproduce the issue. | - A "Log State" button is present in the main header of the PCPP. <br> - Clicking the button generates a formatted message in the "Data Curation Environment" output channel. <br> - **(C3 Update)** The log output is now focused specifically on the state variables relevant to cycle management to diagnose bugs like data loss or being stuck on a cycle. It will include: <br> &nbsp;&nbsp;&nbsp; 1. A summary of the key frontend state variables (`currentCycle`, `maxCycle`, `isNewCycleButtonDisabled`). <br> &nbsp;&nbsp;&nbsp; 2. A **truncated** JSON dump of the entire `dce_history.json` file from the backend for comparison, with large code blocks shortened to prevent flooding the logs. |

## 3. Technical Implementation Plan

1.  **UI (`view.tsx`):**
    *   A "Log State" button will be added to the main header toolbar.
    *   Its `onClick` handler will gather the complete current state of the panel into a single `PcppCycle` object and send it to the backend via a new IPC message.

2.  **IPC Channels (`channels.enum.ts`, `channels.type.ts`):**
    *   Create a new `ClientToServerChannel.RequestLogState`.
    *   The payload will be `{ currentState: PcppCycle }`.

3.  **Backend Logic (`prompt.service.ts`):**
    *   A new public method, `public async generateStateLog(currentState: PcppCycle)`, will be created.
    *   **Step 1: Generate Formatted State Dump (C3 Revision):**
        *   It will fetch the full history from `history.service.ts`.
        *   It will construct a focused log string containing the most relevant frontend state variables for the current bug (`currentCycle`, `maxCycle`, `isNewCycleButtonDisabled`, `cycleTitle`, `cycleContext`, `selectedResponseId`).
        *   It will use the `truncateCodeForLogging` utility on the `content` of each response in the history before creating a `JSON.stringify` of the full history file content.
    *   **Step 2: Log to Output Channel:**
        *   It will combine these strings into a single, clearly labeled log message and send it to `Services.loggerService.log()`.
        *   It will then call `Services.loggerService.show()` to programmatically open the output channel for the user.
</file_artifact>

<file path="src/Artifacts/A60. DCE - Phase 2 - Cycle 0 Onboarding Experience.md">
# Artifact A60: DCE - Phase 2 - Cycle 0 Onboarding Experience
# Date Created: C139
# Author: AI Model & Curator
# Updated on: C187 (Rename README.md to DCE_README.md)

## 1. Vision & Goal

The Parallel Co-Pilot Panel (PCPP) is a powerful tool, but its effectiveness relies on a structured set of planning and documentation artifacts. For a new user, bootstrapping this structure is a major hurdle.

The goal of the "Cycle 0" onboarding experience is to automate this bootstrapping process. The extension will capture the user's high-level project scope and generate a prompt that instructs an AI to create a starter pack of essential **planning and documentation artifacts**. As part of this process, it will also create a `DCE_README.md` file within the `src/Artifacts` directory that explains the artifact-driven workflow itself, providing meta-context to both the user and the AI.

## 2. User Flow

1.  **Detection:** The extension detects a "fresh workspace" by confirming the absence of any `A0.*Master Artifact List.md` file in the `src/Artifacts/` directory.
2.  **Cycle 0 UI:** The PCPP loads into a special "Cycle 0" view. It presents the user with an introduction and a single large text area for their "Project Scope".
3.  **User Input:** The user describes their project's vision and goals.
4.  **Generate Prompt & Artifacts:** The user clicks "Generate Initial Artifacts Prompt".
5.  **Backend Process:**
    *   The backend `PromptService` constructs a unique `prompt.md` file. The prompt's static context will contain the content of all template artifacts (files prefixed with `T` in the extension's artifacts).
    *   **Prompt Instruction Refinement (C179):** The instructions within the generated prompt will be updated to strongly encourage the AI to generate a comprehensive set of initial artifacts. It will explicitly prioritize foundational documents like **`T14. Template - GitHub Repository Setup Guide.md`** and **`T7. Template - Development and Testing Guide.md`** to ensure the user receives critical operational guidance from the very beginning, addressing potential setup hurdles like Git initialization proactively.
    *   It creates `src/Artifacts/DCE_README.md`, populated with the content from the extension's internal `A72. DCE - README for Artifacts.md`.
    *   It saves the user's "Project Scope" to a persistent field in `dce_history.json`.
6.  **Transition to Cycle 1:** The frontend reloads its state. Since an `A0` file does not yet exist, the user is presented with a "Continue to Cycle 1" button. Clicking this transitions them to the main PCPP interface.
7.  **User Action:** The user takes the generated `prompt.md` and uses it with their preferred LLM.
8.  **First Iteration:** The user pastes the AI's response (which should contain the new, correctly formatted documentation artifacts, including a project-specific `A0` file) back into the PCPP's "Cycle 1" tab. The standard iterative workflow begins.
9.  **Return to Cycle 0:** The user can click the "Project Plan" button to navigate back to Cycle 0 to view and edit their master project scope. A "Return to Cycles" button will take them back to their latest cycle.

## 3. Meta-Context Injection Process

To ensure the AI can always generate perfectly parsable responses, the DCE injects "meta-context" into the prompts for all cycles *after* Cycle 0. This process is automatic and transparent to the user.

-   **Cycle 0 (Bootstrapping):** Uses the curated `T` (template) artifacts as static context to guide the AI in creating initial *planning* documents for the user's project. The goal is to establish the project's structure.
-   **Cycle 1+ (Iterative Development):** The `prompt.service.ts` automatically reads and injects the following critical artifacts into the `<M3. Interaction Schema>` section of every generated `prompt.md`:
    -   **`A52.1 DCE - Parser Logic and AI Guidance.md`**: Contains the literal source code of the response parser, showing the AI exactly how its output will be interpreted.
    -   **`A52.2 DCE - Interaction Schema Source.md`**: Contains the canonical rules of interaction, ensuring the AI always has the latest formatting guidelines.
</file_artifact>

<file path="src/Artifacts/A61. DCE - Phase 2 - Cycle History Management Plan.md">
# Artifact A61: DCE - Phase 2 - Cycle History Management Plan
# Date Created: C152
# Author: AI Model & Curator
# Updated on: C163 (Flesh out plan and user stories for Import/Export)

- **Key/Value for A0:**
- **Description:** Outlines the plan to allow users to save and load their entire cycle history (`dce_history.json`), enabling them to manage multiple development threads or back up their work.
- **Tags:** feature plan, phase 2, history, import, export, cycle management

## 1. Overview & Goal

The `dce_history.json` file is a valuable asset that captures the entire iterative development process for a project, including the project scope, cycle notes, and all AI-generated responses. Users may want to work on different feature branches or experiments, each with its own cycle history.

The goal of this feature is to provide commands and UI controls to **export** the current cycle history to a file and **import** a history file, effectively allowing users to save and load different "cycle chains."

## 2. User Stories

| ID | User Story | Acceptance Criteria |
|---|---|---|
| P2-CHM-01 | **Export Cycle History** | As a developer, I want to export the entire cycle history to a named JSON file, so I can create a backup or save the history for a specific feature branch before starting a new one. | - A "Save History..." button is available in the cycle navigator toolbar. <br> - Clicking it opens a native "Save As..." dialog. <br> - The current content of `.vscode/dce_history.json` is written to the user-specified file. <br> - A success notification is shown. |
| P2-CHM-02 | **Import Cycle History** | As a developer, I want to import a cycle history from a JSON file, so I can switch between different development threads or restore a backup. | - A "Load History..." button is available in the cycle navigator toolbar. <br> - Clicking it opens a native "Open..." dialog to select a JSON file. <br> - The content of the selected file overwrites the current `.vscode/dce_history.json`. <br> - The PCPP UI automatically refreshes to show the new, imported history. |

## 3. Technical Implementation Plan

1.  **IPC Channels:**
    *   `ClientToServerChannel.RequestExportHistory`: No payload.
    *   `ClientToServerChannel.RequestImportHistory`: No payload.

2.  **Backend (`history.service.ts`):**
    *   **`handleExportHistory()`:**
        *   Read the current `.vscode/dce_history.json` file.
        *   Use `vscode.window.showSaveDialog` to get a destination URI from the user.
        *   If a URI is provided, write the history content to that file.
        *   Show a `showInformationMessage` on success.
    *   **`handleImportHistory()`:**
        *   Use `vscode.window.showOpenDialog` to get a source URI from the user.
        *   If a URI is provided, read its content.
        *   Perform basic validation to ensure it looks like a history file (e.g., has `version` and `cycles` properties).
        *   Overwrite the workspace's `.vscode/dce_history.json` with the new content.
        *   Trigger a `ForceRefresh` message with `reason: 'history'` to the PCPP frontend to force a full state reload.

3.  **Frontend (`view.tsx`):**
    *   The "Save History" (`VscCloudUpload`) and "Load History" (`VscCloudDownload`) buttons in the cycle navigator toolbar will be enabled.
    *   Their `onClick` handlers will trigger the corresponding IPC messages.
    *   The existing handler for the `ForceRefresh` message will automatically handle the UI update after a successful import.
</file_artifact>

<file path="src/Artifacts/A65. DCE - Universal Task Checklist.md">
# Artifact A65: DCE - Universal Task Checklist
# Date Created: C165
# Author: AI Model & Curator
# Updated on: C22 (Add new tasks from playtest feedback)

## 1. Purpose

This artifact provides a structured, universal format for tracking development tasks, feedback, and bugs. Unlike cycle-specific trackers, this checklist organizes work by the group of files involved in a given task. It also introduces a simple complexity metric based on the total token count of the affected files and an estimation of whether the task will require more than one development cycle to complete.

This file-centric approach helps in planning and prioritizing work, especially in an AI-assisted development workflow where context size (token count) is a primary constraint.

## 2. How to Use

-   **Group by File Packages:** Create a new `##` section for each logical task or feature. List all the files that are expected to be modified for this task.
-   **Assign an ID:** Give each task package a unique, simple ID (e.g., `T-1`, `T-2`) for easy reference in feedback.
-   **Estimate Complexity:**
    -   Calculate the **Total Tokens** for all files in the package. This gives a quantitative measure of the context size.
    -   Estimate if the task is likely to take **More than one cycle?**. This is a qualitative judgment based on the complexity of the changes required.
-   **List Action Items:** Under each file package, create a checklist of specific actions, bugs to fix, or features to implement.
-   **Add Verification Steps:** After the action items, add a section describing how the curator should test the feature to confirm it is working as expected.
-   **Note on Output Length:** Remember that the maximum output length for a single response is approximately 65,000 tokens. Do not prematurely stop generating files; attempt to complete as many full files as possible within this limit.
-   **Keep it Current:** At the beginning of each new cycle, review and update this checklist. Move completed tasks to a "Completed" section, add new tasks based on feedback, and re-prioritize as needed. This ensures the checklist remains a living, accurate reflection of the project's status.

---

## Task List for Cycle 22+

## T-1: Fix Onboarding Auto-Save Icon
- **Files Involved:**
    - `src/client/views/parallel-copilot.view/view.tsx`
- **Total Tokens:** ~8,500
- **More than one cycle?** No
- **Status:** In Progress

- [ ] **Task (T-ID: 1.1):** The `useEffect` hook listening for `NotifySaveComplete` is missing a dependency on `saveStatus`. Add it to the dependency array to ensure the callback has the latest state and can correctly transition from 'saving' to 'saved'.

### Verification Steps
1.  Launch the extension in a fresh workspace to trigger the onboarding view.
2.  Type a character in the "Project Scope" text area.
3.  **Expected:** The save status icon should change from a checkmark to a caution sign.
4.  Stop typing.
5.  **Expected:** The icon should change to a circular processing animation, and then, after a short delay, it should change back to the green checkmark. It should not get stuck on the processing animation.

## T-2: Fix File Duplication Bug
- **Files Involved:**
    - `src/backend/services/flattener.service.ts`
    - `src/backend/services/file-tree.service.ts`
- **Total Tokens:** ~6,800
- **More than one cycle?** No
- **Status:** In Progress

- [ ] **Task (T-ID: 2.1):** Add a safeguard in `flattener.service.ts` to de-duplicate the incoming file path list using `[...new Set(paths)]` before any processing occurs.
- [ ] **Task (T-ID: 2.2):** Review and harden the `processAutoAddQueue` logic in `file-tree.service.ts` to prevent race conditions that might add duplicate files to the selection state.

### Verification Steps
1.  Enable "Automatically add new files to selection".
2.  Create a new workspace and go through the Cycle 0 onboarding to generate the initial set of artifacts.
3.  Click "Flatten Context".
4.  Inspect the generated `flattened_repo.md` file.
5.  **Expected:** The file list and content should contain no duplicate file paths.

## T-3: Implement "Open All" Button
- **Files Involved:**
    - `src/client/views/parallel-copilot.view/components/ParsedView.tsx`
    - `src/backend/services/file-operation.service.ts`
    - `src/common/ipc/channels.enum.ts`
    - `src/common/ipc/channels.type.ts`
    - `src/client/views/parallel-copilot.view/on-message.ts`
- **Total Tokens:** ~8,000
- **More than one cycle?** No
- **Status:** In Progress

- [ ] **Task (T-ID: 3.1):** Add an "Open All" button to the header of the "Associated Files" section in `ParsedView.tsx`.
- [ ] **Task (T-ID: 3.2):** Create a new `RequestBatchFileOpen` IPC channel.
- [ ] **Task (T-ID: 3.3):** Implement the `handleBatchFileOpenRequest` method in `file-operation.service.ts` to iterate through a list of paths and open each one.

### Verification Steps
1.  Parse a response with multiple associated files.
2.  Click the "Open All" button.
3.  **Expected:** All files listed in the "Associated Files" section should open as new tabs in the VS Code editor.

## T-4: Plan Native Diff Integration
- **Files Involved:**
    - `src/Artifacts/A88. DCE - Native Diff Integration Plan.md`
- **Total Tokens:** ~1,000
- **More than one cycle?** Yes (Implementation is deferred)
- **Status:** In Progress

- [ ] **Task (T-ID: 4.1):** Create the new planning artifact `A88` to detail the implementation of a native VS Code diff view using a `TextDocumentContentProvider`.

### Verification Steps
1.  Check the `src/Artifacts` directory.
2.  **Expected:** The new `A88` artifact should exist and contain a detailed technical plan.
</file_artifact>

<file path="src/Artifacts/A67. DCE - PCPP View Refactoring Plan.md">
# Artifact A67. DCE - PCPP View Refactoring Plan
# Date Created: C167
# Author: AI Model & Curator

- **Key/Value for A0:**
- **Description:** A plan to refactor the large `parallel-copilot.view.tsx` into smaller, more manageable components to improve maintainability.
- **Tags:** refactor, architecture, technical debt, pcpp

## 1. Problem Statement

The `parallel-copilot.view/view.tsx` component has become a "god component," currently exceeding 8,000 tokens. It manages the state and rendering for the entire Parallel Co-Pilot Panel, including:
-   The main view and the onboarding view.
-   The cycle navigator.
-   The context input text areas.
-   The response tab bar.
-   The raw text view for each tab.
-   The complex, multi-pane parsed view.
-   The diff viewer.
-   All associated state management (`useState`, `useMemo`, `useEffect`).
-   All IPC message handling.

This monolithic structure makes the component difficult to read, debug, and maintain. A single change can have unintended consequences, and the high token count makes it a challenging file to work with.

## 2. Refactoring Plan

The goal is to break down `view.tsx` into a series of smaller, single-responsibility components. The main `view.tsx` file will be refactored into a "container" component that manages the core state and orchestrates the new, smaller "presentational" components.

### 2.1. Proposed Component Structure

-   **`view.tsx` (Container):**
    -   **Responsibility:** Manages all primary state (`currentCycle`, `tabs`, `isParsedMode`, etc.) and all IPC message handlers. It will render the appropriate child components and pass down state and callbacks as props.

-   **`src/client/views/parallel-copilot.view/components/` (New Directory):**
    -   **`CycleNavigator.tsx`:** Renders the cycle navigation bar, including the cycle number, title input, and navigation buttons. Receives the current cycle state and `onCycleChange` callbacks as props.
    -   **`ContextInputs.tsx`:** Renders the "Cycle Context" and "Ephemeral Context" text areas, including their new line number and token count displays. Receives content and `onChange` handlers as props.
    -   **`ResponseTabs.tsx`:** Renders the main tab bar. Receives the list of tabs, the active tab, and the `onTabSelect` handler as props.
    -   **`ResponsePane.tsx`:** A larger component responsible for rendering the content of a single, active tab. It will contain the logic to display either the raw `textarea` or the parsed view.
    -   **`ParsedView.tsx`:** Renders the multi-pane parsed view, including the "Associated Files" list, summary, and course of action. It will contain the logic for selecting a file to view.
    -   **`CodeViewer.tsx`:** Renders the syntax-highlighted code or the `DiffViewer`. Receives the file content and diff data as props.
    -   **`NumberedTextarea.tsx`:** The new reusable component for text areas with line numbers and resizing.

## 3. Benefits of Refactoring

-   **Improved Readability:** Each component will be smaller and focused on a single part of the UI, making the code easier to understand.
-   **Improved Maintainability:** Bugs and feature requests can be addressed in isolated components, reducing the risk of unintended side effects.
-   **Reduced Token Count:** Splitting the large file into many smaller ones makes each file more manageable for both human and AI developers.
-   **Better Performance:** Memoization (`React.memo`) can be applied more effectively to smaller components, preventing unnecessary re-renders.
</file_artifact>

<file path="src/Artifacts/A68. DCE - PCPP Context Pane UX Plan.md">
# Artifact A68: DCE - PCPP Context Pane UX Plan
# Date Created: C167
# Author: AI Model & Curator

- **Key/Value for A0:**
- **Description:** A plan to enhance the UX of the cycle context and ephemeral context text areas with features like token counts and line numbers.
- **Tags:** feature plan, ui, ux, pcpp, context

## 1. Overview & Goal

The "Cycle Context" and "Ephemeral Context" text areas in the Parallel Co-Pilot Panel are crucial for prompt engineering, but their current implementation as basic `<textarea>` elements lacks key features. The goal of this plan is to significantly enhance their usability by adding token counts, line numbers, and persistent resizing.

## 2. User Stories

| ID | User Story | Acceptance Criteria |
|---|---|---|
| P2-CTX-01 | **See Context Token Count** | As a developer, I want to see a live token count for the Cycle Context and Ephemeral Context fields, so I can manage the size of my prompt effectively. | - Below each text area, a label displays the approximate token count of its content. <br> - The count updates in real-time as the user types. |
| P2-CTX-02 | **See Line Numbers** | As a developer, I want to see line numbers in the context text areas, so I can easily reference specific parts of a long context or error log. | - A line number gutter is displayed to the left of the text input area. <br> - The line numbers scroll in sync with the text content. |
| P2-CTX-03 | **Persistent Resizing** | As a developer, when I resize the height of a context text area, I want it to remain that size when I navigate between cycles, so I don't lose my layout preferences. | - The `height` of each text area is stored as part of the `PcppCycle` state. <br> - When the user resizes a text area, its new height is saved. <br> - When the panel re-renders or a cycle is loaded, the text areas are restored to their saved heights. |

## 3. Technical Implementation Plan

### 3.1. Token Counts
-   **State:** Add new state variables to `view.tsx`: `cycleContextTokens` and `ephemeralContextTokens`.
-   **UI:** Add `<span>` elements below each text area to display these state values.
-   **Logic:** The `onChange` handlers for the text areas will be updated to calculate the token count (`e.target.value.length / 4`) and update the corresponding token count state.

### 3.2. Line Numbers & Resizing
-   **New Component (`NumberedTextarea.tsx`):**
    -   Create a new reusable component that renders a `textarea` alongside a synchronized `div` for line numbers.
    -   This component will manage its own internal state for line count based on the `value` prop.
    -   It will include a draggable handle at the bottom. `onMouseDown`, `onMouseMove`, and `onMouseUp` handlers will be used to track the drag gesture.
    -   It will call an `onHeightChange` prop function with the new height, allowing the parent to manage the state.
-   **Integration (`view.tsx`):**
    -   Replace the existing `<textarea>` elements with the new `<NumberedTextarea>` component.
    -   **State:** Add `cycleContextHeight` and `ephemeralContextHeight` to the component's state and to the `PcppCycle` type definition.
    -   The `onHeightChange` prop of the new component will be wired to update these state variables, which will be persisted via the existing debounced save mechanism.
</file_artifact>

<file path="src/Artifacts/A69. DCE - Animated UI Workflow Guide.md">
# Artifact A69: DCE - Animated UI Workflow Guide
# Date Created: C169
# Author: AI Model & Curator
# Updated on: C187 (Correct final workflow steps)

## 1. Overview & Goal

The Parallel Co-Pilot Panel (PCPP) has a powerful, multi-step workflow that may not be immediately obvious to new users. The goal of this feature is to implement a guided experience using subtle UI animations. These animations will highlight the next logical action the user should take, gently guiding them through the process from project creation to generating the next cycle's prompt.

## 2. User Story

| ID | User Story | Acceptance Criteria |
|---|---|---|
| P2-WF-01 | **Guided Workflow** | As a new user, I want the UI to visually guide me through the steps of a development cycle, so I can learn the workflow intuitively. | - After a specific action is completed, the UI element for the next logical action is highlighted with a subtle animation (e.g., a pulsing blue glow). |

## 3. The Animated Workflow Sequence (The Perfect Loop)

The highlighting will follow this specific sequence of user actions:

### Onboarding / Cycle 0
1.  **Start (New Workspace):** User opens a new, empty folder in VS Code.
    *   **Auto-Action:** The **DCE Parallel Co-Pilot Panel** automatically opens.

2.  **Open PCPP (Welcome View):** The PCPP is open to the "Welcome" / "Onboarding" view.
    *   **Highlight:** The **Project Scope `textarea`** pulses.

3.  **Input Project Scope:** User types their project plan into the `textarea`.
    *   **Highlight:** The **`Generate Initial Artifacts Prompt`** button pulses.

4.  **Generate `prompt.md`:** User clicks the button. `prompt.md` and `DCE_README.md` are created. The view transitions to Cycle 1.
    *   **Auto-Action:** `prompt.md` and `src/Artifacts/DCE_README.md` are automatically opened in the editor.
    *   **Highlight:** The **`Resp 1`** tab in the PCPP pulses.

### Main Loop (Cycle 1+)
5.  **Paste Responses:** The user gets responses from an LLM and pastes them into the response tabs.
    *   **Highlight:** The highlight moves sequentially from **`Resp 1`** to **`Resp 2`**, etc., as each `textarea` is filled.
    *   **Trigger:** Once content is present in all tabs, the highlight moves to the next step.

6.  **Parse Responses:**
    *   **Highlight:** The **`Parse All`** button pulses.

7.  **Sort Responses:** User clicks `Parse All`.
    *   **Highlight:** The **`Sort`** button pulses. (Skips if already sorted).

8.  **Select a Response:** User reviews the responses.
    *   **Highlight:** The **`Select This Response`** button on each tab pulses.

9.  **Create Baseline:** User clicks `Select This Response`.
    *   **Highlight:** The **`Baseline (Commit)`** button pulses.
    *   **State-Aware Skip:** This step is skipped if the backend reports that the Git working tree is already clean.

10. **Select Files for Acceptance:** A successful baseline is created.
    *   **Highlight:** The "Associated Files" list panel and the **`Select All`** button within it pulse.

11. **Accept Changes:** User checks one or more files in the "Associated Files" list.
    *   **Highlight:** The **`Accept Selected`** button pulses.

12. **Write Context:** User clicks `Accept Selected`.
    *   **Highlight:** The **"Cycle Context"** `textarea` pulses.

13. **Write Title:** User types into the "Cycle Context" `textarea`.
    *   **Highlight:** The **"Cycle Title"** input field pulses.

14. **Generate Next Prompt:** User types a bespoke "Cycle Title".
    *   **Highlight:** The **`Generate prompt.md`** button pulses.

15. **Create New Cycle:** User clicks `Generate prompt.md`.
    *   **Highlight:** The **`[ + ]` (New Cycle)** button pulses, completing the loop and preparing for the next iteration which starts back at Step 5.
</file_artifact>

<file path="src/Artifacts/A70. DCE - Git-Integrated Testing Workflow Plan.md">
# Artifact A70: DCE - Git-Integrated Testing Workflow Plan
# Date Created: C169
# Author: AI Model & Curator
# Updated on: C12 (Specify that Restore must only delete associated new files)

## 1. Overview & Goal

A core part of the DCE workflow involves accepting an AI-generated response and testing it in the live workspace. If the response introduces bugs, the user must manually revert the changes. The goal of this feature is to automate this "test and revert" loop by deeply integrating with Git. This will provide a one-click method to create a baseline commit before testing and a one-click method to restore that baseline if the test fails.

**Status (C187):** In Progress.

## 2. User Stories

| ID | User Story | Acceptance Criteria |
|---|---|---|
| P2-GIT-01 | **Create Baseline** | As a developer, after accepting an AI response but before testing it, I want to click a "Baseline (Commit)" button to create a Git commit, so I have a safe restore point. | - A "Baseline (Commit)" button is available in the response acceptance header. <br> - Clicking it executes `git add .` and `git commit -m "DCE Baseline: Cycle [currentCycle] - [cycleTitle]"`. <br> - A "Successfully created baseline commit" notification is shown. |
| P2-GIT-02 | **Restore Baseline** | As a developer, after testing an AI response and finding issues, I want to click a "Restore Baseline" button to discard all changes, so I can quickly test a different response. | - A "Restore Baseline" button is available. <br> - Clicking it executes `git restore .` to revert changes to tracked files. <br> - It also deletes any new, untracked files that were part of the accepted AI response, leaving other untracked files untouched. <br> - The restore operation must **exclude** DCE-specific state files (e.g., `.vscode/dce_history.json`) to prevent data loss. |
| P2-GIT-03 | **State-Aware Baseline** | As a developer, I don't want to be prompted to create a baseline if my project is already in a clean state, and I want clear feedback if I try to baseline an already-clean repository. | - Before highlighting the "Baseline" button, the extension checks the `git status`. <br> - If the working tree is clean, the "Baseline" step in the animated workflow is skipped. <br> - If the user manually clicks "Baseline" on a clean tree, a message like "Already baselined" is shown. |
| P2-GIT-04 | **Guided Git Initialization** | As a new user who hasn't initialized a Git repository, when I click "Baseline," I want to see a clear error message that tells me what's wrong and gives me the option to fix it with one click. | - If `git` is not initialized, clicking "Baseline" shows a `vscode.window.showErrorMessage`. <br> - The message explains that the folder is not a Git repository. <br> - The message includes an "Open README Guide" button that opens the project's `DCE_README.md`. <br> - The message also includes an "Initialize Repository" button that, when clicked, automatically runs `git init` in the workspace. |
| P2-GIT-05 | **Post-Baseline Workflow** | As a developer, after a successful baseline is created, I want the animated guide to immediately advance to the next step, so I know what to do next. | - After a successful baseline commit, the animated workflow highlight immediately moves to the "Select All" button in the "Associated Files" list. |

## 3. Feasibility Analysis

-   **"Insanely Powerful" Idea (Simulate TS Errors):**
    -   **Concept:** Programmatically run the TypeScript compiler on a virtual file system containing the proposed changes and display the resulting errors without modifying the user's workspace.
    -   **Feasibility:** This is a highly complex task. It would require integrating the TypeScript compiler API, creating an in-memory representation of the workspace file system, and managing dependencies. While theoretically possible, this is a very advanced feature that would require significant research and multiple development cycles.
    -   **Recommendation:** Defer as a long-term research goal.

-   **"Baseline/Restore" Idea:**
    -   **Concept:** Execute standard Git commands from the extension backend.
    -   **Feasibility:** This is highly feasible. The VS Code Git extension exposes an API that can be used to run commands, or a child process can be used to execute the `git` CLI directly. The main challenge is ensuring the `git restore` command excludes the necessary files.
    -   **Recommendation:** Proceed with planning and implementation.

## 4. Technical Implementation Plan

1.  **IPC Channels:**
    *   `ClientToServerChannel.RequestGitBaseline`: Payload `{ commitMessage: string }`.
    *   `ClientToServerChannel.RequestGitRestore`: Payload `{ filesToDelete: string[] }`.
    *   `ClientToServerChannel.RequestGitStatus`: No payload.
    *   `ClientToServerChannel.RequestGitInit`: (New) No payload.
    *   `ServerToClientChannel.SendGitStatus`: Payload `{ isClean: boolean }`.
    *   `ServerToClientChannel.NotifyGitOperationResult`: Payload `{ success: boolean; message: string; }`. This channel is critical for the backend to provide explicit feedback to the frontend's workflow state machine.

2.  **Backend (New `GitService` - See `A73`):**
    *   A new `GitService` will encapsulate all Git command logic.
    *   **`handleGitStatusRequest()`:** A new handler that runs `git status --porcelain`. If the output is empty, it sends `{ isClean: true }` to the frontend.
    *   **`handleGitBaselineRequest(commitMessage)`:**
        *   Checks the status first. If clean, it returns a specific "Already baselined" result.
        *   Otherwise, it executes `git add .` and `git commit -m "..."`.
        *   **Crucially, it will have a specific `catch` block for "not a git repository" errors. This block will trigger the user-facing `showErrorMessage` with the two action buttons.**
    *   **`handleGitRestoreRequest({ filesToDelete })`:**
        *   Executes `git restore -- . ':(exclude).vscode/dce_history.json'`.
        *   Iterates through `filesToDelete` and deletes each one using `vscode.workspace.fs.delete`.
        *   Returns a result object.
    *   **`handleGitInitRequest()`:** (New) A new handler that executes `git init` and returns a success/failure result.

3.  **Frontend (`view.tsx`):**
    *   The frontend will request the Git status at appropriate times to drive the workflow state.
    *   The `onClick` handler for "Baseline" will construct the commit message and send the `RequestGitBaseline` message.
    *   The `onClick` handler for "Restore" will determine which files were newly created and send them in the `RequestGitRestore` message.
    *   A new message handler for `NotifyGitOperationResult` will display the result message and, if successful, will advance the `workflowStep` state from `awaitingBaseline` to `awaitingFileSelect`.
</file_artifact>

<file path="src/Artifacts/A71. Sample M0 Prompt.md">
<prompt.md>

<M1. artifact schema>
M1. artifact schema
M2. cycle overview
M3. interaction schema
M4. current project scope
M5. organized artifacts list
M6. cycles
M7. Flattened Repo
</M1. artifact schema>

<M2. cycle overview>
Current Cycle 0 - Project Initialization
</M2. cycle overview>

<M3. Interaction Schema>
1.  Artifacts are complete, individual texts enclosed in `<xmltags>`. To ensure consistent parsing by the DCE extension, all file artifacts **must** be enclosed in `<file path="path/to/file.ts">...</file>` tags. The path must be relative to the workspace root. The closing tag must be a simple `</file>`. Do not use the file path in the closing tag.
2.  Our Document Artifacts serve as our `Source of Truth` throughout multiple cycles. As such, over time, as issues occur, or code repeatedly regresses in the same way, seek to align our `Source of Truth` such that the Root Cause of such occurances is codified so that it can be avoided on subsequent cycles visits to those Code artifacts.
3.  Please output entire Document or Code artifacts. Do not worry about Token length. If your length continues for too long, and you reach the 600 second timeout, I will simply incorporate the work you did complete, and we can simply continue from where you left off. Better to have half of a solution to get started with, than not to have it. **Preference is for larger, more complete updates over smaller, incremental ones to align with the human curator's parallel processing workflow.** The human curator often sends the same prompt to multiple AI instances simultaneously and selects the most comprehensive response as the primary base for the next cycle, using other responses as supplementary information. Providing more complete updates increases the likelihood of a response being selected as the primary base.
4.  Do not output artifacts that do not require updates in this cycle. (Eg. Do not do this: // Updated on: Cycle 1040 (No functional changes, only cycle header))
5.  **Critical: `flattened_repo_v2.txt` contains all project files. Output updated *individual* files that are part of it (like `<src/state/coreStore.ts>...`). However, do **NOT** output the surrounding Artifact container tags (`<flattened_repo_v2.txt>...</flattened_repo_v2.txt>`) or any auto-generated metadata sections within it (like the Total Files summary, Top 10 list, or the `<files list>` section) which are created by the `flatten.js` script.**
5.1. `flattened_repo_v2.txt` is a copy of the codebase, generated by a script; assume its an accurate representation of the existing codebase, but not necessarily a 'source of truth' like we treat our documents as, our codebase is a living artifact, documents, while we can update them, should be considered less transient.
5.2. **`.local` File Convention:** To manage token count, some large data files (e.g., `researchNodes.ts`) may be represented by a truncated `.local.ts` version in the context. This version contains the essential structure and a few examples. If the full content of a file is required for a task (e.g., a comprehensive data refactor or fixing a bug related to a specific entry), explicitly state this need in your summary of actions and request that the curator swap the `.local.ts` file with the full `.ts` version in the `files_list.txt` for the subsequent cycle.
6.  remember to output complete artifacts without placeholders, im taking your output, putting it in winmerge, and confirming we arent losing data in the update. when you provide placeholders, my cursory review turns into a meticulous file parsing, taking me from what is 5 seconds per artifact to upwards of 5 minutes, only to realize that the output is actually un-parseable, due to the nature of relativity, as the theory of relativity also applies to code. if you give me a code snippet, and do not give me the code surrounding that snippet, i do not know where that code should go. by providing the complete file, on the other hand, i can put it in a diff, see easily what was altered, and if anything was accidentally omitted or lost, i can be sure that it's retained.
7.  **Update documentation before writing code.** document artifacts are like our project readme files, our source of truth. they are our blueprints. they guide the code we write. when we realize we need to alter our approach or invent new game mechanics, we update the source of truth first, cause english is easy and flexible, then we codify that.
8.  this query is part of a larger software engineering project
9.  After you complete delivery on a code artifact, review it to make sure you did not miss any intermediary files. for instance, if we have a DevelopmentSystem.ts, using the componentData.ts, which is displaying on the ComponentProductionTab.tsx. But then theres also still a DevPanel.tsx file that is in-between that *could*, but shouldnt, get overlooked.
10. If you are deciding where to put a particular piece of code or function, and due to its nature, there are one or more candidate files that it could be placed in, choose the smaller file (in tokens).
11. Begin your response with a course of action and end with a review of your work, surface any self corrections in the summary of changes for the subsequent cycle.
12. do not underestimate how much you can accomplish in a given cycle; you'd only accomplish handicapping yourself. (Eg. you've authored this whole thing with just my guidance. good job, keep it up.)
13. Not as relevant for this project: **Log State Button:** The 'Log State' button in the `DevInfoOverlay` is a dynamic debugging tool. Modify the `triggerDebugLogs` action in `uiStore.ts` to output specific state information relevant to the current bug being investigated. **See A85 (Logging Guide) for usage details.**
14. Not as relevant for this project: **Regression Case Studies:** Use Artifact A106 to document persistent or complex bugs and their resolutions. Add entries *after* a fix is confirmed to codify the RCA and solution, preventing future regressions.
15. Include in your cycle summary, a short list of files you've updated. This makes it easy for my reviews.
16. if you seem to have spare time in a cycle, see if you can spot any particular file with excessive levels of comments or logging that seems extensive and for troubleshooting an error that has since been resolved, see to it to clean those files but preserve their functionalities. im just looking to shave off excess tokens wherever possible in the master_content.txt file.
17. if you see `(No change from C850)` such language, it's data loss. there was supposed to be actual language behind that placeholder, but in one iteration (C850, in this case) you had provided a placeholder, and i 'missed it' and did not capture the initial information. you either need to deliver the placeholder in such a way as i can easily press the left arrow instead of the rigth arrow in winmerge to not accept that part, but to also not have winmerge confuse it with the rest, otherwise i must manually parse the information. when the process is a single keystroke, i can manage it quickly enough. when we remove that ability because you provided me data in a format that has placeholders AND the placeholders do not parse within winmerge such that it removes the benefit winmerge is adding, then we have our problem. when you see this, try to correct it using whatever current relevant context you have.
18. basically, you should not worry about brevity, because when you go too long, your response gets interrupted by the system anyway. its better that the products you do deliver are all complete except for the last one, rather than you delivering all incomplete products, including the last one. does that make sense?
19. remember, do not stop outputting for the reason of preventing a potential artifact interruption mid-output. you actually end up stopping yourself from producting two or three additional files before you actually get interrupted. what i mean is, in the outputs where you do not do this, you produce for 500 seconds, producing 7-9 files, and only the last one is interrupted and unusable. compared to when you stop yourself prematurely, for the reason stated, and you produce for 180 seconds and provide maybe 3-4 files. even with the -1, producing as much as you can still outperforms the alternative.
20. This is a misaligned statement: `// (For full history, see master_content.txt)` because your changes get rolled into master_content.txt. therefore, if you remove the history, then when your updates are rolled in, they will remove the full history. understand? after a while, the history is not relevant and can be rolled out, for a while, it ought to stay. you can see what we're working on + the current cycle and make this determination.
21. Each time we create a new documentation artifact, lets also create the key/value pairs needed for me to add it into our Master Artifact List. they can simply be added into the new artifact itself and ill make the new entry in A0. this will solve for me manually generating a description and tag for each new documentation artifact. also, dont place `/` in the title/name of a documentation artifact. VSCode treats it as a folder separator.
21.1. when creating a new documentation artifact, also just update the master artifacts list itself.
</M3. Interaction Schema>

<M4. current project scope>
I want to build a turn-based tactical RPG game using the Phaser game engine and TypeScript. The game should feature a grid-based combat system similar to Final Fantasy Tactics or XCOM.
</M4. current project scope>

<M5. organized artifacts list>
# No artifacts exist yet.
</M5. organized artifacts list>

<M6. Cycles>
<Cycle 0>
<Cycle Context>
Review the user's project scope in M4. Your task is to act as a senior project architect and begin establishing the necessary documentation to achieve the user's goals. You have been provided with a set of best-practice templates for software engineering documentation as static context. Use these examples to guide your output. Your first response should be to generate a starter set of artifacts for this new project. Begin by creating a Master Artifact List (A0), similar to the provided template, and then create the first few essential planning documents (e.g., Project Vision, High-Level Requirements).
</Cycle Context>
<Static Context>
<T1. Template - Master Artifact List.md>
...
</T1. Template - Master Artifact List.md>

<T2. Template - Project Vision and Goals.md>
...
</T2. Template - Project Vision and Goals.md>

... (and so on for all templates T1-T10) ...

</Static Context>
</Cycle 0>
</M6. Cycles>

<M7. Flattened Repo>
<!-- No files selected for initial prompt -->
</M7. Flattened Repo>

</prompt.md>
</file_artifact>

<file path="src/Artifacts/A72. DCE - README for Artifacts.md">
# Artifact A72: DCE - README for Artifacts
# Date Created: C158
# Author: AI Model & Curator
# Updated on: C128 (Enhanced Git initialization instructions)

- **Key/Value for A0:**
- **Description:** The content for the `README.md` file that is automatically created in a new project's `src/Artifacts` directory, explaining the purpose of the extension and the artifact-driven workflow.
- **Tags:** documentation, onboarding, readme, source of truth

## 1. Welcome to the Data Curation Environment (DCE)

This directory (`src/Artifacts/`) is the heart of your project's planning and documentation. It's managed by the **Data Curation Environment (DCE)**, a VS Code extension designed to streamline AI-assisted development.

This `README.md` file was automatically generated to provide context for you (the developer) and for the AI assistants you will be working with.

## 2. What is an "Artifact"?

In the context of this workflow, an **Artifact** is a formal, written document that serves as a "source of truth" for a specific part of your project. Think of these files as the official blueprints, plans, and records.

The core principle of the DCE workflow is **"Documentation First."** Before writing code, you and your AI partner should first create or update an artifact that describes the plan.

## 3. The Iterative Cycle Workflow

Development in the DCE is organized into **Cycles**. You have just completed the initial setup.

### Your Next Steps (CRITICAL)

To take full advantage of the DCE's featuresespecially the "Baseline" and "Restore" buttons for safe testingyou **must** initialize a Git repository for this project.

**Do this now:**

1.  Open a terminal in your project's root directory (VS Code menu: `Terminal > New Terminal`).
2.  Run the following commands in order:

    ```bash
    # 1. Initialize the repository
    git init

    # 2. Create a .gitignore file to exclude DCE system files
    # This is CRITICAL to prevent the extension from flashing/refreshing constantly.
    echo ".vscode/" >> .gitignore
    echo "node_modules/" >> .gitignore

    # 3. Stage all current files
    git add .

    # 4. Create your first commit
    git commit -m "Initial commit: DCE Project Setup"
    ```

3.  **Submit Your First Prompt:** The `prompt.md` file has been automatically generated for you. It contains your project plan and instructions. Copy its entire contents and paste it into your preferred AI chat interface (e.g., Google AI Studio, ChatGPT).

4.  **Review and Accept Responses:** Paste the AI's responses back into the "Resp 1", "Resp 2", etc. tabs in the Parallel Co-Pilot panel. The UI will guide you through parsing the responses, selecting the best one, and accepting its changes into your workspace.

5.  **Repeat:** This completes a cycle. You then start the next cycle, building upon the newly accepted code and documentation.
</file_artifact>

<file path="src/Artifacts/A73. DCE - GitService Plan.md">
# Artifact A73: DCE - GitService Plan
# Date Created: C175
# Author: AI Model & Curator

- **Key/Value for A0:**
- **Description:** A plan for a dedicated backend service to encapsulate all interactions with the Git command line for features like baselining and restoring.
- **Tags:** plan, architecture, backend, git, service

## 1. Overview & Goal

To implement the Git-integrated testing workflow (`A70`), we need a dedicated backend component to handle the execution of Git commands. The goal is to create a new, single-responsibility `GitService` that encapsulates all interactions with the Git CLI. This improves modularity and makes the code easier to maintain and test.

## 2. Service Responsibilities

The `GitService` will be responsible for:
-   Executing `git` commands in the user's workspace directory using Node.js's `child_process`.
-   Parsing the output (stdout and stderr) of Git commands.
-   Handling errors gracefully and providing clear feedback to the user.

## 3. Technical Implementation Plan

1.  **New File (`src/backend/services/git.service.ts`):**
    *   Create the new service file.
    *   It will import `exec` from `child_process` and `vscode`.

2.  **Core `execGitCommand` Method:**
    *   A private helper method will be the foundation of the service: `private execGitCommand(command: string): Promise<{ stdout: string; stderr: string }>`.
    *   This method will wrap the `exec` call in a `Promise`, making it easy to use with `async/await`.
    *   It will get the workspace root path from `vscode.workspace.workspaceFolders`.
    *   It will execute the command within that workspace directory.

3.  **Public Handler Methods:**
    *   **`handleGitBaselineRequest(commitMessage: string)`:**
        *   Calls `await this.execGitCommand('git add .')`.
        *   On success, calls `await this.execGitCommand(\`git commit -m "${commitMessage}"\`)`.
        *   Will show a `vscode.window.showInformationMessage` on success or `showErrorMessage` on failure.
    *   **`handleGitRestoreRequest()`:**
        *   Constructs the command: `git restore -- . ':(exclude).vscode/dce_history.json'`.
        *   Calls `await this.execGitCommand(...)`.
        *   Shows appropriate success or error messages to the user.

4.  **Integration:**
    *   The new `GitService` will be instantiated in `src/backend/services/services.ts`.
    *   The `parallel-copilot.view/on-message.ts` file will be updated to call the new service's methods when it receives the `RequestGitBaseline` and `RequestGitRestore` IPC messages.
</file_artifact>

<file path="src/Artifacts/A74. DCE - Per-Input Undo-Redo Feature Plan.md">
# Artifact A74: DCE - Per-Input Undo-Redo Feature Plan
# Date Created: C178
# Author: AI Model & Curator

- **Key/Value for A0:**
- **Description:** A plan to implement a separate undo/redo history for each major text input in the PCPP to provide a more intuitive editing experience.
- **Tags:** feature plan, ui, ux, undo, redo, state management

## 1. Overview & Goal

Currently, all text inputs in the Parallel Co-Pilot Panel (e.g., Cycle Title, Cycle Context, Ephemeral Context) share a single, global undo/redo history stack, which is the default behavior for a webview. This leads to a confusing and non-standard user experience. For example, typing in the "Cycle Context" and then pressing `Ctrl+Z` in the "Cycle Title" input will undo the change made in the context field, not the title field.

The goal of this feature is to implement a separate, independent undo/redo history for each major text input, aligning the panel's behavior with standard application design.

## 2. User Story

| ID | User Story | Acceptance Criteria |
|---|---|---|
| P2-UNDO-01 | **Per-Input Undo/Redo** | As a developer, when I am editing multiple text fields, I want `Ctrl+Z` (Undo) and `Ctrl+Y` (Redo) to apply only to the text field I am currently focused on, so I can manage my edits for each field independently. | - Changes made to the "Cycle Title" input can be undone/redone without affecting the other text areas. <br> - Changes made to the "Cycle Context" text area can be undone/redone independently. <br> - Changes made to the "Ephemeral Context" text area can be undone/redone independently. |

## 3. Technical Implementation Plan

This is a complex feature that requires overriding the browser's default undo/redo behavior and implementing a custom state management solution.

1.  **Create a Custom `useHistoryState` Hook:**
    *   A new React hook, `useHistoryState`, will be created to manage the state history for a single value (e.g., a string).
    *   This hook will manage a state object: `{ past: string[], present: string, future: string[] }`.
    *   It will return an array: `[state, setState, undo, redo, canUndo, canRedo]`.
    *   The `setState` function will update the `present` value and push the old `present` value onto the `past` stack.
    *   The `undo` and `redo` functions will move values between the `past`, `present`, and `future` stacks.

2.  **Integrate the Hook in `view.tsx`:**
    *   The main `view.tsx` component will use this custom hook for each of the relevant state variables:
        ```typescript
        const [cycleTitle, setCycleTitle, undoTitle, redoTitle] = useHistoryState('');
        const [cycleContext, setCycleContext, undoContext, redoContext] = useHistoryState('');
        const [ephemeralContext, setEphemeralContext, undoContext, redoContext] = useHistoryState('');
        ```

3.  **Implement Custom `onKeyDown` Handlers:**
    *   A new `onKeyDown` handler will be created and attached to each of the relevant input/textarea components.
    *   This handler will check for `Ctrl+Z` and `Ctrl+Y` (and their platform-specific variants).
    *   When an undo/redo shortcut is detected, it will call `event.preventDefault()` to stop the default browser action.
    *   It will then call the corresponding `undo` or `redo` function from the `useHistoryState` hook for that specific input.

4.  **Refactor `NumberedTextarea.tsx`:**
    *   The `NumberedTextarea` component will need to be updated to accept the new, more complex `onKeyDown` handler.

This approach will provide the robust, per-input undo/redo functionality required for a professional user experience.
</file_artifact>

<file path="src/Artifacts/A75. DCE - Text Area Component A-B-C Test Plan.md">
# Artifact A75: DCE - Text Area Component A-B-C Test Plan
# Date Created: C179
# Author: AI Model & Curator
# Updated on: C180 (Acknowledge word-wrap limitation)

- **Key/Value for A0:**
- **Description:** A plan to create a test harness for the `NumberedTextarea` component to diagnose and fix persistent scrolling and alignment bugs.
- **Tags:** plan, process, debugging, troubleshooting, ui, ux, react

## 1. Overview & Goal

The `NumberedTextarea` component, used for the "Cycle Context" and "Ephemeral Context" fields in the Parallel Co-Pilot Panel, has been a persistent source of UI bugs across multiple cycles (C1, C2, C3, C167, C174). The primary issues are a lack of synchronized scrolling between the line numbers and the text content, and a misalignment of the cursor and text selection, making the component difficult to use.

The goal of this plan is to apply the "Original-A-B-C" testing strategy, as defined in `A51`, to definitively diagnose and resolve these issues. We will create a test harness within the PCPP that allows for parallel testing of the original component and three new, isolated test components, each attempting a different solution.

## 2. Known Limitation: Word-Wrap Line Numbering

As of Cycle 4, it has been observed that the current architecture of the `NumberedTextarea` (and all proposed test variants) does not correctly handle line numbering for word-wrapped text. The component counts lines based on newline characters (`\n`), not on how the text visually wraps in the view. This means a single line of text that wraps into three visual lines will only get one line number.

**This is a known limitation.** A true fix for this requires a significantly more complex architecture, likely involving rendering text into a hidden element and measuring the resulting line boxes. For the current development phase, the priority is to fix the blocking usability bugs (scrolling, focus, performance). The word-wrap numbering issue will be deferred to a future cycle dedicated to advanced component architecture.

## 3. The Strategy

### 3.1. Test Harness Implementation
The main `parallel-copilot.view/view.tsx` component will be refactored to include a new "Test Harness" mode.
-   A new state, `activeTestView`, will control which view is active: `'Original'`, `'TestA'`, `'TestB'`, or `'TestC'`.
-   A simple tab bar UI will be added to switch between these views.
-   The "Original" view will render the current, fully-featured PCPP layout.
-   The other views will render the isolated test components.

### 3.2. Isolated Test Components
Three new test components will be created to isolate and test specific variables.

-   **Test A (`TestPane1.tsx`): Synchronized Scrolling**
    -   **Hypothesis:** The scrolling is failing because the `onScroll` event is not being correctly used to synchronize the `scrollTop` of the line number gutter and the text area.
    -   **Implementation:** This component will feature a barebones `textarea` next to a `div` for line numbers. It will implement a robust `onScroll` handler that programmatically sets the `scrollTop` of the line number gutter, with extensive logging to confirm the event is firing and the values are changing.

-   **Test B (`TestPane2.tsx`): Pixel-Perfect Alignment**
    -   **Hypothesis:** The cursor and selection are misaligned due to subtle differences in CSS properties (`font-family`, `font-size`, `line-height`, `padding`, `box-sizing`) between the transparent `textarea` and the underlying `div` that displays the highlighted text.
    -   **Implementation:** This component will implement the overlay approach. It will meticulously ensure that every single font and box-model CSS property is identical across both elements. It will contain no complex logic, only the minimal structure needed to test for visual alignment.

-   **Test C (`TestPane3.tsx`): Combined & Cleaned Solution**
    -   **Hypothesis:** A clean implementation combining the lessons from Test A and Test B will provide a fully functional component.
    -   **Implementation:** This component will integrate the synchronized scrolling from Test A with the pixel-perfect styling from Test B into a new, clean version of the `NumberedTextarea` component, free from any other complex logic from the main view.

## 4. Cleanup Process
Once a working pattern is identified in a test component:
1.  **Codify Findings:** The successful pattern and the root cause of the failure will be documented in `A11. DCE - Regression Case Studies`.
2.  **Integrate Solution:** The original `NumberedTextarea.tsx` component will be refactored to use the successful pattern.
3.  **Remove Test Artifacts:** The test harness UI and the `TestPane*.tsx` component files will be removed from the project.
</file_artifact>

<file path="src/Artifacts/A76. DCE - Word Wrap Line Numbering Challenges.md">
# Artifact A76: DCE - Word Wrap Line Numbering Challenges
# Date Created: C181
# Author: AI Model & Curator

- **Key/Value for A0:**
- **Description:** Explains the technical complexity of implementing line numbers that accurately reflect visual word wrapping in a textarea component.
- **Tags:** documentation, technical debt, ui, ux, word wrap, line numbers

## 1. Problem Statement

The user has requested that the line numbers in the `NumberedTextarea` component should respect word wrapping. Currently, the component counts lines based on newline characters (`\n`). This means a single logical line that visually wraps into three lines in the UI still only receives one line number. The user correctly points out that this is not ideal.

This document explains why this seemingly simple feature is technically complex to implement in a standard HTML `<textarea>` and outlines potential solutions.

## 2. The Core Challenge: Logical vs. Visual Lines

The fundamental issue is the difference between how a `<textarea>` handles content versus how the browser renders it.

*   **Logical Lines:** The `<textarea>` element's `value` is a simple string. The only concept of a "line" it has is the presence of a newline character (`\n`). When we split the string by `\n`, we are counting these logical lines. This is what our current implementation does, and it's fast and simple.

*   **Visual Lines:** Word wrapping is a purely visual phenomenon handled by the browser's rendering engine. The browser calculates how many words fit on a line based on the element's width, font size, font family, letter spacing, and word spacing. It then visually breaks the line and renders the overflow text below. **Crucially, the browser does not expose a simple API to ask, "How many visual lines are you currently rendering for this text?"**

Because we cannot directly query the rendered line count, we must resort to indirect methods to calculate it.

## 3. Potential Solutions & Their Complexity

Here are the common approaches to solving this problem, each with its own trade-offs.

### Solution A: The Hidden `div` Measurement Technique

This is the most common and reliable method.

1.  **How it Works:**
    *   Create a hidden `div` element off-screen or with `visibility: hidden`.
    *   Apply the *exact same* CSS styles to this `div` as the `<textarea>` (width, font, padding, etc.).
    *   Copy the content of the `<textarea>` into the `innerHTML` of the hidden `div`.
    *   Calculate the number of visual lines by dividing the `scrollHeight` of the hidden `div` by its `line-height`.

2.  **Complexity & Downsides:**
    *   **Performance:** This calculation must be run on every single keystroke, as any character change could affect word wrapping. Copying large amounts of text into the DOM and forcing a browser re-layout on every key press can be performance-intensive and may cause input lag.
    *   **Fragility:** The CSS styles must be perfectly synchronized. Any discrepancy in padding, border, font-size, etc., will result in an incorrect calculation.
    *   **Implementation:** Requires careful DOM manipulation within our React component, managing refs to both the textarea and the hidden div, and ensuring the calculation is efficient.

### Solution B: Using a Full-Fledged Code Editor Component

Instead of building our own, we could replace the `<textarea>` with a lightweight, embeddable code editor library.

1.  **How it Works:**
    *   Integrate a library like **CodeMirror** or **Monaco Editor** (the editor that powers VS Code itself, though it's much heavier).
    *   These components are not simple textareas; they are complete editing surfaces that render each line individually. Because they control the rendering process, they have full knowledge of visual lines and can provide accurate line numbering out of the box.

2.  **Complexity & Downsides:**
    *   **Bundle Size:** These libraries are significantly larger than a simple React component, which would increase the extension's load time.
    *   **Integration:** Integrating them into our existing React and VS Code Webview architecture can be complex, requiring custom wrappers and careful handling of the component's lifecycle.
    *   **Overkill:** For a simple context input field, using a full code editor might be architectural overkill.

## 4. Conclusion & Path Forward

The user's request is valid and would be a great UX improvement. However, due to the performance and implementation complexities described above, this feature is considered a significant piece of technical debt that requires a dedicated cycle to solve correctly.

The current priority is to fix the more critical usability bugs like scrolling, focus management, and highlighting. Once the component is stable, we can revisit this challenge and dedicate a future cycle to implementing one of the more advanced solutions above.
</file_artifact>

<file path="src/Artifacts/A77. DCE - Whitepaper Generation Plan.md">
# Artifact A77: DCE - Whitepaper Generation Plan

# Date Created: C181

# Author: AI Model & Curator

# Updated on: C182 (Incorporate "Process as Asset" theme and use case)

  - **Key/Value for A0:**
  - **Description:** A plan for brainstorming and developing a whitepaper to explain the value of the DCE to external stakeholders, particularly those in government and military contexts.
  - **Tags:** documentation, planning, whitepaper, stakeholders, government, military

## 1\. Overview & Goal

The director of UKILRN, along with NSA and naval officers, has expressed interest in the Data Curation Environment (DCE) project and requested a whitepaper. The goal of this artifact is to brainstorm themes and develop abstracts tailored to an audience focused on efficiency, auditability, and the application of technology to complex, mission-critical systems.

## 2\. Key Value Proposition & Use Case (Updated C182)

The central argument for the DCE is that it **accelerates the development and maintenance of complex systems by transforming the human-AI interaction workflow.** It moves beyond ad-hoc prompting to a structured process where curated context becomes a persistent, shared asset, enabling rapid iteration and efficient collaboration.

### 2.1. Use Case Spotlight: Rapid Iteration on Curated Datasets

A compelling example of the DCE's value is the curation and maintenance of specialized datasets, such as labs, lessons, or intelligence reports.

1.  **Curation:** An operator uses the DCE to precisely select the relevant source materials (e.g., a set of exam questions) for a specific task.
2.  **Collaboration:** This "selection set" (the curated context) is a shareable asset. A colleague can instantly load the exact same context, review the previous cycle's work (the history), and continue the task.
3.  **Rapid Iteration:** When feedback is received (e.g., "The correct answer is too often the longest choice"), the operator doesn't need to manually edit the files. They simply load the curated context and issue a targeted instruction to the AI (e.g., "Camouflage the distractors with more meaningful but ultimately fluffy language"). The AI performs the complex edits against the precise context, completing the update in a single, efficient cycle.

## 3\. Brainstormed Whitepaper Themes

*(See previous versions for initial brainstorming themes A-D)*

### 3.1. Refined Theme (C182)

Based on feedback emphasizing the DCE as an accelerator for existing priorities, a new primary theme has been developed.

**Theme E: Process as Asset: Accelerating specialized content creation through structured Human-AI collaboration.**

  * **Focus:** This theme emphasizes that the DCE transforms the workflow itself into a valuable, reusable asset. It highlights how the combination of rapid data curation, seamless sharing of context (Selection Sets), and the persistent knowledge graph (Cycle History) dramatically accelerates the creation and maintenance of specialized content.
  * **Audience Appeal:** Directly addresses the concern of "too many priorities" by positioning the DCE as the tool that makes achieving those priorities faster and more efficient. It appeals to operational leadership focused on scaling expertise and accelerating output.

## 4\. Selected Themes & Sample Abstracts

The following abstracts represent the most promising directions. **Sample 4 (Theme E) is the recommended primary direction based on C182 feedback.**

-----

### **Sample 1: Accelerating Complex Systems Development with Parallel AI Scrutiny**

**Executive Summary:** The integration of Artificial Intelligence into the software development lifecycle (SDLC) promises to accelerate delivery and enhance innovation. However, the stochastic nature of Large Language Models (LLMs) introduces significant risks, as a single AI-generated solution may contain subtle flaws, security vulnerabilities, or inefficiencies. This whitepaper introduces the Data Curation Environment (DCE), a novel framework integrated into Visual Studio Code that mitigates these risks by enabling a parallelized workflow. The DCE allows developers to generate, manage, and test multiple, distinct AI-generated solutions simultaneously. By providing tools for rapid, side-by-side comparison, integrated diffing, and one-click testing within a version-controlled environment, the DCE transforms the process from a linear, high-risk "accept/reject" decision into a strategic portfolio management approach. This paper details the DCE methodology and presents a case for its adoption in mission-critical software projects where speed, quality, and reliability are paramount.

-----

### **Sample 2: The Auditable Knowledge Graph: Structuring Human-AI Collaboration for Mission-Critical Systems**

**Executive Summary:** As Artificial Intelligence becomes a collaborative partner in complex problem-solving, the process of interactionthe prompts, the AI's suggestions, and the human's decisionsbecomes a valuable asset. Traditional AI chat interfaces leave this history as an unstructured, ephemeral transcript. This whitepaper presents the Data Curation Environment (DCE), a system that captures the iterative human-AI collaboration process as a structured, persistent **Knowledge Graph**. Each "cycle" in the DCE workflow creates a node representing the system's state, the curated data context, the human's intent, multiple AI-generated solutions, and the operator's final decision. The resulting graph provides an unprecedented, fully auditable record of the entire analytical or development process. This has profound implications for after-action reviews, training new personnel on complex decision-making, and ensuring accountability in high-stakes environments. This paper outlines the architecture of the DCE and its application in creating transparent, traceable, and valuable knowledge assets from every human-AI interaction.

-----

### **Sample 3: A Framework for High-Fidelity Context Management in AI-Assisted Operations**

**Executive Summary:** The quality of output from any Large Language Model (LLM) is fundamentally dependent on the quality and precision of the input context. In high-stakes government and military applications, providing incomplete, incorrect, or bloated context can lead to flawed, misleading, or insecure results. This whitepaper introduces the Data Curation Environment (DCE), a framework and toolset designed to solve this "last mile" problem of context engineering. The DCE provides operators with a high-fidelity interface to precisely select, manage, and version the exact datasource code, technical documents, intelligence reportsthat forms the prompt for an LLM. By integrating directly into the operator's native environment (VS Code), the DCE minimizes workflow friction and enables a rigorous, repeatable, and auditable process for context curation. This paper argues that such a framework is an essential component for the safe and effective operationalization of AI, moving beyond ad-hoc prompting to a deliberate, engineered approach to human-AI interaction.

-----

### **Sample 4 (Recommended): Process as Asset: Accelerating Specialized Content Creation through Structured Human-AI Collaboration**

**Executive Summary:** Organizations tasked with developing highly specialized contentsuch as technical training materials, intelligence reports, or complex software documentationface a constant bottleneck: the time and expertise required to curate accurate data, collaborate effectively, and rapidly iterate on feedback. Traditional workflows are often manual, opaque, and inefficient. This whitepaper introduces the Data Curation Environment (DCE), a framework that transforms the content creation process itself into a valuable organizational asset. The DCE provides a structured, human-in-the-loop methodology that enables rapid dataset curation, seamless sharing of curated contexts between colleagues, and instant iteration on feedback. By capturing the entire workflow as a persistent, auditable knowledge graph, the DCE doesn't just help teams build content faster; it provides the infrastructure necessary to scale expertise, ensure quality, and accelerate the entire organizational mission.

## 5\. Production Plan

1.  **Theme Selection:** The curator will review the sample abstracts and select the final direction for the whitepaper. (Recommended: Sample 4).
2.  **Full Draft Generation:** In a subsequent cycle, the AI will be tasked to write the full whitepaper based on the selected theme, using all existing project artifacts as context.
3.  **Review and Refine:** The curator will review the AI-generated draft, provide feedback, and iterate until the whitepaper is finalized.
</file_artifact>

<file path="src/Artifacts/A78. DCE - VSIX Packaging and FTV Flashing Bug.md">
# Artifact A78: DCE - VSIX Packaging and FTV Flashing Bug
# Date Created: C183
# Author: AI Model & Curator

- **Key/Value for A0:**
- **Description:** Documents the root cause and solution for the bloated VSIX package and the persistent File Tree View flashing bug in the packaged extension.
- **Tags:** bug fix, packaging, vsix, vscodeignore, file watcher, git

## 1. Overview

This document addresses two critical issues identified during the packaging and testing of the DCE extension in Cycle 183:
1.  The final `.vsix` extension file is excessively large due to the inclusion of unnecessary development files.
2.  The File Tree View (FTV) exhibits a rapid "flashing" or refresh storm in the packaged version, which does not occur in the Extension Development Host.

## 2. Problem 1: Bloated VSIX Package

-   **Symptom:** The generated `.vsix` file is over 80MB and contains numerous files and directories that are not required for the extension to run, such as `prompt.md`, `flattened_repo.md`, the `The-Creator-AI-main/` reference directory, and the project's own `.vscode/` settings.
-   **Root Cause Analysis (RCA):** The `.vscodeignore` file, which instructs the `vsce` packaging tool which files to exclude, was incomplete. By default, `vsce` includes all files not explicitly ignored or listed in `.gitignore`.
-   **Codified Solution:** The `.vscodeignore` file must be updated to include patterns for all development-time artifacts, large output files, and source code that is not needed at runtime. This ensures a lean, efficient package.

### Proposed `.vscodeignore` additions:
```
# Development and output files
prompt.md
flattened_repo.md
log-state-logs.md
bootstrap-flattener.js

# Reference directories
The-Creator-AI-main/

# Project-specific VSCode settings
.vscode/

# Source maps and source code (already compiled to dist/)
**/*.map
**/*.ts
**/*.tsx
```

## 3. Problem 2: FTV Flashing in Packaged Extension

-   **Symptom:** The FTV continuously refreshes, making it unusable. Console logs show a storm of `[triggerFullRefresh] Called because: git state change` events.
-   **Root Cause Analysis (RCA):** The refresh storm is caused by an overly sensitive event listener combined with file system activity. The listener for `repo.state.onDidChange` in `file-tree.service.ts` is the primary culprit. This event fires for almost any change detected by the Git extension, including changes to build artifacts in the `dist/` directory or internal Git state files. In the packaged extension, the file layout and timing differ from the dev host, likely exposing this sensitivity more acutely. The file system watcher may also be contributing by picking up changes that slip past the exclusion patterns.
-   **Codified Solution & Best Practice:**
    1.  **Diagnose with Aggressive Logging:** The immediate solution is to inject high-visibility logging into `file-tree.service.ts` to pinpoint the exact trigger.
        *   Add a log inside the `repo.state.onDidChange` listener to confirm its firing frequency.
        *   Add a log at the very beginning of the `onFileChange` handler to see every single file path the watcher detects, before any exclusion logic is applied.
    2.  **Strengthen Exclusions:** The exclusion logic in `file-tree.service.ts` must be made more robust to explicitly ignore build artifacts and internal state files under all conditions.
    3.  **Dampen Event Listener:** The `repo.state.onDidChange` listener should be heavily debounced via the `triggerFullRefresh` function to prevent a storm of events from causing a storm of UI updates. A longer-term solution would be to find a more specific Git API event to listen to, if one exists.
</file_artifact>

<file path="src/Artifacts/A79. DCE - Autosave and Navigation Locking Plan.md">
# Artifact A79: DCE - Autosave and Navigation Locking Plan
# Date Created: C7
# Author: AI Model & Curator

- **Key/Value for A0:**
- **Description:** Outlines the plan to fix the cycle data loss bug by implementing a UI-driven autosave status indicator and locking navigation controls while there are unsaved changes.
- **Tags:** bug fix, data integrity, race condition, autosave, ui, ux

## 1. Overview & Goal

A critical data loss bug has been observed where navigating between cycles in the Parallel Co-Pilot Panel can cause data from one cycle to overwrite another. This is caused by a race condition between the debounced auto-save of the departing cycle and the loading of the new cycle's state.

The goal is to implement a definitive fix by creating a clear and robust user experience that prevents this race condition from occurring. This will be achieved by making the user aware of the save state and preventing navigation until all changes are safely persisted.

## 2. User Stories

| ID | User Story | Acceptance Criteria |
|---|---|---|
| BUG-01 | **Prevent Data Loss** | As a user, when I quickly navigate between cycles, I want to be confident that my data from the previous cycle is saved before the new cycle loads, so no data is ever lost or corrupted. | - Navigating away from a cycle with unsaved changes is prevented until the save operation is complete. |
| UX-01 | **See Save Status** | As a user, I want to see a clear visual indicator of the current save status (e.g., "Unsaved changes," "Saving...," "Saved"), so I understand the state of my work. | - An icon or text is displayed near the cycle navigator. <br> - It updates in real-time to reflect the save status. |
| UX-02 | **Locked Navigation** | As a user, when I have unsaved changes, I want the cycle navigation buttons to be temporarily disabled, so I have a clear visual cue that I cannot change cycles until my work is saved. | - The "Next" (`>`), "Previous" (`<`), and "New" (`+`) cycle buttons are disabled when the save status is "unsaved" or "saving." <br> - The buttons become enabled once the status returns to "saved." |

## 3. Technical Implementation Plan

1.  **New State Management (`view.tsx`):**
    *   Introduce a new state variable to track the save status: `const [saveStatus, setSaveStatus] = useState<'saved' | 'saving' | 'unsaved'>('saved');`
    *   All `onChange` handlers for data that is persisted per-cycle (title, contexts, response tabs) will be updated to immediately call `setSaveStatus('unsaved')`.

2.  **Refactor Autosave Logic:**
    *   **IPC:** A new `ServerToClientChannel.NotifySaveComplete` channel will be created. The payload will be `{ cycleId: number }`.
    *   **Backend (`history.service.ts`):** The `saveCycleData` method will, after successfully writing the file, send the `NotifySaveComplete` message back to the client with the ID of the cycle that was just saved.
    *   **Frontend (`view.tsx`):**
        *   The existing debounced `saveCurrentCycleState` function will be modified.
        *   When triggered, it will first call `setSaveStatus('saving')`.
        *   It will then send the `SaveCycleData` message to the backend as it does now.
        *   A new message handler will be added to listen for `NotifySaveComplete`. When it receives confirmation for the *currently viewed cycle*, it will call `setSaveStatus('saved')`.

3.  **Update UI Components:**
    *   **`CycleNavigator.tsx`:**
        *   This component will receive `saveStatus` as a prop.
        *   The `disabled` attribute of the `<`, `>`, and `+` buttons will be set to `saveStatus !== 'saved'`.
    *   **`view.tsx` & `view.scss`:**
        *   A new component or set of icons will be rendered near the cycle navigator to display the current `saveStatus`. For example:
            *   `'unsaved'`: A yellow dot with the tooltip "Unsaved changes".
            *   `'saving'`: A spinning icon with the tooltip "Saving...".
            *   `'saved'`: A green checkmark with the tooltip "Saved".

4.  **Update Navigation Logic (`view.tsx`):**
    *   The `handleCycleChange` function will be simplified. Since the navigation buttons are disabled when there are unsaved changes, it no longer needs to trigger a save itself. Its only job is to request the data for the new cycle.
</file_artifact>

<file path="src/Artifacts/A80. DCE - Settings Panel Plan.md">
# Artifact A80: DCE - Settings Panel Plan
# Date Created: C6
# Author: AI Model & Curator
# Updated on: C17 (Reflect removal of Context Chooser icon)

- **Key/Value for A0:**
- **Description:** A plan for a new settings panel, accessible via a command, to house changelogs, settings, and other informational content.
- **Tags:** feature plan, settings, ui, ux, changelog

## 1. Overview & Goal

As the Data Curation Environment (DCE) grows in features, users will need a centralized location to manage settings, view changelogs, and access help documentation. The goal of this feature is to create a dedicated "Settings & Help" panel that serves as this central hub.

**Status (C17):** Implemented. The panel is now functional and opens as a `WebviewPanel` in the main editor area. The entry point icon from the Context Chooser view has been removed, and the panel is now accessed via the `DCE: Open Settings & Help` command.

## 2. User Stories

| ID | User Story | Acceptance Criteria |
|---|---|---|
| P2-SET-01 | **Access Help and Settings** | As a user, I want to execute a command to open a dedicated panel, so I can access settings and information about the extension. | - A command `DCE: Open Settings & Help` is available in the command palette. <br> - Executing it opens a new `WebviewPanel` in the main editor area, titled "DCE Settings & Help". |
| P2-SET-02 | **View Changelog** | As a user, I want to view a changelog within the settings panel, so I can see what has changed in the latest version of the extension. | - The settings panel has a "Changelog" tab or collapsible section. <br> - This section displays the content of a `CHANGELOG.md` file from the workspace root, rendered as formatted Markdown. |
| P2-SET-03 | **View About/README** | As a user, I want to view an "About" page that explains the purpose and workflow of the DCE, so I can get help on how to use it. | - The settings panel has an "About" tab or collapsible section. <br> - This section displays the content of the `README.md` file from the workspace root. |
| P2-SET-04 | **Manage Settings** | As a user, I want to manage extension settings from this panel, so I can configure features to my preference. | - The settings panel has a "Settings" section. <br> - It provides UI controls for managing settings, such as a field for a local API URL and a toggle for "Free Mode" vs. "Local Mode". |

## 3. Technical Implementation Plan

1.  **Command Registration:**
    *   **`package.json`:** The `view/title` menu contribution for the `viewType.sidebar.contextChooser` has been removed. A new command `dce.openSettingsPanel` is registered for the command palette.
    *   **`commands.ts`:** The command executes an internal `dce.showSettingsPanel` command.
    *   **`extension.ts`:** The handler for `dce.showSettingsPanel` creates and manages a singleton `WebviewPanel`.

2.  **New Settings Webview (`settings.view/`):**
    *   `view.tsx` renders a UI with collapsible sections for "Changelog", "About", and "Settings".
    *   On mount, it sends IPC messages to the backend to request the content for the `CHANGELOG.md` and `README.md` files.
    *   The "Settings" section contains placeholder UI elements for future functionality.

3.  **Backend Logic (`file-operation.service.ts`):**
    *   The `handleChangelogContentRequest` and `handleReadmeContentRequest` methods read the respective files from the workspace root and send their content back to the settings webview.
    *   **IPC:** The existing channels (`RequestChangelogContent`, `SendChangelogContent`, etc.) facilitate this communication.
</file_artifact>

<file path="src/Artifacts/A81. DCE - Curator Activity Plan.md">
# Artifact A81: DCE - Curator Activity Plan
# Date Created: C6
# Author: AI Model & Curator

- **Key/Value for A0:**
- **Description:** A plan to introduce a new `<curator_activity>` section to the AI response format, allowing for explicit instructions to the human curator.
- **Tags:** documentation, process, interaction schema, workflow

## 1. Overview & Goal

Currently, if the AI needs the human curator to perform an action it cannot (e.g., delete a file, install a dependency), it must embed this instruction within the "Course of Action" or summary. This can be missed and is not machine-parsable.

The goal of this feature is to create a formal, dedicated channel for these instructions. A new `<curator_activity>...</curator_activity>` section will be added to the interaction schema. The extension will parse this section and display it in a distinct, highly visible area of the UI, ensuring the curator sees and can act upon these critical instructions.

## 2. User Story

| ID | User Story | Acceptance Criteria |
|---|---|---|
| P2-CA-01 | **Receive Curator Instructions** | As a curator, when an AI response includes actions I need to perform manually, I want to see them clearly separated from the AI's own course of action, so I don't miss them. | - The AI can include a `<curator_activity>` block in its response. <br> - The PCPP parser extracts the content of this block. <br> - The UI displays this content in a new, clearly labeled "Curator Activity" collapsible section. |

## 3. Technical Implementation Plan

1.  **Update Interaction Schema:**
    *   **`A52.2 DCE - Interaction Schema Source.md`:** A new rule will be added, defining the `<curator_activity>...</curator_activity>` section and explaining its purpose to the AI.

2.  **Update Parser (`response-parser.ts`):**
    *   A new `CURATOR_ACTIVITY_REGEX` will be added to extract the content from the new tags.
    *   The `ParsedResponse` interface in `pcpp.types.ts` will be updated with a new optional property, `curatorActivity?: string`.

3.  **Update UI (`ParsedView.tsx`):**
    *   A new `CollapsibleSection` will be added to the parsed view.
    *   It will be titled "Curator Activity".
    *   It will be conditionally rendered only if `parsedContent.curatorActivity` exists and is not empty.
    *   The content will be rendered as formatted Markdown.
</file_artifact>

<file path="src/Artifacts/A82. DCE - Advanced Exclusion Management Plan.md">
# Artifact A82: DCE - Advanced Exclusion Management Plan
# Date Created: C6
# Author: AI Model & Curator

- **Key/Value for A0:**
- **Description:** A plan for a feature allowing users to right-click files or folders and add them to a persistent exclusion list, preventing them from being automatically selected or flattened.
- **Tags:** feature plan, context menu, exclusion, ignore, ux

## 1. Overview & Goal

Users need a simple, intuitive way to manage which files are included in the Data Curation Environment's view and processes. While some files are excluded by default (e.g., `.git`), users may have project-specific directories (like `dist`, `build`, or custom log folders) that they want to permanently ignore.

The goal of this feature is to allow users to right-click any file or folder in the main file tree and add it to a persistent exclusion list, which will be stored in the workspace's settings.

## 2. User Story

| ID | User Story | Acceptance Criteria |
|---|---|---|
| P1-EX-01 | **Exclude from View** | As a developer, I want to right-click a build output directory (e.g., `dist`) and select "Add to DCE Exclusions", so it no longer appears in the Data Curation file tree and is never included in flattened contexts. | - A new "Add to DCE Exclusions" option is available in the file tree's right-click context menu. <br> - Selecting this option adds the file or folder's path to a custom setting in `.vscode/settings.json`. <br> - The file tree immediately refreshes and the excluded item (and its children) is no longer visible. |

## 3. Technical Implementation Plan

1.  **Configuration (`package.json`):**
    *   A new configuration point will be defined in the `contributes.configuration` section.
    *   This will create a new setting, `dce.files.exclude`, which will be an object similar to the native `files.exclude`.

2.  **Backend (`file-tree.service.ts`):**
    *   The file traversal logic will be updated to read this new `dce.files.exclude` setting from the workspace configuration.
    *   It will merge these user-defined patterns with the default exclusion patterns before scanning the file system.

3.  **UI & IPC:**
    *   **`ContextMenu.tsx`:** A new menu item, "Add to DCE Exclusions," will be added.
    *   **IPC:** A new IPC channel, `RequestAddToExclusions`, will be created.
    *   **Backend Handler (`settings.service.ts` - new or existing):** A new handler will receive the path to exclude. It will:
        1.  Get the current exclusion configuration object using `vscode.workspace.getConfiguration('dce')`.
        2.  Add the new path to the object (`newExclusion[path] = true`).
        3.  Update the configuration using `config.update('files.exclude', newExclusion, vscode.ConfigurationTarget.Workspace)`.
        4.  This will automatically trigger a refresh of the file tree as the configuration has changed.

This approach leverages VS Code's built-in settings infrastructure, making the exclusions persistent and easily manageable for the user.
</file_artifact>

<file path="src/Artifacts/A85. DCE - Phase 3 - Model Cards Feature Plan.md">
# Artifact A85: DCE - Phase 3 - Model Cards Feature Plan
# Date Created: C17
# Author: AI Model & Curator

- **Key/Value for A0:**
- **Description:** A plan for a feature allowing users to create and manage "model cards" to easily switch between different local or remote LLM configurations.
- **Tags:** feature plan, settings, ui, ux, llm, configuration, phase 3

## 1. Overview & Goal

As the DCE project moves towards deeper AI integration (Phase 3), users will need a flexible way to manage connections to different Large Language Models (LLMs). A single text field for a local API is insufficient for users who may want to switch between different local models (e.g., a coding model vs. a writing model) or connect to various remote APIs.

The goal of this feature is to create a "Model Card" system within the DCE Settings Panel. This will allow users to create, save, and select from multiple configurations, making it easy to switch between different AI backends.

## 2. User Stories

| ID | User Story | Acceptance Criteria |
|---|---|---|
| P3-MC-01 | **Create a Model Card** | As a user, I want to create a new "model card" where I can input all the necessary information to connect to an LLM, so I can configure different models for different tasks. | - A "New Model Card" button exists in the Settings Panel. <br> - Clicking it opens a form with fields for: Display Name, API Endpoint URL, API Key (optional), and Context Window Size (tokens). <br> - A "Save" button persists this card. |
| P3-MC-02 | **Manage Model Cards** | As a user, I want to see a list of my saved model cards and be able to edit or delete them, so I can manage my configurations. | - The Settings Panel displays a list of all saved model cards. <br> - Each card in the list has "Edit" and "Delete" buttons. |
| P3-MC-03 | **Select Active Model** | As a user, I want to select one of my model cards as the "active" model, so the extension knows which LLM to use for its API calls. | - Each model card in the list has a "Select" or "Activate" button (or a radio button). <br> - A default, non-deletable "AI Studio" (manual mode) card is always present. <br> - The currently active model is visually highlighted. |

## 3. Proposed UI/UX

The "Settings" section of the existing Settings Panel will be redesigned to accommodate this feature.

1.  **Main View:**
    *   A list of existing model cards will be displayed. Each entry will show the `Display Name` and part of the `Endpoint URL`.
    *   Each entry will have `Edit`, `Delete`, and `Select` buttons.
    *   A prominent "Add New Model Card" button will be at the bottom of the list.

2.  **Creation/Editing View:**
    *   Clicking "Add New" or "Edit" will either show a modal or navigate to a separate view within the panel.
    *   This view will contain a form with the following fields:
        *   **Display Name:** (e.g., "Local Llama3-70B", "OpenAI GPT-4o")
        *   **API Endpoint URL:** The full URL for the API.
        *   **API Key:** (Optional) A password field for the API key.
        *   **Context Window Size:** A number input for the model's context window in tokens. This is crucial for future calculations and prompt management.
    *   "Save" and "Cancel" buttons will be present.

## 4. Technical Implementation Plan (High-Level)

1.  **Data Storage:**
    *   Model card configurations will be stored in the VS Code `workspaceState` or global state under a dedicated key (e.g., `dce.modelCards`).
    *   API keys will be stored securely using the `SecretStorage` API, keyed by a unique ID associated with each model card.

2.  **Backend (`settings.service.ts` - New or Existing):**
    *   A new service, or an expansion of an existing one, will be needed to manage the CRUD (Create, Read, Update, Delete) operations for model cards.
    *   It will handle the logic for reading/writing from `workspaceState` and `SecretStorage`.

3.  **Frontend (`settings.view.tsx`):**
    *   The settings view will be refactored into a more complex React component that manages the state for the list of cards and the editing form.
    *   It will use new IPC channels to communicate with the backend service to perform the CRUD operations.
</file_artifact>

<file path="src/Artifacts/A86. DCE - PCPP Workflow Centralization and UI Persistence Plan.md">
# Artifact A86: DCE - PCPP Workflow Centralization and UI Persistence Plan
# Date Created: C19
# Author: AI Model & Curator
# Updated on: C21 (Re-add requirement for Select All buttons)

- **Key/Value for A0:**
- **Description:** A plan to centralize the main workflow buttons in the PCPP, make the animated workflow highlight persistent, and fix the broken cost calculation.
- **Tags:** feature plan, ui, ux, workflow, refactor, bug fix

## 1. Overview & Goal

User feedback from Cycle 19 identified three key areas for improvement in the Parallel Co-Pilot Panel (PCPP):
1.  **Scattered UI:** The buttons for the core workflow are located in different places, making the process unintuitive.
2.  **Ephemeral UI State:** The animated highlight that guides the user disappears if they switch away from the PCPP tab.
3.  **Broken Metric:** The total estimated cost calculation is non-functional.

The goal of this plan is to address all three issues to create a more intuitive, robust, and functional user experience.

## 2. The User Workflow Articulated

To centralize the buttons effectively, we must first define the ideal user workflow as a sequence of steps.

1.  **Paste & Parse:** User pastes responses into tabs. Clicks **`Parse All`**.
2.  **Sort & Select:** User reviews metadata. Clicks **`Sort`** to order responses. Clicks **`Select This Response`** on the most promising one.
3.  **Baseline (Optional):** User may click **`Baseline (Commit)`** to save the current state before testing.
4.  **Accept:** User checks files in the "Associated Files" list and clicks **`Accept Selected`**.
5.  **Test & Restore (Loop):** User tests the applied changes. If they fail, the user clicks **`Restore Baseline`** and returns to Step 4 to test a different set of files or a different response.
6.  **Finalize & Proceed:** Once satisfied, the user provides a cycle title/context and clicks **`Generate prompt.md`** and then **`+`** to start the next cycle.

## 3. Button Centralization Plan

### 3.1. ASCII Mockup of New Toolbar

The new, centralized toolbar will be located directly below the response tabs, making it the central point of interaction.

```
|=================================================================================================|
| [ Resp 1 (5 files, 2.1K tk) ] [ Resp 2 (4 files, 1.8K tk) ] [ Resp 3 ] [ Resp 4 ]      [ Sort ] |
|-------------------------------------------------------------------------------------------------|
|                                                                                                 |
|   +-----------------------------------------------------------------------------------------+   |
|   | [ Parse All ] [ Select This Resp ] [ Baseline ] [ Restore ] [ Accept Selected ]         |   |
|   +-----------------------------------------------------------------------------------------+   |
|                                                                                                 |
| | [v] Associated Files (5) [Select All] [Deselect All Across Responses]                     | | |
| |-------------------------------------------------------------------------------------------| | |
| | [] [ ] src/Artifacts/A86. ... .md                                                        | | |
| | [] [ ] src/client/views/.../view.tsx                                                     | | |
| | ...                                                                                       | | |
|-------------------------------------------------------------------------------------------------|```

### 3.2. Technical Implementation
-   A new component, `src/client/views/parallel-copilot.view/components/WorkflowToolbar.tsx`, will be created.
-   It will contain all the buttons related to the main workflow.
-   **(C21 Update):** The "Select All" and "Deselect All Across Responses" buttons, which were lost in a previous refactor, will be re-added to the toolbar to provide critical batch selection functionality for associated files.
-   The main `view.tsx` will manage the state for enabling/disabling these buttons and pass the state and `onClick` handlers down as props.
-   The buttons will be removed from their old locations (the main header and the `ParsedView` header). The "Select This Response" button will now act on the currently active tab.

## 4. Persistent Animation Plan

-   **Problem:** The `workflowStep` state is currently a local `useState` in `view.tsx`, which is lost when the webview is hidden and shown again.
-   **Solution:** The `workflowStep` will be elevated to become part of the persisted cycle state.
    1.  **Type Definition:** Add `activeWorkflowStep?: string;` to the `PcppCycle` interface in `src/common/types/pcpp.types.ts`.
    2.  **State Management:** The `saveCurrentCycleState` function in `view.tsx` will now also update the main `PcppCycle` object with the current `workflowStep`.
    3.  **Restoration:** When a cycle is loaded, the `activeWorkflowStep` from the loaded data will be used to initialize the state, ensuring the highlight is correctly re-applied.

## 5. Cost Calculation Fix Plan

-   **Problem:** The total estimated cost always shows `$0.00`.
-   **Investigation:** The cost is calculated based on a `totalPromptTokens` state, which is populated by a message from the backend. The request for this calculation is debounced and triggered by changes to the cycle context or title. It appears this request is not being triggered on the initial load of a cycle.
-   **Solution:**
    1.  In `view.tsx`, locate the `useEffect` hook that handles the `SendInitialCycleData` and `SendCycleData` messages.
    2.  Inside this hook, after the component's state is updated with the new cycle data, add a direct call to the `requestCostEstimation()` function.
    3.  This will ensure that a cost estimation is requested from the backend every time a cycle is loaded, fixing the bug and displaying an accurate cost.
</file_artifact>

<file path="src/Artifacts/A87. VCPG - vLLM High-Throughput Inference Plan.md">
# Artifact A87: VCPG - vLLM High-Throughput Inference Plan

# Date Created: C78
# Author: AI Model
# Updated on: C29 (Add API Proxy Server architecture)

- **Key/Value for A0:**
- **Description:** A research and planning document analyzing the potential of using vLLM for high-throughput, low-latency inference, and detailing the architecture for connecting to it via a secure proxy server.
- **Tags:** guide, research, planning, ai, llm, vllm, inference, performance, proxy

## 1. Vision & Goal

The goal is to investigate and plan the migration of our AI inference backend from the current LM Studio setup to a more performant and scalable solution using **vLLM**. As described by the curator's research, vLLM offers significant performance gains through techniques like continuous batching, which could enable more advanced AI capabilities, such as near-real-time analysis of multiple data streams or providing concurrent, low-latency AI assistance to every user of the DCE extension.

## 2. Analysis of vLLM

Research and community reports highlight several key advantages of vLLM:
-   **High Throughput:** Demonstrations show massive performance increases (e.g., 10,000+ tokens/second on a single high-end GPU).
-   **Continuous Batching:** vLLM's core innovation is its ability to dynamically batch incoming requests. This is highly efficient for serving multiple requests simultaneously, which is key to our goal of generating 10+ parallel responses.
-   **Low Latency:** Sub-100ms time-to-first-token (TTFT) is achievable, which is critical for a responsive user experience.
-   **OpenAI-Compatible Server:** vLLM includes a built-in server that mimics the OpenAI API protocol. This is a critical feature, as it allows our extension and proxy to interact with it using a standard, well-documented interface.

## 3. Proposed Architecture: Secure API Proxy

To securely connect the DCE extension to a powerful vLLM instance, we will use a backend proxy server. This architecture prevents exposing the vLLM server directly to the public internet and gives us a central point of control.

```
+---------------+      +-------------------------+      +----------------------+
| DCE Extension |----->| aiascent.game (Proxy)   |----->|   vLLM Server        |
| (VS Code)     |      | (Node.js/Express)       |      | (Python)             |
+---------------+      +-------------------------+      +----------------------+
```

### 3.1. vLLM Server Setup
-   **Deployment:** The vLLM server will be a dedicated Python application, likely in a Docker container for easy management.
-   **Model:** It can be configured to serve any Hugging Face model compatible with vLLM.
-   **Interface:** It will run the built-in OpenAI-compatible server, listening on a local port (e.g., `8000`).

### 3.2. AI Ascent Proxy Server (`server.ts`)
-   **Role:** The existing `aiascent.game` server will be enhanced to act as a secure proxy.
-   **New Endpoint:** A new API endpoint, `/api/dce/proxy`, will be created.
-   **Logic:**
    1.  This endpoint will receive requests from authenticated DCE extension users.
    2.  It will read the prompt data from the request body.
    3.  It will make a new `fetch` request to the internal vLLM server (e.g., `http://localhost:8000/v1/chat/completions`), forwarding the prompt.
    4.  Crucially, it will **stream** the response from vLLM back to the DCE extension client, providing the low-latency experience we need.

### 3.3. Caddyfile Configuration
-   The existing `Caddyfile` is already configured with a `reverse_proxy` directive that forwards all traffic to the Node.js server. This configuration is sufficient and automatically handles WebSocket upgrades and necessary headers, so no changes are required.

## 4. Implementation Plan (Future Cycle)

1.  **Setup vLLM Server:** Install vLLM and its dependencies, download a model, and run the OpenAI-compatible server.
2.  **Update `server.ts`:** Add the new `/api/dce/proxy` route with the streaming logic.
3.  **Configure DCE:** Update the DCE settings (via a Model Card) to point to the new `https://aiascent.game/api/dce/proxy` endpoint.
4.  **Test:** Send a prompt from the DCE and verify that the response is streamed back from the vLLM server through the proxy.
</file_artifact>

<file path="src/Artifacts/A88. DCE - Native Diff Integration Plan.md">
# Artifact A88: DCE - Native Diff Integration Plan
# Date Created: C22
# Author: AI Model & Curator
# Updated on: C27 (Mark as In Progress)

- **Key/Value for A0:**
- **Description:** A plan to integrate VS Code's native diff viewer (`vscode.diff`) for comparing AI-generated file content against the current workspace file, leveraging a TextDocumentContentProvider for in-memory content.
- **Tags:** feature plan, ui, ux, diff, vscode api, virtual document

## 1. Overview & Goal

**Status (C27): In Progress**

The current integrated diff viewer is functional but lacks the native feel, performance, and rich features of VS Code's own diffing engine (e.g., syntax highlighting, minimap, inline actions). The goal of this feature is to replace our custom `DiffViewer` component with a button that triggers the built-in `vscode.diff` command.

This provides a superior user experience and reduces the maintenance burden of our custom component. The primary technical challenge is that the AI-generated content exists only in the frontend's state (in-memory) and not as a file on disk. The solution is to create a **Virtual Document** using a `TextDocumentContentProvider`.

## 2. User Story

| ID | User Story | Acceptance Criteria |
|---|---|---|
| P2-DIFF-NATIVE-01 | **View Diff Natively** | As a developer, when I hover over an associated file in the PCPP, I want to click an "Open Changes" button that opens the diff in a native VS Code diff tab, so I can use all the familiar features of the editor to review the changes. | - An "Open Changes" icon appears on hover for each existing file in the "Associated Files" list. <br> - Clicking it executes the `vscode.diff` command. <br> - A new editor tab opens, showing a side-by-side diff. <br> - The right side shows the current content of the workspace file. <br> - The left side shows the AI-generated content from the response tab. |

## 3. Technical Implementation Plan

This implementation involves creating a new backend provider and coordinating state between the frontend and backend.

### Step 1: Create a TextDocumentContentProvider
-   **New File (`src/backend/providers/ResponseContentProvider.ts`):** A new class will be created that implements `vscode.TextDocumentContentProvider`.
-   **State Cache:** This provider will need a simple in-memory cache (e.g., a `Map<string, string>`) to store the AI-generated content. The key will be a unique identifier (like the URI itself), and the value will be the file content string.
-   **`provideTextDocumentContent` method:** This is the core method. When VS Code needs to open a virtual document (e.g., `dce-response:path/to/file.ts?cycle=22&resp=1`), this method will be called with the URI. It will look up the content in its cache using the URI as the key and return it.

### Step 2: Register the Provider and Command
-   **`extension.ts`:** In the `activate` function, the new provider will be registered with a custom URI scheme: `vscode.workspace.registerTextDocumentContentProvider('dce-response', responseContentProvider);`.

### Step 3: Implement the Frontend-to-Backend Workflow
-   **UI (`ParsedView.tsx`):** An "Open Changes" button will be added to each associated file item, visible on hover.
-   **IPC Channel (`RequestNativeDiff`):** A new IPC channel will be created. Its payload will be `{ originalPath: string; modifiedContent: string; title: string; }`.
-   **Backend Handler (`file-operation.service.ts`):**
    1.  A new `handleNativeDiffRequest` method will be implemented.
    2.  When it receives a request, it will generate a unique URI for the virtual document, incorporating the file path and potentially cycle/response IDs to ensure uniqueness (e.g., `dce-response:${originalPath}?cycle=${cycleId}&resp=${respId}&ts=${Date.now()}`).
    3.  It will store the `modifiedContent` in the `ResponseContentProvider`'s cache, keyed by this unique URI.
    4.  It will then execute the command: `vscode.commands.executeCommand('vscode.diff', vscode.Uri.file(originalAbsolutePath), vscode.Uri.parse(virtualUri), title);`.
</file_artifact>

<file path="src/Artifacts/A89. DCE - vLLM Integration and API Proxy Plan.md">
# Artifact A89: DCE - vLLM Integration and API Proxy Plan
# Date Created: C29
# Author: AI Model & Curator

- **Key/Value for A0:**
- **Description:** Details the end-to-end plan for integrating the DCE with a remote vLLM instance via a secure proxy server, enabling high-throughput, parallelized AI responses.
- **Tags:** feature plan, vllm, llm, proxy, api, integration, performance

## 1. Vision & Goal

The goal of this integration is to unlock a new level of performance for the Data Curation Environment (DCE) by connecting its parallel response UI to a high-throughput vLLM backend. This will enable users to generate multiple, simultaneous AI responses with extremely low latency, dramatically accelerating the iterative development workflow.

To achieve this securely and flexibly, we will use the curator's existing `aiascent.game` server as a proxy, which will receive requests from the DCE extension and forward them to a dedicated vLLM instance.

## 2. End-to-End Architecture

The data will flow through three distinct components:

```
+---------------+      +---------------------------+      +----------------------+
| DCE Extension |----->|   aiascent.game (Proxy)   |----->|   vLLM Server        |
| (VS Code)     |      | (Node.js/Express Server)  |      | (Python Instance)    |
+---------------+      +---------------------------+      +----------------------+
```

1.  **DCE Extension (The Client):**
    *   The user will configure a "Model Card" in the DCE settings pointing to the proxy server's endpoint: `https://aiascent.game/api/dce/proxy`.
    *   When the user sends a prompt, the extension will make a `POST` request to this endpoint, sending the prompt data in the request body.
    *   It will be configured to handle a streaming response.

2.  **aiascent.game (The Proxy Server):**
    *   This server acts as a secure intermediary.
    *   A new API endpoint, `/api/dce/proxy`, will be added to `server.ts`.
    *   This endpoint will receive the request from the DCE extension.
    *   It will then create a new request to the internal vLLM server, whose address will be stored in an environment variable (e.g., `VLLM_URL=http://localhost:8000`).
    *   It will stream the response from the vLLM server back to the DCE extension client.

3.  **vLLM Server (The Inference Engine):**
    *   This is a dedicated Python process running the vLLM library.
    *   It will be configured to serve a specific model (e.g., `unsloth/gpt-oss-20b`) and will expose an OpenAI-compatible API endpoint.
    *   Its primary job is to handle the computationally intensive task of model inference with high efficiency through continuous batching.

## 3. Implementation Details

### 3.1. `server.ts` Modifications
A new route will be added to handle the proxy request. This route will use `node-fetch` or a similar library to make a server-to-server request to the vLLM instance and pipe the streaming response back.

**See Artifact `A90` for the proposed code.**

### 3.2. `Caddyfile` Configuration
The existing `Caddyfile` is already configured to reverse proxy all traffic to the Node.js server on port 3001. This configuration is sufficient and automatically handles HTTPS termination and header forwarding, so no changes are required.

**See Artifact `A91` for the full file and analysis.**

### 3.3. DCE Extension Configuration
The user will configure the connection in the DCE settings panel as follows:
-   **Model Card Name:** `Remote vLLM via AI Ascent`
-   **Endpoint URL:** `https://aiascent.game/api/dce/proxy`
-   **API Key:** (None required, as the proxy handles authentication if needed)

This architecture provides a secure, scalable, and highly performant solution for integrating the DCE with vLLM.
</file_artifact>

<file path="src/Artifacts/A90. AI Ascent - server.ts (Reference).md">
# Artifact A90: AI Ascent - server.ts (Reference)
# Date Created: C29
# Author: AI Model & Curator
# Updated on: C102 (Add stream error handler to prevent crash)

- **Key/Value for A0:**
- **Description:** A reference copy of the `server.ts` file from the `aiascent.game` project. The proxy route has been updated with a stream error handler to gracefully catch `AbortError` and prevent the server from crashing when a client cancels a request.
- **Tags:** reference, source code, backend, nodejs, express, streaming, sse, abortcontroller, error handling

## 1. Overview

This artifact contains the updated source code for `server.ts`. The `/api/dce/proxy` route has been made more robust. A `.on('error', ...)` handler has been added to the stream being piped from the vLLM server. This is the critical fix that catches the `AbortError` emitted when a stream is cancelled, preventing the unhandled exception that was crashing the Node.js process in the previous cycle.

## 2. Source Code (with stream error handling)

```typescript
// Updated on: C1384 (Correct import path for generateSpeech from llmService.)
// Updated on: C1383 (Add /api/tts/generate route handler.)
// Updated on: C1355 (Add /api/report/vote route handler.)
// Updated on: C41 (DCE Integration: Correct route to /api/dce/proxy)
import dotenv from 'dotenv';
dotenv.config();

import express from 'express';
import http from 'http';
import { Server as SocketIOServer } from 'socket.io';
import NextAuth from 'next-auth';
import { authOptions } from './pages/api/auth/[...nextauth]';
import cors from 'cors';
import { logInfo, logError, logWarn } from './logger';
import cookieParser from 'cookie-parser';
import path from 'path';
import fs from 'fs';
import { Readable } from 'stream';
import { type PlayerDirection, type PlayerProfile, type PoetryBattleChatbotData } from './state/gameStoreTypes';
import type { Founder } from './state';
import { CompetitionSystem } from './game/systems/CompetitionSystem';
import { PvpSystem } from './game/systems/PvpSystem';
import { PoetryBattleSystem } from './game/systems/PoetryBattleSystem';
import { handleAscentiaStream, handleAscentiaWelcome, loadAscentiaKnowledgeBase, loadReportKnowledgeBase, handleReportAscentiaStream } from './server/api/ascentiaHandler';
import { handlePlayerProductStream, handlePlayerProductRequest, generateSpeech } from './server/llmService';
import updateProfileHandler from './server/api/userProfileHandler';
import { handleReportVote } from './server/api/reportHandler';
import threadsHandler from './pages/api/bbs/threads';
import postsHandler from './pages/api/bbs/posts';
import voteHandler from './pages/api/bbs/vote';
import tagsHandler from './pages/api/bbs/tags';
import leaderboardHandler from './pages/api/leaderboard';
import leaderboardUpdateHandler from './pages/api/leaderboard/update';
import playersListHandler from './pages/api/players/list';
import playerProfileHandler from './pages/api/players/[userId]';
import prisma from './lib/prisma';

const app = express();
const server = http.createServer(app);
const port = process.env.PORT || 3001;
const isProduction = process.env.NODE_ENV === 'production';

// --- DCE/vLLM Integration Configuration ---
const VLLM_ENDPOINT = process.env.VLLM_ENDPOINT || 'http://127.0.0.1:8000/v1/chat/completions';
const DCE_API_KEY = process.env.DCE_API_KEY;

let clientOrigin = 'http://localhost:8867';
if (process.env.NEXTAUTH_URL) {
    try {
        const url = new URL(process.env.NEXTAUTH_URL);
        clientOrigin = url.origin;
    } catch (e) {
        logError('[SERVER]', `Invalid NEXTAUTH_URL format: ${process.env.NEXTAUTH_URL}. Falling back to default localhost.`);
    }
} else {
    logWarn('[SERVER]', 'NEXTAUTH_URL environment variable is not set. CORS may fail in production.');
}

logInfo('[SERVER]', `Server starting... Client Origin for CORS: ${clientOrigin}, Production: ${isProduction}`);
logInfo('[DCE]', `vLLM proxy endpoint configured for: ${VLLM_ENDPOINT}`);
if (!DCE_API_KEY) {
    logWarn('[DCE]', 'DCE_API_KEY is not set. The /api/dce/proxy endpoint will be unsecured.');
}

// Instantiate systems
const competitionSystem = new CompetitionSystem();
const io = new SocketIOServer(server, {
    path: "/api/socket.io",
    cors: {
        origin: [clientOrigin, 'vscode-webview://*'], // Allow requests from VS Code webviews
        methods: ["GET", "POST"]
    },
    connectTimeout: 90000,
    pingTimeout: 90000,
    pingInterval: 25000,
});
const pvpSystem = new PvpSystem(competitionSystem, io);
const poetryBattleSystem = new PoetryBattleSystem(io);
(global as any).world = { poetryBattleSystem };

app.use(cors({
    origin: [clientOrigin, 'vscode-webview://*'], // Also apply CORS for standard HTTP requests
    credentials: true,
}));

logInfo('[SERVER]', 'Socket.IO server initialized.');

export interface PlayerState {
    id: string; // socket.id
    userId: string;
    x: number;
    y: number;
    direction: PlayerDirection;
    isMoving: boolean;
    displayName: string;
    founderKey: Founder;
    countryCode: string | null;
}
const players: Record<string, PlayerState> = {};

// --- Socket.IO Connection Handling ---
io.on('connection', (socket) => {
    logInfo('[SOCKET.IO]', `Player connected: ${socket.id}`);
    (socket as any).playerState = {};
    socket.on('identify', (data) => {
        logInfo('[SOCKET.IO]', `Player identified: ${socket.id} as ${data.displayName} (User ID: ${data.userId})`);
        const playerState: PlayerState = {
            id: socket.id,
            userId: data.userId,
            x: data.x,
            y: data.y,
            direction: data.direction,
            isMoving: false,
            displayName: data.displayName,
            founderKey: data.founderKey,
            countryCode: data.countryCode,
        };
        players[socket.id] = playerState;
        (socket as any).playerState = playerState;
        socket.emit('playersUpdate', Object.values(players));
        socket.broadcast.emit('playerJoined', players[socket.id]);
        pvpSystem.handleRejoin(data.userId, socket.id);
    });
    socket.on('playerMove', (data) => {
        if (players[socket.id]) {
            players[socket.id] = { ...players[socket.id], ...data };
            socket.broadcast.emit('playerMoved', players[socket.id]);
        }
    });
    // --- Delegate Handlers ---
    socket.on('get_ascentia_welcome', (payload) => handleAscentiaWelcome(socket, players, payload));
    socket.on('start_ascentia_stream', (payload) => handleAscentiaStream(io, socket, players, payload));
    socket.on('start_report_ascentia_stream', (payload) => handleReportAscentiaStream(io, socket, players, payload));
    socket.on('start_chatbot_stream', (payload) => handlePlayerProductStream(socket, players, payload));
    // --- PvP Handlers (Delegated to PvpSystem) ---
    socket.on('send_pvp_challenge', (payload) => pvpSystem.handleChallenge(socket, players, payload));
    socket.on('accept_pvp_challenge', (payload) => pvpSystem.handleAcceptChallenge(socket, players, payload));
    socket.on('decline_pvp_challenge', (payload) => pvpSystem.handleDeclineChallenge(socket, players, payload));
    socket.on('claim_pvp_rewards', (payload) => pvpSystem.claimRewards(players[socket.id]?.userId, payload.matchId));
    socket.on('change_pvp_speed', (payload) => pvpSystem.handleChangeSpeed(players[socket.id]?.userId, payload.matchId, payload.requestedSpeed));
    socket.on('send_poetry_battle_challenge', (payload) => {
        const challenger = players[socket.id];
        const target = players[payload.targetSocketId];
        logInfo('[[SERVER]]', `Received 'send_poetry_battle_challenge' from ${challenger?.displayName ?? 'Unknown'} to ${target?.displayName ?? 'Unknown'} (socketId: ${payload.targetSocketId})`);
        pvpSystem.handlePoetryBattleChallenge(socket, players, payload);
    });
    socket.on('accept_poetry_battle_challenge', (payload) => pvpSystem.handleAcceptPoetryBattleChallenge(socket, players, payload));
    socket.on('decline_poetry_battle_challenge', (payload) => pvpSystem.handleDeclinePoetryBattleChallenge(socket, players, payload));
    socket.on('poetry_battle_submit_move', (payload) => poetryBattleSystem.handlePlayerMove(socket, payload));
    socket.on('submit_poetry_chatbot_data', (payload: { matchId: string, chatbotData: PoetryBattleChatbotData | null }) => {
        pvpSystem.handleSubmitPoetryChatbotData(socket, players, payload);
    });
    socket.on('send_pvp_match_message', async (payload) => {
        const logPrefix = '[SocketHandler:send_pvp_match_message]';
        const senderState = players[socket.id];
        if (!senderState) {
            logWarn(logPrefix, `Received message from unidentified socket ${socket.id}`);
            return;
        }
        try {
            const senderDb = await prisma.leaderboardEntry.findUnique({
                where: { userId: senderState.userId },
                include: { user: { select: { displayName: true, countryCode: true } } }
            });
            if (!senderDb || !senderDb.user) {
                logError(logPrefix, `Could not find DB entry for sender ${senderState.userId}`);
                return;
            }
            const senderProfile: PlayerProfile = {
                userId: senderState.userId,
                displayName: senderDb.user.displayName ?? 'Player',
                companyName: senderDb.companyName ?? 'Company',
                agentName: senderDb.gameAiAgentName ?? 'Agent',
                elo: senderDb.highestGameAIElo,
                countryCode: senderDb.user.countryCode,
                socketId: senderState.id,
            };
            pvpSystem.handleMatchChatMessage(senderState.userId, payload.matchId, payload.message, senderProfile);
        } catch (error) {
            logError(logPrefix, `Error constructing sender profile for chat message.`, error);
        }
    });

    socket.on('sendMessage', (payload) => pvpSystem.handleLobbyChatMessage(io, socket, players, payload));

    socket.on('disconnect', (reason) => {
        logInfo('[SOCKET.IO]', `Player disconnected: ${socket.id}. Reason: ${reason}`);
        pvpSystem.handleDisconnect(socket.id, players);
        delete players[socket.id];
        io.emit('playerLeft', { id: socket.id });
    });
});

// --- PvpSystem Global Timer ---
setInterval(() => {
    pvpSystem.tickMatches(1); // Tick every 1 second
}, 1000);
// --- Middleware and API Routes ---
app.use(cookieParser());
app.use(express.json({ limit: '50mb' })); // Increase limit for large prompts
app.use(express.urlencoded({ extended: true, limit: '50mb' }));

app.use((req, res, next) => {
    (req as any).io = io;
    (req as any).players = players;
    next();
});

app.all('/api/auth/*', (req, res) => {
    if (!(req.query as any).nextauth) {
      const nextauth = req.path.split('/').slice(3);
      (req.query as any).nextauth = nextauth;
      logInfo('[SERVER:Auth]', `Manually setting req.query.nextauth to:`, nextauth);
    }
    return NextAuth(req as any, res as any, authOptions);
});

// --- API Routes ---
app.get('/api/bbs/threads', (req, res) => threadsHandler(req as any, res as any));
app.post('/api/bbs/threads', (req, res) => threadsHandler(req as any, res as any));
app.put('/api/bbs/threads', (req, res) => threadsHandler(req as any, res as any));
app.delete('/api/bbs/threads', (req, res) => threadsHandler(req as any, res as any));
app.get('/api/bbs/posts', (req, res) => postsHandler(req as any, res as any));
app.post('/api/bbs/posts', (req, res) => postsHandler(req as any, res as any));
app.post('/api/bbs/vote', (req, res) => voteHandler(req as any, res as any));
app.get('/api/bbs/tags', (req, res) => tagsHandler(req as any, res as any));
app.get('/api/leaderboard', (req, res) => leaderboardHandler(req as any, res as any));
app.post('/api/leaderboard/update', (req, res) => leaderboardUpdateHandler(req as any, res as any));
app.get('/api/players/list', (req, res) => playersListHandler(req as any, res as any));
app.get('/api/players/:userId', (req, res) => playerProfileHandler(req as any, res as any));
app.post('/api/user/updateProfile', (req, res) => updateProfileHandler(req as any, res as any));
app.post('/api/llm/proxy', (req, res) => handlePlayerProductRequest(req as any, res as any));
app.post('/api/report/vote', (req, res) => handleReportVote(req as any, res as any));

// CORRECTED: DCE vLLM Proxy Route
app.post('/api/dce/proxy', async (req, res) => {
    logInfo('[DCE]', 'Received request on /api/dce/proxy');

    const controller = new AbortController();
    const signal = controller.signal;

    res.on('close', () => {
        logWarn('[DCE]', 'Client closed the connection. Aborting request to vLLM.');
        controller.abort();
    });

    if (DCE_API_KEY) {
        // ... (API key validation remains the same)
    }

    const { messages, n = 1, ...rest } = req.body;

    if (!messages || !Array.isArray(messages) || messages.length === 0 || !messages[0].content) {
        logError('[DCE]', `Bad request: Missing or invalid messages content.`, req.body);
        return res.status(400).json({ error: 'Messages content is required in OpenAI chat format' });
    }

    logInfo('[DCE]', `Proxying streaming prompt to vLLM. Requesting ${n} parallel responses.`);

    try {
        const vllmResponse = await fetch(VLLM_ENDPOINT, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'Accept': 'text/event-stream'
            },
            body: JSON.stringify({
                ...rest,
                messages,
                n,
                stream: true,
            }),
            signal, 
        });

        if (!vllmResponse.ok || !vllmResponse.body) {
            const errorBody = await vllmResponse.text();
            throw new Error(`vLLM server returned an error: ${vllmResponse.status} ${vllmResponse.statusText} - ${errorBody}`);
        }
        res.setHeader('Content-Type', 'text/event-stream');
        res.setHeader('Cache-Control', 'no-cache');
        res.setHeader('Connection', 'keep-alive');

        const stream = vllmResponse.body;
        const nodeStream = Readable.fromWeb(stream as any);

        // --- C102 FIX: Add error handler to prevent crash on abort ---
        nodeStream.on('error', (error) => {
            if ((error as any).name === 'AbortError') {
                logInfo('[DCE]', 'vLLM stream successfully aborted on the server.');
            } else {
                logError('[DCE]', 'An error occurred in the vLLM response stream.', error);
            }
        });
        // --- END C102 FIX ---

        nodeStream.pipe(res);
        logInfo('[DCE]', 'Successfully established stream from vLLM to client.');

    } catch (error: any) {
        if (error.name === 'AbortError') {
            logInfo('[DCE]', 'vLLM request was successfully aborted.');
        } else {
            logError('[DCE]', 'Error proxying request to vLLM:', error.message);
            if (!res.headersSent) {
                res.status(500).json({ error: 'Failed to get responses from vLLM backend.' });
            }
        }
    }
});

// NEW: TTS Proxy Route
app.post('/api/tts/generate', async (req, res) => {
    try {
        const { text } = req.body;
        if (!text || typeof text !== 'string') {
            return res.status(400).send('Invalid request: "text" field is required.');
        }
        const audioStream = await generateSpeech(text);
        if (audioStream) {
            res.setHeader('Content-Type', 'audio/wav');
            audioStream.pipe(res);
        } else {
            res.status(500).send('Failed to generate speech.');
        }
    } catch (error) {
        logError('[API:TTS]', 'Error in TTS generation route', error);
        res.status(500).send('Internal server error during TTS generation.');
    }
});


// --- Static File Serving (Production Only) ---
if (isProduction) {
    const buildPath = path.join(__dirname);
    logInfo('[SERVER]', `Production mode detected. Serving static files from: ${buildPath}`);
    app.use(express.static(buildPath));

    app.get('*', (req, res) => {
        const indexPath = path.join(buildPath, 'index.html');
        if (fs.existsSync(indexPath)) {
            res.sendFile(indexPath);
        } else {
            res.status(404).send(`'index.html' not found.`);
        }
    });
}

// --- Server Startup ---
server.listen(port, () => {
    logInfo('[SERVER]', `Server listening on http://localhost:${port}`);
    const publicPath = isProduction ? __dirname : path.join(__dirname, '..', 'public');
    loadAscentiaKnowledgeBase(publicPath);
    loadReportKnowledgeBase(publicPath);
});

process.on('SIGINT', () => {
    logInfo('[SERVER]', 'Shutting down...');
    io.close();
    server.close(() => process.exit(0));
});
</file_artifact>

<file path="src/Artifacts/A91. AI Ascent - Caddyfile (Reference).md">
# Artifact A91: AI Ascent - Caddyfile (Reference)
# Date Created: C29
# Author: AI Model & Curator

- **Key/Value for A0:**
- **Description:** A reference copy of the `Caddyfile` from the `aiascent.game` project, used for configuring the web server proxy.
- **Tags:** reference, configuration, caddy, proxy

## 1. Overview

This artifact contains the literal source code of the `Caddyfile` from the `aiascent.game` project, as provided in Cycle 29. Caddy is a powerful, modern web server that automatically handles HTTPS. This configuration shows how it's used as a reverse proxy to route all traffic for `aiascent.game` to the backend Node.js server running on port 3001.

This configuration is a good reference for setting up a production environment. No changes are needed to it to support the new DCE LLM proxy endpoint, as the existing `reverse_proxy` directive is a catch-all that will correctly forward the new API routes.

## 2. Source Code

```caddy
# Artifact 146: Caddyfile (Production)
# Date Created: Cycle 1188
# Author: AI Model
# Updated on: C1268 (Refactor for production static file serving.)

# This Caddyfile provides a robust configuration for running AI Ascent in a production
# environment. It automatically handles HTTPS, serves the static client application,
# and correctly routes API and WebSocket traffic to the backend Node.js server.

aiascent.game {
    # Caddy will automatically provision and renew a free SSL certificate from Let's Encrypt.
    
    # Enable gzip and zstd compression for better performance.
    encode zstd gzip

    # Log all requests and errors.
    log {
        output file aiascent_caddy.log
    }

    # Reverse proxy ALL incoming requests to the backend Node.js server,
    # which is now responsible for handling API, WebSockets, and serving static files.
    # The `header_up` directives ensure WebSocket connections can be established correctly.
    reverse_proxy localhost:3001 {
        header_up Host {host}
        header_up X-Real-IP {remote_ip}
        header_up X-Forwarded-For {remote_ip}
        header_up X-Forwarded-Proto {scheme}
        header_up Connection {>Connection}
        header_up Upgrade {>Upgrade}
    }
}

# Optional: Redirect www to the main domain
www.aiascent.game {
    redir https://aiascent.game{uri} permanent
}
</file_artifact>

<file path="src/Artifacts/A92. DCE - vLLM Setup Guide.md">
# Artifact A92: DCE - vLLM Setup Guide
# Date Created: C30
# Author: AI Model & Curator
# Updated on: C45 (Add note about matching model name in proxy)

- **Key/Value for A0:**
- **Description:** A step-by-step guide for setting up the vLLM inference server with an OpenAI-compatible API endpoint for use with the DCE.
- **Tags:** guide, setup, vllm, llm, inference, performance, openai

## 1. Overview & Goal

This guide provides the necessary steps to install `vLLM` and run a large language model with a high-throughput, OpenAI-compatible API server. This will allow the Data Curation Environment (DCE) to connect to a powerful local or remote inference engine.

## 2. Prerequisites

*   **OS:** Linux or Windows with WSL2 (Windows Subsystem for Linux).
*   **Python:** Version 3.9 - 3.12.
*   **GPU:** An NVIDIA GPU with CUDA drivers installed. Compute capability 7.0 or higher is recommended (e.g., V100, T4, RTX 20-series or newer).
*   **Package Manager:** `pip` is required. Using a virtual environment manager like `venv` or `conda` is highly recommended.

## 3. Recommended Method for Windows: Using WSL2


The vLLM server has a dependency on `uvloop`, a library that is not compatible with native Windows. The most reliable and performant way to run vLLM on a Windows machine is within a WSL2 environment.

### Step 1: Install or Verify WSL2
Open PowerShell and check your WSL status.
```powershell
wsl --status
```
If WSL is not installed, run the following command and then restart your machine.
```powershell
wsl --install
```

### Step 2: Set up Python in WSL
Open your WSL terminal (e.g., by typing `wsl` in the Start Menu). Update your package lists and install the necessary Python tools.
```bash
sudo apt update
sudo apt install python3-venv python3-pip -y
```

### Step 3: Create and Activate a Virtual Environment in WSL
It is crucial to install `vLLM` and its dependencies in an isolated environment *inside WSL*.

```bash
# Create a directory for your project
mkdir -p ~/projects/vLLM
cd ~/projects/vLLM

# Create the virtual environment
python3 -m venv vllm-env

# Activate the environment
source vllm-env/bin/activate
```
Your terminal prompt should now be prefixed with `(vllm-env)`.

### Step 4: Install vLLM and uvloop
With the virtual environment activated inside WSL, you can now install `vLLM` and its required dependency `uvloop`.
```bash
pip install vllm uvloop
```

### Step 5: Launch the OpenAI-Compatible Server
This command will download the specified model and start the server.
```bash
python -m vllm.entrypoints.openai.api_server --model "unsloth/gpt-oss-20b"
```
The server will start on `http://localhost:8000` *inside* the WSL environment.

### Step 6: Accessing the Server from Windows
WSL2 automatically forwards network ports to your Windows host machine. This means you can access the vLLM server from your Windows applications (like the DCE extension or your browser) by navigating to **`http://localhost:8000`**.

### Step 7: Verifying the API Endpoint
When you navigate to `http://localhost:8000` in a web browser, you will see a `404 Not Found` error. This is expected and correct. The server is an API endpoint and is not designed to serve a webpage.

To verify that the API is working, run the following `curl` command from your **WSL terminal** (the same one where the server is running). This sends a test prompt to the completions endpoint.

```bash
curl http://localhost:8000/v1/completions \
-H "Content-Type: application/json" \
-d '{
    "model": "unsloth/gpt-oss-20b",
    "prompt": "San Francisco is a",
    "max_tokens": 7,
    "temperature": 0
}'
```

A successful response will be a JSON object that looks something like this:
```json
{"id":"cmpl-a1b2c3d4e5f6","object":"text_completion","created":1677652288,"model":"unsloth/gpt-oss-20b","choices":[{"index":0,"text":" city in Northern California,","logprobs":null,"finish_reason":"length"}],"usage":{"prompt_tokens":5,"total_tokens":12,"completion_tokens":7}}
```
If you receive this JSON response, your vLLM server is running correctly.

### Step 8: Connecting the DCE Extension
Once you have verified the API is running, you are ready to connect the DCE extension to it.

For detailed instructions, please refer to the next guide: **`A94. DCE - Connecting to a Local LLM Guide.md`**.
</file_artifact>

<file path="src/Artifacts/A93. DCE - vLLM Encryption in Transit Guide.md">
# Artifact A93: DCE - vLLM Encryption in Transit Guide
# Date Created: C32
# Author: AI Model & Curator

- **Key/Value for A0:**
- **Description:** Explains the standard architectural pattern of using a reverse proxy to provide HTTPS encryption for the vLLM API endpoint.
- **Tags:** guide, security, encryption, https, proxy, caddy, vllm

## 1. The Challenge: Securing LLM Traffic

When the Data Curation Environment (DCE) extension communicates with a remote vLLM server, the data (which includes source code and prompts) must be encrypted in transit to prevent eavesdropping. The vLLM OpenAI-compatible server runs on plain `http` by default, which is unencrypted. Connecting to an `http` endpoint over the public internet is insecure.

The goal is to provide a secure `https` endpoint for the DCE extension while allowing the vLLM server to run in its default, simple configuration.

## 2. The Solution: The Reverse Proxy Pattern

The standard and most robust solution is to place a **reverse proxy** in front of the vLLM server. The reverse proxy acts as a secure, public-facing gateway.

### 2.1. How It Works

The data flow is as follows:

```
+---------------+      +----------------------+      +----------------------+
| DCE Extension |----->|  Reverse Proxy       |----->|   vLLM Server        |
| (Client)      |      |  (e.g., Caddy/Nginx) |      | (Internal Service)   |
|               |      |                      |      |                      |
| (HTTPS Request)      |  (Handles TLS/SSL)   |      |  (HTTP Request)      |
+---------------+      +----------------------+      +----------------------+
```

1.  **Encrypted Connection:** The DCE extension makes a request to a secure URL, like `https://my-llm-server.com`. This connection is encrypted using HTTPS.
2.  **HTTPS Termination:** The reverse proxy server (e.g., Caddy) receives this encrypted request. Its primary job is to handle the complexity of TLS/SSL certificates. It decrypts the request.
3.  **Forwarding:** After decrypting the request, the proxy forwards it to the internal vLLM server over a trusted local network (e.g., to `http://localhost:8000`). Since this traffic never leaves the secure server environment, it does not need to be re-encrypted.
4.  **Response:** The vLLM server processes the request and sends its `http` response back to the proxy, which then encrypts it and sends it back to the DCE extension over `https`.

### 2.2. Benefits of this Architecture

-   **Security:** All traffic over the public internet is encrypted.
-   **Simplicity:** The vLLM server itself does not need to be configured with complex SSL certificates. Tools like Caddy can automatically provision and renew free Let's Encrypt certificates, making setup very easy.
-   **Flexibility:** The proxy can also handle load balancing, caching, and routing to multiple backend services if needed in the future.

## 3. Implementation Example with Caddy

Caddy is a modern web server that makes this process extremely simple.

-   **Prerequisites:** You need a server with a public IP address and a domain name pointing to it.
-   **Example `Caddyfile`:**
    ```caddy
    # Your domain name
    my-llm-server.com {
        # Caddy will automatically handle HTTPS for this domain
        
        # Log all requests for debugging
        log {
            output file /var/log/caddy/vllm.log
        }

        # Reverse proxy all requests to the vLLM server running on port 8000
        reverse_proxy localhost:8000
    }
    ```
-   **Reference:** For a more detailed example of a production `Caddyfile` used in a similar project, see **`A91. AI Ascent - Caddyfile (Reference).md`**.

This architecture is the industry standard for securing web services and is the recommended approach for deploying the vLLM server for use with the DCE.
</file_artifact>

<file path="src/Artifacts/A94. DCE - Connecting to a Local LLM Guide.md">
# Artifact A94: DCE - Connecting to a Local LLM Guide
# Date Created: C35
# Author: AI Model & Curator
# Updated on: C36 (Align with new multi-modal settings UI)

- **Key/Value for A0:**
- **Description:** A step-by-step guide on how to configure the DCE extension to use a local LLM with an OpenAI-compatible API via the new settings panel.
- **Tags:** guide, setup, llm, vllm, configuration, local

## 1. Overview & Goal

This guide explains how to configure the Data Curation Environment (DCE) extension to communicate with a locally hosted Large Language Model (LLM), such as the one set up via the `A92. DCE - vLLM Setup Guide`.

The goal is to switch the extension from its default "Manual" mode to one of the automated modes that can make API calls directly to your local model, streamlining the development workflow.

## 2. Step-by-Step Configuration

### Step 1: Open the Settings Panel
- Open the Command Palette (`Ctrl+Shift+P` or `Cmd+Shift+P`).
- Run the command: **`DCE: Open Settings & Help`**. This will open the settings panel in a new editor tab.

### Step 2: Navigate to the Settings Section
- In the settings panel, find and expand the **"Settings"** section.

### Step 3: Select Your Connection Mode
You will see a list of connection modes. Choose the one that matches your setup.

#### Option A: Demo Mode (Recommended for `aiascent.game` users)
This is the simplest option if you are using the pre-configured `aiascent.game` proxy.
-   Select the radio button for **"Demo Mode (Local vLLM via `aiascent.game`)"**.
-   The endpoint is pre-configured. No other steps are needed.

#### Option B: API Mode (URL)
Use this option if you are running your own vLLM server (or another OpenAI-compatible service) and want to connect to it directly without a proxy.
-   Select the radio button for **"API (URL)"**.
-   An input field will appear. Enter the full API endpoint URL. For a standard vLLM server, this will be `http://localhost:8000/v1`.
    -   **Important:** If your LLM server is on a different machine, replace `localhost` with that machine's local network IP address (e.g., `http://192.168.1.100:8000/v1`).
-   Save the settings.

## 4. Next Steps

The DCE extension is now configured to send its API requests to your local LLM server. You can now use the "Generate Responses" button (once implemented) in the Parallel Co-Pilot Panel to automatically populate the response tabs, completing the automated workflow. To switch back to the manual copy/paste method, simply re-open the settings and select **"Free Mode (Manual Copy/Paste)"**.
</file_artifact>

<file path="src/Artifacts/A95. DCE - LLM Connection Modes Plan.md">
# Artifact A95: DCE - LLM Connection Modes Plan
# Date Created: C36
# Author: AI Model & Curator
# Updated on: C42 (Refine "Generate Responses" workflow to create a new cycle first)

- **Key/Value for A0:**
- **Description:** Outlines the plan for a multi-modal settings UI and the associated workflow changes, allowing users to switch between manual copy/paste, a pre-configured demo mode, and user-provided API URLs or Keys.
- **Tags:** feature plan, settings, ui, ux, llm, configuration, api, streaming

## 1. Overview & Goal

To maximize the utility and accessibility of the DCE extension, users need a flexible way to connect to different LLM backends. This plan details the implementation of a multi-modal settings UI and the corresponding changes to the main workflow. This will allow users to seamlessly switch between different connection methods, from a simple manual workflow to advanced, automated API integrations.

This plan refines and supersedes `A85. DCE - Model Card Management Plan.md` by focusing on a more user-friendly, mode-based approach.

## 2. User Stories

| ID | User Story | Acceptance Criteria |
|---|---|---|
| P3-CM-01 | **Use Manual Mode** | As a new user, I want the extension to default to a "Free (Manual)" mode, so I can use the core features by copying and pasting without any setup. | - The default setting is "Free Mode". <br> - In this mode, a "Generate prompt.md" button is shown. |
| P3-CM-02 | **Use Demo Mode** | As a demo user, I want to select a "Demo Mode" that connects to a local vLLM endpoint, so I can experience the full automated workflow. | - A "Demo Mode" option is available. <br> - When selected, the "Generate prompt.md" button is replaced with a "Generate responses" button. |
| P3-CM-03 | **Generate Into New Cycle** | As a user in an automated mode, when I click "Generate responses" on Cycle `N`, I want the extension to automatically create a new Cycle `N+1` and place the generated responses there, so my new results are cleanly separated from the prompt that created them. | - Clicking "Generate responses" initiates a process that creates a new cycle. <br> - The generated responses from the LLM populate the tabs of the new cycle. <br> - The UI automatically navigates to the new cycle upon completion. |
| P3-CM-04 | **Monitor Generation Speed** | As a user generating responses, I want to see a live "tokens per second" metric, so I have feedback on the generation performance. | - A "Tokens/sec" display appears near the "Generate responses" button during generation. <br> - It updates in real-time as token data streams in. |
| P3-CM-05 | **Persistent Settings** | As a user, I want my selected connection mode to be saved, so I don't have to re-configure it every time I open VS Code. | - The selected connection mode and any associated URL/Key is persisted in the workspace settings. |

## 3. UI/UX Design

(No changes from C37)

## 4. Technical Implementation Plan

### 4.1. Settings Persistence
(No changes from C37)

### 4.2. "Generate Responses" Workflow (C42 Update)
The workflow is now designed to be more robust and atomic, with the backend handling the creation of the new cycle.

1.  **Frontend (`view.tsx`):**
    *   The `handleGenerateResponses` `onClick` handler will gather the *current* cycle's data (`PcppCycle` object for Cycle `N`) and send it to the backend via a `RequestBatchGeneration` message.
2.  **Backend (`on-message.ts`):**
    *   The handler for `RequestBatchGeneration` receives the full data for Cycle `N`.
    *   It first calls `prompt.service.ts` to generate the prompt string from Cycle `N`'s data.
    *   It then calls `llm.service.ts` to get the array of response strings from the vLLM.
    *   It then calls a new method in `history.service.ts`, `createNewCycleWithResponses`, passing in the array of responses.
    *   The `history.service.ts` creates the new cycle (`N+1`), populates its response tabs, and saves the entire updated history.
    *   Finally, the backend sends a `SendBatchGenerationComplete` message to the frontend, containing the `newCycleId`.
3.  **Frontend (`view.tsx`):**
    *   A new message handler for `SendBatchGenerationComplete` receives the ID of the new cycle.
    *   It then calls the existing `handleCycleChange` logic to navigate the UI to this new cycle, which now contains all the generated responses.

### 4.3. Streaming & Metrics (Future Cycle)
-   The backend `llm.service.ts` will be updated to handle streaming responses.
-   New IPC channels (`StreamResponseChunk`, `StreamResponseEnd`) will be created.
-   The frontend in `view.tsx` will be updated to handle these streaming messages, append content to the tabs in real-time, and calculate the tokens/second metric.
</file_artifact>

<file path="src/Artifacts/A96. DCE - Harmony-Aligned Response Schema Plan.md">
# Artifact A96: DCE - Harmony-Aligned Response Schema Plan
# Date Created: C45
# Author: AI Model & Curator

- **Key/Value for A0:**
- **Description:** An analysis of the `openai_harmony` library and a proposed plan for migrating the DCE's vLLM interaction schema from XML tags to a more robust, token-based structured format.
- **Tags:** plan, architecture, interaction schema, parsing, llm, vllm, harmony

## 1. Overview & Goal

The current interaction schema (`A52.2`) relies on parsing XML-like tags (`<file>`, `<summary>`) and markdown headers from the LLM's free-text response. While functional, this approach is brittle. It is susceptible to minor formatting errors from the model and requires complex, string-based `stop` tokens that can prematurely truncate responses, as seen in Cycle 44.

The `GPT-OSS` repository introduces a more advanced approach, "Harmony," which uses a vocabulary of special control tokens (e.g., `<|start|>`, `<|channel|>`, `<|message|>`, `<|end|>`) to guide the model's generation into a structured, machine-readable format. This is a significantly more robust and powerful way to handle structured data generation with LLMs.

The goal of this plan is to outline a phased migration from our current XML-based schema to a Harmony-aligned schema for all communication with the vLLM backend.

## 2. Analysis of the Harmony Approach

The `openai_harmony` library and `harmony_vllm_app.py` demonstrate a sophisticated workflow:

1.  **Structured Prompt Rendering:** Instead of a single block of text, the prompt is constructed as a series of messages, each with a `role` (system, user, assistant), and potentially a `channel` (analysis, commentary, final). This entire structure is "rendered" into a sequence of tokens that includes the special control tokens.
2.  **Guided Generation:** The model is trained or fine-tuned to understand these control tokens. It learns to "speak" in this format, for example, by placing its internal monologue in an `analysis` channel and its final answer in a `final` channel.
3.  **Robust Parsing:** The response from the model is not just a block of text; it's a stream of tokens that can be parsed deterministically using the same control tokens. A `StreamableParser` can listen to the token stream and identify when the model is opening a new message, writing to a specific channel, or finishing its turn.

This is fundamentally superior to our current regex-based parsing.

## 3. Proposed Migration Plan

This is a major architectural change and should be implemented in phases.

### Phase 1: Adopt Harmony for File Formatting (Immediate)

-   **Goal:** Replace the `<file path="...">` and `
</file_artifact>

<file path="src/Artifacts/A97. DCE - vLLM Response Progress UI Plan.md">
# Artifact A97: DCE - vLLM Response Progress UI Plan
# Date Created: C48
# Author: AI Model & Curator
# Updated on: C76 (Add requirement for per-response timers)

- **Key/Value for A0:**
- **Description:** A plan and textual mockup for a UI to display the progress of incoming vLLM responses, including color-coded progress bars, status indicators, timers, and a manual "View Responses" button.
- **Tags:** feature plan, ui, ux, vllm, progress indicator, metrics, streaming, sse

## 1. Vision & Goal

Generating multiple, large AI responses can take a significant amount of time. To improve the user experience, it's critical to provide clear, real-time feedback that the system is working and to show the progress of the generation. The goal of this feature is to create a dedicated UI that appears during response generation, displaying progress bars, status indicators, performance metrics, and timing information for each parallel response.

## 2. User Stories

| ID | User Story | Acceptance Criteria |
|---|---|---|
| P3-PROG-01 | **See Generation Progress** | As a user, when I click "Generate responses," I want a UI to immediately appear that shows me the progress of each response being generated, so I know the system is working and not frozen. | - When generation starts, a progress display UI is shown. <br> - It contains a separate progress bar for each of the `N` requested responses. <br> - Each progress bar updates in real-time as tokens are received. |
| P3-PROG-02 | **See Performance Metrics** | As a user, I want to see a live "tokens per second" metric during generation, so I can gauge the performance of the LLM backend. | - The progress UI displays a "Tokens/sec" value. <br> - This value is calculated and updated periodically throughout the generation process. |
| P3-PROG-03 | **Understand Progress Bar**| As a user, I want the progress bar to be color-coded so I can understand the allocation of tokens for the prompt versus the generated response. | - The progress bar is a stacked bar with multiple colors. <br> - One color represents the "thinking" (prompt) tokens. <br> - A second color represents the currently generated response tokens. <br> - **(C69 Update)** A third color (blue) represents the remaining, unused tokens up to the model's maximum. |
| P3-PROG-04 | **See Response Status** | As a user, I want to see the status of each individual response (e.g., "Thinking...", "Generating...", "Complete"), so I know what the system is doing. | - A text indicator next to each progress bar shows its current status. <br> - The indicator is animated during the "Thinking" and "Generating" phases. <br> - When a response is complete, the "unused" portion of its progress bar changes color to signify completion. |
| P3-PROG-05 | **See Unused Tokens** | As a user, once a response is complete, I want to see how many tokens were left unused, so I can understand how much headroom the model had. | - After a response's status changes to "Complete", a text element appears showing the count of unused tokens. |
| P3-PROG-06 | **Manage Responses** | As a user, I want to sort responses, stop a generation, or re-generate an individual response, so I have more control over the process. | - A sort button cycles through different sort orders. <br> - A "Stop" button for each response cancels its generation. <br> - A "Re-generate" button for each response triggers a new generation just for that slot. |
| P3-PROG-07 | **See Elapsed Time** | As a user, I want to see a timer showing the total elapsed time for the generation, so I can understand how long the process is taking. | - **(C76 Update)** Each response displays its own independent elapsed timer, showing how long that specific generation has taken. |
| P3-PROG-08 | **Review Metrics Before Navigating** | As a user, after all responses are complete, I want to stay on the progress screen to review the final metrics, and then click a button to navigate to the new cycle, so I am in control of the workflow. | - When generation finishes, the UI does not automatically navigate away. <br> - A "View Responses" button appears. <br> - A completion counter (e.g., "4/4 Responses Complete") is displayed. |
| P3-PROG-09 | **Three-Way Sorting** | As a user, I want the sort button to cycle between three states: the default order, sorting by total tokens (thinking + response), and sorting by response tokens only, so I can analyze the results in different ways. | - The sort button cycles through three distinct states. <br> - The UI re-orders the list of responses accordingly. |
| P3-PROG-10 | **Color-Coded Totals** | As a user, I want the total token count display to also be color-coded, so it's consistent with the individual progress bars. | - The numbers in the "Total Tokens" display are color-coded to match the "thinking", "response", and "unused" categories. |

## 3. UI Mockup (Textual Description - C76 Update)

The progress UI will be a dedicated component that is conditionally rendered in the PCPP view when `isGenerating` is true.

```
+----------------------------------------------------------------------+
| Generating Responses... [Sort by Total Tk] Tokens/sec: 1234            |
|----------------------------------------------------------------------|
|                                                                      |
| Resp 1: [blue|green|blue]  80% | 00:35.8 | Status: Gen... [Stop] [Re-gen]|
|         (1k+5.5k/8.1k tk)      |                                      |
| Resp 2: [blue|green|blue]  70% | 00:28.1 | Status: Gen... [Stop] [Re-gen]|
|         (1k+4.7k/8.1k tk)      |                                      |
| Resp 3: [blue|blue      ]  12% | 00:05.2 | Status: Think... [Stop] [Re-gen]|
|         (1k+0k/8.1k tk)        |                                      |
| Resp 4: [blue|green|done] 100% | 00:41.0 | Status: Complete  [   ] [Re-gen]|
|         (1k+7.1k/8.1k tk)      | Unused: 1,024 tk                     |
|----------------------------------------------------------------------|
| [ 4/4 Responses Complete ]                                           |
+----------------------------------------------------------------------+
```
*   **Header:** The "Sort" button and TPS metric remain.
*   **Per-Response:**
    *   A new, individual timer (e.g., `00:35.8`) is displayed for each response.
    *   Stop/Regen buttons are on the same row as the status.
*   **Footer:** Appears only when generation is complete.

## 4. Technical Implementation Plan (C76 Revision)

1.  **IPC (`channels.type.ts`):** The `GenerationProgress` interface will be updated to include `startTime: number` for each individual response.
2.  **Backend (`llm.service.ts`):** The `generateBatch` method will be updated. When initializing the `progressData` array, it will set `startTime: Date.now()` for each response object.
3.  **Frontend (`GenerationProgressDisplay.tsx`):**
    *   **New Component (`ResponseTimer.tsx`):** A new, small component will be created to manage the timer logic. It will receive a `startTime` prop and use a `useEffect` with `setInterval` to calculate and render the elapsed time. This isolates the timer logic.
    *   **Integration:** `GenerationProgressDisplay.tsx` will map over the `progressData` and render a `ResponseTimer` for each item, passing `p.startTime`. This will result in an independent timer for each response.
4.  **Frontend (`view.tsx`):** No changes are required here for the timer, but it will be updated to handle the new navigation and view-switching logic.
</file_artifact>

<file path="src/Artifacts/A149. Local LLM Integration Plan.md">
# Artifact: A149. Local LLM Integration Plan
# Updated on: C1280 (Add documentation for REMOTE_LLM_URL environment variable.)
# Updated on: C1217 (Update architecture to reflect that @Ascentia now uses a streaming Socket.IO event.)
# Updated on: C1216 (Reflect change from /chat/completions to /completions endpoint for chatbot streaming.)
# Date Created: Cycle 1211
# Author: AI Model

## 1. Overview & Goal

This document outlines the technical plan for integrating a locally hosted Large Language Model (LLM) into the "AI Ascent" game. The goal is to create a secure and robust connection between the game client/server and a local LLM endpoint (like one provided by LM Studio) to power new, dynamic gameplay features.

This integration will enable:
1.  An in-game helper bot, `@Ascentia`, that can answer player questions about the game.
2.  Interactive sessions where players can "talk" to their own AI products.
3.  A new "Poetry Battle" PvP competition between players' chatbot products.

## 2. Core Architecture: Backend Proxy

To ensure security and control, the game client will **never** directly call the local LLM endpoint. All communication will be routed through a dedicated backend API endpoint or WebSocket handler that acts as a proxy.

### 2.1. Rationale for a Backend Proxy
*   **Security:** Prevents malicious clients from directly accessing or overloading the local LLM server. It keeps the endpoint address and any potential API keys hidden from the client.
*   **Control:** Allows the server to inject, modify, or augment prompts before they are sent to the LLM. This is critical for:
    *   Adding system prompts and context for the `@Ascentia` helper bot.
    *   Injecting parameters to simulate quality degradation for the Poetry Battle.
    *   Enforcing rate limiting and preventing abuse.
*   **Flexibility:** The client-facing API remains consistent even if the underlying LLM provider or endpoint changes in the future.
*   **State Management:** The server can access the game's database (`prisma`) to fetch context for prompts (e.g., player stats, game rules from documentation artifacts).

### 2.2. Implementation: API Handlers in `server.ts`
*   The existing Express server (`src/server.ts`) will handle all LLM-related requests.
*   **Socket.IO `'start_ascentia_stream'` event:** This event is now used for all `@Ascentia` queries. It provides a streaming response for a better user experience.
*   **Socket.IO `'start_chatbot_stream'` event:** This event will be used for all streaming requests, specifically for the "Chat with Service" feature.
*   **`/api/llm/proxy` (POST):** This endpoint now handles only non-streaming, single-turn requests for features like the Player LLM Terminal.
*   The handlers for these routes and events will:
    1.  Authenticate the user session.
    2.  Based on the request's `context`, construct a final prompt string, potentially adding system instructions, game rules, or degradation parameters.
    3.  Use a server-side `fetch` to send the final, formatted request to the appropriate local LLM endpoint specified in an environment variable.
    4.  **For streaming:** The handler will read the `ReadableStream`, parse the SSE chunks, and emit the relevant `_stream_chunk` and `_stream_end` events back to the originating client socket.
    5.  **For non-streaming:** The handler will return the full response in the JSON body.

## 3. Local LLM Server Configuration (LM Studio)

### 3.1. Environment Variables (`.env` file)

To allow for flexible connections to different LLM servers (local, remote on the same network, or even production endpoints), the `server.ts` logic will prioritize URLs in the following order:

1.  **`REMOTE_LLM_URL` (NEW):** Use this to specify the address of an LLM running on a different machine on your local network. This is ideal for a two-PC development setup.
    *   **Example:** `REMOTE_LLM_URL=http://192.168.1.85:1234`
2.  **`LOCAL_LLM_URL`:** The standard variable for an LLM running on the same machine as the game server.
    *   **Example:** `LOCAL_LLM_URL=http://127.0.0.1:1234`
3.  **Hardcoded Default:** If neither environment variable is set, the server will fall back to `http://127.0.0.1:1234`.

The server will log which URL it is using upon startup for easy debugging.

### 3.2. Recommended Model & Settings
*   **Model:**
    *   **Identifier:** `qwen/qwen3-30b-a3b`
    *   **Context Length:** 32,768
*   **Server:**
    *   **Address:** Match the address in your `.env` file (e.g., `http://192.168.1.85:1234`).
    *   **Enable "Serve on Local Network"** in LM Studio if you are using `REMOTE_LLM_URL`.
    *   **Preset:** OpenAI API
*   **Hardware & Performance:**
    *   **GPU Offload:** Max
*   **Inference Parameters (Default for Creative/Chat Tasks):**
    *   **Temperature:** 0.8
    *   **Top K Sampling:** 40
    *   **Repeat Penalty:** 1.1
    *   **Top P Sampling:** 0.95
*   **Prompt Format:** For chatbot conversations sent to the `/v1/completions` endpoint, the prompt must be manually constructed using the model's chat template.

## 4. State Management: `llmStore.ts`

A new Zustand store will be created to manage the state of LLM-related interactions.

*   **`src/state/llmStore.ts`**
*   **State:**
    *   `isPlayerLlmTerminalOpen: boolean`
    *   `isPlayerChatbotInterfaceOpen: boolean`
    *   `isPoetryBattleViewerOpen: boolean`
    *   `productIdForInteraction: string | null`
    *   `activePoetryBattle: PoetryBattleState | null`
*   **Actions:**
    *   `openLlmTerminal(productId)`
    *   `openChatbotInterface(productId)`
    *   `closeInteractions()`
    *   ...and other actions for managing poetry battles.

## 5. New Files & Components

*   **Frontend UI:**
    *   `src/components/menus/llm/PlayerLlmTerminal.tsx`
    *   `src/components/menus/llm/PlayerChatbotInterface.tsx`
    *   `src/components/menus/llm/PoetryBattleViewer.tsx`
*   **Game Logic:** `src/game/systems/PoetryBattleSystem.ts`
*   **State:** `src/state/llmStore.ts`

This plan establishes a secure and extensible foundation for integrating LLM-powered features into AI Ascent.
</file_artifact>

<file path="src/Artifacts/A189. Number Formatting Reference Guide.md">
# Artifact A189: Number Formatting Guide (K/M Suffixes & Dynamic Decimals)
# Date Created: Cycle 14
# Author: AI Model & Curator

- **Key/Value for A0:**
- **Description:** A standalone guide and utility script for formatting large numbers with K/M/B/T suffixes and dynamic decimal place adjustment for clean UI presentation.
- **Tags:** utility, script, formatting, numbers, ui, ux, javascript, typescript

## 1. Purpose

This artifact provides a set of robust, reusable TypeScript functions for formatting numbers in a user-friendly way. The core function, `formatLargeNumber`, intelligently converts large numbers into a compact format using suffixes like 'K' (thousands), 'M' (millions), 'B' (billions), and 'T' (trillions).

The key features of this utility are:
*   **Automatic Suffixing:** Automatically scales numbers and adds the appropriate suffix.
*   **Dynamic Decimal Precision:** Adjusts the number of decimal places shown based on the magnitude of the number, ensuring a clean and consistent look in the UI (e.g., `12.3K`, `123.5K`, `1.23M`).
*   **Handling of Small Numbers:** Gracefully handles numbers below 1,000 without applying a suffix.
*   **Specialized Wrappers:** Includes helper functions like `formatCurrency` and `formatCount` for common use cases.

## 2. Core Utility Functions (from `src/utils.ts`)

Below is the complete TypeScript code. You can save this as a `formatting.ts` file in a new project's `utils` directory.

```typescript
// src/common/utils/formatting.ts

const KMBT_SUFFIXES = ['', 'K', 'M', 'B', 'T', 'Q']; // Extend as needed

/**
 * Formats a large number with appropriate K/M/B/T suffixes and dynamic decimal places.
 * Handles very small near-zero numbers gracefully to avoid scientific notation.
 *
 * @param value The number to format.
 * @param decimalPlaces The base number of decimal places to aim for.
 * @returns A formatted string.
 */
export function formatLargeNumber(value: number | undefined | null, decimalPlaces: number = 2): string {
    if (value === null || value === undefined || isNaN(value) || !Number.isFinite(value)) {
        return '---';
    }
    if (value === 0) {
        return '0';
    }

    const VERY_SMALL_THRESHOLD = 1e-6; // 0.000001
    if (Math.abs(value) < VERY_SMALL_THRESHOLD) {
        return (0).toFixed(decimalPlaces);
    }

    const isNegative = value < 0;
    const absValue = Math.abs(value);

    let unitIndex = 0;
    let scaledValue = absValue;

    if (absValue < 1000) {
        return String(Math.round(value)); // Return whole number if less than 1000
    }

    if (absValue >= 1000) {
        unitIndex = Math.floor(Math.log10(absValue) / 3);
        unitIndex = Math.min(unitIndex, KMBT_SUFFIXES.length - 1);
        scaledValue = absValue / Math.pow(1000, unitIndex);
    }

    let adjustedDecimalPlaces = decimalPlaces;
    if (unitIndex > 0) { // If a suffix is used (K, M, B, T, Q)
        if (scaledValue >= 100) adjustedDecimalPlaces = Math.max(0, decimalPlaces - 2);
        else if (scaledValue >= 10) adjustedDecimalPlaces = Math.max(0, decimalPlaces - 1);
    } else { // No unit suffix (value < 1000)
        if (Math.abs(scaledValue) < 0.01 && scaledValue !== 0) {
            adjustedDecimalPlaces = Math.max(decimalPlaces, 4);
        } else if (Number.isInteger(scaledValue)) {
             adjustedDecimalPlaces = 0;
        }
    }

    const unit = KMBT_SUFFIXES[unitIndex] ?? '';
    let formattedValue = scaledValue.toFixed(adjustedDecimalPlaces);

    // Remove trailing .00 or .0
    if (adjustedDecimalPlaces > 0 && formattedValue.endsWith('0')) {
        formattedValue = formattedValue.replace(/\.?0+$/, '');
    }


    return `${isNegative ? '-' : ''}${formattedValue}${unit}`;
}```

## 3. Usage Examples

Here is how you can use these functions in your code:

```typescript
import { formatLargeNumber } from './path/to/formatting';

// formatLargeNumber examples
console.log(formatLargeNumber(123));        // "123"
console.log(formatLargeNumber(1234));       // "1.23K"
console.log(formatLargeNumber(12345));      // "12.3K"
console.log(formatLargeNumber(123456));     // "123K"
console.log(formatLargeNumber(1234567));    // "1.23M"
console.log(formatLargeNumber(9876543210)); // "9.88B"
console.log(formatLargeNumber(-54321));     // "-54.3K"
console.log(formatLargeNumber(0.0000001));  // "0.00"
```

## 4. Integration Guide

1.  **Copy the Code:** Save the code from Section 2 into a file named `formatting.ts` inside your project's `src/common/utils` directory.
2.  **Import and Use:** Import the function into your UI components.
    ```typescript
    import { formatLargeNumber } from '@/common/utils/formatting';

    const MyComponent = () => {
      const displayValue = formatLargeNumber(123456); // "123K"
      return <div>Tokens: {displayValue}</div>;
    };
    ```
</file_artifact>

<file path="src/Artifacts/DCE_README.md">
# Artifact A72: DCE - README for Artifacts
# Date Created: C158
# Author: AI Model & Curator
# Updated on: C183 (Strengthen Git initialization and `.gitignore` guidance)

- **Key/Value for A0:**
- **Description:** The content for the `README.md` file that is automatically created in a new project's `src/Artifacts` directory, explaining the purpose of the extension and the artifact-driven workflow.
- **Tags:** documentation, onboarding, readme, source of truth

## 1. Welcome to the Data Curation Environment (DCE)

This directory (`src/Artifacts/`) is the heart of your project's planning and documentation. It's managed by the **Data Curation Environment (DCE)**, a VS Code extension designed to streamline AI-assisted development.

This `README.md` file was automatically generated to provide context for you (the developer) and for the AI assistants you will be working with.

## 2. What is an "Artifact"?

In the context of this workflow, an **Artifact** is a formal, written document that serves as a "source of truth" for a specific part of your project. Think of these files as the official blueprints, plans, and records.

The core principle of the DCE workflow is **"Documentation First."** Before writing code, you and your AI partner should first create or update an artifact that describes the plan.

## 3. The Iterative Cycle Workflow

Development in the DCE is organized into **Cycles**. You have just completed the initial setup.

### Your Next Steps

1.  **Initialize Your Git Repository (CRITICAL):**
    To take full advantage of the DCE's testing workflow (creating baselines and restoring changes), you **must** initialize a Git repository.
    
    Open a terminal in your project's root directory (you can use the integrated terminal in VS Code: `Terminal > New Terminal`) and run the following commands:
    ```bash
    git init
    # Create or update your .gitignore file with the line below
    echo ".vscode/" >> .gitignore
    git add .
    git commit -m "Initial commit"
    ```
    **Why `.gitignore`?** The DCE saves its state in a `.vscode/dce_history.json` file. Adding `.vscode/` to your `.gitignore` is crucial to prevent the extension's UI from flashing every time it auto-saves. For a complete guide, refer to the `GitHub Repository Setup Guide.md` artifact.

2.  **Submit Your First Prompt:** The `prompt.md` file has been automatically opened for you. This file contains your project plan and instructions for the AI. Copy its entire contents and paste it into your preferred AI chat interface (like Google's AI Studio, ChatGPT, etc.).

3.  **Review and Accept Responses:** Paste the AI's responses back into the "Resp 1", "Resp 2", etc. tabs in the Parallel Co-Pilot panel. The UI will guide you through parsing the responses, selecting the best one, and accepting its changes into your workspace.

4.  **Repeat:** This completes a cycle. You then start the next cycle, building upon the newly accepted code and documentation.

This structured, iterative process helps maintain project quality and ensures that both human and AI developers are always aligned with the project's goals.
</file_artifact>

<file path="src/backend/commands/commands.ts">
// Updated on: C11 (Alias dce.openSettingsPanel)
import * as vscode from 'vscode';
import { Services } from '../services/services';
import { serverIPCs } from '@/client/views';
import { ServerToClientChannel } from '@/common/ipc/channels.enum';
import { VIEW_TYPES } from '@/common/view-types';

export const commands = [
    {
        commandId: 'dce.saveCurrentSelection',
        callback: async (selectedPaths: string[]) => {
            if (!selectedPaths || selectedPaths.length === 0) {
                vscode.window.showWarningMessage("No files are selected to save.");
                return;
            }
            const name = await vscode.window.showInputBox({
                prompt: 'Enter a name for the selection set',
                placeHolder: 'e.g., "API Feature" or "Frontend Refactor"'
            });
            if (name) {
                await Services.selectionService.saveSelectionSet(name, selectedPaths);
                const serverIpc = serverIPCs[VIEW_TYPES.SIDEBAR.CONTEXT_CHOOSER];
                if(serverIpc) {
                    serverIpc.sendToClient(ServerToClientChannel.SendSelectionSets, { sets: Services.selectionService.getSelectionSets() });
                }
            }
        }
    },
    {
        commandId: 'dce.loadSelectionSet',
        callback: async () => {
            const sets = Services.selectionService.getSelectionSets();
            const setNames = Object.keys(sets);
             if (setNames.length === 0) {
                vscode.window.showInformationMessage("No saved selection sets.");
                return;
            }
            const name = await vscode.window.showQuickPick(setNames, {
                placeHolder: 'Select a selection set to load'
            });

            if (name) {
                const paths = sets[name];
                if (paths) {
                    const serverIpc = serverIPCs[VIEW_TYPES.SIDEBAR.CONTEXT_CHOOSER];
                    if(serverIpc) {
                        serverIpc.sendToClient(ServerToClientChannel.ApplySelectionSet, { paths });
                        Services.loggerService.log(`Command: Loaded selection set '${name}'.`);
                        vscode.window.showInformationMessage(`Loaded selection set '${name}'.`);
                    }
                }
            }
        }
    },
    {
        commandId: 'dce.manageSelectionSets',
        callback: async () => {
            const sets = Services.selectionService.getSelectionSets();
            const setNames = Object.keys(sets);
            if (setNames.length === 0) {
                vscode.window.showInformationMessage("No selection sets to manage.");
                return;
            }
            const setToDelete = await vscode.window.showQuickPick(setNames, {
                placeHolder: 'Select a selection set to delete'
            });

            if (setToDelete) {
                await Services.selectionService.deleteSelectionSet(setToDelete);
                 const serverIpc = serverIPCs[VIEW_TYPES.SIDEBAR.CONTEXT_CHOOSER];
                 if(serverIpc) {
                     serverIpc.sendToClient(ServerToClientChannel.SendSelectionSets, { sets: Services.selectionService.getSelectionSets() });
                 }
            }
        }
    },
    {
        commandId: 'dce.refreshTree',
        callback: () => {
            const serverIpc = serverIPCs[VIEW_TYPES.SIDEBAR.CONTEXT_CHOOSER];
            if (serverIpc) {
                Services.loggerService.log("Executing dce.refreshTree command.");
                Services.fileTreeService.handleWorkspaceFilesRequest(serverIpc, true);
            } else {
                Services.loggerService.warn("Could not refresh tree: serverIpc not found.");
            }
        }
    },
    {
        commandId: 'dce.openParallelCopilot',
        callback: () => {
            Services.loggerService.log("Executing dce.openParallelCopilot command to open WebviewPanel.");
            vscode.commands.executeCommand('dce.showParallelCopilot');
        }
    },
    {
        commandId: 'dce.openSettingsPanel',
        callback: () => {
            Services.loggerService.log("Executing dce.openSettingsPanel command.");
            vscode.commands.executeCommand('dce.showSettingsPanel');
        }
    },
    {
        commandId: 'dce.gitInit',
        callback: () => {
            Services.loggerService.log("Executing dce.gitInit command.");
            Services.gitService.handleGitInitRequest();
        }
    }
];
</file_artifact>

<file path="src/backend/commands/register-commands.ts">
import * as vscode from "vscode";
import { commands } from "./commands";
import { Services } from "../services/services";

export function registerCommands(context: vscode.ExtensionContext) {
    Services.loggerService.log(`Registering ${commands.length} commands.`);
    commands.forEach(({ commandId, callback }) => {
        let disposable = vscode.commands.registerCommand(commandId, callback);
        context.subscriptions.push(disposable);
    });
}
</file_artifact>

<file path="src/backend/providers/ResponseContentProvider.ts">
// src/backend/providers/ResponseContentProvider.ts
// New file in C27
import * as vscode from 'vscode';
import { Services } from '../services/services';

export class ResponseContentProvider implements vscode.TextDocumentContentProvider {
    public readonly onDidChangeEmitter = new vscode.EventEmitter<vscode.Uri>();
    public readonly onDidChange = this.onDidChangeEmitter.event;

    // A simple cache to hold the in-memory content of AI responses
    private contentCache = new Map<string, string>();

    public provideTextDocumentContent(uri: vscode.Uri): string {
        Services.loggerService.log(`[ResponseContentProvider] Providing content for URI: ${uri.toString()}`);
        return this.contentCache.get(uri.toString()) || '// Content not found for this response.';
    }

    public cacheContent(uri: vscode.Uri, content: string): void {
        Services.loggerService.log(`[ResponseContentProvider] Caching content for URI: ${uri.toString()}`);
        this.contentCache.set(uri.toString(), content);
        // Notify VS Code that the content for this URI has changed (or is now available)
        this.onDidChangeEmitter.fire(uri);
    }
}
</file_artifact>

<file path="src/backend/services/action.service.ts">
// Updated on: C12 (Add logic to ignore file for auto-add on undo)
import * as vscode from 'vscode';
import { Services } from './services';

export type ActionType = 'move' | 'delete';

export interface Action {
    type: ActionType;
    payload: any;
}

export interface MoveActionPayload {
    fromPath: string;
    toPath: string;
}

export class ActionService {
    private undoStack: Action[] = [];
    private redoStack: Action[] = [];

    public push(action: Action) {
        this.undoStack.push(action);
        this.redoStack = [];
        Services.loggerService.log(`[ActionService] Pushed action to undo stack: ${action.type}`);
    }

    public async undo() {
        const action = this.undoStack.pop();
        if (!action) {
            Services.loggerService.log(`[ActionService] Undo stack is empty.`);
            return;
        }
        Services.loggerService.log(`[ActionService] Undoing action: ${action.type}`);
        await this.performReverseAction(action);
        this.redoStack.push(action);
    }

    public async redo() {
        const action = this.redoStack.pop();
        if (!action) {
            Services.loggerService.log(`[ActionService] Redo stack is empty.`);
            return;
        }
        Services.loggerService.log(`[ActionService] Redoing action: ${action.type}`);
        await this.performOriginalAction(action);
        this.undoStack.push(action);
    }

    private async performReverseAction(action: Action) {
        switch (action.type) {
            case 'move':
                const { fromPath, toPath } = action.payload as MoveActionPayload;
                // Temporarily ignore the original path so the auto-adder doesn't re-check it
                Services.fileOperationService.addFileToIgnoreForAutoAdd(fromPath);
                await vscode.workspace.fs.rename(vscode.Uri.file(toPath), vscode.Uri.file(fromPath));
                break;
        }
    }

    private async performOriginalAction(action: Action) {
        switch (action.type) {
            case 'move':
                const { fromPath, toPath } = action.payload as MoveActionPayload;
                 await vscode.workspace.fs.rename(vscode.Uri.file(fromPath), vscode.Uri.file(toPath));
                break;
            case 'delete':
                await vscode.workspace.fs.delete(vscode.Uri.file(action.payload.path), { recursive: true, useTrash: true });
                break;
        }
    }
}
</file_artifact>

<file path="src/backend/services/content-extraction.service.ts">
// src/backend/services/content-extraction.service.ts
import * as vscode from "vscode";
import * as path from "path";
import * as fs from "fs/promises";
import { ServerPostMessageManager } from "@/common/ipc/server-ipc";
import { ServerToClientChannel } from "@/common/ipc/channels.enum";
import { Services } from "./services";
// @ts-ignore
import pdf from 'pdf-parse/lib/pdf-parse.js';
import * as XLSX from 'xlsx';
import mammoth from 'mammoth';

export class ContentExtractionService {
    private pdfTextCache = new Map<string, { text: string; tokenCount: number }>();
    private excelMarkdownCache = new Map<string, { markdown: string; tokenCount: number }>();
    private wordTextCache = new Map<string, { text: string; tokenCount: number }>();

    public getVirtualPdfContent(filePath: string) {
        return this.pdfTextCache.get(filePath);
    }

    public getVirtualExcelContent(filePath: string) {
        return this.excelMarkdownCache.get(filePath);
    }

    public getVirtualWordContent(filePath: string) {
        return this.wordTextCache.get(filePath);
    }

    public async handlePdfToTextRequest(filePath: string, serverIpc: ServerPostMessageManager) {
        Services.loggerService.log(`Received RequestPdfToText for: ${filePath}`);
        if (this.pdfTextCache.has(filePath)) {
            const cached = this.pdfTextCache.get(filePath)!;
            serverIpc.sendToClient(ServerToClientChannel.UpdateNodeStats, { path: filePath, tokenCount: cached.tokenCount });
            Services.loggerService.log(`PDF served from cache: ${filePath}`);
            return;
        }

        try {
            Services.loggerService.log(`[PDF] Processing: ${filePath}`);
            const buffer = await fs.readFile(filePath);
            const data = await pdf(buffer);
            const text = data.text;
            const tokenCount = Math.ceil(text.length / 4);
            
            this.pdfTextCache.set(filePath, { text, tokenCount });
            Services.loggerService.log(`PDF Parsed and cached: ${path.basename(filePath)} (${tokenCount} tokens)`);

            serverIpc.sendToClient(ServerToClientChannel.UpdateNodeStats, { path: filePath, tokenCount: tokenCount });
        } catch (error: any) {
            const errorMessage = `Failed to parse PDF: ${path.basename(filePath)}`;
            Services.loggerService.error(`[PDF] Error processing ${filePath}: ${error.stack || error.message}`);
            serverIpc.sendToClient(ServerToClientChannel.UpdateNodeStats, { path: filePath, tokenCount: 0, error: errorMessage });
        }
    }

    private _sheetToMarkdown(sheet: XLSX.WorkSheet): string {
        const data: any[][] = XLSX.utils.sheet_to_json(sheet, { header: 1 });
        if (data.length === 0) return "";
    
        const sanitizedData = data.map(row => 
            row.map(cell => {
                const cellStr = cell ? String(cell) : '';
                return cellStr.replace(/\|/g, '\\|').replace(/\r?\n/g, '<br/>');
            })
        );
    
        const header = sanitizedData[0];
        const body = sanitizedData.slice(1);
        const headerLine = `| ${header.join(' | ')} |`;
        const separatorLine = `| ${header.map(() => '---').join(' | ')} |`;
        const bodyLines = body.map(row => `| ${row.join(' | ')} |`).join('\n');
        return `${headerLine}\n${separatorLine}\n${bodyLines}`;
    }

    public async handleExcelToTextRequest(filePath: string, serverIpc: ServerPostMessageManager) {
        Services.loggerService.log(`Received RequestExcelToText for: ${filePath}`);
        if (this.excelMarkdownCache.has(filePath)) {
            const cached = this.excelMarkdownCache.get(filePath)!;
            serverIpc.sendToClient(ServerToClientChannel.UpdateNodeStats, { path: filePath, tokenCount: cached.tokenCount });
            Services.loggerService.log(`Excel served from cache: ${filePath}`);
            return;
        }

        try {
            Services.loggerService.log(`[Excel] Processing: ${filePath}`);
            const buffer = await fs.readFile(filePath);
            const workbook = XLSX.read(buffer, { type: 'buffer' });
            
            let markdown = '';
            workbook.SheetNames.forEach(sheetName => {
                markdown += `### Sheet: ${sheetName}\n\n`;
                const worksheet = workbook.Sheets[sheetName];
                markdown += this._sheetToMarkdown(worksheet);
                markdown += '\n\n';
            });

            const tokenCount = Math.ceil(markdown.length / 4);
            this.excelMarkdownCache.set(filePath, { markdown, tokenCount });
            Services.loggerService.log(`Excel Parsed and cached: ${path.basename(filePath)} (${tokenCount} tokens)`);

            serverIpc.sendToClient(ServerToClientChannel.UpdateNodeStats, { path: filePath, tokenCount: tokenCount });
        } catch (error: any) {
             const errorMessage = `Failed to parse Excel/CSV file: ${path.basename(filePath)}`;
             Services.loggerService.error(`[Excel] Error processing ${filePath}: ${error.stack || error.message}`);
             serverIpc.sendToClient(ServerToClientChannel.UpdateNodeStats, { path: filePath, tokenCount: 0, error: errorMessage });
        }
    }

    public async handleWordToTextRequest(filePath: string, serverIpc: ServerPostMessageManager) {
        Services.loggerService.log(`Received RequestWordToText for: ${filePath}`);
        if (this.wordTextCache.has(filePath)) {
            const cached = this.wordTextCache.get(filePath)!;
            serverIpc.sendToClient(ServerToClientChannel.UpdateNodeStats, { path: filePath, tokenCount: cached.tokenCount });
            Services.loggerService.log(`Word served from cache: ${filePath}`);
            return;
        }

        const extension = path.extname(filePath).toLowerCase();
        if (extension === '.doc') {
            const unsupportedMessage = "UNSUPPORTED_FORMAT";
            this.wordTextCache.set(filePath, { text: unsupportedMessage, tokenCount: 0 });
            Services.loggerService.warn(`[Word] Legacy .doc format is not supported for file: ${filePath}`);
            serverIpc.sendToClient(ServerToClientChannel.UpdateNodeStats, { path: filePath, tokenCount: 0, error: "Legacy .doc format not supported." });
            return;
        }

        try {
            Services.loggerService.log(`[Word] Processing: ${filePath}`);
            const buffer = await fs.readFile(filePath);
            const result = await mammoth.extractRawText({ buffer });
            const text = result.value;
            const tokenCount = Math.ceil(text.length / 4);
            
            this.wordTextCache.set(filePath, { text, tokenCount });
            Services.loggerService.log(`Word Parsed and cached: ${path.basename(filePath)} (${tokenCount} tokens)`);

            serverIpc.sendToClient(ServerToClientChannel.UpdateNodeStats, { path: filePath, tokenCount: tokenCount });
        } catch (error: any) {
            let errorMessage = `Failed to parse Word file: ${path.basename(filePath)}`;
            if (error instanceof Error && error.message.includes("Can't find end of central directory")) {
                errorMessage = "File may be corrupted or is not a valid .docx format.";
            }
            Services.loggerService.error(`[Word] Error processing ${filePath}: ${error.stack || error.message}`);
            serverIpc.sendToClient(ServerToClientChannel.UpdateNodeStats, { path: filePath, tokenCount: 0, error: errorMessage });
        }
    }
}
</file_artifact>

<file path="src/backend/services/file-operation.service.ts">
// src/backend/services/file-operation.service.ts
// Updated on: C126 (Add enhanced logging to handleFileExistenceRequest)
import * as vscode from "vscode";
import * as path from "path";
import { promises as fs } from 'fs';
import { ServerPostMessageManager } from "@/common/ipc/server-ipc";
import { ServerToClientChannel } from "@/common/ipc/channels.enum";
import { Services } from "./services";
import { Action, MoveActionPayload } from "./action.service";
import { BatchWriteFile } from "@/common/ipc/channels.type";
import { diceCoefficient } from "@/common/utils/similarity";

const normalizePath = (p: string) => p.replace(/\\/g, '/');

export class FileOperationService {
    private filesToIgnoreForAutoAdd: Set<string> = new Set();
    
    private getWorkspaceRoot(): string {
        const workspaceFolders = vscode.workspace.workspaceFolders;
        if (!workspaceFolders || workspaceFolders.length === 0) {
            throw new Error("No workspace folder open.");
        }
        return workspaceFolders[0].uri.fsPath;
    }

    public async handleNativeDiffRequest(originalPath: string, modifiedContent: string, title: string) {
        Services.loggerService.log(`[Native Diff] Received request for: ${originalPath}`);
        try {
            const workspaceRoot = this.getWorkspaceRoot();
            const originalUri = vscode.Uri.file(path.resolve(workspaceRoot, originalPath));

            // Create a unique URI for the virtual document
            const virtualUri = vscode.Uri.parse(`dce-response:${originalPath}?ts=${new Date().getTime()}`);
            
            // Cache the AI-generated content in our provider
            Services.responseContentProvider.cacheContent(virtualUri, modifiedContent);

            // Execute the diff command
            await vscode.commands.executeCommand('vscode.diff', originalUri, virtualUri, title);
        } catch (error: any) {
            Services.loggerService.error(`[Native Diff] Failed to open diff view: ${error.message}`);
            vscode.window.showErrorMessage(`Failed to open diff view: ${error.message}`);
        }
    }

    public async handleMarkdownPreviewRequest(filePath: string) {
        Services.loggerService.log(`[Markdown Preview] Received request for: ${filePath}`);
        try {
            const workspaceRoot = this.getWorkspaceRoot();
            const absolutePath = path.resolve(workspaceRoot, filePath);
            const uri = vscode.Uri.file(absolutePath);
            
            // Ensure file exists before trying to preview
            try {
                await vscode.workspace.fs.stat(uri);
            } catch {
                 vscode.window.showErrorMessage(`File not found: ${filePath}`);
                 return;
            }

            await vscode.commands.executeCommand('markdown.showPreview', uri);
        } catch (error: any) {
            Services.loggerService.error(`[Markdown Preview] Failed: ${error.message}`);
            vscode.window.showErrorMessage(`Failed to open Markdown preview: ${error.message}`);
        }
    }

    public async handleReadmeContentRequest(serverIpc: ServerPostMessageManager) {
        try {
            const readmePath = path.join(Services.context.extensionPath, 'README.md');
            Services.loggerService.log(`Attempting to read README from extension path: ${readmePath}`);
            const content = await fs.readFile(readmePath, 'utf-8');
            serverIpc.sendToClient(ServerToClientChannel.SendReadmeContent, { content });
        } catch (error) {
            Services.loggerService.error(`Failed to read README.md: ${error}`);
            serverIpc.sendToClient(ServerToClientChannel.SendReadmeContent, { content: '# README.md not found in extension files.' });
        }
    }

    public async handleChangelogContentRequest(serverIpc: ServerPostMessageManager) {
        try {
            const changelogPath = path.join(Services.context.extensionPath, 'CHANGELOG.md');
            Services.loggerService.log(`Attempting to read CHANGELOG from extension path: ${changelogPath}`);
            const content = await fs.readFile(changelogPath, 'utf-8');
            serverIpc.sendToClient(ServerToClientChannel.SendChangelogContent, { content });
        } catch (error) {
            Services.loggerService.error(`Failed to read CHANGELOG.md: ${error}`);
            serverIpc.sendToClient(ServerToClientChannel.SendChangelogContent, { content: '# CHANGELOG.md not found in extension files.' });
        }
    }

    public async fileExists(filePath: string): Promise<boolean> {
        try {
            await vscode.workspace.fs.stat(vscode.Uri.file(filePath));
            return true;
        } catch {
            return false;
        }
    }

    public async handleShowInformationMessageRequest(message: string) {
        Services.loggerService.log(`[UI NOTIFY] Received request to show message: "${message}"`);
        vscode.window.showInformationMessage(message);
    }

    public async handleOpenFolderRequest() {
        Services.loggerService.log(`[File Operation] Received request to open folder.`);
        try {
            await vscode.commands.executeCommand('vscode.openFolder');
        } catch (error: any) {
            Services.loggerService.error(`[File Operation] Failed to execute open folder command: ${error.message}`);
            vscode.window.showErrorMessage(`Failed to open folder: ${error.message}`);
        }
    }

    public async handleCopyTextToClipboardRequest(text: string) {
        Services.loggerService.log(`[Clipboard] Received request to copy text.`);
        try {
            await vscode.env.clipboard.writeText(text);
            vscode.window.showInformationMessage('File content copied to clipboard.');
        } catch (error: any) {
            Services.loggerService.error(`[Clipboard] Failed to copy: ${error.message}`);
            vscode.window.showErrorMessage('Failed to copy file content to clipboard.');
        }
    }

    public async handleFileComparisonRequest(filePath: string, modifiedContent: string, tabId: string, serverIpc: ServerPostMessageManager) {
        Services.loggerService.log(`[Comparison] Received request for: ${filePath} (Tab: ${tabId})`);
        try {
            const absolutePath = path.resolve(this.getWorkspaceRoot(), filePath);
            const originalContentBuffer = await vscode.workspace.fs.readFile(vscode.Uri.file(absolutePath));
            const originalContent = Buffer.from(originalContentBuffer).toString('utf-8');

            const originalTokens = Math.ceil(originalContent.length / 4);
            const modifiedTokens = Math.ceil(modifiedContent.length / 4);
            const similarity = diceCoefficient(originalContent, modifiedContent);

            serverIpc.sendToClient(ServerToClientChannel.SendFileComparison, {
                filePath,
                originalTokens,
                modifiedTokens,
                similarity,
                tabId
            });
        } catch (error: any) {
            Services.loggerService.error(`[Comparison] Failed for ${filePath}: ${error.message}`);
            // Send back error state
            serverIpc.sendToClient(ServerToClientChannel.SendFileComparison, {
                filePath,
                originalTokens: -1,
                modifiedTokens: Math.ceil(modifiedContent.length / 4),
                similarity: 0,
                tabId
            });
        }
    }

    public async handleBatchFileWrite(files: BatchWriteFile[]): Promise<string[]> {
        Services.loggerService.log(`[File Operation] Received request to write ${files.length} files.`);
        const rootPath = this.getWorkspaceRoot();
        const successfulPaths: string[] = [];

        try {
            for (const file of files) {
                const absolutePath = path.resolve(rootPath, file.path);
                const uri = vscode.Uri.file(absolutePath);
                // Ensure directory exists
                await vscode.workspace.fs.createDirectory(vscode.Uri.file(path.dirname(absolutePath)));
                const contentBuffer = Buffer.from(file.content, 'utf-8');
                await vscode.workspace.fs.writeFile(uri, contentBuffer);
                Services.loggerService.log(`Successfully wrote content to: ${file.path}`);
                successfulPaths.push(file.path);
            }
            vscode.window.showInformationMessage(`Successfully accepted and wrote ${files.length} files to the workspace.`);
        } catch (error: any) {
            Services.loggerService.error(`Failed during batch file write: ${error.message}`);
            vscode.window.showErrorMessage(`Failed to write files: ${error.message}`);
        }
        return successfulPaths;
    }

    public async handleFileContentRequest(filePath: string, serverIpc: ServerPostMessageManager) {
        Services.loggerService.log(`handleFileContentRequest initiated for: ${filePath}`);
        try {
            const absolutePath = path.resolve(this.getWorkspaceRoot(), filePath);
            const uri = vscode.Uri.file(absolutePath);
            const contentBuffer = await vscode.workspace.fs.readFile(uri);
            const content = Buffer.from(contentBuffer).toString('utf-8');
            Services.loggerService.log(`Successfully read content for: ${filePath}. Sending to client.`);
            serverIpc.sendToClient(ServerToClientChannel.SendFileContent, { path: filePath, content });
        } catch (error: any) {
            Services.loggerService.error(`Failed to read file content for ${filePath}: ${error.message}`);
            serverIpc.sendToClient(ServerToClientChannel.SendFileContent, { path: filePath, content: `// Error: Could not read file content for ${filePath}. It may not exist in the workspace.` });
        }
    }

    public async handleFileExistenceRequest(paths: string[], serverIpc: ServerPostMessageManager) {
        Services.loggerService.log(`[File Existence] Received request to check paths: ${JSON.stringify(paths)}`);
        const rootPath = this.getWorkspaceRoot();
        Services.loggerService.log(`[File Existence] Root Path: ${rootPath}`);
    
        const existenceMap: { [path: string]: boolean } = {};
        const checks = paths.map(async (p_raw) => {
            // Normalize path separators and trim quotes
            const p = p_raw.trim().replace(/^[`"']|[`"']$/g, '');
            if (!p) return;
    
            // Resolve to absolute path, then normalize to forward slashes
            let absolutePath = path.resolve(rootPath, p);
            let normalizedPath = normalizePath(absolutePath);
            
            Services.loggerService.log(`[File Existence] Checking: ${p_raw} -> ${normalizedPath}`);
    
            try {
                await vscode.workspace.fs.stat(vscode.Uri.file(normalizedPath));
                existenceMap[p_raw] = true;
            } catch {
                // Fallback check for Artifacts (sometimes referenced relatively)
                if (/^A\d+/.test(p)) {
                    const artifactPath = path.resolve(rootPath, 'src/Artifacts', p);
                    const normalizedArtifactPath = normalizePath(artifactPath);
                    try {
                        await vscode.workspace.fs.stat(vscode.Uri.file(normalizedArtifactPath));
                        existenceMap[p_raw] = true;
                        return;
                    } catch {}
                }
                existenceMap[p_raw] = false;
            }
        });
        await Promise.all(checks);
        serverIpc.sendToClient(ServerToClientChannel.SendFileExistence, { existenceMap });
    }

    private async _findAvailableCopyName(destinationPath: string): Promise<string> {
        try {
            await vscode.workspace.fs.stat(vscode.Uri.file(destinationPath));
        } catch (error) {
            return destinationPath;
        }
    
        const dir = path.dirname(destinationPath);
        const ext = path.extname(destinationPath);
        const baseName = path.basename(destinationPath, ext);
    
        let copyNum = 1;
        let nextPath = path.join(dir, `${baseName}-copy${ext}`);
        
        while (true) {
            try {
                await vscode.workspace.fs.stat(vscode.Uri.file(nextPath));
                copyNum++;
                nextPath = path.join(dir, `${baseName}-copy-${copyNum}${ext}`);
            } catch (error) {
                return nextPath;
            }
        }
    }

    public async handleCopyFileRequest(sourcePath: string, destinationDir: string) {
        try {
            const sourceName = path.basename(sourcePath);
            const initialDestinationPath = path.join(destinationDir, sourceName);
            const finalDestinationPath = await this._findAvailableCopyName(initialDestinationPath);
            const sourceUri = vscode.Uri.file(sourcePath);
            const destinationUri = vscode.Uri.file(finalDestinationPath);

            await vscode.workspace.fs.copy(sourceUri, destinationUri, { overwrite: false });
        } catch (error: any) {
            vscode.window.showErrorMessage(`Failed to copy file: ${error.message}`);
        }
    }

    public async handleCopyFileFromUri(sourceUriString: string, targetDir: string) {
        try {
            const sourceUri = vscode.Uri.parse(sourceUriString);
            const fileName = path.basename(sourceUri.fsPath);
            const targetUri = vscode.Uri.file(path.join(targetDir, fileName));
            await vscode.workspace.fs.copy(sourceUri, targetUri);
        } catch (error: any) {
            vscode.window.showErrorMessage(`Failed to copy file from URI: ${error.message}`);
        }
    }

    public async handleAddFileFromBuffer(targetPath: string, data: Uint8Array) {
        try {
            await vscode.workspace.fs.writeFile(vscode.Uri.file(targetPath), data);
        } catch (error: any) {
            vscode.window.showErrorMessage(`Failed to add file from buffer: ${error.message}`);
        }
    }

    public async handleOpenFileRequest(filePath: string) {
        try {
            // Ensure path is absolute
            const absolutePath = path.isAbsolute(filePath) ? filePath : path.join(this.getWorkspaceRoot(), filePath);
            await vscode.commands.executeCommand('vscode.open', vscode.Uri.file(absolutePath));
        } catch (error: any) {
            vscode.window.showErrorMessage(`Failed to open file ${filePath}: ${error.message}`);
        }
    }

    public async handleNewFileRequest(parentDirectory: string) {
        const newFileName = await vscode.window.showInputBox({ prompt: "Enter the name of the new file", value: "new-file.ts" });
        if (newFileName) {
            try {
                await vscode.workspace.fs.writeFile(vscode.Uri.file(path.join(parentDirectory, newFileName)), new Uint8Array());
            } catch (error: any) {
                vscode.window.showErrorMessage(`Failed to create file: ${error.message}`);
            }
        }
    }
    
    public async handleCreateFileRequest(filePath: string) {
        Services.loggerService.log(`Received request to create file: ${filePath}`);
        try {
            const absolutePath = path.resolve(this.getWorkspaceRoot(), filePath);
            await vscode.workspace.fs.writeFile(vscode.Uri.file(absolutePath), new Uint8Array());
            Services.loggerService.log(`Successfully created file: ${filePath}`);
        } catch (error: any) {
            vscode.window.showErrorMessage(`Failed to create file: ${error.message}`);
            Services.loggerService.error(`Failed to create file ${filePath}: ${error.message}`);
        }
    }

    public async handleNewFolderRequest(parentDirectory: string) {
        const newFolderName = await vscode.window.showInputBox({ prompt: "Enter the name of the new folder", value: "new-folder" });
        if (newFolderName) {
            try {
                await vscode.workspace.fs.createDirectory(vscode.Uri.file(path.join(parentDirectory, newFolderName)));
            } catch (error: any) {
                vscode.window.showErrorMessage(`Failed to create folder: ${error.message}`);
            }
        }
    }

    public async handleFileRenameRequest(oldPath: string, newName: string) {
        try {
            await vscode.workspace.fs.rename(vscode.Uri.file(oldPath), vscode.Uri.file(path.join(path.dirname(oldPath), newName)));
        } catch (error: any) {
            vscode.window.showErrorMessage(`Failed to rename: ${error.message}`);
        }
    }

    public async handleMoveFileRequest(oldPath: string, newPath: string) {
        try {
            const lastSelection = await Services.selectionService.getLastSelection();
            if (!lastSelection.some(p => p.startsWith(oldPath))) {
                this.addFileToIgnoreForAutoAdd(newPath);
            }

            await vscode.workspace.fs.rename(vscode.Uri.file(oldPath), vscode.Uri.file(newPath));
            await Services.selectionService.updatePathInSelections(oldPath, newPath);
            Services.actionService.push({ type: 'move', payload: { fromPath: oldPath, toPath: newPath } as MoveActionPayload });
        } catch (error: any) {
            vscode.window.showErrorMessage(`Failed to move file: ${error.message}`);
        }
    }

    public async handleFileDeleteRequest(filePath: string) {
        const confirmation = await vscode.window.showWarningMessage(`Are you sure you want to delete ${path.basename(filePath)}?`, { modal: true }, 'Delete');
        if (confirmation === 'Delete') {
            try {
                await vscode.workspace.fs.delete(vscode.Uri.file(filePath), { recursive: true, useTrash: true });
            } catch (error: any) {
                vscode.window.showErrorMessage(`Failed to delete: ${error.message}`);
            }
        }
    }

    public async handleBatchFileDeleteRequest(paths: string[]) {
        if (paths.length === 0) return;
        const confirmation = await vscode.window.showWarningMessage(`Are you sure you want to delete ${paths.length} item(s)?`, { modal: true }, 'Delete');
        if (confirmation === 'Delete') {
            try {
                await Promise.all(paths.map(p => vscode.workspace.fs.delete(vscode.Uri.file(p), { recursive: true, useTrash: true })));
            } catch (error: any) {
                vscode.window.showErrorMessage(`Failed to delete items: ${error.message}`);
            }
        }
    }

    public handleRevealInExplorerRequest(filePath: string) {
        vscode.commands.executeCommand('revealInExplorer', vscode.Uri.file(filePath));
    }

    public handleCopyPathRequest(filePath: string, relative: boolean) {
        const workspaceFolders = vscode.workspace.workspaceFolders;
        let pathToCopy = filePath;
        if (relative && workspaceFolders && workspaceFolders.length > 0) {
            // Use the first workspace folder's URI to compute a relative path
            pathToCopy = path.relative(workspaceFolders[0].uri.fsPath, filePath);
        }
        vscode.env.clipboard.writeText(pathToCopy);
        vscode.window.showInformationMessage(`Copied to clipboard: ${pathToCopy}`);
    }

    public addFileToIgnoreForAutoAdd(filePath: string) {
        Services.loggerService.log(`[Auto-Add] Temporarily ignoring: ${filePath}`);
        this.filesToIgnoreForAutoAdd.add(filePath);
        setTimeout(() => this.removeFileToIgnoreForAutoAdd(filePath), 2000);
    }

    public hasFileToIgnoreForAutoAdd(filePath: string): boolean {
        return this.filesToIgnoreForAutoAdd.has(filePath);
    }

    public removeFileToIgnoreForAutoAdd(filePath: string) {
        this.filesToIgnoreForAutoAdd.delete(filePath);
    }
}
</file_artifact>

<file path="src/backend/services/file-tree.service.ts">
// src/backend/services/file-tree.service.ts
// Updated on: C26 (Add targeted logging)
import * as vscode from "vscode";
import * as path from "path";
import * as fs from "fs/promises";
import { ServerPostMessageManager } from "@/common/ipc/server-ipc";
import { ServerToClientChannel } from "@/common/ipc/channels.enum";
import { FileNode } from "@/common/types/file-node";
import { Services } from "@/backend/services/services";
import { serverIPCs } from "@/client/views";
import { VIEW_TYPES } from "@/common/view-types";
import { API as GitAPI, Status, Repository } from "../types/git";
import { ProblemCountsMap, GitStatusMap } from "@/common/ipc/channels.type";

const IMAGE_EXTENSIONS = new Set(['.png', '.jpg', '.jpeg', '.gif', '.bmp', '.svg', '.webp', '.ico']);
const EXCEL_EXTENSIONS = new Set(['.xlsx', '.xls', '.csv']);
const WORD_EXTENSIONS = new Set(['.docx', '.doc']);
const EXCLUSION_PATTERNS = ['dce_cache', 'out']; 
const NON_SELECTABLE_PATTERNS = ['node_modules', '.vscode', '.git', 'venv', '.venv', 'flattened_repo.md', 'prompt.md', 'package-lock.json', 'tsconfig.tsbuildinfo', 'dce_history_export_', 'dist', '.next'];

const normalizePath = (p: string) => p.replace(/\\/g, '/');

export class FileTreeService {
    private fileTreeCache: FileNode[] | null = null;
    private watcher: vscode.FileSystemWatcher | null = null;
    private refreshDebounceTimer: NodeJS.Timeout | null = null;
    private decorationsDebounceTimer: NodeJS.Timeout | null = null;
    private gitApi?: GitAPI;
    private autoAddQueue: string[] = [];
    private historyFilePath: string | undefined;
    private debouncedProcessAutoAdd: () => void;

    constructor(gitApi?: GitAPI) {
        this.gitApi = gitApi;
        const workspaceFolders = vscode.workspace.workspaceFolders;
        if (workspaceFolders && workspaceFolders.length > 0) {
            this.historyFilePath = normalizePath(path.join(workspaceFolders[0].uri.fsPath, '.vscode', 'dce_history.json'));
        }

        if (this.gitApi) {
            this.gitApi.onDidOpenRepository(() => this.triggerFullRefresh('git repo opened'));
            this.gitApi.repositories.forEach(repo => {
                repo.state.onDidChange(() => {
                    this.triggerDecorationsUpdate();
                });
            });
        }
        
        this.debouncedProcessAutoAdd = this.debounce(this.processAutoAddQueue.bind(this), 200);
    }

    private debounce(func: (...args: any[]) => void, delay: number) {
        let timeoutId: NodeJS.Timeout | null = null;
        return (...args: any[]) => {
            if (timeoutId) clearTimeout(timeoutId);
            timeoutId = setTimeout(() => func(...args), delay);
        };
    }

    private triggerFullRefresh(reason: string) {
        Services.loggerService.log(`[FTV Refresh] Full refresh triggered. Reason: ${reason}`);
        if (this.refreshDebounceTimer) clearTimeout(this.refreshDebounceTimer);
        this.refreshDebounceTimer = setTimeout(() => {
            this.fileTreeCache = null;
            const serverIpc = serverIPCs[VIEW_TYPES.SIDEBAR.CONTEXT_CHOOSER];
            if (serverIpc) {
                serverIpc.sendToClient(ServerToClientChannel.ForceRefresh, { reason: 'fileOp' });
            }
        }, 1500);
    }

    private triggerDecorationsUpdate() {
        if (this.decorationsDebounceTimer) clearTimeout(this.decorationsDebounceTimer);
        this.decorationsDebounceTimer = setTimeout(() => {
            const serverIpc = serverIPCs[VIEW_TYPES.SIDEBAR.CONTEXT_CHOOSER];
            if (serverIpc) {
                serverIpc.sendToClient(ServerToClientChannel.UpdateDecorations, { 
                    problemMap: this.getProblemCountsMap(),
                    gitStatusMap: this.getGitStatusMap()
                });
            }
        }, 750);
    }

    public initializeWatcher() {
        if (this.watcher) this.watcher.dispose();
        
        this.watcher = vscode.workspace.createFileSystemWatcher('**/*');
        const onFileChange = (uri: vscode.Uri, source: string) => {
            const normalizedPath = normalizePath(uri.fsPath);
            if (this.historyFilePath && normalizedPath === this.historyFilePath) {
                return;
            }
            // Also ignore dce.db related files
            if (normalizedPath.includes('.vscode/dce.db')) {
                return;
            }
            for (const pattern of EXCLUSION_PATTERNS) {
                if (normalizedPath.includes(`/${pattern}/`)) {
                    return;
                }
            }
            this.triggerFullRefresh(`file change: ${path.basename(normalizedPath)}`);
        };

        this.watcher.onDidCreate(async (uri: vscode.Uri) => {
            const normalizedPath = normalizePath(uri.fsPath);
            if (this.historyFilePath && normalizedPath === this.historyFilePath) return;
            if (normalizedPath.includes('.vscode/dce.db')) return;
            
            const isNonSelectable = !this._isSelectable(normalizedPath, vscode.FileType.File);
            if (isNonSelectable) {
                onFileChange(uri, 'onDidCreate');
                return;
            }

            if (Services.fileOperationService.hasFileToIgnoreForAutoAdd(normalizedPath)) {
                Services.fileOperationService.removeFileToIgnoreForAutoAdd(normalizedPath);
            } else if (Services.selectionService.getAutoAddState()) {
                this.autoAddQueue.push(normalizedPath);
                this.debouncedProcessAutoAdd();
            }
            onFileChange(uri, 'onDidCreate');
        });
        this.watcher.onDidChange((uri) => onFileChange(uri, 'onDidChange'));
        this.watcher.onDidDelete((uri) => onFileChange(uri, 'onDidDelete'));
        vscode.languages.onDidChangeDiagnostics(() => this.triggerDecorationsUpdate());
    }

    private async processAutoAddQueue() {
        if (this.autoAddQueue.length === 0) return;
    
        const pathsToAdd = [...new Set(this.autoAddQueue)];
        this.autoAddQueue = [];
        Services.loggerService.log(`[Auto-Add] Processing queue with ${pathsToAdd.length} files: ${JSON.stringify(pathsToAdd)}`);

        const currentSelection = await Services.selectionService.getLastSelection();
        const newSelection = [...new Set([...currentSelection, ...pathsToAdd])];
    
        await Services.selectionService.saveCurrentSelection(newSelection);
        
        const serverIpc = serverIPCs[VIEW_TYPES.SIDEBAR.CONTEXT_CHOOSER];
        if (serverIpc) {
            Services.loggerService.log(`[Auto-Add] Sending ApplySelectionSet to client with ${newSelection.length} total paths.`);
            serverIpc.sendToClient(ServerToClientChannel.ApplySelectionSet, { paths: newSelection });
        }
    }

    private async getFileStats(filePath: string): Promise<Omit<FileNode, 'name' | 'absolutePath' | 'children'>> {
        const extension = path.extname(filePath).toLowerCase();
        try {
            const stats = await fs.stat(filePath);
            const isImage = IMAGE_EXTENSIONS.has(extension);
            const isPdf = extension === '.pdf';
            const isExcel = EXCEL_EXTENSIONS.has(extension);
            const isWordDoc = WORD_EXTENSIONS.has(extension);
            const baseStats = { sizeInBytes: stats.size, isImage, extension, isPdf, isExcel, isWordDoc, fileCount: 1 };
            if (isImage) return { ...baseStats, tokenCount: 0, isSelectable: true };
            if (isPdf) return { ...baseStats, tokenCount: Services.contentExtractionService.getVirtualPdfContent(filePath)?.tokenCount || 0, isSelectable: true };
            if (isExcel) return { ...baseStats, tokenCount: Services.contentExtractionService.getVirtualExcelContent(filePath)?.tokenCount || 0, isSelectable: true };
            if (isWordDoc) return { ...baseStats, tokenCount: Services.contentExtractionService.getVirtualWordContent(filePath)?.tokenCount || 0, isSelectable: true };
            if (stats.size > 5_000_000) return { ...baseStats, tokenCount: 0, isSelectable: true };
            const content = await fs.readFile(filePath, 'utf-8');
            return { ...baseStats, tokenCount: Math.ceil(content.length / 4), isSelectable: true };
        } catch (error: any) {
            try {
                const stats = await fs.stat(filePath);
                return { tokenCount: 0, sizeInBytes: stats.size, isImage: false, extension, isPdf: false, isExcel: false, isWordDoc: false, fileCount: 1, error: error.message, isSelectable: true };
            } catch (statError) {
                return { tokenCount: 0, sizeInBytes: 0, isImage: false, extension, isPdf: false, isExcel: false, isWordDoc: false, fileCount: 1, error: error.message, isSelectable: true };
            }
        }
    }

    public async handleWorkspaceFilesRequest(serverIpc: ServerPostMessageManager, forceRefresh: boolean = false) {
        if (!forceRefresh && this.fileTreeCache) {
            serverIpc.sendToClient(ServerToClientChannel.SendWorkspaceFiles, { files: this.fileTreeCache });
            this.triggerDecorationsUpdate();
            return;
        }
        const workspaceFolders = vscode.workspace.workspaceFolders;
        if (!workspaceFolders || workspaceFolders.length === 0) {
            serverIpc.sendToClient(ServerToClientChannel.SendWorkspaceFiles, { files: [] });
            return;
        }
        const fileTrees = await Promise.all(workspaceFolders.map(wf => this.buildTreeFromTraversal(wf.uri)));
        this.fileTreeCache = fileTrees;
        serverIpc.sendToClient(ServerToClientChannel.SendWorkspaceFiles, { files: this.fileTreeCache });
        this.triggerDecorationsUpdate();
    }

    private getGitStatusMap(): GitStatusMap {
        if (!this.gitApi?.repositories || this.gitApi.repositories.length === 0) return {};
        const getStatusChar = (s: Status) => ({ [Status.INDEX_ADDED]: 'A', [Status.MODIFIED]: 'M', [Status.DELETED]: 'D', [Status.UNTRACKED]: 'U', [Status.IGNORED]: 'I', [Status.CONFLICT]: 'C' }[s] || '');
        const statusMap: GitStatusMap = {};
        for (const repo of this.gitApi.repositories) {
            try {
                const changes = [...repo.state.workingTreeChanges, ...repo.state.indexChanges, ...repo.state.mergeChanges];
                changes.forEach(change => {
                    const statusChar = getStatusChar(change.status);
                    if (statusChar) statusMap[normalizePath(change.uri.fsPath)] = statusChar;
                });
            } catch (e) {
                Services.loggerService.warn(`[getGitStatusMap] Error reading repo status: ${(e as Error).message}`);
            }
        }
        return statusMap;
    }

    private getProblemCountsMap(): ProblemCountsMap {
        const problemMap: ProblemCountsMap = {};
        for (const [uri, diagnosticArr] of vscode.languages.getDiagnostics()) {
            const path = normalizePath(uri.fsPath);
            problemMap[path] = problemMap[path] || { error: 0, warning: 0 };
            for (const diag of diagnosticArr) {
                if (diag.severity === vscode.DiagnosticSeverity.Error) problemMap[path].error++;
                else if (diag.severity === vscode.DiagnosticSeverity.Warning) problemMap[path].warning++;
            }
        }
        return problemMap;
    }

    private async buildTreeFromTraversal(rootUri: vscode.Uri): Promise<FileNode> {
        const rootPath = rootUri.fsPath;
        const rootNode: FileNode = { name: path.basename(rootPath), absolutePath: normalizePath(rootPath), children: await this._traverseDirectory(rootUri), tokenCount: 0, fileCount: 0, isImage: false, sizeInBytes: 0, extension: '', isPdf: false, isExcel: false, isWordDoc: false, isSelectable: true, };
        this._aggregateStats(rootNode);
        return rootNode;
    }
    
    private _isSelectable(filePath: string, fileType: vscode.FileType): boolean {
        const normalizedPath = normalizePath(filePath);
        const name = path.basename(normalizedPath);
        
        return !NON_SELECTABLE_PATTERNS.some(pattern => {
            if (name === pattern) return true;
            if (normalizedPath.includes(`/${pattern}/`)) return true;
            if (pattern.startsWith('**/') && pattern.endsWith('/**')) {
                return normalizedPath.includes(`/${pattern.slice(3, -3)}/`);
            }
            if (name.startsWith(pattern)) return true;
            return false;
        });
    }

    private async _traverseDirectory(dirUri: vscode.Uri): Promise<FileNode[]> {
        const children: FileNode[] = [];
        try {
            const entries = await vscode.workspace.fs.readDirectory(dirUri);
            for (const [name, type] of entries) {
                const childUri = vscode.Uri.joinPath(dirUri, name);
                const childPath = normalizePath(childUri.fsPath);
                const isSelectable = this._isSelectable(childPath, type);
                if (type === vscode.FileType.Directory) {
                    const isSpecialDir = ['node_modules', '.git', 'venv', '.venv', 'dist', '.next'].includes(name.toLowerCase());
                    const dirNode: FileNode = { name, absolutePath: childPath, children: isSpecialDir ? [] : await this._traverseDirectory(childUri), tokenCount: 0, fileCount: 0, isImage: false, sizeInBytes: 0, extension: '', isPdf: false, isExcel: false, isWordDoc: false, isSelectable };
                    this._aggregateStats(dirNode);
                    children.push(dirNode);
                } else if (type === vscode.FileType.File) {
                    const stats = await this.getFileStats(childPath);
                    children.push({ name, absolutePath: childPath, ...stats, isSelectable });
                }
            }
        } catch (error: any) {
            Services.loggerService.error(`Error traversing directory ${dirUri.fsPath}: ${error.message}`);
        }
        return children.sort((a, b) => (!!a.children === !!b.children) ? a.name.localeCompare(b.name, undefined, { numeric: true, sensitivity: 'base' }) : (!!a.children ? -1 : 1));
    }

    private _aggregateStats(node: FileNode): void {
        if (!node.children) return;
        if (['node_modules', '.git', 'venv', '.venv', 'dist', '.next'].includes(node.name.toLowerCase())) {
            node.tokenCount = 0;
            node.fileCount = 0;
            node.sizeInBytes = 0;
            return; 
        }
        let totalTokens = 0, totalFiles = 0, totalBytes = 0;
        for (const child of node.children) {
            totalTokens += child.tokenCount;
            totalFiles += child.fileCount;
            totalBytes += child.sizeInBytes;
        }
        node.tokenCount = totalTokens;
        node.fileCount = totalFiles;
        node.sizeInBytes = totalBytes;
    }
}
</file_artifact>

<file path="src/backend/services/flattener.service.ts">
// Updated on: C127 (Implement Directory Summarization d-info)
import * as vscode from 'vscode';
import * as path from 'path';
import * as fs from 'fs/promises';
import { Services } from './services';
import { VIEW_TYPES } from '@/common/view-types';
import { serverIPCs } from '@/client/views';
import { ServerToClientChannel } from '@/common/ipc/channels.enum';
import { formatBytes } from '@/common/utils/formatting';

interface FileStats {
    filePath: string;
    lines: number;
    characters: number;
    tokens: number;
    content: string;
    error: string | null;
    isBinary: boolean;
    sizeInBytes: number;
}

const BINARY_EXTENSIONS = new Set(['.png', '.jpg', '.jpeg', '.gif', '.bmp', '.svg', '.webp', '.ico', '.exe', '.dll', '.bin', '.zip', '.gz', '.7z', '.mp3', '.wav', '.mov', '.mp4']);
const EXCEL_EXTENSIONS = new Set(['.xlsx', '.xls', '.csv']);
const WORD_EXTENSIONS = new Set(['.docx', '.doc']);
const NON_SELECTABLE_PATTERNS = ['/node_modules', '/.vscode', '/.git', '/venv', '/.venv', 'flattened_repo.md', 'prompt.md', 'package-lock.json', 'tsconfig.tsbuildinfo'];

const normalizePath = (p: string) => p.replace(/\\/g, '/');

export class FlattenerService {

    public async getFlattenedContent(selectedPaths: string[]): Promise<string> {
        const workspaceFolders = vscode.workspace.workspaceFolders;
        if (!workspaceFolders || workspaceFolders.length === 0 || selectedPaths.length === 0) {
            return '<!-- No files selected for flattening -->';
        }
        
        const rootPath = workspaceFolders[0].uri.fsPath;
        const allFilePaths = await this.expandDirectories(selectedPaths);
        const uniqueFilePaths = [...new Set(allFilePaths)];

        // C127: Consolidate large directories
        const { paths: processedPaths, summaryMap } = this.consolidateSelections(uniqueFilePaths);

        const fileStatsPromises = processedPaths.map(filePath => this.getFileStatsAndContent(filePath, rootPath, summaryMap.get(filePath)));
        const results = await Promise.all(fileStatsPromises);
        
        return this.generateOutputContent(results, rootPath, 'in-memory-prompt.md', false);
    }

    public async flatten(selectedPaths: string[]) {
        const workspaceFolders = vscode.workspace.workspaceFolders;
        if (!workspaceFolders || workspaceFolders.length === 0) {
            vscode.window.showErrorMessage("Cannot flatten context: No workspace folder is open.");
            return;
        }
        if (selectedPaths.length === 0) {
            vscode.window.showWarningMessage("Cannot flatten context: No files or folders are selected.");
            return;
        }

        const rootPath = workspaceFolders[0].uri.fsPath;
        const outputFilePath = path.join(rootPath, 'flattened_repo.md');

        try {
            const allFilePaths = await this.expandDirectories(selectedPaths);
            const uniqueFilePaths = [...new Set(allFilePaths.map(p => normalizePath(p)))];

            // C127: Consolidate large directories
            const { paths: processedPaths, summaryMap } = this.consolidateSelections(uniqueFilePaths);

            const fileStatsPromises = processedPaths.map(filePath => this.getFileStatsAndContent(filePath, rootPath, summaryMap.get(filePath)));
            const results = await Promise.all(fileStatsPromises);
            const validResults = results.filter(r => !r.error);

            const outputContent = this.generateOutputContent(results, rootPath, outputFilePath, true);

            await fs.writeFile(outputFilePath, outputContent, 'utf-8');
            vscode.window.showInformationMessage(`Successfully flattened ${validResults.length} files to flattened_repo.md.`);
            
            const isFileOpen = vscode.window.visibleTextEditors.some(editor => editor.document.uri.fsPath === outputFilePath);
            if (!isFileOpen) {
                await Services.fileOperationService.handleOpenFileRequest(outputFilePath);
            }

            const serverIpc = serverIPCs[VIEW_TYPES.SIDEBAR.CONTEXT_CHOOSER];
            if (serverIpc) {
                setTimeout(() => {
                    serverIpc.sendToClient(ServerToClientChannel.FocusFile, { path: outputFilePath });
                }, 500);
            }

        } catch (error: any) {
            vscode.window.showErrorMessage(`Failed to flatten context: ${error.message}`);
        }
    }

    // C127: Group files by directory and summarize if > 50
    private consolidateSelections(paths: string[]): { paths: string[], summaryMap: Map<string, string[]> } {
        const dirMap = new Map<string, string[]>();
        const summaryMap = new Map<string, string[]>();
        const finalPaths: string[] = [];

        // 1. Group files by directory
        for (const p of paths) {
            const dir = path.dirname(p);
            if (!dirMap.has(dir)) dirMap.set(dir, []);
            dirMap.get(dir)!.push(p);
        }

        // 2. Decide whether to summarize
        for (const [dir, files] of dirMap.entries()) {
            if (files.length > 50) { // Threshold
                const dInfoPath = path.join(dir, 'd-info.md').replace(/\\/g, '/');
                summaryMap.set(dInfoPath, files.sort());
                finalPaths.push(dInfoPath);
            } else {
                finalPaths.push(...files);
            }
        }

        return { paths: finalPaths, summaryMap };
    }

    private async expandDirectories(paths: string[]): Promise<string[]> {
        const uniquePaths = [...new Set(paths.map(normalizePath))]; 
        const allFiles: string[] = [];
        for (const p of uniquePaths) {
            try {
                const stats = await fs.stat(p);
                if (stats.isDirectory()) {
                    allFiles.push(...await this.getAllFilesRecursive(p));
                } else {
                    allFiles.push(p);
                }
            } catch (e) {
                // Ignore errors for paths that might not exist
            }
        }
        return allFiles;
    }

    private async getAllFilesRecursive(dirPath: string): Promise<string[]> {
        let files: string[] = [];
        const normalizedDirPath = normalizePath(dirPath);
        try {
            const entries = await fs.readdir(normalizedDirPath, { withFileTypes: true });
            for (const entry of entries) {
                const fullPath = path.join(normalizedDirPath, entry.name);
                const normalizedFullPath = normalizePath(fullPath);

                if (NON_SELECTABLE_PATTERNS.some(p => normalizedFullPath.includes(p) || entry.name === p)) {
                    continue;
                }

                if (entry.isDirectory()) {
                    files = files.concat(await this.getAllFilesRecursive(normalizedFullPath));
                } else {
                    files.push(normalizedFullPath);
                }
            }
        } catch (e) {
            // Ignore errors
        }
        return files;
    }

    private async _parseImageMetadata(filePath: string): Promise<any> {
        try {
            const buffer = await fs.readFile(filePath);
            const sizeInBytes = buffer.length;
            const metadata: any = { sizeInBytes };

            if (buffer.length > 24 && buffer.toString('hex', 0, 8) === '89504e470d0a1a0a') { // PNG
                const ihdrIndex = buffer.indexOf('IHDR');
                if (ihdrIndex !== -1) metadata.dimensions = { width: buffer.readUInt32BE(ihdrIndex + 4), height: buffer.readUInt32BE(ihdrIndex + 8) };
            } else if (buffer.length > 10 && buffer.toString('utf8', 0, 3) === 'GIF') { // GIF
                 metadata.dimensions = { width: buffer.readUInt16LE(6), height: buffer.readUInt16LE(8) };
            } else if (buffer.length > 11 && buffer[0] === 0xff && buffer[1] === 0xd8) { // JPEG
                let pos = 2;
                while (pos < buffer.length - 9) {
                    if (buffer[pos] === 0xff && (buffer[pos + 1] & 0xf0) === 0xc0) {
                        metadata.dimensions = { width: buffer.readUInt16BE(pos + 7), height: buffer.readUInt16BE(pos + 5) };
                        break;
                    }
                    pos += buffer[pos + 2] ? buffer.readUInt16BE(pos + 2) + 2 : 1;
                }
            }
            return metadata;
        } catch (err: any) {
            try { return { sizeInBytes: (await fs.stat(filePath)).size }; } catch { return { sizeInBytes: -1 }; }
        }
    }

    private async getFileStatsAndContent(filePath: string, rootPath: string, summaryFiles?: string[]): Promise<FileStats> {
        const extension = path.extname(filePath).toLowerCase();
        
        // C127: Handle virtual d-info.md
        if (path.basename(filePath) === 'd-info.md' && summaryFiles) {
            const relativeDir = path.relative(rootPath, path.dirname(filePath)).replace(/\\/g, '/');
            let content = `<d-info.md (directory info)>\n`;
            content += `File Count: ${summaryFiles.length}\n`;
            content += `Directory Located at: ${relativeDir}/\n`;
            content += `Files:\n`;
            summaryFiles.forEach((f, i) => {
                content += `${i + 1}. ${path.basename(f)}\n`;
            });
            content += `</d-info.md (directory info)>`;
            
            return { 
                filePath, 
                lines: content.split('\n').length, 
                characters: content.length, 
                tokens: Math.ceil(content.length / 4), 
                content, 
                error: null, 
                isBinary: false, 
                sizeInBytes: 0 
            };
        }

        if (extension === '.pdf') {
            const virtualContent = Services.contentExtractionService.getVirtualPdfContent(filePath);
            if (virtualContent) return { filePath, content: virtualContent.text, lines: virtualContent.text.split('\n').length, characters: virtualContent.text.length, tokens: virtualContent.tokenCount, error: null, isBinary: false, sizeInBytes: 0 };
            return { filePath, lines: 0, characters: 0, tokens: 0, content: '<!-- PDF content not processed or cached -->', error: null, isBinary: false, sizeInBytes: 0 };
        }

        if (EXCEL_EXTENSIONS.has(extension)) {
            const virtualContent = Services.contentExtractionService.getVirtualExcelContent(filePath);
            if (virtualContent) return { filePath, content: virtualContent.markdown, lines: virtualContent.markdown.split('\n').length, characters: virtualContent.markdown.length, tokens: virtualContent.tokenCount, error: null, isBinary: false, sizeInBytes: 0 };
            return { filePath, lines: 0, characters: 0, tokens: 0, content: '<!-- Excel/CSV content not processed or cached -->', error: null, isBinary: false, sizeInBytes: 0 };
        }

        if (WORD_EXTENSIONS.has(extension)) {
            const virtualContent = Services.contentExtractionService.getVirtualWordContent(filePath);
            if (virtualContent) {
                const content = virtualContent.text === "UNSUPPORTED_FORMAT" ? `<!-- Content of .doc file '${path.basename(filePath)}' could not be extracted. Legacy .doc format is not supported. Please convert to .docx. -->` : virtualContent.text;
                return { filePath, content: content, lines: content.split('\n').length, characters: content.length, tokens: virtualContent.tokenCount, error: null, isBinary: false, sizeInBytes: 0 };
            }
            return { filePath, lines: 0, characters: 0, tokens: 0, content: '<!-- Word content not processed or cached -->', error: null, isBinary: false, sizeInBytes: 0 };
        }

        if (BINARY_EXTENSIONS.has(extension)) {
            try {
                const imageMetadata = await this._parseImageMetadata(filePath);
                const metadata = { name: path.basename(filePath), directory: path.dirname(filePath), fileType: extension.substring(1).toUpperCase(), sizeInBytes: imageMetadata.sizeInBytes, ...(imageMetadata.dimensions && { dimensions: imageMetadata.dimensions }) };
                const metadataContent = `<metadata>\n${JSON.stringify(metadata, null, 2)}\n</metadata>`;
                return { filePath, lines: 0, characters: 0, tokens: 0, content: metadataContent, error: null, isBinary: true, sizeInBytes: imageMetadata.sizeInBytes };
            } catch (error: any) {
                 return { filePath, lines: 0, characters: 0, tokens: 0, content: '', error: `Could not get stats for binary file: ${error.message}`, isBinary: true, sizeInBytes: -1 };
            }
        }

        try {
            const content = await fs.readFile(filePath, 'utf-8');
            const stats = await fs.stat(filePath);
            return { filePath, lines: content.split('\n').length, characters: content.length, tokens: Math.ceil(content.length / 4), content, error: null, isBinary: false, sizeInBytes: stats.size };
        } catch (error: any) {
            return { filePath, lines: 0, characters: 0, tokens: 0, content: '', error: error.message, isBinary: false, sizeInBytes: -1 };
        }
    }

    private generateOutputContent(results: FileStats[], rootDir: string, outputFilename: string, includeHeader: boolean): string {
        const validResults = results.filter(r => !r.error);
        
        let output = '';

        if (includeHeader) {
            const totalTokens = validResults.reduce((sum, r) => sum + r.tokens, 0);
            output += `<!--\n  File: ${path.basename(outputFilename)}\n  Source Directory: ${rootDir}\n  Date Generated: ${new Date().toISOString()}\n  ---\n`;
            output += `  Total Files: ${validResults.length}\n  Approx. Tokens: ${totalTokens}\n-->\n\n`;
            
            output += `<!-- Top 10 Text Files by Token Count -->\n`;
            [...validResults].filter(r => r.tokens > 0).sort((a, b) => b.tokens - a.tokens).slice(0, 10)
                .forEach((r, i) => output += `${i + 1}. ${path.relative(rootDir, r.filePath)} (${r.tokens} tokens)\n`);
            output += `\n`;

            output += `<!-- Full File List -->\n`;
            results.forEach((r, i) => {
                const relPath = path.relative(rootDir, r.filePath);
                if (r.error) output += `${i + 1}. ${relPath} - ERROR: ${r.error}\n`;
                else if (r.isBinary) output += `${i + 1}. ${relPath} - [Binary] Size: ${formatBytes(r.sizeInBytes)}\n`;
                else output += `${i + 1}. ${relPath} - Lines: ${r.lines} - Chars: ${r.characters} - Tokens: ${r.tokens}\n`;
            });
            output += `\n`;
        }

        for (const { filePath, content, error } of results) {
            const relativePath = path.relative(rootDir, filePath).replace(/\\/g, '/');
            output += `<file path="${relativePath}">\n`;
            output += error ? `Error reading file: ${error}\n` : content;
            if (content && !content.endsWith('\n')) output += '\n';
            output += `</file_artifact>\n\n`;
        }
        return output;
    }
}
</file_artifact>

<file path="src/backend/services/git.service.ts">
// src/backend/services/git.service.ts
// Updated on: C12 (Refine Restore logic)
import * as vscode from 'vscode';
import { exec } from 'child_process';
import * as path from 'path';
import { Services } from './services';
import { ServerPostMessageManager } from '@/common/ipc/server-ipc';
import { ServerToClientChannel } from '@/common/ipc/channels.enum';

export class GitService {
    private getWorkspaceRoot(): string | undefined {
        return vscode.workspace.workspaceFolders?.[0]?.uri.fsPath;
    }

    private async execGitCommand(command: string): Promise<{ stdout: string; stderr: string }> {
        const workspaceRoot = this.getWorkspaceRoot();
        if (!workspaceRoot) {
            throw new Error("No workspace folder open.");
        }

        return new Promise((resolve, reject) => {
            exec(command, { cwd: workspaceRoot }, (error, stdout, stderr) => {
                if (error) {
                    Services.loggerService.error(`Git command error: ${error.message}`);
                    reject(error);
                    return;
                }
                if (stderr) {
                    Services.loggerService.warn(`Git command stderr: ${stderr}`);
                }
                resolve({ stdout, stderr });
            });
        });
    }

    public async handleGitInitRequest() {
        Services.loggerService.log("Executing Git Init.");
        try {
            await this.execGitCommand('git init');
            vscode.window.showInformationMessage("Successfully initialized Git repository. You can now create a baseline.");
        } catch (error: any) {
            vscode.window.showErrorMessage(`Failed to initialize Git repository: ${error.message}`);
        }
    }

    public async handleGitStatusRequest(serverIpc: ServerPostMessageManager) {
        Services.loggerService.log("Executing Git Status check.");
        try {
            const { stdout } = await this.execGitCommand('git status --porcelain');
            const isClean = stdout.trim() === '';
            serverIpc.sendToClient(ServerToClientChannel.SendGitStatus, { isClean });
        } catch (error) {
            serverIpc.sendToClient(ServerToClientChannel.SendGitStatus, { isClean: false });
        }
    }

    public async handleGitBaselineRequest(commitMessage: string, serverIpc: ServerPostMessageManager) {
        Services.loggerService.log(`Executing Git Baseline with message: "${commitMessage}"`);
        let result = { success: false, message: 'An unknown error occurred.' };
        try {
            const { stdout: statusOutput } = await this.execGitCommand('git status --porcelain');
            if (statusOutput.trim() === '') {
                result = { success: true, message: 'Workspace is already clean. No baseline needed.' };
            } else {
                await this.execGitCommand('git add .');
                const { stderr } = await this.execGitCommand(`git commit -m "${commitMessage.replace(/"/g, '\\"')}"`);
                if (stderr && stderr.includes('nothing to commit')) {
                    result = { success: true, message: 'You are already baselined.' };
                } else {
                    result = { success: true, message: 'Successfully created baseline commit.' };
                }
            }
        } catch (error: any) {
            if (error.message.includes('fatal: not a git repository')) {
                const openReadme = 'Open README Guide';
                const initRepo = 'Initialize Repository';
                vscode.window.showErrorMessage(
                    'This is not a Git repository. Please initialize it first to use the baseline feature.',
                    openReadme,
                    initRepo
                ).then(selection => {
                    if (selection === openReadme) {
                        const workspaceRoot = this.getWorkspaceRoot();
                        if (workspaceRoot) {
                            const readmePath = path.join(workspaceRoot, 'src', 'Artifacts', 'DCE_README.md');
                            vscode.workspace.openTextDocument(vscode.Uri.file(readmePath)).then(doc => {
                                vscode.window.showTextDocument(doc);
                            });
                        }
                    } else if (selection === initRepo) {
                        vscode.commands.executeCommand('dce.gitInit');
                    }
                });
                return; 
            }
            result = { success: false, message: `Git Baseline failed: ${error.message}` };
        }
        Services.loggerService.log(`[GIT_SERVICE] Sending NotifyGitOperationResult: ${JSON.stringify(result)}`);
        serverIpc.sendToClient(ServerToClientChannel.NotifyGitOperationResult, result);
    }

    public async handleGitRestoreRequest(filesToDelete: string[], serverIpc: ServerPostMessageManager) {
        Services.loggerService.log("Executing Git Restore.");
        let result = { success: false, message: 'An unknown error occurred.' };
        const workspaceRoot = this.getWorkspaceRoot();
        if (!workspaceRoot) {
            result = { success: false, message: 'No workspace open.'};
            serverIpc.sendToClient(ServerToClientChannel.NotifyGitOperationResult, result);
            return;
        }

        try {
            // 1. Revert changes to all tracked files, excluding the history file
            const restoreCommand = `git restore -- . ":(exclude).vscode/dce_history.json"`;
            await this.execGitCommand(restoreCommand);

            // 2. Surgically delete only the newly created files from the accepted response
            for (const file of filesToDelete) {
                const absolutePath = path.resolve(workspaceRoot, file);
                Services.loggerService.log(`[Restore] Deleting newly created file: ${absolutePath}`);
                await vscode.workspace.fs.delete(vscode.Uri.file(absolutePath), { recursive: true });
            }

            result = { success: true, message: 'Successfully restored workspace to baseline.' };
        } catch (error: any) {
            result = { success: false, message: `Git Restore failed: ${error.message}` };
        }
        serverIpc.sendToClient(ServerToClientChannel.NotifyGitOperationResult, result);
    }
}
</file_artifact>

<file path="src/backend/services/highlighting.service.ts">
// src/backend/services/highlighting.service.ts
// Updated on: C126 (Add JSON grammar)
import { createStarryNight, common } from '@wooorm/starry-night';
import sourceTsx from '@wooorm/starry-night/source.tsx';
import sourceJs from '@wooorm/starry-night/source.js';
import sourceTs from '@wooorm/starry-night/source.ts';
import sourceCss from '@wooorm/starry-night/source.css';
import sourceScss from '@wooorm/starry-night/source.css.scss';
import textHtml from '@wooorm/starry-night/text.html.basic';
import textMd from '@wooorm/starry-night/text.md';
import sourceJson from '@wooorm/starry-night/source.json'; // C126 Added
import { toHtml } from 'hast-util-to-html';
import { Services } from './services';
import { ServerPostMessageManager } from '@/common/ipc/server-ipc';
import { ServerToClientChannel } from '@/common/ipc/channels.enum';

export class HighlightingService {
    private starryNight: any = null;

    constructor() {
        this.initializeStarryNight();
    }

    private async initializeStarryNight() {
        try {
            // C126: Added sourceJson to the grammars list
            const grammars = [...common, sourceTsx, sourceJs, sourceTs, sourceCss, sourceScss, textHtml, textMd, sourceJson];
            this.starryNight = await createStarryNight(grammars);
            Services.loggerService.log('Starry Night syntax highlighter initialized.');
        } catch (error) {
            Services.loggerService.error(`Failed to initialize Starry Night: ${error}`);
        }
    }
    
    public async handleSyntaxHighlightRequest(code: string, lang: string, id: string, serverIpc: ServerPostMessageManager) {
        if (!this.starryNight) {
            Services.loggerService.error('Starry Night not initialized, cannot highlight.');
            serverIpc.sendToClient(ServerToClientChannel.SendSyntaxHighlight, { highlightedHtml: `<pre><code>${code}</code></pre>`, id });
            return;
        }

        // Map 'json' to 'source.json' explicitly if needed, though starry-night usually handles standard aliases.
        const scope = this.starryNight.flagToScope(lang);
        
        if (!scope) {
            Services.loggerService.warn(`[WARN] No Starry Night scope found for language: ${lang}. Defaulting to plain text.`);
            serverIpc.sendToClient(ServerToClientChannel.SendSyntaxHighlight, { highlightedHtml: `<pre><code>${code}</code></pre>`, id });
            return;
        }

        try {
            const tree = this.starryNight.highlight(code, scope);
            const hastHtml = toHtml(tree);
            const finalHtml = `<pre><code>${hastHtml}</code></pre>`;
            serverIpc.sendToClient(ServerToClientChannel.SendSyntaxHighlight, { highlightedHtml: finalHtml, id });
        } catch (error) {
            Services.loggerService.error(`Starry Night highlighting failed for lang ${lang}: ${error}`);
            serverIpc.sendToClient(ServerToClientChannel.SendSyntaxHighlight, { highlightedHtml: `<pre><code>${code}</code></pre>`, id });
        }
    }

    public async handleHighlightContextRequest(context: string, id: string, serverIpc: ServerPostMessageManager) {
        if (!this.starryNight) {
            serverIpc.sendToClient(ServerToClientChannel.SendHighlightContext, { highlightedHtml: context, id });
            return;
        }

        const scope = this.starryNight.flagToScope('markdown');
        try {
            const tree = this.starryNight.highlight(context, scope);
            const hastHtml = toHtml(tree);
            serverIpc.sendToClient(ServerToClientChannel.SendHighlightContext, { highlightedHtml: hastHtml, id });
        } catch (error) {
            serverIpc.sendToClient(ServerToClientChannel.SendHighlightContext, { highlightedHtml: context, id });
        }
    }
}
</file_artifact>

<file path="src/backend/services/history.service.ts">
// src/backend/services/history.service.ts
// Updated on: C126 (Include isCycleCollapsed in default cycle)
import * as vscode from 'vscode';
import * as path from 'path';
import { Services } from './services';
import { PcppCycle, PcppResponse } from '@/common/types/pcpp.types';
import { serverIPCs } from '@/client/views';
import { VIEW_TYPES } from '@/common/view-types';
import { ServerToClientChannel } from '@/common/ipc/channels.enum';
import { promises as fs } from 'fs';
import { getContext } from '@/extension';

const LAST_VIEWED_CYCLE_ID_KEY = 'dce.lastViewedCycleId';

export class HistoryService {
    private workspaceRoot: string | undefined;

    private get context(): vscode.ExtensionContext {
        return getContext();
    }

    constructor() {
        const workspaceFolders = vscode.workspace.workspaceFolders;
        if (workspaceFolders && workspaceFolders.length > 0) {
            this.workspaceRoot = workspaceFolders[0].uri.fsPath;
        }
    }

    public async getFullHistory(): Promise<any> {
        const projectScope = Services.databaseService.getGlobalValue<string>('project_scope');
        const cycles = Services.databaseService.getAllCycles();
        return { version: 1, projectScope, cycles };
    }

    public async saveLastViewedCycleId(id: number | null): Promise<void> {
        await this.context.workspaceState.update(LAST_VIEWED_CYCLE_ID_KEY, id);
    }

    public getLastViewedCycleId(): number | undefined {
        return this.context.workspaceState.get<number>(LAST_VIEWED_CYCLE_ID_KEY);
    }

    public async getInitialCycle(): Promise<PcppCycle> {
        if (!this.workspaceRoot) {
            return { cycleId: -1, timestamp: '', title: '', cycleContext: '', ephemeralContext: '', responses: {} };
        }

        let isFreshEnvironment = true;
        try {
            await vscode.workspace.fs.stat(vscode.Uri.file(path.join(this.workspaceRoot, 'src/Artifacts/DCE_README.md')));
            isFreshEnvironment = false;
        } catch (e) { isFreshEnvironment = true; }
        
        const settings = await Services.settingsService.getSettings();

        const defaultCycle: PcppCycle = {
            cycleId: isFreshEnvironment ? 0 : 1, 
            timestamp: new Date().toISOString(), 
            title: 'New Cycle', 
            cycleContext: '', 
            ephemeralContext: '', 
            responses: { "1": { content: "", status: 'complete' } }, 
            isParsedMode: false, 
            leftPaneWidth: 33, 
            selectedResponseId: null, 
            selectedFilesForReplacement: [], 
            tabCount: 4, 
            activeTab: 1,
            isSortedByTokens: false, 
            pathOverrides: {},
            activeWorkflowStep: null,
            status: 'complete',
            isEphemeralContextCollapsed: true,
            isCycleCollapsed: false, // C126: Default to expanded
            connectionMode: settings.connectionMode,
        };

        if (isFreshEnvironment) {
             return defaultCycle;
        }

        const cycles = Services.databaseService.getAllCycles();

        if (cycles.length === 0) {
            Services.databaseService.saveCycle(defaultCycle);
            return defaultCycle;
        }

        const lastViewedId = this.getLastViewedCycleId();
        const cycleMap = new Map(cycles.map(c => [c.cycleId, c]));

        if (lastViewedId !== undefined && cycleMap.has(lastViewedId)) {
            return cycleMap.get(lastViewedId)!;
        }
        
        const latestCycle = cycles.reduce((latest, current) => current.cycleId > latest.cycleId ? current : latest);
        return latestCycle;
    }

    public async getCycleData(cycleId: number): Promise<PcppCycle | null> {
        if (cycleId === 0) {
            const projectScope = Services.databaseService.getGlobalValue<string>('project_scope');
            const settings = await Services.settingsService.getSettings();
            return {
                cycleId: 0, timestamp: new Date().toISOString(), title: 'Project Setup', cycleContext: projectScope || '', ephemeralContext: '', responses: {}, isParsedMode: false, tabCount: 4, isSortedByTokens: false, pathOverrides: {}, status: 'complete', connectionMode: settings.connectionMode, isCycleCollapsed: false,
                selectedFilesForReplacement: []
            };
        }
        return Services.databaseService.getCycle(cycleId);
    }

    public async saveProjectScope(scope: string): Promise<void> {
        Services.databaseService.setGlobalValue('project_scope', scope);
        const serverIpc = serverIPCs[VIEW_TYPES.PANEL.PARALLEL_COPILOT];
        if (serverIpc) {
            serverIpc.sendToClient(ServerToClientChannel.NotifySaveComplete, { cycleId: 0 });
        }
    }

    public async saveCycleData(cycleData: PcppCycle): Promise<void> {
        const serverIpc = serverIPCs[VIEW_TYPES.PANEL.PARALLEL_COPILOT];

        if (cycleData.cycleId === 0) {
            await this.saveProjectScope(cycleData.cycleContext);
        } else {
            Services.databaseService.saveCycle(cycleData);
        }

        if (serverIpc) {
            serverIpc.sendToClient(ServerToClientChannel.NotifySaveComplete, { cycleId: cycleData.cycleId });
        }
    }

    public async createNewCyclePlaceholder(tabCount: number): Promise<{ newCycle: PcppCycle; newMaxCycle: number; }> {
        const cycles = Services.databaseService.getAllCycles();
        const newCycleId = (cycles.reduce((max, c) => Math.max(max, c.cycleId), 0)) + 1;

        const newResponses: { [tabId: string]: PcppResponse } = {};
        for(let i = 0; i < tabCount; i++) {
            newResponses[(i+1).toString()] = { content: '', status: 'generating' };
        }
        
        const settings = await Services.settingsService.getSettings();

        const newCycle: PcppCycle = {
            cycleId: newCycleId,
            timestamp: new Date().toISOString(),
            title: 'New Cycle',
            cycleContext: '',
            ephemeralContext: '',
            responses: newResponses,
            tabCount: tabCount,
            isParsedMode: true,
            status: 'generating',
            isEphemeralContextCollapsed: true,
            isCycleCollapsed: false,
            connectionMode: settings.connectionMode,
            selectedFilesForReplacement: []
        };

        Services.databaseService.saveCycle(newCycle);
        Services.loggerService.log(`Created new placeholder cycle ${newCycleId}.`);
        
        return { newCycle, newMaxCycle: newCycleId };
    }
    
    public async finalizeCycleStatus(cycleId: number): Promise<void> {
        const cycle = Services.databaseService.getCycle(cycleId);
        if (cycle) {
            cycle.status = 'complete';
            Services.databaseService.saveCycle(cycle);
            Services.loggerService.log(`[History] Cycle ${cycleId} status set to 'complete'.`);
        }
    }

    public async updateCycleWithResponses(cycleId: number, responses: PcppResponse[]): Promise<void> {
        const cycle = Services.databaseService.getCycle(cycleId);
        if (cycle) {
            Object.keys(cycle.responses).forEach((tabId, index) => {
                if (responses[index]) {
                    cycle.responses[tabId] = responses[index];
                }
            });
            Services.databaseService.saveCycle(cycle);
            Services.loggerService.log(`Updated cycle ${cycleId} with ${responses.length} responses.`);
        }
    }

    public async updateSingleResponseInCycle(cycleId: number, tabId: string, newResponse: PcppResponse | null): Promise<void> {
        const cycle = Services.databaseService.getCycle(cycleId);
        if (cycle) {
            if (newResponse !== null) {
                cycle.responses[tabId] = newResponse;
            } else {
                cycle.responses[tabId] = { content: '', status: 'generating' };
            }
            Services.databaseService.saveCycle(cycle);
        }
    }

    public async deleteCycle(cycleId: number): Promise<number> {
        const confirmation = await vscode.window.showWarningMessage(
            `Are you sure you want to delete Cycle ${cycleId}? This action cannot be undone.`,
            { modal: true },
            "Delete"
        );

        if (confirmation !== "Delete") {
            const cycles = Services.databaseService.getAllCycles();
            return cycles.reduce((max, c) => Math.max(max, c.cycleId), 0);
        }
        
        const cycles = Services.databaseService.getAllCycles();
        if (cycles.length <= 1) {
            vscode.window.showWarningMessage("Cannot delete the last cycle.");
            return 1;
        }

        Services.databaseService.deleteCycle(cycleId);
        
        const updatedCycles = Services.databaseService.getAllCycles();
        const newMaxCycle = updatedCycles.reduce((max, c) => Math.max(max, c.cycleId), 0);

        const serverIpc = serverIPCs[VIEW_TYPES.PANEL.PARALLEL_COPILOT];
        if (serverIpc) {
            serverIpc.sendToClient(ServerToClientChannel.ForceRefresh, { reason: 'history' });
        }
        return newMaxCycle;
    }

    public async resetHistory(): Promise<void> {
        const confirmation = await vscode.window.showWarningMessage(
            "Are you sure you want to delete ALL cycle history? This action cannot be undone.",
            { modal: true },
            "Delete All"
        );

        if (confirmation !== "Delete All") {
            return;
        }

        Services.databaseService.reset();
        await this.saveLastViewedCycleId(null);
        const serverIpc = serverIPCs[VIEW_TYPES.PANEL.PARALLEL_COPILOT];
        if (serverIpc) {
            serverIpc.sendToClient(ServerToClientChannel.ForceRefresh, { reason: 'history' });
        }
    }

    public async handleExportHistory() {
        if (!this.workspaceRoot) {
            vscode.window.showErrorMessage("No workspace open.");
            return;
        }
        try {
            const historyContent = await this.getFullHistory();
            const saveUri = await vscode.window.showSaveDialog({
                defaultUri: vscode.Uri.file(path.join(this.workspaceRoot, 'dce_history_export.json')),
                filters: { 'JSON': ['json'] }
            });
            if (saveUri) {
                await fs.writeFile(saveUri.fsPath, JSON.stringify(historyContent, null, 2), 'utf-8');
                vscode.window.showInformationMessage("Cycle history exported successfully.");
            }
        } catch (error: any) {
            vscode.window.showErrorMessage(`Failed to export history: ${error.message}`);
        }
    }

    public async handleImportHistory() {
        if (!this.workspaceRoot) {
            vscode.window.showErrorMessage("No workspace open.");
            return;
        }
        try {
            const openUris = await vscode.window.showOpenDialog({
                canSelectMany: false,
                filters: { 'JSON': ['json'] }
            });
            if (openUris && openUris.length > 0) {
                const content = await fs.readFile(openUris[0].fsPath, 'utf-8');
                const historyData = JSON.parse(content);
                if (historyData.version && Array.isArray(historyData.cycles)) {
                    // Wipe DB and load from JSON
                    Services.databaseService.reset();
                    
                    if (historyData.projectScope) {
                        Services.databaseService.setGlobalValue('project_scope', historyData.projectScope);
                    }
                    
                    for (const cycle of historyData.cycles) {
                        Services.databaseService.saveCycle(cycle);
                    }

                    await this.saveLastViewedCycleId(null);
                    vscode.window.showInformationMessage("Cycle history imported successfully. Reloading...");
                    const serverIpc = serverIPCs[VIEW_TYPES.PANEL.PARALLEL_COPILOT];
                    if (serverIpc) {
                        serverIpc.sendToClient(ServerToClientChannel.ForceRefresh, { reason: 'history' });
                    }
                } else {
                    throw new Error("Invalid history file format.");
                }
            }
        } catch (error: any) {
            vscode.window.showErrorMessage(`Failed to import history: ${error.message}`);
        }
    }
}
</file_artifact>

<file path="src/backend/services/llm.service.ts">
// src/backend/services/llm.service.ts
// Updated on: C116 (Ensure shared agentkeepalive is used for all requests)
import { Services } from './services';
import fetch from 'node-fetch';
import { PcppCycle, PcppResponse } from '@/common/types/pcpp.types';
import { ServerPostMessageManager } from '@/common/ipc/server-ipc';
import { serverIPCs } from '@/client/views';
import { VIEW_TYPES } from '@/common/view-types';
import { ServerToClientChannel } from '@/common/ipc/channels.enum';
import { GenerationProgress } from '@/common/ipc/channels.type';
import { Readable } from 'stream';
import { HttpsAgent } from 'agentkeepalive';

const MAX_TOKENS_PER_RESPONSE = 16384;
const generationControllers = new Map<string, AbortController>();

// C116 FIX: Create a single, shared agent instance to be used for all requests.
const httpsAgent = new HttpsAgent({
    maxSockets: 100,
    maxFreeSockets: 10,
    timeout: 60000,
    freeSocketTimeout: 30000,
});

export class LlmService {

    public stopSingleGeneration(cycleId: number, responseId: number) {
        const controllerKey = `${cycleId}_${responseId}`;
        if (generationControllers.has(controllerKey)) {
            Services.loggerService.log(`[LLM Service] Aborting generation for cycle ${cycleId}, response ${responseId}.`);
            generationControllers.get(controllerKey)?.abort();
        }
    }

    public stopBatchGeneration(cycleId: number) {
        Services.loggerService.log(`[LLM Service] Aborting all generations for cycle ${cycleId}.`);
        for (const [key, controller] of generationControllers.entries()) {
            if (key.startsWith(`${cycleId}_`)) {
                controller.abort();
            }
        }
    }
    
    public async generateSingle(prompt: string, cycleId: number, tabId: string) {
        Services.loggerService.log(`[LLM Service] Starting single regeneration for cycle ${cycleId}, tab ${tabId}.`);
        await Services.historyService.updateSingleResponseInCycle(cycleId, tabId, null);

        const settings = await Services.settingsService.getSettings();
        const serverIpc = serverIPCs[VIEW_TYPES.PANEL.PARALLEL_COPILOT];
        if (!serverIpc) return;

        let endpointUrl = '';
        let requestBodyBase: any = {};
        const reasoningEffort = 'medium';

        switch (settings.connectionMode) {
            case 'demo':
                endpointUrl = 'https://aiascent.game/api/dce/proxy';
                requestBodyBase = { model: "unsloth/gpt-oss-20b", messages: [{ role: "user", content: prompt }], max_tokens: MAX_TOKENS_PER_RESPONSE, stream: true, reasoning_effort: reasoningEffort };
                break;
            case 'url':
                endpointUrl = settings.apiUrl || '';
                requestBodyBase = { model: "local-model", messages: [{ role: "user", content: prompt }], max_tokens: MAX_TOKENS_PER_RESPONSE, stream: true, reasoning_effort: reasoningEffort };
                break;
            default: return;
        }

        const controller = new AbortController();
        const responseId = parseInt(tabId, 10);
        const controllerKey = `${cycleId}_${responseId}`;
        generationControllers.set(controllerKey, controller);

        const finalResponse = await this._generateSingleStream(endpointUrl, { ...requestBodyBase, n: 1 }, controller, cycleId, responseId, serverIpc);
        
        await Services.historyService.updateSingleResponseInCycle(cycleId, tabId, finalResponse);
        serverIpc.sendToClient(ServerToClientChannel.NotifySingleResponseComplete, { responseId: parseInt(tabId), content: finalResponse.content });
        Services.loggerService.log(`[LLM Service] Single regeneration for C${cycleId}/T${tabId} complete.`);
    }

    private _generateSingleStream(url: string, body: any, controller: AbortController, cycleId: number, responseId: number, serverIpc: ServerPostMessageManager): Promise<PcppResponse> {
        const controllerKey = `${cycleId}_${responseId}`;
        
        return new Promise(async (resolve) => {
            let responseContent = '';
            const richResponse: PcppResponse = { content: '', status: 'pending', startTime: Date.now() };
            const progress: GenerationProgress = { responseId, promptTokens: 0, thinkingTokens: 0, currentTokens: 0, totalTokens: MAX_TOKENS_PER_RESPONSE, status: 'pending', startTime: Date.now() };
            let buffer = '';

            try {
                const response = await fetch(url, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(body),
                    signal: controller.signal,
                    agent: httpsAgent, // C116 FIX: Ensure the shared agent is used here
                });

                if (!response.ok || !response.body) { throw new Error(`API request failed: ${response.status} ${await response.text()}`); }
                
                const stream = response.body;

                stream.on('data', (chunk) => {
                    buffer += chunk.toString();
                    let boundaryIndex;
                    while ((boundaryIndex = buffer.indexOf('\n\n')) !== -1) {
                        const message = buffer.substring(0, boundaryIndex);
                        buffer = buffer.substring(boundaryIndex + 2);
                        
                        const lines = message.split('\n');
                        for (const line of lines) {
                            if (line.startsWith('data: ')) {
                                const dataStr = line.substring(6).trim();
                                if (dataStr === '[DONE]') continue;
                                
                                try {
                                    const data = JSON.parse(dataStr);
                                    if (data.choices?.[0]?.finish_reason !== null) {
                                        richResponse.status = 'complete';
                                        richResponse.endTime = Date.now();
                                        progress.status = 'complete';
                                    } else if (data.choices?.[0]?.delta) {
                                        const delta = data.choices[0].delta;
                                        if (delta.reasoning_content) {
                                            if (richResponse.status !== 'thinking') { richResponse.status = 'thinking'; progress.status = 'thinking'; }
                                            const contentChunk = delta.reasoning_content;
                                            const chunkTokens = Math.ceil(contentChunk.length / 4);
                                            richResponse.thinkingTokens = (richResponse.thinkingTokens || 0) + chunkTokens;
                                            progress.thinkingTokens += chunkTokens;
                                        }
                                        if (delta.content) {
                                            if (richResponse.status !== 'generating') { richResponse.status = 'generating'; progress.status = 'generating'; richResponse.thinkingEndTime = Date.now(); }
                                            const contentChunk = delta.content;
                                            responseContent += contentChunk;
                                            const chunkTokens = Math.ceil(contentChunk.length / 4);
                                            richResponse.responseTokens = (richResponse.responseTokens || 0) + chunkTokens;
                                            progress.currentTokens += chunkTokens;
                                        }
                                    }
                                } catch (e) {
                                    Services.loggerService.warn(`Could not parse JSON object from stream message: ${dataStr}`);
                                }
                            }
                        }
                    }
                    serverIpc.sendToClient(ServerToClientChannel.UpdateSingleGenerationProgress, { progress, content: responseContent });
                });

                stream.on('end', () => {
                    generationControllers.delete(controllerKey);
                    richResponse.content = responseContent;
                    progress.status = 'complete';
                    serverIpc.sendToClient(ServerToClientChannel.UpdateSingleGenerationProgress, { progress, content: responseContent });
                    resolve(richResponse);
                });

                stream.on('error', (err: any) => {
                    if (err.name === 'AbortError') {
                        Services.loggerService.log(`[LLM Stream] Stream for C${cycleId}/R${responseId} was aborted.`);
                        generationControllers.delete(controllerKey);
                        richResponse.content = responseContent;
                        richResponse.status = 'stopped';
                        progress.status = 'stopped';
                        serverIpc.sendToClient(ServerToClientChannel.UpdateSingleGenerationProgress, { progress, content: responseContent });
                        resolve(richResponse);
                    } else {
                        throw err;
                    }
                });

            } catch (error: any) {
                generationControllers.delete(controllerKey);
                if (error.name === 'AbortError') {
                    Services.loggerService.log(`[LLM Fetch] Fetch for C${cycleId}/R${responseId} was aborted.`);
                    richResponse.content = responseContent;
                    richResponse.status = 'stopped';
                    progress.status = 'stopped';
                } else {
                    Services.loggerService.error(`Failed to generate single stream for C${cycleId}/R${responseId}: ${error.message || error}`);
                    richResponse.status = 'error';
                    progress.status = 'error';
                }
                serverIpc.sendToClient(ServerToClientChannel.UpdateSingleGenerationProgress, { progress, content: responseContent });
                resolve(richResponse);
            }
        });
    }

    public async generateBatch(prompt: string, count: number, cycleData: PcppCycle): Promise<PcppResponse[]> {
        const settings = await Services.settingsService.getSettings();
        const serverIpc = serverIPCs[VIEW_TYPES.PANEL.PARALLEL_COPILOT];
        if (!serverIpc) return [];

        let endpointUrl = '';
        let requestBodyBase: any = {};
        const reasoningEffort = 'medium';

        switch (settings.connectionMode) {
            case 'demo':
                endpointUrl = 'https://aiascent.game/api/dce/proxy';
                requestBodyBase = { model: "unsloth/gpt-oss-20b", messages: [{ role: "user", content: prompt }], max_tokens: MAX_TOKENS_PER_RESPONSE, stream: true, reasoning_effort: reasoningEffort };
                break;
            case 'url':
                endpointUrl = settings.apiUrl || '';
                requestBodyBase = { model: "local-model", messages: [{ role: "user", content: prompt }], max_tokens: MAX_TOKENS_PER_RESPONSE, stream: true, reasoning_effort: reasoningEffort };
                break;
            default: return [];
        }

        if (!endpointUrl) {
            Services.loggerService.error("LLM endpoint URL is not configured.");
            return [];
        }

        const promises = Array.from({ length: count }, (_, i) => {
            const responseId = i + 1;
            const controllerKey = `${cycleData.cycleId}_${responseId}`;
            const controller = new AbortController();
            generationControllers.set(controllerKey, controller);

            return this._generateSingleStream(
                endpointUrl,
                { ...requestBodyBase, n: 1 },
                controller,
                cycleData.cycleId,
                responseId,
                serverIpc
            ).catch(error => {
                Services.loggerService.error(`Error in stream for C${cycleData.cycleId}/R${responseId}: ${error.message}`);
                return {
                    content: `Error generating response: ${error.message}`,
                    status: 'error' as 'error',
                    startTime: Date.now(),
                    endTime: Date.now()
                };
            });
        });

        const richResponses = await Promise.all(promises);
        
        let allFinished = true;
        for (const key of generationControllers.keys()) {
            if (key.startsWith(`${cycleData.cycleId}_`)) {
                allFinished = false;
                break;
            }
        }
        
        if (allFinished) {
            Services.loggerService.log(`All streams for cycle ${cycleData.cycleId} are complete.`);
        }

        return richResponses;
    }

    private throttle(func: (...args: any[]) => void, limit: number) {
        let inThrottle: boolean;
        let lastFunc: NodeJS.Timeout;
        let lastRan: number;
        return function(this: any, ...args: any[]) {
            const context = this;
            if (!inThrottle) {
                func.apply(context, args);
                lastRan = Date.now();
                inThrottle = true;
            } else {
                clearTimeout(lastFunc);
                lastFunc = setTimeout(function() {
                    if ((Date.now() - lastRan) >= limit) {
                        func.apply(context, args);
                        lastRan = Date.now();
                    }
                }, limit - (Date.now() - lastRan));
            }
        };
    }
}
</file_artifact>

<file path="src/backend/services/logger.service.ts">
import * as vscode from 'vscode';

export class LoggerService {
    private static instance: LoggerService;
    private outputChannel: vscode.OutputChannel;

    private constructor() {
        this.outputChannel = vscode.window.createOutputChannel("Data Curation Environment");
    }

    public static getInstance(): LoggerService {
        if (!LoggerService.instance) {
            LoggerService.instance = new LoggerService();
        }
        return LoggerService.instance;
    }

    public show() {
        this.outputChannel.show(true); // true => preserve focus
    }

    private logMessage(level: 'INFO' | 'WARN' | 'ERROR', message: string): void {
        const timestamp = new Date().toLocaleTimeString();
        this.outputChannel.appendLine(`[${level}] [${timestamp}] ${message}`);
    }

    public log(message: string): void {
        this.logMessage('INFO', message);
    }

    public warn(message: string): void {
        this.logMessage('WARN', message);
    }

    public error(message: string): void {
        this.logMessage('ERROR', message);
    }
}
</file_artifact>

<file path="src/backend/services/prompt.service.ts">
// src/backend/services/prompt.service.ts
// Updated on: C128 (Use markdown preview for README, log selection count)
import * as vscode from 'vscode';
import * as path from 'path';
import { promises as fs } from 'fs';
import { Services } from './services';
import { parseResponse } from '@/client/utils/response-parser';
import { PcppCycle } from '@/common/types/pcpp.types';
import { truncateCodeForLogging, calculatePromptCost } from '@/common/utils/formatting';
import { ServerPostMessageManager } from '@/common/ipc/server-ipc';
import { ServerToClientChannel } from '@/common/ipc/channels.enum';

export class PromptService {
    private extensionUri: vscode.Uri;
    private workspaceRoot: string | undefined;

    constructor(extensionUri: vscode.Uri) {
        this.extensionUri = extensionUri;
        this.workspaceRoot = vscode.workspace.workspaceFolders?.[0]?.uri.fsPath;
    }

    private artifactSchemaTemplate = `<M1. artifact schema>
M1. artifact schema
M2. cycle overview
M3. interaction schema
M4. current project scope
M5. organized artifacts list
M6. cycles
M7. Flattened Repo
</M1. artifact schema>`;

    public getPromptTokenCount(prompt: string): number {
        return Math.ceil(prompt.length / 4);
    }

    private getPreviousCycleSummary(cycle: PcppCycle | undefined): string {
        if (!cycle) return '';
        
        const selectedResponseId = cycle.selectedResponseId;
        if (!selectedResponseId || !cycle.responses[selectedResponseId]) {
            Services.loggerService.warn(`Could not find selected response content for cycle ${cycle.cycleId}`);
            return `<!-- No response was selected for cycle ${cycle.cycleId} -->`;
        }

        const previousResponseContent = cycle.responses[selectedResponseId].content;
        if (!previousResponseContent.trim()) {
            return `<!-- Selected response for cycle ${cycle.cycleId} was empty -->`;
        }

        const parsed = parseResponse(previousResponseContent);
        
        return `${parsed.summary}\n\n${parsed.courseOfAction}`;
    }

    private async _generateCycle0Content(): Promise<string> {
        const allArtifactEntries = await vscode.workspace.fs.readDirectory(vscode.Uri.joinPath(this.extensionUri, 'dist', 'Artifacts'));
        const templateFilenames = allArtifactEntries
            .map(([filename]) => filename)
            .filter(filename => filename.startsWith('T') && filename.endsWith('.md'));

        templateFilenames.sort((a, b) => {
            const numA = parseInt(a.match(/T(\d+)/)?.[1] || '0', 10);
            const numB = parseInt(b.match(/T(\d+)/)?.[1] || '0', 10);
            return numA - numB;
        });

        const priorityArtifacts = ['T14. Template - GitHub Repository Setup Guide.md', 'T7. Template - Development and Testing Guide.md'];
        priorityArtifacts.forEach(pa => {
            const index = templateFilenames.indexOf(pa);
            if (index > -1) {
                templateFilenames.splice(index, 1);
                templateFilenames.unshift(pa);
            }
        });

        let staticContext = '<!-- START: Project Templates -->\n';
        for (const filename of templateFilenames) {
            const content = await this.getArtifactContent(`${filename}`, `<!-- ${filename} not found -->`);
            staticContext += `<${filename}>\n${content}\n</${filename}>\n\n`;
        }
        staticContext += '<!-- END: Project Templates -->';

        const cycleContextInstructions = `Review the user's project scope in M4. Your task is to act as a senior project architect and generate a starter set of planning and documentation artifacts for this new project.

**CRITICAL INSTRUCTIONS:**
1.  You have been provided with a set of best-practice templates for software engineering documentation in the <Static Context> section.
2.  Your primary goal is to **select the most relevant templates** and generate project-specific versions of them.
3.  **PRIORITIZE ESSENTIAL GUIDES:** You **MUST** generate artifacts based on "T14. Template - GitHub Repository Setup Guide.md" and "T7. Template - Development and Testing Guide.md". These are mandatory for the user to begin their project.
4.  Generate a Master Artifact List (A0) and at least two other core planning documents (e.g., Project Vision, Technical Scaffolding Plan).
5.  **DO NOT** generate any code files (e.g., .ts, .tsx, .js) in this initial cycle. The focus is on planning and documentation only.`;

        return `<Cycle 0>
<Cycle Context>
${cycleContextInstructions}
</Cycle Context>
<Static Context>
${staticContext.trim()}
</Static Context>
</Cycle 0>`;
    }

    private async _generateCyclesContent(currentCycleData: PcppCycle, fullHistory: PcppCycle[]): Promise<string> {
        Services.loggerService.log(`[Prompt Gen] Generating cycles content. Current cycle ID from frontend: ${currentCycleData.cycleId}`);
        const cycleMap = new Map(fullHistory.map(c => [c.cycleId, c]));
        
        // Ensure the most up-to-date data from the frontend is used for the current cycle
        cycleMap.set(currentCycleData.cycleId, currentCycleData);
        Services.loggerService.log(`[Prompt Gen] Cycle map updated with fresh data for cycle ${currentCycleData.cycleId}. Context length: ${currentCycleData.cycleContext.length}`);
        
        const sortedHistory = [...cycleMap.values()].sort((a, b) => b.cycleId - a.cycleId);
    
        let cyclesContent = '<M6. Cycles>';
    
        for (const cycle of sortedHistory) {
            if (cycle.cycleId === 0) continue;
            // This is the filter that ensures we only include the current cycle and past cycles
            if (cycle.cycleId > currentCycleData.cycleId) continue;

            Services.loggerService.log(`[Prompt Gen] Processing Cycle ${cycle.cycleId} for M6 block.`);
            cyclesContent += `\n\n<Cycle ${cycle.cycleId}>\n`;
    
            if (cycle.cycleContext && cycle.cycleContext.trim()) {
                cyclesContent += `<Cycle Context>\n${cycle.cycleContext}\n</Cycle Context>\n`;
            }
    
            if (cycle.cycleId === currentCycleData.cycleId && cycle.ephemeralContext && cycle.ephemeralContext.trim()) {
                cyclesContent += `<Ephemeral Context>\n${cycle.ephemeralContext}\n</Ephemeral Context>\n`;
            }
    
            const previousCycleId = cycle.cycleId - 1;
            if (previousCycleId > 0) {
                const previousCycle = cycleMap.get(previousCycleId);
                if (previousCycle) {
                    const summary = this.getPreviousCycleSummary(previousCycle);
                    if (summary.trim()) {
                        cyclesContent += `<Previous Cycle ${previousCycleId} Summary of Actions>\n${summary}\n</Previous Cycle ${previousCycleId} Summary of Actions>\n`;
                    }
                }
            }
            cyclesContent += `</Cycle ${cycle.cycleId}>`;
        }

        const cycle0Content = await this._generateCycle0Content();
        cyclesContent += `\n\n${cycle0Content}`;

        cyclesContent += '\n\n</M6. Cycles>';
        return cyclesContent;
    }

    private async getPromptParts(cycleData: PcppCycle, flattenedRepoContent: string): Promise<{ [key: string]: string }> {
        const rootPath = this.workspaceRoot;
        if (!rootPath) throw new Error("No workspace folder open.");

        const fullHistoryFile = await Services.historyService.getFullHistory();
        const fullHistory: PcppCycle[] = fullHistoryFile.cycles;
        
        const cycleMap = new Map(fullHistory.map(c => [c.cycleId, c]));
        cycleMap.set(cycleData.cycleId, cycleData);
        
        const allCycles = [...cycleMap.values()].filter(c => c.cycleId <= cycleData.cycleId);
        const sortedHistoryForOverview = [...allCycles].sort((a, b) => b.cycleId - a.cycleId);

        let cycleOverview = '<M2. cycle overview>\n';
        for (const cycle of sortedHistoryForOverview) {
            if (cycle.cycleId > 0) {
                cycleOverview += `Cycle ${cycle.cycleId} - ${cycle.title}\n`;
            }
        }
        if (!cycleOverview.includes('Cycle 0')) {
            cycleOverview += 'Cycle 0 - Project Initialization/Template Archive\n';
        }
        cycleOverview += '</M2. cycle overview>';
       
        const cyclesContent = await this._generateCyclesContent(cycleData, fullHistory);

        const userA0Files = await vscode.workspace.findFiles('**/*A0*Master*Artifact*List.md', '**/node_modules/**', 1);
        let a0Content = '<!-- Master Artifact List (A0) not found in workspace -->';
        if (userA0Files.length > 0) {
            const contentBuffer = await vscode.workspace.fs.readFile(userA0Files[0]);
            a0Content = Buffer.from(contentBuffer).toString('utf-8');
        }
        
        const settings = await Services.settingsService.getSettings();
        const isDemoMode = settings.connectionMode === 'demo';
        
        const schemaArtifact = isDemoMode ? 'A52.3 DCE - Harmony Interaction Schema Source.md' : 'A52.2 DCE - Interaction Schema Source.md';
        const schemaError = isDemoMode ? '<!-- A52.3 Harmony Schema not found -->' : '<!-- A52.2 Interaction Schema Source not found -->';
        const schemaSourceContent = await this.getArtifactContent(schemaArtifact, schemaError);

        let interactionSchemaContent = `<M3. Interaction Schema>\n${schemaSourceContent}\n`;
        
        if (!isDemoMode) {
            const a52_1_Content = await this.getArtifactContent('A52.1 DCE - Parser Logic and AI Guidance.md', '<!-- A52.1 Parser Logic not found -->');
            interactionSchemaContent += `\n${a52_1_Content}\n`;
        }
        
        interactionSchemaContent += '</M3. Interaction Schema>';

        const projectScope = `<M4. current project scope>\n${fullHistoryFile.projectScope || 'No project scope defined.'}\n</M4. current project scope>`;
        const m5Content = `<M5. organized artifacts list>\n${a0Content}\n</M5. organized artifacts list>`;
        const m7Content = `<M7. Flattened Repo>\n${flattenedRepoContent}\n</M7. Flattened Repo>`;

        return {
            "M1 Artifact Schema": this.artifactSchemaTemplate,
            "M2 Cycle Overview": cycleOverview,
            "M3 Interaction Schema": interactionSchemaContent,
            "M4 Project Scope": projectScope,
            "M5 Artifact List": m5Content,
            "M6 Cycles": cyclesContent,
            "M7 Flattened Repo": m7Content
        };
    }

    public async generatePromptString(cycleData: PcppCycle): Promise<string> {
        Services.loggerService.log(`[Prompt Gen] Starting prompt string generation for Cycle ${cycleData.cycleId}.`);
        const lastSelection = await Services.selectionService.getLastSelection();
        Services.loggerService.log(`[Prompt Gen] Found ${lastSelection.length} files in current selection.`);
        
        let flattenedContent = '<!-- No files selected for flattening -->';
        if (lastSelection.length > 0) {
            flattenedContent = await Services.flattenerService.getFlattenedContent(lastSelection);
            Services.loggerService.log(`[Prompt Gen] Generated flattened content (${Math.ceil(flattenedContent.length / 4)} tokens).`);
        }
        
        const promptParts = await this.getPromptParts(cycleData, flattenedContent);
        const promptContent = Object.values(promptParts).join('\n\n');
        return `<prompt.md>\n\n${promptContent}\n\n</prompt.md>`;
    }

    public async handlePromptCostBreakdownRequest(cycleData: PcppCycle, serverIpc: ServerPostMessageManager) {
        try {
            const selectedFiles = await Services.selectionService.getLastSelection();
            Services.loggerService.log(`[CostCalc] Found ${selectedFiles.length} selected files.`);
            if (selectedFiles.length === 0) {
                serverIpc.sendToClient(ServerToClientChannel.SendPromptCostEstimation, { totalTokens: 0, estimatedCost: 0, breakdown: {} });
                Services.loggerService.log("[CostCalc] No files selected, sending 0 cost.");
                return;
            }
            const flattenedContent = await Services.flattenerService.getFlattenedContent(selectedFiles);
            Services.loggerService.log(`[CostCalc] In-memory flattened content generated (${Math.ceil(flattenedContent.length / 4)} tokens).`);
            
            const promptParts = await this.getPromptParts(cycleData, flattenedContent);
            
            const breakdown: { [key: string]: number } = {};
            let totalTokens = 0;

            Services.loggerService.log("[CostCalc] Calculating breakdown:");
            for (const [key, value] of Object.entries(promptParts)) {
                const partTokens = Math.ceil(value.length / 4);
                breakdown[key] = partTokens;
                totalTokens += partTokens;
                Services.loggerService.log(`  - ${key}: ${partTokens} tokens`);
            }

            const estimatedCost = calculatePromptCost(totalTokens);
            Services.loggerService.log(`[CostCalc] Total Tokens: ${totalTokens}, Estimated Cost: $${estimatedCost}`);
            Services.loggerService.log("[CostCalc] Sending estimation to client.");
            serverIpc.sendToClient(ServerToClientChannel.SendPromptCostEstimation, { totalTokens, estimatedCost, breakdown });
        } catch (error: any) {
            Services.loggerService.error(`[CostCalc] Failed to estimate prompt cost: ${error.message}`);
        }
    }

    public async generateStateLog(currentState: PcppCycle, costState: any, serverIpc: ServerPostMessageManager) {
        Services.loggerService.log("--- GENERATING STATE LOG ---");
        try {
            Services.loggerService.log(`\n========================= FRONTEND STATE DUMP =========================\n${JSON.stringify({ FRONTEND_COST_STATE: costState }, null, 2)}\n======================================================================`);
            await this.handlePromptCostBreakdownRequest(currentState, serverIpc);
            Services.loggerService.show();
            vscode.window.showInformationMessage("State and cost calculation logged to 'Data Curation Environment' output channel.");
        } catch (error: any) {
            Services.loggerService.error(`Failed to generate state log: ${error.message}`);
        }
    }

    private async getArtifactContent(artifactFilename: string, errorMessage: string): Promise<string> {
        try {
            const uri = vscode.Uri.joinPath(this.extensionUri, 'dist', 'Artifacts', artifactFilename);
            const contentBuffer = await vscode.workspace.fs.readFile(uri);
            return Buffer.from(contentBuffer).toString('utf-8');
        } catch (e) {
            Services.loggerService.error(`Could not read ${artifactFilename}. Error: ${e}`);
            return errorMessage;
        }
    }

    public async generatePromptFile(cycleTitle: string, currentCycleId: number) {
        if (!this.workspaceRoot) {
            vscode.window.showErrorMessage("Cannot generate prompt: No workspace folder is open.");
            return;
        }
        const rootPath = this.workspaceRoot;
        const promptMdPath = path.join(rootPath, 'prompt.md');

        try {
            Services.loggerService.log(`Generating prompt.md file for cycle ${currentCycleId}...`);
            
            const lastSelection = await Services.selectionService.getLastSelection();
            if (lastSelection.length > 0) {
                await Services.flattenerService.flatten(lastSelection);
            } else {
                Services.loggerService.warn("No files selected for flattening. 'flattened_repo.md' may be stale or non-existent.");
            }
            
            const fullHistoryFile = await Services.historyService.getFullHistory();
            let currentCycleData: PcppCycle | undefined;
            let readmePath: string | undefined;

            if (currentCycleId === 0) {
                const artifactsDirInWorkspace = path.join(this.workspaceRoot, 'src', 'Artifacts');
                await vscode.workspace.fs.createDirectory(vscode.Uri.file(artifactsDirInWorkspace));
                
                const readmeContent = await this.getArtifactContent('A72. DCE - README for Artifacts.md', '# Welcome!');
                const readmeUri = vscode.Uri.file(path.join(artifactsDirInWorkspace, 'DCE_README.md'));
                readmePath = readmeUri.fsPath;
                await vscode.workspace.fs.writeFile(readmeUri, Buffer.from(readmeContent, 'utf-8'));

                currentCycleData = {
                    cycleId: 0,
                    title: cycleTitle,
                    cycleContext: fullHistoryFile.projectScope || '',
                    ephemeralContext: '',
                    responses: {},
                    timestamp: new Date().toISOString(),
                    status: 'complete'
                };
            } else {
                const historyCycle = fullHistoryFile.cycles.find(c => c.cycleId === currentCycleId);
                if (!historyCycle) {
                    throw new Error(`Could not find data for current cycle (${currentCycleId}) in history.`);
                }
                currentCycleData = { ...historyCycle, title: cycleTitle };
            }

            const finalPrompt = await this.generatePromptString(currentCycleData);

            await fs.writeFile(promptMdPath, finalPrompt, 'utf-8');
            vscode.window.showInformationMessage(`Successfully generated prompt.md for Cycle ${currentCycleId}.`);
            Services.loggerService.log(`Successfully generated prompt.md file for Cycle ${currentCycleId}.`);

            await Services.fileOperationService.handleOpenFileRequest(promptMdPath);
            if (readmePath) {
                // C128 UPDATE: Open README in Preview Mode
                await Services.fileOperationService.handleMarkdownPreviewRequest(readmePath);
            }

        } catch (error: any) {
            let errorMessage = `Failed to generate prompt.md: ${error.message}`;
            vscode.window.showErrorMessage(errorMessage);
            Services.loggerService.error(errorMessage);
        }
    }

    public async generateInitialArtifactsAndResponses(projectScope: string, responseCount: number, serverIpc: ServerPostMessageManager) {
        if (!this.workspaceRoot) {
            vscode.window.showErrorMessage("Cannot generate prompt: No workspace folder is open.");
            return;
        }
        
        try {
            Services.loggerService.log("Generating Cycle 0 prompt and starting generation...");
            await Services.historyService.saveProjectScope(projectScope);
            
            const dummyCycleData: PcppCycle = { cycleId: 0, title: 'Initial Artifacts', responses: {}, cycleContext: projectScope, ephemeralContext: '', timestamp: '', tabCount: responseCount, status: 'complete' };
            const prompt = await this.generatePromptString(dummyCycleData);
            
            await vscode.workspace.fs.writeFile(vscode.Uri.file(path.join(this.workspaceRoot, 'prompt.md')), Buffer.from(prompt, 'utf-8'));
            Services.loggerService.log("prompt.md file created successfully before sending API request.");

            const { newCycle, newMaxCycle } = await Services.historyService.createNewCyclePlaceholder(responseCount);
            serverIpc.sendToClient(ServerToClientChannel.NavigateToNewGeneratingCycle, { newCycleData: newCycle, newMaxCycle });

            const artifactsDirInWorkspace = path.join(this.workspaceRoot, 'src', 'Artifacts');
            await vscode.workspace.fs.createDirectory(vscode.Uri.file(artifactsDirInWorkspace));
            
            const readmeContent = await this.getArtifactContent('A72. DCE - README for Artifacts.md', '# Welcome!');
            const readmeUri = vscode.Uri.file(path.join(artifactsDirInWorkspace, 'DCE_README.md'));
            await vscode.workspace.fs.writeFile(readmeUri, Buffer.from(readmeContent, 'utf-8'));
            
            const responses = await Services.llmService.generateBatch(prompt, responseCount, { ...dummyCycleData, cycleId: newCycle.cycleId });
            
            await Services.historyService.updateCycleWithResponses(newCycle.cycleId, responses);
            
            const finalHistory = await Services.historyService.getFullHistory();
            const finalMaxCycle = finalHistory.cycles.reduce((max, c) => Math.max(max, c.cycleId), 0);
            serverIpc.sendToClient(ServerToClientChannel.SendBatchGenerationComplete, { newCycleId: newCycle.cycleId, newMaxCycle: finalMaxCycle });

        } catch (error: any) {
            vscode.window.showErrorMessage(`Failed to generate initial artifacts: ${error.message}`);
            Services.loggerService.error(`Failed to generate initial artifacts: ${error.message}`);
        }
    }
}
</file_artifact>

<file path="src/backend/services/selection.service.ts">
import * as vscode from 'vscode';
import { getContext } from '@/extension';
import { Services } from './services';
import * as fs from 'fs/promises';

const SELECTION_SETS_KEY = 'dce.selectionSets';
const LAST_SELECTION_KEY = 'dce.lastSelection';
const AUTO_ADD_STATE_KEY = 'dce.autoAddState';


export interface SelectionSet {
    [name: string]: string[];
}

export class SelectionService {
    
    private get context(): vscode.ExtensionContext {
        return getContext();
    }

    // --- Named Selection Sets ---

    public getSelectionSets(): SelectionSet {
        return this.context.workspaceState.get<SelectionSet>(SELECTION_SETS_KEY, {});
    }

    public async saveSelectionSet(name: string, paths: string[]): Promise<void> {
        if (!name) {
            vscode.window.showErrorMessage("Selection set name cannot be empty.");
            return;
        }
        const sets = this.getSelectionSets();
        sets[name] = paths;
        await this.context.workspaceState.update(SELECTION_SETS_KEY, sets);
        Services.loggerService.log(`Selection set '${name}' saved with ${paths.length} paths.`);
        vscode.window.showInformationMessage(`Selection set '${name}' saved.`);
    }

    public async deleteSelectionSet(name: string): Promise<void> {
        const sets = this.getSelectionSets();
        if (sets[name]) {
            delete sets[name];
            await this.context.workspaceState.update(SELECTION_SETS_KEY, sets);
            Services.loggerService.log(`Selection set '${name}' deleted.`);
            vscode.window.showInformationMessage(`Selection set '${name}' deleted.`);
        }
    }

    // --- Persistent Current Selection ---

    public async getLastSelection(): Promise<string[]> {
        const savedPaths = this.context.workspaceState.get<string[]>(LAST_SELECTION_KEY, []);
        if (savedPaths.length === 0) {
            Services.loggerService.log("[SelectionService] No last selection found in state.");
            return [];
        }
    
        Services.loggerService.log(`[SelectionService] Found ${savedPaths.length} paths in persisted state. Validating...`);
        
        const validationPromises = savedPaths.map(path => 
            fs.stat(path).then(() => ({ path, valid: true })).catch(() => ({ path, valid: false }))
        );
    
        const results = await Promise.all(validationPromises);
    
        const validPaths = results.filter(r => r.valid).map(r => r.path);
        const invalidPaths = results.filter(r => !r.valid).map(r => r.path);
    
        if (invalidPaths.length > 0) {
            Services.loggerService.warn(`[SelectionService] Removing ${invalidPaths.length} invalid paths from persisted state: ${invalidPaths.join(', ')}`);
            // Self-heal the state by saving only the valid paths
            await this.saveCurrentSelection(validPaths);
        }
    
        Services.loggerService.log(`[SelectionService] Returning ${validPaths.length} valid paths.`);
        return validPaths;
    }

    public async saveCurrentSelection(paths: string[]): Promise<void> {
        await this.context.workspaceState.update(LAST_SELECTION_KEY, paths);
        Services.loggerService.log(`Persisted current selection of ${paths.length} items.`);
    }

    // --- Path Manipulation for File Moves ---
    public async updatePathInSelections(oldPath: string, newPath: string): Promise<void> {
        Services.loggerService.log(`Updating path in selections: ${oldPath} -> ${newPath}`);

        // Update last active selection
        const lastSelection = await this.getLastSelection();
        const updatedLastSelection = this.updatePathsInList(lastSelection, oldPath, newPath);
        await this.saveCurrentSelection(updatedLastSelection);

        // Update all named selection sets
        const allSets = this.getSelectionSets();
        let setsUpdated = false;
        for (const setName in allSets) {
            const updatedSet = this.updatePathsInList(allSets[setName], oldPath, newPath);
            if (updatedSet.length !== allSets[setName].length || updatedSet.some((p, i) => p !== allSets[setName][i])) {
                allSets[setName] = updatedSet;
                setsUpdated = true;
            }
        }
        if (setsUpdated) {
            await this.context.workspaceState.update(SELECTION_SETS_KEY, allSets);
            Services.loggerService.log(`Updated paths in named selection sets.`);
        }
    }

    private updatePathsInList(paths: string[], oldPath: string, newPath: string): string[] {
        return paths.map(p => {
            if (p === oldPath) {
                return newPath; // Exact match
            }
            if (p.startsWith(oldPath + '/')) {
                // Descendant path
                return newPath + p.substring(oldPath.length);
            }
            return p;
        });
    }


    // --- Auto-Add New Files State ---

    public getAutoAddState(): boolean {
        return this.context.workspaceState.get<boolean>(AUTO_ADD_STATE_KEY, true);
    }

    public async saveAutoAddState(enabled: boolean): Promise<void> {
        await this.context.workspaceState.update(AUTO_ADD_STATE_KEY, enabled);
        Services.loggerService.log(`Auto-add new files state saved: ${enabled}.`);
    }
}
</file_artifact>

<file path="src/backend/services/services.ts">
import "reflect-metadata";
import * as vscode from 'vscode';
import { FlattenerService } from "./flattener.service";
import { SelectionService } from "./selection.service";
import { LoggerService } from "./logger.service";
import { ActionService } from "./action.service";
import { HistoryService } from "./history.service";
import { PromptService } from "./prompt.service";
import { API as GitAPI } from "../types/git";
import { FileTreeService } from "./file-tree.service";
import { FileOperationService } from "./file-operation.service";
import { ContentExtractionService } from "./content-extraction.service";
import { HighlightingService } from "./highlighting.service";
import { GitService } from "./git.service";
import { ResponseContentProvider } from "../providers/ResponseContentProvider";
import { SettingsService } from "./settings.service";
import { LlmService } from "./llm.service";
import { DatabaseService } from "./database.service";

class ServiceContainer {
    public fileTreeService!: FileTreeService;
    public fileOperationService = new FileOperationService();
    public contentExtractionService = new ContentExtractionService();
    public highlightingService = new HighlightingService();
    
    public flattenerService = new FlattenerService();
    public selectionService = new SelectionService();
    public loggerService = LoggerService.getInstance();
    public actionService = new ActionService();
    public databaseService = new DatabaseService(); // Init first
    public historyService!: HistoryService;
    public promptService!: PromptService;
    public gitService = new GitService();
    public settingsService = new SettingsService();
    public llmService = new LlmService();
    public context!: vscode.ExtensionContext;
    public responseContentProvider = new ResponseContentProvider();
    
    public initialize(context: vscode.ExtensionContext, gitApi?: GitAPI) {
        this.context = context;
        this.loggerService.log("Services initializing...");
        this.databaseService.initialize(); // Initialize DB connection
        this.promptService = new PromptService(context.extensionUri);
        this.historyService = new HistoryService();
        this.fileTreeService = new FileTreeService(gitApi);
        this.fileTreeService.initializeWatcher();
        this.loggerService.log("Services initialized successfully.");
    }
}

export const Services = new ServiceContainer();
</file_artifact>

<file path="src/backend/services/settings.service.ts">
// src/backend/services/settings.service.ts
// New file in C37
import * as vscode from 'vscode';
import { getContext } from '@/extension';
import { Services } from './services';

const CONNECTION_MODE_KEY = 'dce.connectionMode';
const API_URL_KEY = 'dce.apiUrl';
// API_KEY would be stored in SecretStorage

export type ConnectionMode = 'manual' | 'demo' | 'url' | 'key';

export interface DceSettings {
    connectionMode: ConnectionMode;
    apiUrl?: string;
}

export class SettingsService {
    
    private get context(): vscode.ExtensionContext {
        return getContext();
    }

    public async getSettings(): Promise<DceSettings> {
        const config = vscode.workspace.getConfiguration();
        const connectionMode = config.get<ConnectionMode>(CONNECTION_MODE_KEY, 'manual');
        const apiUrl = config.get<string>(API_URL_KEY);
        
        return { connectionMode, apiUrl };
    }

    public async saveSettings(settings: DceSettings): Promise<void> {
        const config = vscode.workspace.getConfiguration();
        try {
            await config.update(CONNECTION_MODE_KEY, settings.connectionMode, vscode.ConfigurationTarget.Workspace);
            await config.update(API_URL_KEY, settings.apiUrl, vscode.ConfigurationTarget.Workspace);
            Services.loggerService.log(`Settings saved: Mode=${settings.connectionMode}, URL=${settings.apiUrl}`);
            vscode.window.showInformationMessage("DCE settings saved.");
        } catch (error: any) {
            Services.loggerService.error(`Failed to save settings: ${error.message}`);
            vscode.window.showErrorMessage("Failed to save DCE settings.");
        }
    }
}
</file_artifact>

<file path="src/backend/types/git.ts">
// This file is a placeholder for the complex types from the vscode.git extension API.
// It helps with type safety in our code without needing the full extension as a dev dependency.

import * as vscode from 'vscode';

export interface GitExtension {
    getAPI(version: 1): API;
}

export interface API {
    readonly state: 'uninitialized' | 'initialized';
    readonly onDidOpenRepository: vscode.Event<Repository>;
    readonly onDidCloseRepository: vscode.Event<Repository>;
    readonly repositories: Repository[];
}

export interface Repository {
    readonly rootUri: vscode.Uri;
    readonly state: RepositoryState;
}

export interface RepositoryState {
    readonly HEAD: Branch | undefined;
    readonly workingTreeChanges: Change[];
    readonly indexChanges: Change[];
    readonly mergeChanges: Change[];
    readonly untrackedChanges: vscode.Uri[]; // This is not in the official API, but we use it conceptually
    readonly onDidChange: vscode.Event<void>;
}

export interface Change {
    readonly uri: vscode.Uri;
    readonly originalUri: vscode.Uri;
    readonly renameUri: vscode.Uri | undefined;
    readonly status: Status;
}

export interface Branch {
    readonly type: RefType;
    readonly name?: string;
    readonly commit?: string;
    readonly upstream?: Upstream;
}

export interface Upstream {
    readonly remote: string;
    readonly name: string;
}

export const enum RefType {
    Head,
    RemoteHead,
    Tag
}

export const enum Status {
    INDEX_MODIFIED,
    INDEX_ADDED,
    INDEX_DELETED,
    INDEX_RENAMED,
    INDEX_COPIED,

    MODIFIED,
    DELETED,
    UNTRACKED,
    IGNORED,
    INTENT_TO_ADD,

    ADDED_BY_US,
    ADDED_BY_THEM,
    DELETED_BY_US,
    DELETED_BY_THEM,
    MODIFIED_BY_US,
    MODIFIED_BY_THEM,

    CONFLICT, // Both Added
    BOTH_DELETED, // Both Deleted
    BOTH_MODIFIED, // Both Modified
}
</file_artifact>

<file path="src/client/components/file-tree/FileTree.tsx">
// Updated on: C184 (Refactor to use gitStatusMap prop)
import React, { useState, useMemo } from 'react';
import TreeView, { TreeNode } from '../tree-view/TreeView';
import { FileNode } from '@/common/types/file-node';
import Checkbox from '../Checkbox';
import {
    VscFile, VscFolder, VscFolderOpened, VscJson, VscMarkdown, VscSymbolFile, VscSymbolNumeric, VscFiles, VscError, VscWarning, VscTable
} from 'react-icons/vsc';
import { SiTypescript, SiReact, SiJavascript, SiSass } from 'react-icons/si';
import { FaFileWord } from 'react-icons/fa';
import { formatLargeNumber, formatBytes, formatNumberWithCommas } from '@/common/utils/formatting';
import ContextMenu from '../ContextMenu';
import { ClientPostMessageManager } from '@/common/ipc/client-ipc';
import { ClientToServerChannel } from '@/common/ipc/channels.enum';
import { ProblemCountsMap, GitStatusMap } from '@/common/ipc/channels.type';

interface FileTreeProps {
  data: FileNode[];
  checkedFiles: string[];
  activeFile?: string;
  updateCheckedFiles: (path: string) => void;
  collapseTrigger?: number;
  expandAllTrigger?: number;
  searchTerm: string;
  problemMap: ProblemCountsMap;
  gitStatusMap: GitStatusMap;
  onNodeDrop?: (event: React.DragEvent, node: FileNode) => void;
  onCopy: (path: string) => void;
  clipboard: { path: string; type: 'copy' } | null;
}

const getFileIcon = (fileName: string) => {
    const extension = fileName.split('.').pop()?.toLowerCase();
    switch (extension) {
        case 'ts': return <SiTypescript color="#3178C6" />;
        case 'tsx': return <SiReact color="#61DAFB" />;
        case 'js': return <SiJavascript color="#F7DF1E" />;
        case 'json': return <VscJson color="#F7DF1E" />;
        case 'md': return <VscMarkdown />;
        case 'scss': case 'css': return <SiSass color="#CF649A"/>;
        case 'svg': case 'png': case 'jpg': case 'jpeg': case 'ico': case 'webp': return <VscSymbolFile />;
        case 'xlsx': case 'xls': case 'csv': return <VscTable color="#217346" />;
        case 'docx': return <FaFileWord color="#2B579A" />;
        default: return <VscFile />;
    }
};

const getGitStatusTooltip = (status?: string): string => {
    switch (status) {
        case 'M': return 'Modified';
        case 'U': return 'Untracked';
        case 'A': return 'Added';
        case 'D': return 'Deleted';
        case 'C': return 'Conflicted';
        case 'I': return 'Ignored';
        default: return 'Git Status';
    }
};

const filterTree = (nodes: FileNode[], term: string): FileNode[] => {
    if (!term) return nodes;
    const lowerCaseTerm = term.toLowerCase();
    return nodes.reduce((acc, node) => {
        if (node.name.toLowerCase().includes(lowerCaseTerm)) {
            acc.push(node);
            return acc;
        }
        if (node.children) {
            const filteredChildren = filterTree(node.children, term);
            if (filteredChildren.length > 0) {
                acc.push({ ...node, children: filteredChildren });
            }
        }
        return acc;
    }, [] as FileNode[]);
};

const FileTree: React.FC<FileTreeProps> = ({ data, checkedFiles, activeFile, updateCheckedFiles, collapseTrigger, expandAllTrigger, searchTerm, problemMap, gitStatusMap, onNodeDrop, onCopy, clipboard }) => {
    const [contextMenu, setContextMenu] = useState<{ x: number, y: number, node: FileNode, paths: string[] } | null>(null);
    const [renamingPath, setRenamingPath] = useState<string | null>(null);
    const [renameValue, setRenameValue] = useState('');
    const clientIpc = ClientPostMessageManager.getInstance();

    const filteredData = useMemo(() => filterTree(data, searchTerm), [data, searchTerm]);
    const handleFileCheckboxChange = (e: React.ChangeEvent<HTMLInputElement>, filePath: string) => { e.stopPropagation(); updateCheckedFiles(filePath); };
    const handleContextMenu = (event: React.MouseEvent, node: FileNode, paths: string[]) => { event.preventDefault(); event.stopPropagation(); setContextMenu({ x: event.clientX, y: event.clientY, node, paths }); };
    const handleRename = () => { if (contextMenu) { setRenamingPath(contextMenu.node.absolutePath); setRenameValue(contextMenu.node.name); setContextMenu(null); } };
    const handleRenameSubmit = () => { if (renamingPath && renameValue) { clientIpc.sendToServer(ClientToServerChannel.RequestFileRename, { oldPath: renamingPath, newName: renameValue }); } setRenamingPath(null); };
    
    const checkboxStates = useMemo(() => {
        const states = new Map<string, { checked: boolean, indeterminate: boolean }>();
        const checkedSet = new Set(checkedFiles);
        const calculateState = (node: FileNode): { selectedCount: number, selectableCount: number } => {
            if (!node.isSelectable) { states.set(node.absolutePath, { checked: false, indeterminate: false }); return { selectedCount: 0, selectableCount: 0 }; }
            if (!node.children) { const isChecked = checkedSet.has(node.absolutePath); states.set(node.absolutePath, { checked: isChecked, indeterminate: false }); return { selectedCount: isChecked ? 1 : 0, selectableCount: 1 }; }
            let totalSelected = 0; let totalSelectable = 0;
            for (const child of node.children) { const childState = calculateState(child); totalSelected += childState.selectedCount; totalSelectable += childState.selectableCount; }
            const isChecked = totalSelectable > 0 && totalSelected === totalSelectable;
            const isIndeterminate = totalSelected > 0 && totalSelected < totalSelectable;
            states.set(node.absolutePath, { checked: isChecked, indeterminate: isIndeterminate });
            return { selectedCount: totalSelected, selectableCount: totalSelectable };
        };
        data.forEach(calculateState);
        return states;
    }, [data, checkedFiles]);

    const calculateCheckedTokens = useMemo(() => {
        const checkedSet = new Set(checkedFiles);
        const memo = new Map<string, number>();
        const calculate = (node: FileNode): number => {
            if (memo.has(node.absolutePath)) return memo.get(node.absolutePath)!;
            if (!node.children) { const result = checkedSet.has(node.absolutePath) ? node.tokenCount : 0; memo.set(node.absolutePath, result); return result; }
            const result = node.children.reduce((acc, child) => acc + calculate(child), 0);
            memo.set(node.absolutePath, result);
            return result;
        };
        return calculate;
    }, [checkedFiles]);

    const renderFileNodeContent = (node: TreeNode, isExpanded: boolean) => {
        const fileNode = node as FileNode;
        const isDirectory = Array.isArray(fileNode.children);
        if (renamingPath === fileNode.absolutePath) { return ( <input type="text" value={renameValue} onChange={(e) => setRenameValue(e.target.value)} onBlur={handleRenameSubmit} onKeyDown={(e) => { if (e.key === 'Enter') handleRenameSubmit(); if ((e.ctrlKey || e.metaKey) && ['c', 'v', 'x'].includes(e.key.toLowerCase())) { e.stopPropagation(); } }} autoFocus className="rename-input" /> ); }
        const checkedTokensInDir = isDirectory ? calculateCheckedTokens(fileNode) : 0;
        const { checked, indeterminate } = checkboxStates.get(fileNode.absolutePath) || { checked: false, indeterminate: false };
        const isFullyChecked = isDirectory && checkedTokensInDir > 0 && checkedTokensInDir === fileNode.tokenCount;
        const liveProblems = problemMap[fileNode.absolutePath];
        const gitStatus = gitStatusMap[fileNode.absolutePath];
        const problemErrorCount = liveProblems?.error || 0;
        const problemWarningCount = liveProblems?.warning || 0;
        const hasProblems = problemErrorCount > 0 || problemWarningCount > 0;
        const problemColorClass = problemErrorCount > 0 ? 'problem-error' : 'problem-warning';
        const problemTooltip = `${problemErrorCount} Errors, ${problemWarningCount} Warnings`;
        const hasError = !!fileNode.error;
        const gitStatusClass = gitStatus ? `git-status-${gitStatus}` : '';

        const renderTokenCount = () => {
            if (hasError) return <span>---</span>;
            if (fileNode.isImage) return <span>{formatBytes(fileNode.sizeInBytes)}</span>;
            if (fileNode.tokenCount > 0) {
                let content;
                if (isDirectory) {
                    if (isFullyChecked || checked) { content = `(${formatLargeNumber(fileNode.tokenCount, 1)})`; } 
                    else if (checkedTokensInDir > 0) { content = <>{formatLargeNumber(fileNode.tokenCount, 1)} <span className="selected-token-count">({formatLargeNumber(checkedTokensInDir, 1)})</span></>; } 
                    else { content = formatLargeNumber(fileNode.tokenCount, 1); }
                } else { content = checked ? `(${formatLargeNumber(fileNode.tokenCount, 1)})` : formatLargeNumber(fileNode.tokenCount, 1); }
                return <><VscSymbolNumeric /> <span>{content}</span></>;
            }
            return null;
        };

        return (
            <div className={`file-item ${gitStatusClass} ${hasProblems ? problemColorClass : ''} ${hasError ? 'has-error' : ''}`} title={fileNode.error}>
                <Checkbox className="file-checkbox" checked={checked} indeterminate={indeterminate} onChange={(_, e) => handleFileCheckboxChange(e, fileNode.absolutePath)} disabled={hasError || !fileNode.isSelectable} />
                <span className="file-icon">{isDirectory ? (isExpanded ? <VscFolderOpened /> : <VscFolder />) : getFileIcon(fileNode.name)}</span>
                <span className="file-name">{fileNode.name}</span>
                <div className="file-stats">
                    {hasError && <span className="error-icon" title={fileNode.error}><VscError/></span>}
                    {gitStatus && <span className="git-status-badge" title={getGitStatusTooltip(gitStatus)}>{gitStatus}</span>}
                    {hasProblems && (<span className="problem-badge" title={problemTooltip}>{problemErrorCount > 0 && <span className='error-icon'><VscError/> {problemErrorCount}</span>}{problemWarningCount > 0 && <span className='warning-icon'><VscWarning/> {problemWarningCount}</span>}</span>)}
                    {isDirectory && fileNode.fileCount > 0 && (<> <VscFiles /> <span>{formatNumberWithCommas(fileNode.fileCount)}</span> </>)}
                    {renderTokenCount()}
                </div>
            </div>
        );
    };

    return (
        <div className="file-tree">
            <TreeView data={filteredData as TreeNode[]} renderNodeContent={(node, isExpanded) => renderFileNodeContent(node, isExpanded as boolean)} onContextMenu={(e, node, paths) => handleContextMenu(e, node as FileNode, paths)} collapseTrigger={collapseTrigger} expandAllTrigger={expandAllTrigger} activeFile={activeFile} updateCheckedFiles={updateCheckedFiles} onNodeDrop={(e, node) => onNodeDrop?.(e, node as FileNode)} onCopy={onCopy} clipboard={clipboard} />
            {contextMenu && <ContextMenu menu={contextMenu} onClose={() => setContextMenu(null)} onRename={handleRename} />}
        </div>
    );
};

export default FileTree;
</file_artifact>

<file path="src/client/components/file-tree/FileTree.utils.ts">
// Updated on: C26 (Make uncheck logic resilient to stale tree)
import { FileNode } from "@/common/types/file-node";
import { logger } from "@/client/utils/logger";

/**
 * Recursively finds all selectable files at or below a given node.
 * @param node The node to start from.
 * @returns A flat array of absolute paths for all selectable files.
 */
export function getAllSelectableFiles(node: FileNode): string[] {
    if (!node.isSelectable) {
        return [];
    }
    if (!node.children) { // It's a file
        return [node.absolutePath];
    }
    // It's a directory
    let files: string[] = [];
    for (const child of node.children) {
        files = files.concat(getAllSelectableFiles(child));
    }
    return files;
}

export const getFileNodeByPath = (
  fileNodes: FileNode[],
  filePath: string
): FileNode | null => {
    for (const rootNode of fileNodes) {
        const found = findNode(rootNode, filePath);
        if (found) return found;
    }
    return null;
};

function findNode(node: FileNode, filePath: string): FileNode | null {
    if (node.absolutePath === filePath) {
        return node;
    }
    if (node.children && filePath.startsWith(node.absolutePath + '/')) {
        for (const child of node.children) {
            const found = findNode(child, filePath);
            if(found) return found;
        }
    }
    return null;
}

export const addRemovePathInSelectedFiles = (
  fileTree: FileNode[],
  path: string, // The path of the node that was clicked
  selectedFiles: string[] // The current set of selected FILE paths
): string[] => {
    const node = getFileNodeByPath(fileTree, path);
    const currentSelection = new Set(selectedFiles);

    if (!node) {
        logger.warn(`[Selection Util] Node not found in file tree for path: ${path}. Selection cannot be changed robustly.`);
        if (currentSelection.has(path)) {
            currentSelection.delete(path);
            return Array.from(currentSelection);
        }
        return selectedFiles;
    }
    
    if (!node.isSelectable) return selectedFiles;

    const filesToToggle = getAllSelectableFiles(node);
    const isCurrentlyChecked = filesToToggle.length > 0 && filesToToggle.every(file => currentSelection.has(file));

    if (isCurrentlyChecked) {
        // UNCHECK: Remove all selectable files under this node from the selection.
        filesToToggle.forEach(file => currentSelection.delete(file));
        
        // C26 Fix: Defensively remove any selected file that is a descendant by path,
        // in case the fileTree state was stale and missed some newly added files.
        if (node.children) { // Only apply this logic to directories
            const dirPathWithSlash = node.absolutePath.endsWith('/') ? node.absolutePath : node.absolutePath + '/';
            for (const selectedFile of selectedFiles) {
                if (selectedFile.startsWith(dirPathWithSlash)) {
                    currentSelection.delete(selectedFile);
                }
            }
        }
    } else {
        // CHECK: Add all selectable files under this node to the selection.
        filesToToggle.forEach(file => currentSelection.add(file));
    }
  
    return Array.from(currentSelection);
};


export const removePathsFromSelected = (
    pathsToRemove: string[],
    currentSelectedFiles: string[],
    fileTree: FileNode[]
): string[] => {
    logger.log(`[Batch Remove] Starting removal of ${pathsToRemove.length} paths.`);
    if (pathsToRemove.length === 0) return currentSelectedFiles;

    const fileMap = new Map<string, FileNode>();
    const buildMap = (node: FileNode) => {
        fileMap.set(node.absolutePath, node);
        node.children?.forEach(buildMap);
    };
    fileTree.forEach(buildMap);

    const effectiveFileSelection = new Set<string>();
    for (const selectedPath of currentSelectedFiles) {
        const node = fileMap.get(selectedPath);
        if (node) {
            if (node.children) {
                getAllSelectableFiles(node).forEach(file => effectiveFileSelection.add(file));
            } else if (node.isSelectable) {
                effectiveFileSelection.add(selectedPath);
            }
        }
    }

    for (const pathToRemove of pathsToRemove) {
        const nodeToRemove = fileMap.get(pathToRemove);
        if (nodeToRemove) {
            if (nodeToRemove.children) {
                getAllSelectableFiles(nodeToRemove).forEach(file => effectiveFileSelection.delete(file));
            } else {
                effectiveFileSelection.delete(pathToRemove);
            }
        }
    }
    
    logger.log(`[Batch Remove] After removal, ${effectiveFileSelection.size} files remain.`);
    return Array.from(effectiveFileSelection);
};
</file_artifact>

<file path="src/client/components/tree-view/TreeView.tsx">
// Updated on: C10 (Add onKeyDown handler for Undo/Redo)
import React, { useState, useEffect, useRef, useCallback } from 'react';
import { VscChevronRight } from 'react-icons/vsc';
import { ClientPostMessageManager } from '@/common/ipc/client-ipc';
import { ClientToServerChannel } from '@/common/ipc/channels.enum';
import { logger } from '@/client/utils/logger';
import { FileNode } from '@/common/types/file-node';

export interface TreeNode {
    name: string;
    absolutePath: string;
    children?: TreeNode[];
    isExpanded?: boolean;
    [key: string]: any;
}

interface TreeViewProps {
    data: TreeNode[];
    renderNodeContent?: (node: TreeNode, isExpanded: boolean) => React.ReactNode;
    collapseTrigger?: number;
    expandAllTrigger?: number;
    onContextMenu?: (event: React.MouseEvent, node: TreeNode, paths: string[]) => void;
    activeFile?: string;
    updateCheckedFiles: (path: string) => void;
    onNodeDrop?: (event: React.DragEvent, node: FileNode) => void;
    onCopy: (path: string) => void;
    clipboard: { path: string; type: 'copy' } | null;
}

const TreeView: React.FC<TreeViewProps> = ({ data, renderNodeContent, collapseTrigger = 0, expandAllTrigger = 0, onContextMenu, activeFile, updateCheckedFiles, onNodeDrop, onCopy, clipboard }) => {
    const [expandedNodes, setExpandedNodes] = useState<string[]>([]);
    const [selectedPaths, setSelectedPaths] = useState<Set<string>>(new Set());
    const [focusedNodePath, setFocusedNodePath] = useState<string | null>(null);
    const [lastClickedPath, setLastClickedPath] = useState<string | null>(null);
    const [draggedPath, setDraggedPath] = useState<string | null>(null);
    const [dropTarget, setDropTarget] = useState<string | null>(null);
    const expansionTimer = useRef<NodeJS.Timeout | null>(null);

    const nodeRefs = useRef<Map<string, HTMLLIElement>>(new Map());
    const treeViewRef = useRef<HTMLDivElement>(null);
    const flatNodeList = useRef<TreeNode[]>([]);
    const clientIpc = ClientPostMessageManager.getInstance();

    const buildFlatNodeList = useCallback((nodes: TreeNode[], expanded: string[]): TreeNode[] => {
        let list: TreeNode[] = [];
        for (const node of nodes) {
            list.push(node);
            if (node.children && expanded.includes(node.absolutePath)) {
                list = list.concat(buildFlatNodeList(node.children, expanded));
            }
        }
        return list;
    }, []);

    useEffect(() => {
        if (data && data.length > 0) {
            flatNodeList.current = buildFlatNodeList(data, expandedNodes);
            if (!focusedNodePath && flatNodeList.current.length > 0) {
                setFocusedNodePath(flatNodeList.current[0].absolutePath);
            }
        }
    }, [data, expandedNodes, buildFlatNodeList, focusedNodePath]);

    const expandNode = (path: string) => {
        setExpandedNodes(prev => [...new Set([...prev, path])]);
    };

    useEffect(() => {
        if (data.length > 0) {
            expandNode(data[0].absolutePath);
        }
    }, [data]);

    useEffect(() => {
        if (collapseTrigger > 0 && data.length > 0) {
            setExpandedNodes([data[0].absolutePath]);
        }
    }, [collapseTrigger, data]);

    useEffect(() => {
        if (expandAllTrigger > 0 && data.length > 0) {
            const allDirPaths: string[] = [];
            const collectDirs = (node: TreeNode) => {
                if (node.children) {
                    allDirPaths.push(node.absolutePath);
                    node.children.forEach(collectDirs);
                }
            };
            data.forEach(collectDirs);
            setExpandedNodes(allDirPaths);
        }
    }, [expandAllTrigger, data]);

    useEffect(() => {
        if (activeFile && data.length > 0) {
            logger.log(`[TreeView] activeFile prop changed: ${activeFile}. Attempting to reveal.`);
            const getParentPaths = (filePath: string, rootPath: string): string[] => {
                if (!filePath.startsWith(rootPath) || filePath === rootPath) {
                    return [];
                }
                const relativePath = filePath.substring(rootPath.length + 1);
                const parts = relativePath.split('/');
                const paths: string[] = [];
                let current = rootPath;
                for (let i = 0; i < parts.length - 1; i++) {
                    current += '/' + parts[i];
                    paths.push(current);
                }
                return paths;
            };
            const rootPath = data[0].absolutePath;
            if (rootPath) {
                const parents = getParentPaths(activeFile, rootPath);
                logger.log(`[TreeView] Parents to expand: ${JSON.stringify(parents)}`);
                setExpandedNodes(prev => [...new Set([...prev, ...parents, rootPath])]);
                setSelectedPaths(new Set([activeFile]));
                setFocusedNodePath(activeFile);
                setLastClickedPath(activeFile);
                setTimeout(() => {
                    const nodeElement = nodeRefs.current.get(activeFile);
                    if (nodeElement) {
                        logger.log(`[TreeView] Scrolling to active file element.`);
                        nodeElement.scrollIntoView({ behavior: 'smooth', block: 'nearest' });
                    } else {
                        logger.warn(`[TreeView] Could not find ref for active file: ${activeFile}`);
                    }
                }, 150);
            }
        }
    }, [activeFile, data]);

    const handleNodeClick = (e: React.MouseEvent, node: TreeNode) => {
        if ((e.target as HTMLElement).closest('.file-checkbox') || (e.target as HTMLElement).closest('.rename-input')) {
            return;
        }
        e.stopPropagation();

        const path = node.absolutePath;
        setFocusedNodePath(path);
        
        if (e.shiftKey && lastClickedPath) {
            const newSelection = new Set(e.ctrlKey ? selectedPaths : []);
            const firstIdx = flatNodeList.current.findIndex(f => f.absolutePath === lastClickedPath);
            const currentIdx = flatNodeList.current.findIndex(f => f.absolutePath === path);
            const start = Math.min(firstIdx, currentIdx);
            const end = Math.max(firstIdx, currentIdx);
            if (start !== -1 && end !== -1) {
                for (let i = start; i <= end; i++) {
                    if (flatNodeList.current[i]) {
                        newSelection.add(flatNodeList.current[i].absolutePath);
                    }
                }
            }
            setSelectedPaths(newSelection);
        } else if (e.ctrlKey) {
            const newSelection = new Set(selectedPaths);
            if (newSelection.has(path)) {
                newSelection.delete(path);
            } else {
                newSelection.add(path);
            }
            setSelectedPaths(newSelection);
            setLastClickedPath(path);
        } else {
            setSelectedPaths(new Set([path]));
            setLastClickedPath(path);
            if (node.children) {
                setExpandedNodes(prev => {
                    const isExpanded = prev.includes(path);
                    return isExpanded ? prev.filter(p => p !== path) : [...prev, path];
                });
            } else {
                clientIpc.sendToServer(ClientToServerChannel.RequestOpenFile, { path });
                setTimeout(() => treeViewRef.current?.focus(), 100);
            }
        }
    };

    const handleKeyDown = (e: React.KeyboardEvent) => {
        if ((e.target as HTMLElement).tagName === 'INPUT') {
            return;
        }

        if (e.ctrlKey || e.metaKey) {
            switch (e.key.toLowerCase()) {
                case 'c':
                    e.preventDefault(); e.stopPropagation();
                    if (focusedNodePath) {
                        logger.log(`[Copy-Paste] Ctrl+C detected. Copying path: ${focusedNodePath}`);
                        onCopy(focusedNodePath);
                    }
                    return;
                case 'v':
                    e.preventDefault(); e.stopPropagation();
                    logger.log(`[Copy-Paste] Ctrl+V detected. Clipboard prop: ${JSON.stringify(clipboard)}. Focused node: ${focusedNodePath}`);
                    if (clipboard && focusedNodePath) {
                        const targetNode = flatNodeList.current.find(n => n.absolutePath === focusedNodePath);
                        if (targetNode) {
                            const destinationDir = targetNode.children 
                                ? targetNode.absolutePath 
                                : targetNode.absolutePath.substring(0, targetNode.absolutePath.lastIndexOf('/'));
                            logger.log(`[Copy-Paste] Pasting '${clipboard.path}' into determined destination: '${destinationDir}'`);
                            clientIpc.sendToServer(ClientToServerChannel.RequestCopyFile, { sourcePath: clipboard.path, destinationDir });
                        } else {
                            logger.error(`[Copy-Paste] Could not find target node for path: ${focusedNodePath}`);
                        }
                    }
                    return;
                case 'z':
                    e.preventDefault(); e.stopPropagation();
                    clientIpc.sendToServer(ClientToServerChannel.RequestUndo, {});
                    return;
                case 'y':
                    e.preventDefault(); e.stopPropagation();
                    clientIpc.sendToServer(ClientToServerChannel.RequestRedo, {});
                    return;
            }
        }

        if (e.key === 'Delete') {
            e.preventDefault();
            e.stopPropagation();
            let pathsToDelete: string[] = [];
            if (selectedPaths.size > 0) {
                pathsToDelete = Array.from(selectedPaths);
            } else if (focusedNodePath) {
                pathsToDelete = [focusedNodePath];
            }
            if (pathsToDelete.length > 0) {
                logger.log(`[Delete] Delete key pressed. Requesting deletion of ${pathsToDelete.length} items.`);
                clientIpc.sendToServer(ClientToServerChannel.RequestBatchFileDelete, { paths: pathsToDelete });
            }
            return;
        }

        if (!focusedNodePath) return;
        const currentIndex = flatNodeList.current.findIndex(n => n.absolutePath === focusedNodePath);
        if (currentIndex === -1) return;
        const currentNode = flatNodeList.current[currentIndex];

        const moveFocus = (nextIndex: number) => {
            if (nextIndex >= 0 && nextIndex < flatNodeList.current.length) {
                const nextNodePath = flatNodeList.current[nextIndex].absolutePath;
                setFocusedNodePath(nextNodePath);
                nodeRefs.current.get(nextNodePath)?.scrollIntoView({ block: 'nearest', inline: 'nearest' });
            }
        };
        
        switch (e.key) {
            case 'ArrowUp': e.preventDefault(); e.stopPropagation(); moveFocus(currentIndex - 1); break;
            case 'ArrowDown': e.preventDefault(); e.stopPropagation(); moveFocus(currentIndex + 1); break;
            case 'ArrowRight': e.preventDefault(); e.stopPropagation(); if (currentNode.children) expandNode(currentNode.absolutePath); break;
            case 'ArrowLeft': e.preventDefault(); e.stopPropagation(); if (currentNode.children && expandedNodes.includes(currentNode.absolutePath)) setExpandedNodes(prev => prev.filter(p => p !== currentNode.absolutePath)); break;
            case ' ': e.preventDefault(); e.stopPropagation(); updateCheckedFiles(currentNode.absolutePath); break;
            case 'Enter': e.preventDefault(); e.stopPropagation(); if (currentNode.children) setExpandedNodes(prev => prev.includes(currentNode.absolutePath) ? prev.filter(p => p !== currentNode.absolutePath) : [...prev, currentNode.absolutePath]); else clientIpc.sendToServer(ClientToServerChannel.RequestOpenFile, { path: currentNode.absolutePath }); break;
        }
    };

    const handleInternalDragStart = (e: React.DragEvent, node: TreeNode) => {
        e.stopPropagation();
        setDraggedPath(node.absolutePath);
        e.dataTransfer.effectAllowed = 'move';
        logger.log(`Internal Drag Start: ${node.name}`);
    };

    const handleDragEnter = (e: React.DragEvent, node: TreeNode) => {
        e.preventDefault();
        e.stopPropagation();
        logger.log(`Drag Enter on node: ${node.name}`);
        if (node.children && node.absolutePath !== draggedPath) {
            setDropTarget(node.absolutePath);
            if (!expandedNodes.includes(node.absolutePath)) {
                expansionTimer.current = setTimeout(() => {
                    logger.log(`Hover-expanding node: ${node.name}`);
                    expandNode(node.absolutePath);
                }, 500);
            }
        }
    };

    const handleDragLeave = (e: React.DragEvent, node: TreeNode) => {
        e.preventDefault();
        e.stopPropagation();
        logger.log(`Drag Leave from node: ${node.name}`);
        if (dropTarget === node.absolutePath) {
            setDropTarget(null);
        }
        if (expansionTimer.current) {
            clearTimeout(expansionTimer.current);
            expansionTimer.current = null;
        }
    };

    const handleDrop = (e: React.DragEvent, node: TreeNode) => {
        e.preventDefault();
        e.stopPropagation();
        logger.log(`Drop on node: ${node.name}`);
        setDropTarget(null);
        if (expansionTimer.current) {
            clearTimeout(expansionTimer.current);
            expansionTimer.current = null;
        }

        if (draggedPath) { 
            if (node.children && node.absolutePath !== draggedPath && !node.absolutePath.startsWith(draggedPath + '/')) {
                const draggedName = draggedPath.split('/').pop();
                if (draggedName) {
                    const newPath = `${node.absolutePath}/${draggedName}`;
                    logger.log(`Requesting internal move from ${draggedPath} to ${newPath}`);
                    clientIpc.sendToServer(ClientToServerChannel.RequestMoveFile, { oldPath: draggedPath, newPath });
                }
            }
            setDraggedPath(null);
        } else if (onNodeDrop) { 
            onNodeDrop(e, node as FileNode);
        }
    };
    
    const handleDragOver = (e: React.DragEvent, node: TreeNode) => {
        e.preventDefault();
        e.stopPropagation();
        if (draggedPath && node.absolutePath.startsWith(draggedPath + '/')) {
            e.dataTransfer.dropEffect = 'none';
        } else {
            e.dataTransfer.dropEffect = 'move';
        }
    };

    const handleContextMenuWrapper = (e: React.MouseEvent, node: TreeNode) => {
        if (onContextMenu) {
            const pathsToActOn = selectedPaths.has(node.absolutePath) ? Array.from(selectedPaths) : [node.absolutePath];
            onContextMenu(e, node, pathsToActOn);
        }
    };

    const renderTreeNodes = (nodes: TreeNode[]) => {
        return nodes.map((node) => {
            const isExpanded = expandedNodes.includes(node.absolutePath);
            const isSelected = selectedPaths.has(node.absolutePath);
            const isFocused = focusedNodePath === node.absolutePath;
            const isDirectory = !!(node.children && node.children.length > 0);
            const isDropTarget = dropTarget === node.absolutePath;

            return (
                <li key={node.absolutePath} 
                    ref={el => {
                        if (el) {
                            nodeRefs.current.set(node.absolutePath, el);
                        } else {
                            nodeRefs.current.delete(node.absolutePath);
                        }
                    }}
                    draggable="true"
                    onDragStart={(e) => handleInternalDragStart(e, node)}
                    onDragEnter={(e) => handleDragEnter(e, node)}
                    onDragLeave={(e) => handleDragLeave(e, node)}
                    onDragOver={(e) => handleDragOver(e, node)}
                    onDrop={(e) => handleDrop(e, node)}
                    className={`treenode-li ${isDropTarget ? 'drop-target' : ''}`}
                    data-path={node.absolutePath}
                >
                    <div
                        className={`treenode-item-wrapper ${isSelected ? 'selected' : ''} ${isFocused ? 'focused' : ''}`}
                        onClick={(e) => handleNodeClick(e, node)}
                        onContextMenu={(e) => handleContextMenuWrapper(e, node)}
                    >
                        <span className={`treenode-chevron ${isExpanded ? 'expanded' : ''}`}>
                            {isDirectory && <VscChevronRight />}
                        </span>
                        <div className="treenode-content">
                            {renderNodeContent ? renderNodeContent(node, isExpanded) : node.name}
                        </div>
                    </div>
                    {isDirectory && isExpanded && (
                        <ul className="treenode-children">{renderTreeNodes(node.children)}</ul>
                    )}
                </li>
            );
        });
    };

    return (
        <div 
            className="tree-view" 
            tabIndex={0} 
            onKeyDown={handleKeyDown} 
            ref={treeViewRef}
            onClick={() => treeViewRef.current?.focus()}
        >
            <ul>{renderTreeNodes(data)}</ul>
        </div>
    );
};

export default TreeView;
</file_artifact>

<file path="src/client/components/tree-view/TreeView.utils.ts">
import { TreeNode } from "./TreeView";

export const getExpandedNodes = (data: TreeNode[]): string[] => {
  return data.reduce((acc: string[], node) => {
    if (node.isExpanded) {
      acc.push(node.absolutePath);
    }
    if (node.children) {
      acc.push(...getExpandedNodes(node.children));
    }
    return acc;
  }, []);
};
</file_artifact>

<file path="src/client/components/Checkbox.tsx">
import React from "react";
import { useEffect, useRef } from "react";

interface CheckboxProps extends Omit<React.DetailedHTMLProps<React.InputHTMLAttributes<HTMLInputElement>, HTMLInputElement>, 'onChange'> {
    checked: boolean;
    indeterminate?: boolean;
    onChange: (checked: boolean, event: React.ChangeEvent<HTMLInputElement>) => void;
}

const Checkbox = (props: CheckboxProps) => {
    const { checked, onChange, indeterminate, ...rest } = props;
    const cRef = useRef<any>(null);

    useEffect(() => {
        if (cRef.current) {
            cRef.current.indeterminate = indeterminate;
        }
    }, [cRef, indeterminate]);

    return (
        <input type="checkbox" ref={cRef} checked={checked} onChange={(e) => onChange(e.target.checked, e)} {...rest} />
    );
};

export default Checkbox;
</file_artifact>

<file path="src/client/components/ContextMenu.tsx">
// Updated on: C167 (Fix multi-select delete)
import React, { useEffect, useRef } from 'react';
import { FileNode } from '@/common/types/file-node';
import { ClientPostMessageManager } from '@/common/ipc/client-ipc';
import { ClientToServerChannel } from '@/common/ipc/channels.enum';

interface ContextMenuProps {
    menu: { x: number; y: number; node: FileNode, paths: string[] };
    onClose: () => void;
    onRename: () => void;
}

const ContextMenu: React.FC<ContextMenuProps> = ({ menu, onClose, onRename }) => {
    const menuRef = useRef<HTMLDivElement>(null);
    const clientIpc = ClientPostMessageManager.getInstance();

    useEffect(() => {
        const handleClickOutside = (event: MouseEvent) => {
            if (menuRef.current && !menuRef.current.contains(event.target as Node)) {
                onClose();
            }
        };
        document.addEventListener('mousedown', handleClickOutside);
        return () => {
            document.removeEventListener('mousedown', handleClickOutside);
        };
    }, [onClose]);

    const handleAction = (action: () => void) => {
        action();
        onClose();
    };
    
    const { node, paths } = menu;
    const isDirectory = !!node.children;
    const isMultiSelect = paths.length > 1;

    const getParentDirectory = () => {
        if (isDirectory) {
            return node.absolutePath;
        }
        const parts = node.absolutePath.split('/');
        parts.pop();
        return parts.join('/');
    };

    const handleDelete = () => {
        clientIpc.sendToServer(ClientToServerChannel.RequestBatchFileDelete, { paths });
    };

    return (
        <>
            <div className="context-menu-overlay" onClick={onClose}></div>
            <div ref={menuRef} className="context-menu" style={{ top: menu.y, left: menu.x }}>
                <ul>
                    <li onClick={() => handleAction(() => clientIpc.sendToServer(ClientToServerChannel.RequestNewFile, { parentDirectory: getParentDirectory() }))}>New File...</li>
                    <li onClick={() => handleAction(() => clientIpc.sendToServer(ClientToServerChannel.RequestNewFolder, { parentDirectory: getParentDirectory() }))}>New Folder...</li>
                    <hr />
                    <li className={isMultiSelect ? 'disabled' : ''} onClick={() => !isMultiSelect && handleAction(() => onRename())}>Rename</li>
                    <li onClick={() => handleAction(handleDelete)}>Delete</li>
                    <hr />
                    <li className={isMultiSelect ? 'disabled' : ''} onClick={() => !isMultiSelect && handleAction(() => clientIpc.sendToServer(ClientToServerChannel.RequestCopyPath, { path: node.absolutePath, relative: false }))}>Copy Path</li>
                    <li className={isMultiSelect ? 'disabled' : ''} onClick={() => !isMultiSelect && handleAction(() => clientIpc.sendToServer(ClientToServerChannel.RequestCopyPath, { path: node.absolutePath, relative: true }))}>Copy Relative Path</li>
                    <hr />
                    <li className={isMultiSelect ? 'disabled' : ''} onClick={() => !isMultiSelect && handleAction(() => clientIpc.sendToServer(ClientToServerChannel.RequestRevealInExplorer, { path: node.absolutePath }))}>Reveal in File Explorer</li>
                </ul>
            </div>
        </>
    );
};

export default ContextMenu;
</file_artifact>

<file path="src/client/components/LocationPane.tsx">
// src/client/components/LocationPane.tsx
import * as React from 'react';

interface PairedLine {
    isDiff: boolean;
}

interface LocationPaneProps {
    pairedLines: PairedLine[];
    onLineClick: (index: number) => void;
}

const LocationPane: React.FC<LocationPaneProps> = ({ pairedLines, onLineClick }) => {
    return (
        <div className="location-pane">
            {pairedLines.map((line, index) => (
                <div
                    key={index}
                    className={`location-line ${line.isDiff ? 'changed' : 'unchanged'}`}
                    onClick={() => onLineClick(index)}
                    title={`Line ${index + 1}`}
                />
            ))}
        </div>
    );
};

export default LocationPane;
</file_artifact>

<file path="src/client/components/SelectedFilesView.tsx">
import * as React from 'react';
import { useState, useMemo, useRef, useEffect } from 'react';
import { FileNode } from '@/common/types/file-node';
import { VscChevronUp, VscChevronDown, VscSymbolFile, VscSymbolNumeric, VscTypeHierarchy, VscClose, VscChevronRight, VscChevronLeft } from 'react-icons/vsc';
import { formatLargeNumber } from '@/common/utils/formatting';
import { SiReact, SiSass, SiTypescript, SiJavascript } from 'react-icons/si';
import { VscFile, VscJson, VscMarkdown, VscTable } from 'react-icons/vsc';
import { logger } from '../utils/logger';
import { ClientPostMessageManager } from '@/common/ipc/client-ipc';
import { ClientToServerChannel } from '@/common/ipc/channels.enum';
import { FaFileWord } from 'react-icons/fa';

type SortableColumn = 'name' | 'tokenCount' | 'extension';
type SortDirection = 'asc' | 'desc';

const getFileIcon = (fileName: string) => {
    const extension = fileName.split('.').pop()?.toLowerCase();
    switch (extension) {
        case 'ts': return <SiTypescript color="#3178C6" />;
        case 'tsx': return <SiReact color="#61DAFB" />;
        case 'js': return <SiJavascript color="#F7DF1E" />;
        case 'json': return <VscJson color="#F7DF1E" />;
        case 'md': return <VscMarkdown />;
        case 'scss': case 'css': return <SiSass color="#CF649A"/>;
        case 'xlsx': case 'xls': case 'csv': return <VscTable color="#217346" />;
        case 'docx': return <FaFileWord color="#2B579A" />;
        default: return <VscFile />;
    }
};

const getTokenBackgroundColor = (tokenCount: number): string => {
    // 0 - 8k: green
    if (tokenCount <= 8000) return 'hsla(120, 60%, 50%, 0.1)';
    // 8k - 10k: green to yellow
    if (tokenCount <= 10000) {
        const percentage = (tokenCount - 8000) / 2000;
        const hue = 120 - (percentage * 60); // 120 (green) -> 60 (yellow)
        return `hsla(${hue}, 70%, 50%, 0.15)`;
    }
    // 10k - 12k: yellow to orange
    if (tokenCount <= 12000) {
        const percentage = (tokenCount - 10000) / 2000;
        const hue = 60 - (percentage * 30); // 60 (yellow) -> 30 (orange)
        return `hsla(${hue}, 80%, 50%, 0.2)`;
    }
    // 12k+: orange to red
    const percentage = Math.min((tokenCount - 12000) / 28000, 1.0); // Cap at 40k for max red
    const hue = 30 - (percentage * 30); // 30 (orange) -> 0 (red)
    return `hsla(${hue}, 80%, 50%, 0.25)`;
};

const getTokenRiskTooltip = (tokenCount: number): string => {
    if (tokenCount <= 8000) return 'Low token count, suitable for most workloads.';
    if (tokenCount <= 10000) return 'Slightly elevated token count, small chance of performance degradation.';
    if (tokenCount <= 12000) return 'Moderate token count, may impact performance on complex tasks.';
    return 'High token count, increased chance of performance degradation or truncation if outputting this file.';
};


interface SelectedFilesViewProps {
    selectedFileNodes: FileNode[];
    onRemove: (pathsToRemove: string[]) => void;
    isMinimized: boolean;
    onToggleMinimize: () => void;
}

const SelectedFilesView: React.FC<SelectedFilesViewProps> = ({ selectedFileNodes, onRemove, isMinimized, onToggleMinimize }) => {
    const [sortColumn, setSortColumn] = useState<SortableColumn>('tokenCount');
    const [sortDirection, setSortDirection] = useState<SortDirection>('desc');
    const [selection, setSelection] = useState<Set<string>>(new Set());
    const [hoveredPath, setHoveredPath] = useState<string | null>(null);
    const [contextMenu, setContextMenu] = useState<{ x: number; y: number } | null>(null);
    const firstClickedPath = useRef<string | null>(null); // Anchor for shift-click
    const listRef = useRef<HTMLUListElement>(null);
    const clientIpc = ClientPostMessageManager.getInstance();

    // Reset selection when the list of files changes
    useEffect(() => {
        setSelection(new Set());
    }, [selectedFileNodes]);

    const sortedFiles = useMemo(() => {
        return [...selectedFileNodes].sort((a, b) => {
            const dir = sortDirection === 'asc' ? 1 : -1;
            if (sortColumn === 'name') {
                return a.name.localeCompare(b.name, undefined, { numeric: true }) * dir;
            }
            if (sortColumn === 'extension') {
                const extA = a.extension || '';
                const extB = b.extension || '';
                if (extA !== extB) {
                    return extA.localeCompare(extB) * dir;
                }
                // Sub-sort by token count if extensions are the same
                return (b.tokenCount - a.tokenCount);
            }
            // Default and tokenCount sort
            return (a.tokenCount - b.tokenCount) * dir;
        });
    }, [selectedFileNodes, sortColumn, sortDirection]);

    const handleSort = (column: SortableColumn) => {
        if (column === sortColumn) {
            setSortDirection(prev => prev === 'asc' ? 'desc' : 'asc');
        } else {
            setSortColumn(column);
            setSortDirection(column === 'tokenCount' ? 'desc' : 'asc');
        }
    };

    const handleItemClick = (e: React.MouseEvent, path: string) => {
        if ((e.target as HTMLElement).closest('.quick-remove-icon')) {
            return;
        }
        
        const newSelection = new Set(selection);

        if (e.shiftKey && firstClickedPath.current) {
            const firstIdx = sortedFiles.findIndex(f => f.absolutePath === firstClickedPath.current);
            const currentIdx = sortedFiles.findIndex(f => f.absolutePath === path);
            const start = Math.min(firstIdx, currentIdx);
            const end = Math.max(firstIdx, currentIdx);
            
            if (!e.ctrlKey) newSelection.clear();

            for (let i = start; i <= end; i++) {
                newSelection.add(sortedFiles[i].absolutePath);
            }
        } else if (e.ctrlKey) {
            if (newSelection.has(path)) {
                newSelection.delete(path);
            } else {
                newSelection.add(path);
            }
            firstClickedPath.current = path; // Update anchor on ctrl-click
        } else {
            clientIpc.sendToServer(ClientToServerChannel.RequestOpenFile, { path });
            // C38 Fix: Re-focus the list after a delay to reclaim focus from the editor
            setTimeout(() => listRef.current?.focus(), 100);
            newSelection.clear();
            newSelection.add(path);
            firstClickedPath.current = path;
        }
        
        setSelection(newSelection);
    };
    
    const handleRemoveSelected = () => {
        logger.log(`"Remove selected" button clicked. Removing ${selection.size} items.`);
        onRemove(Array.from(selection));
        setSelection(new Set());
    };

    const handleKeyDown = (e: React.KeyboardEvent<HTMLUListElement>) => {
        switch (e.key) {
            case 'a':
                if (e.ctrlKey || e.metaKey) {
                    e.preventDefault();
                    e.stopPropagation();
                    logger.log('Ctrl+A detected in SelectedFilesView.');
                    const allPaths = new Set(sortedFiles.map(f => f.absolutePath));
                    setSelection(allPaths);
                }
                break;
            case 'Delete':
                e.preventDefault();
                e.stopPropagation();
                if (selection.size > 0) {
                    logger.log(`Delete key pressed. Removing ${selection.size} items.`);
                    handleRemoveSelected();
                }
                break;
        }
    };

    const handleContainerClick = () => {
        listRef.current?.focus();
    };

    const handleContextMenu = (event: React.MouseEvent) => {
        event.preventDefault();
        setContextMenu({ x: event.clientX, y: event.clientY });
    };

    const handleSelectAll = () => {
        const allPaths = new Set(sortedFiles.map(f => f.absolutePath));
        setSelection(allPaths);
        setContextMenu(null);
    };

    const handleDeselectAll = () => {
        setSelection(new Set());
        setContextMenu(null);
    };
    
    const SortIndicator = ({ column }: { column: SortableColumn }) => {
        if (sortColumn !== column) return null;
        return sortDirection === 'asc' ? <VscChevronUp /> : <VscChevronDown />;
    };

    return (
        <div className="selected-files-panel" onClick={handleContainerClick}>
            <div className="panel-header">
                <span>Selected Items ({selectedFileNodes.length})</span>
                <button onClick={onToggleMinimize} className="toolbar-button" title={isMinimized ? "Expand" : "Minimize"}>
                    {isMinimized ? <VscChevronRight /> : <VscChevronDown />}
                </button>
            </div>
            {!isMinimized && (
                <>
                    <div className="panel-toolbar">
                        <button onClick={handleRemoveSelected} disabled={selection.size === 0}>
                            Remove selected ({selection.size})
                        </button>
                    </div>
                    <div className="selected-files-list-container">
                        <div className="selected-list-header">
                            <div className="header-index">#</div>
                            <div className="header-type" onClick={() => handleSort('extension')} title="Sort by File Type">
                                <VscTypeHierarchy /> <SortIndicator column="extension" />
                            </div>
                            <div className="header-name" onClick={() => handleSort('name')}>
                                <VscSymbolFile /> File <SortIndicator column="name" />
                            </div>
                            <div className="header-tokens" onClick={() => handleSort('tokenCount')}>
                                <VscSymbolNumeric /> Tokens <SortIndicator column="tokenCount" />
                            </div>
                        </div>
                        <ul className="selected-files-list" ref={listRef} tabIndex={0} onKeyDown={handleKeyDown} onContextMenu={handleContextMenu}>
                            {sortedFiles.map((node, index) => (
                                <li key={node.absolutePath} 
                                    className={selection.has(node.absolutePath) ? 'selected' : ''}
                                    onClick={(e) => handleItemClick(e, node.absolutePath)}
                                    onMouseEnter={() => setHoveredPath(node.absolutePath)}
                                    onMouseLeave={() => setHoveredPath(null)}
                                    style={{ backgroundColor: node.isImage ? 'transparent' : getTokenBackgroundColor(node.tokenCount) }}
                                    title={node.isImage ? `Binary file: ${node.name}` : getTokenRiskTooltip(node.tokenCount)}
                                >
                                    <span className="file-index">
                                        {hoveredPath === node.absolutePath ? (
                                            <span 
                                                className="quick-remove-icon" 
                                                title="Remove from selection"
                                                onClick={(e) => { e.stopPropagation(); onRemove([node.absolutePath]); }}
                                            >
                                                <VscClose />
                                            </span>
                                        ) : (
                                            index + 1
                                        )}
                                    </span>
                                    <span className="file-icon">{getFileIcon(node.name)}</span>
                                    <span className="file-name" title={node.absolutePath}>{node.name}</span>
                                    <span className="file-tokens">{formatLargeNumber(node.tokenCount, 1)}</span>
                                </li>
                            ))}
                        </ul>
                    </div>
                </>
            )}
            {contextMenu && (
                 <>
                    <div className="context-menu-overlay" onClick={() => setContextMenu(null)}></div>
                    <div className="context-menu" style={{ top: contextMenu.y, left: contextMenu.x }}>
                        <ul>
                            <li onClick={handleSelectAll}>Select All</li>
                            <li onClick={handleDeselectAll}>Deselect All</li>
                        </ul>
                    </div>
                </>
            )}
        </div>
    );
};

export default SelectedFilesView;
</file_artifact>

<file path="src/client/utils/logger.ts">
import { ClientPostMessageManager } from "@/common/ipc/client-ipc";
import { ClientToServerChannel } from "@/common/ipc/channels.enum";

const clientIpc = ClientPostMessageManager.getInstance();

export const logger = {
    log: (message: string) => {
        console.log(message); // Also log to dev console
        clientIpc.sendToServer(ClientToServerChannel.LogMessage, { level: 'info', message });
    },
    warn: (message: string) => {
        console.warn(message);
        clientIpc.sendToServer(ClientToServerChannel.LogMessage, { level: 'warn', message });
    },
    error: (message: string) => {
        console.error(message);
        clientIpc.sendToServer(ClientToServerChannel.LogMessage, { level: 'error', message });
    }
};
</file_artifact>

<file path="src/client/views/context-chooser.view/index.ts">
import { onMessage } from "./on-message";

export const viewConfig = {
    entry: "contextChooserView.js",
    type: "viewType.sidebar.contextChooser",
    handleMessage: onMessage,
};
</file_artifact>

<file path="src/client/views/context-chooser.view/on-message.ts">
// Updated on: C166 (Add RequestOpenFolder handler)
import { ServerPostMessageManager } from "@/common/ipc/server-ipc";
import { Services } from "@/backend/services/services";
import { ClientToServerChannel, ServerToClientChannel } from "@/common/ipc/channels.enum";
import * as vscode from 'vscode';

export function onMessage(serverIpc: ServerPostMessageManager) {
    const { 
        fileTreeService, 
        flattenerService, 
        selectionService, 
        loggerService, 
        actionService,
        contentExtractionService,
        fileOperationService
    } = Services;

    loggerService.log("Context Chooser view message handler initialized.");

    serverIpc.onClientMessage(ClientToServerChannel.RequestInitialData, () => {
        loggerService.log("[on-message] Received RequestInitialData. Forwarding to services.");
        fileTreeService.handleWorkspaceFilesRequest(serverIpc);
        serverIpc.sendToClient(ServerToClientChannel.SendSelectionSets, { sets: selectionService.getSelectionSets() });
        serverIpc.sendToClient(ServerToClientChannel.SendAutoAddState, { enabled: selectionService.getAutoAddState() });
    });

    serverIpc.onClientMessage(ClientToServerChannel.RequestWorkspaceFiles, (data) => {
        loggerService.log(`[C161 DEBUG] IPC received RequestWorkspaceFiles. force=${data.force}`);
        fileTreeService.handleWorkspaceFilesRequest(serverIpc, data.force);
    });
    
    serverIpc.onClientMessage(ClientToServerChannel.RequestFlattenContext, (data) => {
        flattenerService.flatten(data.selectedPaths);
    });

    serverIpc.onClientMessage(ClientToServerChannel.LogMessage, (data) => {
        loggerService[data.level](`[WebView] ${data.message}`);
    });
    
    serverIpc.onClientMessage(ClientToServerChannel.SaveCurrentSelection, (data) => {
        selectionService.saveCurrentSelection(data.paths);
    });

    serverIpc.onClientMessage(ClientToServerChannel.RequestLastSelection, async () => {
        const paths = await selectionService.getLastSelection();
        serverIpc.sendToClient(ServerToClientChannel.ApplySelectionSet, { paths });
    });

    serverIpc.onClientMessage(ClientToServerChannel.VSCodeCommand, (data) => {
        vscode.commands.executeCommand(data.command, ...(data.args || []));
    });

    serverIpc.onClientMessage(ClientToServerChannel.SaveAutoAddState, (data) => {
        selectionService.saveAutoAddState(data.enabled);
    });

    // File Operations
    serverIpc.onClientMessage(ClientToServerChannel.RequestNewFile, (data) => fileOperationService.handleNewFileRequest(data.parentDirectory));
    serverIpc.onClientMessage(ClientToServerChannel.RequestNewFolder, (data) => fileOperationService.handleNewFolderRequest(data.parentDirectory));
    serverIpc.onClientMessage(ClientToServerChannel.RequestFileRename, (data) => fileOperationService.handleFileRenameRequest(data.oldPath, data.newName));
    serverIpc.onClientMessage(ClientToServerChannel.RequestFileDelete, (data) => fileOperationService.handleFileDeleteRequest(data.path));
    serverIpc.onClientMessage(ClientToServerChannel.RequestBatchFileDelete, (data) => fileOperationService.handleBatchFileDeleteRequest(data.paths));
    serverIpc.onClientMessage(ClientToServerChannel.RequestRevealInExplorer, (data) => fileOperationService.handleRevealInExplorerRequest(data.path));
    serverIpc.onClientMessage(ClientToServerChannel.RequestCopyPath, (data) => fileOperationService.handleCopyPathRequest(data.path, data.relative));
    serverIpc.onClientMessage(ClientToServerChannel.RequestOpenFile, (data) => fileOperationService.handleOpenFileRequest(data.path));
    serverIpc.onClientMessage(ClientToServerChannel.RequestOpenFolder, () => fileOperationService.handleOpenFolderRequest());
    serverIpc.onClientMessage(ClientToServerChannel.RequestMoveFile, (data) => fileOperationService.handleMoveFileRequest(data.oldPath, data.newPath));
    serverIpc.onClientMessage(ClientToServerChannel.RequestUndo, () => actionService.undo());
    serverIpc.onClientMessage(ClientToServerChannel.RequestRedo, () => actionService.redo());
    serverIpc.onClientMessage(ClientToServerChannel.RequestAddFileFromBuffer, (data) => fileOperationService.handleAddFileFromBuffer(data.targetPath, data.data));
    serverIpc.onClientMessage(ClientToServerChannel.RequestCopyFile, (data) => fileOperationService.handleCopyFileRequest(data.sourcePath, data.destinationDir));
    serverIpc.onClientMessage(ClientToServerChannel.RequestCopyFileFromUri, (data) => fileOperationService.handleCopyFileFromUri(data.sourceUri, data.targetDir));
    
    // Content Extraction
    serverIpc.onClientMessage(ClientToServerChannel.RequestPdfToText, (data) => contentExtractionService.handlePdfToTextRequest(data.path, serverIpc));
    serverIpc.onClientMessage(ClientToServerChannel.RequestExcelToText, (data) => contentExtractionService.handleExcelToTextRequest(data.path, serverIpc));
    serverIpc.onClientMessage(ClientToServerChannel.RequestWordToText, (data) => contentExtractionService.handleWordToTextRequest(data.path, serverIpc));
}
</file_artifact>

<file path="src/client/views/context-chooser.view/view.scss">
/* Updated on: C167 (Add secondary button style) */
body {
    padding: 0;
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, "Noto Sans", sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol", "Noto Color Emoji";
    font-size: 13px;
    color: var(--vscode-editor-foreground);
    background-color: var(--vscode-sideBar-background);
}

.workspace-trust-banner {
    display: flex;
    align-items: center;
    gap: 8px;
    padding: 6px 8px;
    background-color: var(--vscode-statusBarItem-warningBackground);
    color: var(--vscode-statusBarItem-warningForeground);
    font-size: 12px;
    flex-shrink: 0;

    button {
        background: none;
        border: 1px solid var(--vscode-button-border, var(--vscode-contrastBorder));
        color: var(--vscode-button-foreground);
        padding: 2px 8px;
        border-radius: 2px;
        cursor: pointer;
        margin-left: auto;

        &:hover {
            background-color: var(--vscode-button-hoverBackground);
        }
    }
}


.view-container {
    display: flex;
    flex-direction: column;
    height: 100vh;
    outline: 2px solid transparent;
    transition: outline-color 0.2s ease-in-out;
}

.view-container.drag-over {
    outline-color: var(--vscode-focusBorder);
    outline-style: dashed;
}


.view-header {
    padding: 0 8px; /* Remove vertical padding */
    border-bottom: 1px solid var(--vscode-panel-border);
    display: flex;
    flex-direction: column; /* Stack title/search and toolbar */
    gap: 4px;
    padding-top: 4px;
    padding-bottom: 4px;
    flex-shrink: 0;
}

.header-row {
    display: flex;
    justify-content: space-between;
    align-items: center;
    min-height: 28px; /* Ensure consistent height */
}

.search-container {
    width: 100%;
    padding-bottom: 4px;

    input {
        width: 100%;
        background-color: var(--vscode-input-background);
        color: var(--vscode-input-foreground);
        border: 1px solid var(--vscode-input-border);
        padding: 2px 4px;
        border-radius: 2px;
        outline: none;

        &:focus {
            border-color: var(--vscode-focusBorder);
        }
    }
}


.toolbar {
    display: flex;
    gap: 4px;
    
    button, .dropdown-button {
        background: none;
        border: none;
        color: var(--vscode-icon-foreground);
        cursor: pointer;
        padding: 4px;
        border-radius: 3px;
        display: flex;
        align-items: center;
        justify-content: center;

        &:hover {
            background-color: var(--vscode-toolbar-hoverBackground);
        }

        &.active {
             background-color: var(--vscode-toolbar-hoverBackground);
             color: var(--vscode-focusBorder);
        }
    }

    .spinner {
        display: flex;
        align-items: center;
        padding: 4px;
        animation: spin 1.5s linear infinite;
    }

    @keyframes spin {
        from { transform: rotate(0deg); }
        to { transform: rotate(360deg); }
    }
}

.selected-files-panel {
    display: flex;
    flex-direction: column;
    flex-shrink: 0; 
    border-top: 1px solid var(--vscode-panel-border);
    max-height: 40%; /* Give it a max height */
}

.panel-header {
    font-weight: bold;
    padding: 4px 8px;
    font-size: 11px;
    text-transform: uppercase;
    color: var(--vscode-sideBar-titleForeground);
    border-bottom: 1px solid var(--vscode-panel-border);
    flex-shrink: 0;
    display: flex;
    justify-content: space-between;
    align-items: center;

    .toolbar-button {
        background: none;
        border: none;
        color: var(--vscode-icon-foreground);
        cursor: pointer;
        padding: 2px;
        border-radius: 3px;
        display: flex;
        align-items: center;
        justify-content: center;

        &:hover {
            background-color: var(--vscode-toolbar-hoverBackground);
        }
    }
}

.panel-toolbar {
    padding: 4px 8px;
    flex-shrink: 0;
    border-bottom: 1px solid var(--vscode-panel-border);

    button {
        background-color: var(--vscode-button-secondaryBackground);
        color: var(--vscode-button-secondaryForeground);
        border: 1px solid var(--vscode-button-border, var(--vscode-focusBorder));
        padding: 2px 8px;
        font-size: 12px;
        cursor: pointer;
        border-radius: 2px;
        
        &:hover {
            background-color: var(--vscode-button-secondaryHoverBackground);
        }

        &:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }
    }
}

.selected-files-list-container {
    overflow-y: auto;
    flex-grow: 1;
}

.selected-list-header {
    display: flex;
    align-items: center; /* Align items vertically */
    font-weight: bold;
    font-size: 11px;
    padding: 2px 8px;
    border-bottom: 1px solid var(--vscode-panel-border);
    user-select: none;
    gap: 8px; /* Add gap for spacing */

    > div {
        cursor: pointer;
        display: flex;
        align-items: center;
        gap: 4px;
    }

    .header-index {
        width: 30px;
        flex-shrink: 0;
        text-align: right; /* Right-align the '#' header */
        padding-right: 10px;
        justify-content: flex-end; /* Ensure flex items are at the end */
    }

    .header-type {
        width: 20px;
        flex-shrink: 0;
        justify-content: center;
    }

    .header-name {
        flex-grow: 1;
    }

    .header-tokens {
        flex-shrink: 0;
        width: 80px;
        justify-content: flex-end;
    }
}

.selected-files-list {
    list-style: none;
    padding: 0;
    margin: 0;

    &:focus {
        outline: 1px solid var(--vscode-focusBorder);
        outline-offset: -1px;
    }

    li {
        display: flex;
        align-items: center;
        padding: 2px 8px;
        font-size: 12px;
        gap: 8px;
        cursor: pointer;
        user-select: none;
        border-radius: 2px;
        margin: 1px 2px;

        &.selected {
            background-color: var(--vscode-list-activeSelectionBackground) !important; /* Use important to override token color */
            color: var(--vscode-list-activeSelectionForeground) !important;
        }

        &:hover {
            background-color: var(--vscode-list-hoverBackground);
        }
        
        .file-index {
            width: 30px;
            flex-shrink: 0;
            color: var(--vscode-descriptionForeground);
            text-align: right; /* Right-align the numbers */
            padding-right: 10px;
            position: relative;
            display: flex;
            justify-content: flex-end; /* Right-align the content (number or icon) */
            align-items: center;
            height: 100%;
        }

        .quick-remove-icon {
            display: flex;
            align-items: center;
            justify-content: center;
            width: 100%;
            height: 100%;
            color: var(--vscode-icon-foreground);
            &:hover {
                color: var(--vscode-errorForeground);
            }
        }

        .file-icon {
            font-size: 16px;
            width: 20px;
            flex-shrink: 0;
            text-align: center;
        }

        .file-name {
            white-space: nowrap;
            overflow: hidden;
            text-overflow: ellipsis;
            flex-grow: 1;
        }

        .file-tokens {
            color: var(--vscode-descriptionForeground);
            font-variant-numeric: tabular-nums;
            width: 80px;
            text-align: right;
            flex-shrink: 0;
        }
    }
}

.file-tree-container {
    flex-grow: 1; 
    overflow-y: auto;
    overflow-x: hidden;
    min-height: 0; /* CRITICAL FIX for flexbox overflow */
    border-right: 1px solid var(--vscode-panel-border); /* Fix for scrollbar gutter visibility */
}

.view-footer {
    padding: 8px;
    border-top: 1px solid var(--vscode-panel-border);
    display: flex;
    flex-direction: column;
    gap: 8px;
    flex-shrink: 0;
}

.footer-buttons {
    display: flex;
    gap: 8px;
}

.dce-button-primary {
    flex-grow: 1;
    padding: 6px;
    border: 1px solid var(--vscode-button-border, var(--vscode-focusBorder));
    background-color: var(--vscode-button-background);
    color: var(--vscode-button-foreground);
    cursor: pointer;
    border-radius: 2px;

    &:hover {
        background-color: var(--vscode-button-hoverBackground);
    }
}

.dce-button-secondary {
    flex-grow: 1;
    padding: 6px;
    border: 1px solid var(--vscode-button-border, var(--vscode-focusBorder));
    background-color: var(--vscode-button-secondaryBackground);
    color: var(--vscode-button-secondaryForeground);
    cursor: pointer;
    border-radius: 2px;

    &:hover {
        background-color: var(--vscode-button-secondaryHoverBackground);
    }
}


.loading-message, .no-folder-message {
    padding: 16px;
    text-align: center;
    color: var(--vscode-descriptionForeground);
    display: flex;
    flex-direction: column;
    gap: 8px;
    align-items: center;
    justify-content: center;
    height: 100%;
}


.summary-panel {
    font-size: 12px;
    color: var(--vscode-descriptionForeground);
    display: flex;
    justify-content: space-between;
    gap: 12px;
}

.summary-item {
    display: flex;
    align-items: center;
    gap: 4px;
}

.tree-view {
    &:focus {
        outline: none; /* Remove default browser focus ring */
    }

    ul {
        list-style-type: none;
        margin: 0;
        padding-left: 0;
    }

    ul.treenode-children {
        padding-left: 10px; 
    }
}


.treenode-li {
    position: relative;
    border-radius: 3px;
}

/* Drag and Drop style */
.treenode-li.drop-target > .treenode-item-wrapper {
    background-color: var(--vscode-list-dropBackground) !important;
    outline: 1px solid var(--vscode-focusBorder) !important;
}

.treenode-item-wrapper {
    display: flex;
    align-items: center;
    cursor: pointer;
    padding: 1px 4px;
    border-radius: 3px;
    min-height: 22px;
    outline: 1px solid transparent; /* Placeholder for focus ring */
    outline-offset: -1px;
}

.treenode-item-wrapper.focused {
    outline-color: var(--vscode-focusBorder);
}

.treenode-item-wrapper:hover {
    background-color: var(--vscode-list-hoverBackground);
}

.treenode-item-wrapper.selected {
    background-color: var(--vscode-list-activeSelectionBackground);
    color: var(--vscode-list-activeSelectionForeground);
}

.treenode-chevron {
    flex-shrink: 0;
    width: 20px;
    height: 22px;
    display: flex;
    align-items: center;
    justify-content: center;
    transition: transform 0.1s ease-in-out;
}

.treenode-chevron.expanded {
    transform: rotate(90deg);
}

.treenode-content {
    flex-grow: 1;
    display: flex;
    align-items: center;
    overflow: hidden;
}


.file-item {
    display: flex;
    align-items: center;
    width: 100%;
    padding: 1px;
    gap: 6px;
}

.file-checkbox {
    cursor: pointer;
    flex-shrink: 0;

    &:disabled {
        cursor: not-allowed;
        opacity: 0.5;
    }
}

.file-icon {
    display: flex;
    align-items: center;
    font-size: 16px;
    flex-shrink: 0;
}

.file-name {
    white-space: nowrap;
    overflow: hidden;
    text-overflow: ellipsis;
    flex-grow: 1;
    user-select: none; /* Prevent text selection on click/drag */
}

/* Error Styling */
.file-item.has-error {
    color: var(--vscode-list-errorForeground);
    opacity: 0.7;

    .file-name {
        text-decoration: line-through;
    }
}

.error-icon {
    color: var(--vscode-errorForeground);
}


/* Git Status & Problems Styling */
.file-item.git-status-M .file-name, .file-item.git-status-M .git-status-badge { color: var(--vscode-gitDecoration-modifiedResourceForeground); }
.file-item.git-status-U .file-name, .file-item.git-status-U .git-status-badge { color: var(--vscode-gitDecoration-untrackedResourceForeground); }
.file-item.git-status-D .file-name, .file-item.git-status-D .git-status-badge { color: var(--vscode-gitDecoration-deletedResourceForeground); }
.file-item.git-status-A .file-name, .file-item.git-status-A .git-status-badge { color: var(--vscode-gitDecoration-addedResourceForeground); }
.file-item.git-status-C .file-name, .file-item.git-status-C .git-status-badge { color: var(--vscode-gitDecoration-conflictingResourceForeground); }
.file-item.git-status-I .file-name, .file-item.git-status-I .git-status-badge { color: var(--vscode-gitDecoration-ignoredResourceForeground); }

.file-item.problem-error .file-name { color: var(--vscode-list-errorForeground); }
.file-item.problem-warning .file-name { color: var(--vscode-list-warningForeground); }

.git-status-badge {
    font-weight: bold;
}

.problem-badge {
    display: flex;
    align-items: center;
    gap: 3px;
    
    & .error-icon {
      color: var(--vscode-list-errorForeground);
    }
    
    & .warning-icon {
      color: var(--vscode-list-warningForeground);
    }
}

.file-stats {
    margin-left: auto;
    padding-left: 8px;
    font-size: 11px;
    color: var(--vscode-descriptionForeground);
    flex-shrink: 0;
    white-space: nowrap;
    display: flex;
    align-items: center;
    gap: 8px;
    justify-content: flex-end;
    text-align: right;
}

.file-stats > * {
    display: flex;
    align-items: center;
    gap: 3px;
}

.selected-token-count {
    font-style: italic;
}

/* Context Menu Styles */
.context-menu-overlay {
    position: fixed;
    top: 0;
    left: 0;
    right: 0;
    bottom: 0;
    z-index: 999;
}

.context-menu {
    position: absolute;
    background-color: var(--vscode-menu-background);
    border: 1px solid var(--vscode-menu-border);
    color: var(--vscode-menu-foreground);
    box-shadow: 0 2px 8px var(--vscode-widget-shadow);
    border-radius: 4px;
    padding: 4px 0;
    min-width: 180px;
    z-index: 1000;

    ul {
        list-style: none;
        padding: 0;
        margin: 0;
    }

    li {
        padding: 4px 12px;
        cursor: pointer;
        display: flex;
        align-items: center;
        gap: 8px;

        &:hover {
            background-color: var(--vscode-menu-selectionBackground);
            color: var(--vscode-menu-selectionForeground);
        }
        
        &.disabled {
            color: var(--vscode-disabledForeground);
            cursor: not-allowed;
            background-color: transparent;
        }
    }

    hr {
        border: none;
        border-top: 1px solid var(--vscode-menu-separatorBackground);
        margin: 4px 0;
    }
}

.rename-input {
    background-color: var(--vscode-input-background);
    color: var(--vscode-input-foreground);
    border: 1px solid var(--vscode-focusBorder);
    outline: none;
    width: 100%;
    padding: 0;
    margin: 0;
    font-size: inherit;
    font-family: inherit;
}
</file_artifact>

<file path="src/client/views/context-chooser.view/view.tsx">
// Updated on: C26 (Add targeted logging)
import * as React from 'react';
import * as ReactDOM from 'react-dom/client';
import './view.scss';
import { ClientPostMessageManager } from '../../../common/ipc/client-ipc';
import { ClientToServerChannel, ServerToClientChannel } from '../../../common/ipc/channels.enum';
import { FileNode } from '../../../common/types/file-node';
import FileTree from '../../components/file-tree/FileTree';
import { useState, useEffect, useMemo, useCallback, useRef } from 'react';
import { formatLargeNumber, formatNumberWithCommas } from '../../../common/utils/formatting';
import { VscFiles, VscSymbolNumeric, VscCollapseAll, VscRefresh, VscNewFile, VscNewFolder, VscLoading, VscSave, VscFolderLibrary, VscSettingsGear, VscCheckAll, VscSearch, VscExpandAll, VscShield, VscFolder } from 'react-icons/vsc';
import { logger } from '../../utils/logger';
import SelectedFilesView from '../../components/SelectedFilesView';
import { addRemovePathInSelectedFiles, removePathsFromSelected } from '../../components/file-tree/FileTree.utils';
import { SelectionSet, ProblemCountsMap, GitStatusMap } from '../../../common/ipc/channels.type';
import path from 'path-browserify';

const EXCEL_EXTENSIONS = new Set(['.xlsx', '.xls', '.csv']);
const WORD_EXTENSIONS = new Set(['.docx', '.doc']);

const App = () => {
    const [files, setFiles] = useState<FileNode[]>([]);
    const [checkedFiles, setCheckedFiles] = useState<string[]>([]);
    const [activeFile, setActiveFile] = useState<string | undefined>();
    const [collapseTrigger, setCollapseTrigger] = useState(0);
    const [expandAllTrigger, setExpandAllTrigger] = useState(0);
    const [isLoading, setIsLoading] = useState(true);
    const [selectionSets, setSelectionSets] = useState<SelectionSet>({});
    const [isSelectionListMinimized, setIsSelectionListMinimized] = useState(false);
    const [isAutoAddEnabled, setIsAutoAddEnabled] = useState(false);
    const [isSearchVisible, setIsSearchVisible] = useState(false);
    const [searchTerm, setSearchTerm] = useState('');
    const [problemMap, setProblemMap] = useState<ProblemCountsMap>({});
    const [gitStatusMap, setGitStatusMap] = useState<GitStatusMap>({});
    const [isDraggingOver, setIsDraggingOver] = useState(false);
    const [isWorkspaceTrusted, setIsWorkspaceTrusted] = useState(true);
    const [clipboard, setClipboard] = useState<{ path: string; type: 'copy' } | null>(null);
    const suppressActiveFileReveal = useRef(false);
    const processedFilesCache = useRef(new Set<string>());
    
    const clientIpc = ClientPostMessageManager.getInstance();

    const requestFiles = (force = false) => {
        setIsLoading(true);
        clientIpc.sendToServer(ClientToServerChannel.RequestWorkspaceFiles, { force });
    };

    const updateCheckedFiles = useCallback((path: string) => {
        setCheckedFiles(currentChecked => {
            const newChecked = addRemovePathInSelectedFiles(files, path, currentChecked);
            clientIpc.sendToServer(ClientToServerChannel.SaveCurrentSelection, { paths: newChecked });
            return newChecked;
        });
    }, [clientIpc, files]);

    useEffect(() => {
        if (files.length === 0 || checkedFiles.length === 0) return;
        const effectivelySelectedFiles = new Set<string>();
        const fileMap = new Map<string, FileNode>();
        const buildFileMap = (node: FileNode) => { fileMap.set(node.absolutePath, node); node.children?.forEach(buildFileMap); };
        files.forEach(buildFileMap);
        const addDescendantFiles = (node: FileNode) => { if (!node.isSelectable) return; if (!node.children) { if (!effectivelySelectedFiles.has(node.absolutePath)) { effectivelySelectedFiles.add(node.absolutePath); } } else { node.children.forEach(addDescendantFiles); } };
        checkedFiles.forEach(path => { const node = fileMap.get(path); if (node) addDescendantFiles(node); });
        effectivelySelectedFiles.forEach(path => { if (processedFilesCache.current.has(path)) return; const extension = `.${path.split('.').pop()?.toLowerCase() || ''}`; let requested = false; if (extension === '.pdf') { clientIpc.sendToServer(ClientToServerChannel.RequestPdfToText, { path }); requested = true; } else if (EXCEL_EXTENSIONS.has(extension)) { clientIpc.sendToServer(ClientToServerChannel.RequestExcelToText, { path }); requested = true; } else if (WORD_EXTENSIONS.has(extension)) { clientIpc.sendToServer(ClientToServerChannel.RequestWordToText, { path }); requested = true; } if (requested) processedFilesCache.current.add(path); });
    }, [checkedFiles, files, clientIpc]);

    useEffect(() => {
        clientIpc.onServerMessage(ServerToClientChannel.SendWorkspaceFiles, ({ files: receivedFiles }) => { logger.log(`[FTV] Received SendWorkspaceFiles with ${receivedFiles.length} root nodes.`); setFiles(receivedFiles); setIsLoading(false); });
        clientIpc.onServerMessage(ServerToClientChannel.ApplySelectionSet, ({ paths }) => { logger.log(`[FTV] Received ApplySelectionSet with ${paths.length} paths.`); setCheckedFiles(paths); clientIpc.sendToServer(ClientToServerChannel.SaveCurrentSelection, { paths }); });
        clientIpc.onServerMessage(ServerToClientChannel.SendSelectionSets, ({ sets }) => setSelectionSets(sets));
        clientIpc.onServerMessage(ServerToClientChannel.SetActiveFile, ({ path }) => { if (!suppressActiveFileReveal.current) { setActiveFile(path); } else { suppressActiveFileReveal.current = false; } });
        clientIpc.onServerMessage(ServerToClientChannel.FocusFile, ({ path }) => setActiveFile(path));
        clientIpc.onServerMessage(ServerToClientChannel.SendAutoAddState, ({ enabled }) => setIsAutoAddEnabled(enabled));
        clientIpc.onServerMessage(ServerToClientChannel.ForceRefresh, ({ reason }) => { logger.log(`[FTV] Received ForceRefresh. Reason: ${reason}.`); if (reason === 'fileOp') { suppressActiveFileReveal.current = true; setTimeout(() => { suppressActiveFileReveal.current = false; }, 2000); } requestFiles(true); });
        clientIpc.onServerMessage(ServerToClientChannel.UpdateProblemCounts, ({ problemMap: newProblemMap }) => setProblemMap(newProblemMap));
        clientIpc.onServerMessage(ServerToClientChannel.UpdateDecorations, ({ problemMap, gitStatusMap }) => { setProblemMap(problemMap); setGitStatusMap(gitStatusMap); });
        clientIpc.onServerMessage(ServerToClientChannel.UpdateNodeStats, ({ path, tokenCount, error }) => { processedFilesCache.current.add(path); setFiles(currentFiles => { const newFiles = JSON.parse(JSON.stringify(currentFiles)); const findAndUpdate = (nodes: FileNode[]) => { for (const node of nodes) { if (node.absolutePath === path) { node.tokenCount = tokenCount; node.error = error; return true; } if (node.children && findAndUpdate(node.children)) return true; } return false; }; findAndUpdate(newFiles); return newFiles; }); });
        clientIpc.sendToServer(ClientToServerChannel.RequestInitialData, {});
        clientIpc.sendToServer(ClientToServerChannel.RequestLastSelection, {});
    }, [clientIpc]);

    const handleFlattenClick = () => {
        clientIpc.sendToServer(ClientToServerChannel.RequestFlattenContext, { selectedPaths: checkedFiles });
    };
    const handleRefresh = () => { processedFilesCache.current.clear(); requestFiles(true); };
    const handleExpandAll = () => setExpandAllTrigger(c => c + 1);
    const handleCollapseAll = () => setCollapseTrigger(c => c + 1);
    const getParentDirForNewItem = (): string => { if (activeFile) { const nodeMap = new Map<string, FileNode>(); const buildMap = (node: FileNode) => { nodeMap.set(node.absolutePath, node); node.children?.forEach(buildMap); }; files.forEach(buildMap); const activeNode = nodeMap.get(activeFile); if (activeNode) { return activeNode.children ? activeNode.absolutePath : activeFile.substring(0, activeFile.lastIndexOf('/')); } } return files.length > 0 ? files[0].absolutePath : ''; };
    const handleNewFile = () => clientIpc.sendToServer(ClientToServerChannel.RequestNewFile, { parentDirectory: getParentDirForNewItem() });
    const handleNewFolder = () => clientIpc.sendToServer(ClientToServerChannel.RequestNewFolder, { parentDirectory: getParentDirForNewItem() });
    const handleToggleAutoAdd = () => { const newState = !isAutoAddEnabled; setIsAutoAddEnabled(newState); clientIpc.sendToServer(ClientToServerChannel.SaveAutoAddState, { enabled: newState }); };
    const handleRemoveFromSelection = (pathsToRemove: string[]) => { setCheckedFiles(currentChecked => { const newChecked = removePathsFromSelected(pathsToRemove, currentChecked, files); clientIpc.sendToServer(ClientToServerChannel.SaveCurrentSelection, { paths: newChecked }); return newChecked; }); };
    const processDrop = (event: React.DragEvent, node: FileNode) => { const targetDir = node.children ? node.absolutePath : path.dirname(node.absolutePath); if (event.dataTransfer.files?.length > 0) { Array.from(event.dataTransfer.files).forEach(file => { const reader = new FileReader(); reader.onload = (e) => { if (e.target?.result instanceof ArrayBuffer) { clientIpc.sendToServer(ClientToServerChannel.RequestAddFileFromBuffer, { targetPath: `${targetDir}/${file.name}`.replace(/\\/g, '/'), data: new Uint8Array(e.target.result) }); } }; reader.readAsArrayBuffer(file); }); return; } const uriList = event.dataTransfer.getData('text/uri-list'); if (uriList) { const sourceUri = uriList.split('\n')[0].trim(); if (sourceUri) clientIpc.sendToServer(ClientToServerChannel.RequestCopyFileFromUri, { sourceUri, targetDir }); } };
    const handleContainerDrop = (event: React.DragEvent<HTMLDivElement>) => { event.preventDefault(); event.stopPropagation(); setIsDraggingOver(false); if (!isWorkspaceTrusted) return; const rootDir = files.length > 0 ? files[0].absolutePath : ''; if (rootDir) processDrop(event, { absolutePath: rootDir, name: path.basename(rootDir), children: [], tokenCount: 0, fileCount: 0, isImage: false, sizeInBytes: 0, extension: '', isPdf: false, isExcel: false, isWordDoc: false, isSelectable: true }); };
    const handleDragOver = (event: React.DragEvent<HTMLDivElement>) => { event.preventDefault(); event.stopPropagation(); event.dataTransfer.dropEffect = (isWorkspaceTrusted && (event.dataTransfer.types.includes('Files') || event.dataTransfer.types.includes('text/uri-list'))) ? 'copy' : 'none'; };
    const handleDragEnter = (event: React.DragEvent<HTMLDivElement>) => { event.preventDefault(); event.stopPropagation(); if (isWorkspaceTrusted && (event.dataTransfer.types.includes('Files') || event.dataTransfer.types.includes('text/uri-list'))) setIsDraggingOver(true); };
    const handleDragLeave = (event: React.DragEvent<HTMLDivElement>) => { event.preventDefault(); event.stopPropagation(); if (!event.currentTarget.contains(event.relatedTarget as Node)) setIsDraggingOver(false); };

    const { totalFiles, totalTokens, selectedFileNodes } = useMemo(() => {
        let totalTokens = 0; const selectedFileSet = new Set<string>(); const selectedNodes: FileNode[] = []; const fileMap: Map<string, FileNode> = new Map();
        const buildFileMap = (node: FileNode) => { fileMap.set(node.absolutePath, node); node.children?.forEach(buildFileMap); };
        files.forEach(buildFileMap);
        const addNodeAndDescendants = (node: FileNode) => {
            if (!node.isSelectable) return;
            if (!node.children) { if (!selectedFileSet.has(node.absolutePath)) { selectedFileSet.add(node.absolutePath); selectedNodes.push(node); totalTokens += node.tokenCount; } } 
            else { node.children.forEach(addNodeAndDescendants); }
        };
        checkedFiles.forEach(path => { const node = fileMap.get(path); if (node) addNodeAndDescendants(node); });
        return { totalFiles: selectedNodes.length, totalTokens, selectedFileNodes: selectedNodes };
    }, [checkedFiles, files]);

    if (isLoading) {
        return <div className="loading-message">Loading file tree...</div>;
    }

    if (files.length === 0) {
        return (
            <div className="no-folder-message">
                <h3>No Folder Opened</h3>
                <p>You have not yet opened a folder.</p>
                <button className="dce-button-primary" onClick={() => clientIpc.sendToServer(ClientToServerChannel.RequestOpenFolder, {})}>
                    <VscFolder /> Open Folder
                </button>
            </div>
        );
    }
    
    return (
        <div className={`view-container ${isDraggingOver ? 'drag-over' : ''}`} onDrop={handleContainerDrop} onDragOver={handleDragOver} onDragEnter={handleDragEnter} onDragLeave={handleDragLeave}>
            {!isWorkspaceTrusted && (<div className="workspace-trust-banner"><VscShield /><span>Drag and drop is disabled because this workspace is not trusted.</span><button onClick={() => clientIpc.sendToServer(ClientToServerChannel.VSCodeCommand, { command: 'workbench.action.manageWorkspaceTrust' })}>Manage Trust</button></div>)}
            <div className="view-header">
                 <div className="header-row">
                     <div className="toolbar"><button onClick={() => clientIpc.sendToServer(ClientToServerChannel.VSCodeCommand, { command: 'dce.saveCurrentSelection', args: [checkedFiles] })} title="Save Selection Set..."><VscSave /></button><button onClick={() => clientIpc.sendToServer(ClientToServerChannel.VSCodeCommand, { command: 'dce.loadSelectionSet' })} title="Load Selection Set..."><VscFolderLibrary /></button><button onClick={() => clientIpc.sendToServer(ClientToServerChannel.VSCodeCommand, { command: 'dce.manageSelectionSets' })} title="Manage Selection Sets..."><VscSettingsGear /></button></div>
                     <div className="toolbar">{isLoading && <span className="spinner" title="Refreshing..."><VscLoading /></span>}<button onClick={() => setIsSearchVisible(v => !v)} title="Search..." className={isSearchVisible ? 'active' : ''}><VscSearch /></button><button onClick={handleToggleAutoAdd} title="Automatically add new files to selection" className={isAutoAddEnabled ? 'active' : ''}><VscCheckAll /></button><button onClick={handleNewFile} title="New File..."><VscNewFile /></button><button onClick={handleNewFolder} title="New Folder..."><VscNewFolder /></button><button onClick={handleRefresh} title="Refresh Explorer"><VscRefresh /></button><button onClick={handleExpandAll} title="Expand All Folders"><VscExpandAll /></button><button onClick={handleCollapseAll} title="Collapse Folders in View"><VscCollapseAll /></button></div>
                 </div>
                {isSearchVisible && (<div className="search-container"><input type="text" placeholder="Filter files..." value={searchTerm} onChange={(e) => setSearchTerm(e.target.value)} /></div>)}
            </div>
            <div className="file-tree-container"><FileTree data={files} checkedFiles={checkedFiles} updateCheckedFiles={updateCheckedFiles} activeFile={activeFile} collapseTrigger={collapseTrigger} expandAllTrigger={expandAllTrigger} searchTerm={searchTerm} problemMap={problemMap} gitStatusMap={gitStatusMap} onNodeDrop={processDrop} onCopy={(path) => setClipboard({ path, type: 'copy' })} clipboard={clipboard} /></div>
            <SelectedFilesView selectedFileNodes={selectedFileNodes} onRemove={handleRemoveFromSelection} isMinimized={isSelectionListMinimized} onToggleMinimize={() => setIsSelectionListMinimized(prev => !prev)} />
            <div className="view-footer">
                <div className="summary-panel"><span className='summary-item' title="Total number of individual files selected for flattening. This does not include empty directories."><VscFiles /> Selected Files: {formatNumberWithCommas(totalFiles)}</span><span className='summary-item' title="Total tokens in selected text files"><VscSymbolNumeric /> {formatLargeNumber(totalTokens, 1)}</span></div>
                <div className="footer-buttons">
                    <button className="dce-button-primary" onClick={handleFlattenClick}>Flatten Context</button>
                </div>
            </div>
        </div>
    );
};

const root = ReactDOM.createRoot(document.getElementById('root')!);
root.render(<App />);
</file_artifact>

<file path="src/client/views/parallel-copilot.view/components/CodeViewer.tsx">
// src/client/views/parallel-copilot.view/components/CodeViewer.tsx
// Updated on: C172 (No functional changes, header update only)
import * as React from 'react';

const CodeViewer: React.FC<{ htmlContent: string | undefined | null }> = ({ htmlContent }) => {
    if (htmlContent === undefined || htmlContent === null) {
        return <div style={{ padding: '8px' }}>Select a file to view its content.</div>;
    }
    if (htmlContent.startsWith('// Error:')) {
         return <div style={{ padding: '8px', color: 'var(--vscode-errorForeground)' }}>{htmlContent}</div>;
    }

    const codeContentMatch = /<pre><code>([\s\S]*)<\/code><\/pre>/s.exec(htmlContent || '');
    const code = codeContentMatch?.[1] ?? (htmlContent || '');

    const lines = code.split('\n');
    if (lines.length > 1 && lines[lines.length - 1] === '') {
        lines.pop();
    }

    return (
        <div className="code-viewer-wrapper">
            <div className="file-content-viewer">
                <div className="line-numbers">
                    {lines.map((_, i) => <span key={i}>{i + 1}</span>)}
                </div>
                <div className="code-content" dangerouslySetInnerHTML={{ __html: htmlContent }} />
            </div>
        </div>
    );
};

export default CodeViewer;
</file_artifact>

<file path="src/client/views/parallel-copilot.view/components/ContextInputs.tsx">
// src/client/views/parallel-copilot.view/components/ContextInputs.tsx
import * as React from 'react';
import { formatLargeNumber } from '@/common/utils/formatting';
import { VscChevronDown } from 'react-icons/vsc';

const CollapsibleSection: React.FC<{ title: string; children: React.ReactNode; isCollapsed: boolean; onToggle: () => void; className?: string; extraHeaderContent?: React.ReactNode; }> = ({ title, children, isCollapsed, onToggle, className, extraHeaderContent }) => (
    <div className={`collapsible-section-inner context-collapsible ${className || ''}`}>
        <div className={`collapsible-header-inner`} onClick={onToggle}>
            <div style={{ display: 'flex', alignItems: 'center', gap: '4px' }}><VscChevronDown className={`chevron ${isCollapsed ? 'collapsed' : ''}`} /><span>{title}</span></div>
            {extraHeaderContent}
        </div>
        {!isCollapsed && <div className="collapsible-content-inner">{children}</div>}
    </div>
);

interface ContextInputsProps {
    cycleContext: string;
    ephemeralContext: string;
    onCycleContextChange: (value: string) => void;
    onEphemeralContextChange: (value: string) => void;
    workflowStep: string | null;
    isEphemeralContextCollapsed: boolean;
    onToggleEphemeralContext: () => void;
}

const ContextInputs: React.FC<ContextInputsProps> = ({
    cycleContext,
    ephemeralContext,
    onCycleContextChange,
    onEphemeralContextChange,
    workflowStep,
    isEphemeralContextCollapsed,
    onToggleEphemeralContext
}) => {
    const cycleContextTokens = React.useMemo(() => Math.ceil(cycleContext.length / 4), [cycleContext]);
    const ephemeralContextTokens = React.useMemo(() => Math.ceil(ephemeralContext.length / 4), [ephemeralContext]);

    return (
        <div className="context-inputs">
            <div className={`context-input-wrapper ${workflowStep === 'awaitingCycleContext' ? 'workflow-highlight' : ''}`}>
                <div className="context-label">
                    <span>Cycle Context</span>
                    <span>({formatLargeNumber(cycleContextTokens, 1)} tk)</span>
                </div>
                <textarea
                    className="response-textarea"
                    value={cycleContext}
                    onChange={(e) => onCycleContextChange(e.target.value)}
                    spellCheck={false}
                />
            </div>
            
            <CollapsibleSection 
                title="Ephemeral Context" 
                isCollapsed={isEphemeralContextCollapsed} 
                onToggle={onToggleEphemeralContext}
                extraHeaderContent={<span className="context-token-count">({formatLargeNumber(ephemeralContextTokens, 1)} tk)</span>}
            >
                <textarea
                    className="response-textarea"
                    value={ephemeralContext}
                    onChange={(e) => onEphemeralContextChange(e.target.value)}
                    spellCheck={false}
                />
            </CollapsibleSection>
        </div>
    );
};

export default ContextInputs;
</file_artifact>

<file path="src/client/views/parallel-copilot.view/components/CycleNavigator.tsx">
// src/client/views/parallel-copilot.view/components/CycleNavigator.tsx
import * as React from 'react';
import { VscChevronLeft, VscChevronRight, VscAdd, VscTrash, VscSync, VscCloudUpload, VscCloudDownload } from 'react-icons/vsc';

interface CycleNavigatorProps {
    currentCycle: number;
    maxCycle: number;
    cycleTitle: string;
    isNewCycleButtonDisabled: boolean;
    onCycleChange: (e: React.MouseEvent | null, newCycle: number) => void;
    onNewCycle: (e: React.MouseEvent) => void;
    onTitleChange: (newTitle: string) => void;
    onDeleteCycle: () => void;
    onResetHistory: () => void;
    onExportHistory: () => void;
    onImportHistory: () => void;
    workflowStep: string | null;
    disabledReason: string;
    saveStatus: 'saved' | 'saving' | 'unsaved';
}

const CycleNavigator: React.FC<CycleNavigatorProps> = ({
    currentCycle,
    maxCycle,
    cycleTitle,
    isNewCycleButtonDisabled,
    onCycleChange,
    onNewCycle,
    onTitleChange,
    onDeleteCycle,
    onResetHistory,
    onExportHistory,
    onImportHistory,
    workflowStep,
    disabledReason,
    saveStatus
}) => {
    const isNavDisabled = saveStatus !== 'saved';

    return (
        <div className="cycle-navigator">
            <span>Cycle:</span>
            <button onClick={(e) => onCycleChange(e, currentCycle - 1)} disabled={currentCycle <= 0 || isNavDisabled} title={isNavDisabled ? "Unsaved changes..." : "Previous Cycle"}>
                <VscChevronLeft />
            </button>
            <input 
                type="number" 
                value={currentCycle} 
                onChange={e => onCycleChange(null, parseInt(e.target.value, 10) || 0)} 
                className="cycle-input" 
                disabled={isNavDisabled}
            />
            <button 
                onClick={(e) => onCycleChange(e, currentCycle + 1)} 
                disabled={currentCycle >= maxCycle || isNavDisabled}
                title={currentCycle >= maxCycle ? "You are on the latest cycle" : isNavDisabled ? "Unsaved changes..." : "Next Cycle"}
            >
                <VscChevronRight />
            </button>
            <button 
                onClick={onNewCycle} 
                title={isNewCycleButtonDisabled ? `Cannot start new cycle:\n${disabledReason}` : isNavDisabled ? "Unsaved changes..." : "New Cycle"}
                disabled={isNewCycleButtonDisabled || isNavDisabled}
                className={workflowStep === 'readyForNewCycle' ? 'workflow-highlight' : ''}
            >
                <VscAdd />
            </button>
            <input 
                type="text" 
                className={`cycle-title-input ${workflowStep === 'awaitingCycleTitle' ? 'workflow-highlight' : ''}`}
                placeholder="Cycle Title..." 
                value={cycleTitle} 
                onChange={e => onTitleChange(e.target.value)} 
            />
            <button onClick={onDeleteCycle} title="Delete Current Cycle"><VscTrash /></button>
            <button onClick={onResetHistory} title="Reset All History"><VscSync /></button>
            <button onClick={onExportHistory} title="Save Cycle History..."><VscCloudUpload /></button>
            <button onClick={onImportHistory} title="Load Cycle History..."><VscCloudDownload /></button>
        </div>
    );
};

export default CycleNavigator;
</file_artifact>

<file path="src/client/views/parallel-copilot.view/components/HighlightedTextarea.tsx">
// src/client/views/parallel-copilot.view/components/HighlightedTextarea.tsx
// New in C3
import * as React from 'react';
import { ClientPostMessageManager } from '@/common/ipc/client-ipc';
import { ClientToServerChannel, ServerToClientChannel } from '@/common/ipc/channels.enum';
import { logger } from '@/client/utils/logger';

const useDebounce = (callback: (...args: any[]) => void, delay: number) => {
    const timeoutRef = React.useRef<NodeJS.Timeout | null>(null);
    return React.useCallback((...args: any[]) => {
        if (timeoutRef.current) clearTimeout(timeoutRef.current);
        timeoutRef.current = setTimeout(() => callback(...args), delay);
    }, [callback, delay]);
};

interface HighlightedTextareaProps {
    id: string;
    initialValue: string;
    onChange: (value: string) => void;
    onKeyDown: (e: React.KeyboardEvent<HTMLTextAreaElement>) => void;
    placeholder?: string;
    className?: string;
}

const HighlightedTextarea: React.FC<HighlightedTextareaProps> = ({ id, initialValue, onChange, onKeyDown, placeholder, className }) => {
    const [value, setValue] = React.useState(initialValue);
    const [highlightedHtml, setHighlightedHtml] = React.useState(initialValue);
    const clientIpc = ClientPostMessageManager.getInstance();
    const textareaRef = React.useRef<HTMLTextAreaElement>(null);
    const highlightDivRef = React.useRef<HTMLDivElement>(null);

    React.useEffect(() => {
        setValue(initialValue);
    }, [initialValue]);

    const requestHighlighting = React.useCallback((text: string) => {
        logger.log(`Requesting highlight for ${id}`);
        clientIpc.sendToServer(ClientToServerChannel.RequestHighlightContext, { context: text, id });
    }, [clientIpc, id]);

    const debouncedRequestHighlighting = useDebounce(requestHighlighting, 300);

    React.useEffect(() => {
        const handleHighlightResponse = ({ highlightedHtml: html, id: responseId }: { highlightedHtml: string, id: string }) => {
            if (responseId === id) {
                setHighlightedHtml(html);
            }
        };
        clientIpc.onServerMessage(ServerToClientChannel.SendHighlightContext, handleHighlightResponse);
        // Initial highlight
        requestHighlighting(value);
    }, [clientIpc, id, value, requestHighlighting]);


    const handleChange = (e: React.ChangeEvent<HTMLTextAreaElement>) => {
        setValue(e.target.value);
        onChange(e.target.value);
        debouncedRequestHighlighting(e.target.value);
    };

    const handleScroll = () => {
        if (textareaRef.current && highlightDivRef.current) {
            highlightDivRef.current.scrollTop = textareaRef.current.scrollTop;
            highlightDivRef.current.scrollLeft = textareaRef.current.scrollLeft;
        }
    };
    
    return (
        <div className={`highlighted-textarea-wrapper ${className || ''}`}>
            <div
                ref={highlightDivRef}
                className="highlighted-content"
                dangerouslySetInnerHTML={{ __html: highlightedHtml + '\n' }} // Add newline to prevent final line cutoff
            />
            <textarea
                ref={textareaRef}
                value={value}
                onChange={handleChange}
                onKeyDown={onKeyDown}
                onScroll={handleScroll}
                placeholder={placeholder}
                spellCheck={false}
                className="highlight-textarea"
            />
        </div>
    );
};

export default HighlightedTextarea;
</file_artifact>

<file path="src/client/views/parallel-copilot.view/components/ParsedView.tsx">
// src/client/views/parallel-copilot.view/components/ParsedView.tsx
// Updated on: C128 (Add Open File button and Markdown Preview in right pane)
import * as React from 'react';
import { VscCheck, VscError, VscDebugDisconnect, VscLink, VscClippy, VscChevronDown, VscDiff, VscPreview, VscGoToFile } from 'react-icons/vsc';
import ReactMarkdown from 'react-markdown';
import * as path from 'path-browserify';
import { ParsedResponse } from '@/common/types/pcpp.types';
import { ComparisonMetrics } from '@/common/ipc/channels.type';
import { formatLargeNumber } from '@/common/utils/formatting';
import CodeViewer from './CodeViewer';
import { ClientPostMessageManager } from '@/common/ipc/client-ipc';
import { ClientToServerChannel } from '@/common/ipc/channels.enum';

const CollapsibleSection: React.FC<{ title: string; children: React.ReactNode; isCollapsed: boolean; onToggle: () => void; className?: string; }> = ({ title, children, isCollapsed, onToggle, className }) => (
    <div className={`collapsible-section-inner ${className || ''}`}>
        <div className="collapsible-header-inner" onClick={onToggle}>
            <VscChevronDown className={`chevron ${isCollapsed ? 'collapsed' : ''}`} />
            <span>{title}</span>
        </div>
        {!isCollapsed && <div className="collapsible-content-inner">{children}</div>}
    </div>
);

const getSimilarityColor = (similarity: number): string => {
    const hue = (similarity * 120).toString(10); // 0 (red) -> 120 (green)
    return `hsl(${hue}, 70%, 50%, 0.15)`;
};

interface ParsedViewProps {
    parsedContent: ParsedResponse;
    fileExistenceMap: Map<string, boolean>;
    selectedFilePath: string | null;
    onSelectForViewing: (path: string) => void;
    selectedFilesForReplacement: Set<string>;
    onFileSelectionToggle: (path: string) => void;
    activeTab: number;
    pathOverrides: Map<string, string>;
    tempOverridePath: string;
    onTempOverridePathChange: (path: string) => void;
    onLinkFile: (originalPath: string) => void;
    onUnlinkFile: (originalPath: string) => void;
    comparisonMetrics: Map<string, ComparisonMetrics | null>;
    viewableContent: string | undefined | null;
    onCopyContent: () => void;
    workflowStep: string | null;
    leftPaneWidth: number;
    onPaneResize: (width: number) => void;
}

const ParsedView: React.FC<ParsedViewProps> = (props) => {
    const [isAssociatedFilesCollapsed, setAssociatedFilesCollapsed] = React.useState(false);
    const [isThoughtsCollapsed, setThoughtsCollapsed] = React.useState(false);
    const [isActionCollapsed, setActionCollapsed] = React.useState(false);
    const [isCuratorActivityCollapsed, setCuratorActivityCollapsed] = React.useState(false);
    const [contextMenu, setContextMenu] = React.useState<{ x: number, y: number, path: string } | null>(null);
    const clientIpc = ClientPostMessageManager.getInstance();
    const menuRef = React.useRef<HTMLDivElement>(null);
    const resizerRef = React.useRef<HTMLDivElement>(null);
    const leftPaneRef = React.useRef<HTMLDivElement>(null);

    React.useEffect(() => {
        const handleClickOutside = (event: MouseEvent) => {
            if (menuRef.current && !menuRef.current.contains(event.target as Node)) {
                setContextMenu(null);
            }
        };
        document.addEventListener('mousedown', handleClickOutside);
        return () => document.removeEventListener('mousedown', handleClickOutside);
    }, []);

    const handleMouseDown = React.useCallback((e: React.MouseEvent) => {
        e.preventDefault();
        const handleMouseMove = (moveEvent: MouseEvent) => {
            if (leftPaneRef.current) {
                const containerWidth = leftPaneRef.current.parentElement?.clientWidth || window.innerWidth;
                const newLeftWidth = moveEvent.clientX - (leftPaneRef.current.parentElement?.getBoundingClientRect().left || 0);
                const newWidthPercent = Math.max(15, Math.min(85, (newLeftWidth / containerWidth) * 100));
                props.onPaneResize(newWidthPercent);
            }
        };
        const handleMouseUp = () => {
            window.removeEventListener('mousemove', handleMouseMove);
            window.removeEventListener('mouseup', handleMouseUp);
        };
        window.addEventListener('mousemove', handleMouseMove);
        window.addEventListener('mouseup', handleMouseUp);
    }, [props.onPaneResize]);

    const handleContextMenu = (event: React.MouseEvent, path: string) => {
        event.preventDefault();
        event.stopPropagation();
        setContextMenu({ x: event.clientX, y: event.clientY, path });
    };

    const handleCopyPath = () => {
        if (contextMenu) {
            clientIpc.sendToServer(ClientToServerChannel.RequestCopyPath, { path: contextMenu.path, relative: true });
            setContextMenu(null);
        }
    };

    const handleNativeDiff = (e: React.MouseEvent, filePath: string) => {
        e.stopPropagation();
        const fileData = props.parsedContent.files.find(f => f.path === filePath);
        if (fileData) {
            const title = `${path.basename(filePath)} (Workspace)  (AI Response)`;
            clientIpc.sendToServer(ClientToServerChannel.RequestNativeDiff, {
                originalPath: filePath,
                modifiedContent: fileData.content,
                title: title
            });
        }
    };
    
    const handleMarkdownPreview = (e: React.MouseEvent, filePath: string) => {
        e.stopPropagation();
        clientIpc.sendToServer(ClientToServerChannel.RequestMarkdownPreview, { filePath });
    };
    
    const handleOpenFile = (e: React.MouseEvent, filePath: string) => {
        e.stopPropagation();
        clientIpc.sendToServer(ClientToServerChannel.RequestOpenFile, { path: filePath });
    };

    const getMetricsKey = (filePath: string) => `${props.activeTab}:::${props.pathOverrides.get(filePath) || filePath}`;

    const currentComparisonMetrics = props.selectedFilePath ? props.comparisonMetrics.get(getMetricsKey(props.selectedFilePath)) : null;

    // C128: Determine if we should show the markdown preview in the right pane
    const isSelectedMarkdown = props.selectedFilePath?.toLowerCase().endsWith('.md');
    const selectedFileContent = props.parsedContent.files.find(f => f.path === props.selectedFilePath)?.content;

    return (
        <div className="parsed-view-grid">
            <div className="parsed-view-left" ref={leftPaneRef} style={{ flexBasis: `${props.leftPaneWidth}%` }}>
                <CollapsibleSection title="Associated Files" isCollapsed={isAssociatedFilesCollapsed} onToggle={() => setAssociatedFilesCollapsed(p => !p)} className={props.workflowStep === 'awaitingFileSelect' ? 'workflow-highlight' : ''}>
                    <ul className="associated-files-list">{props.parsedContent.filesUpdated.map(file => {
                        const fileExists = props.fileExistenceMap.get(file);
                        const hasOverride = props.pathOverrides.has(file);
                        const metrics = props.comparisonMetrics.get(getMetricsKey(file));
                        const similarity = metrics?.similarity ?? 0;
                        const bgColor = (metrics && fileExists) ? getSimilarityColor(similarity) : 'transparent';
                        const isMarkdown = file.toLowerCase().endsWith('.md');
                        
                        return <li key={file} className={props.selectedFilePath === file ? 'selected' : ''} onClick={() => props.onSelectForViewing(file)} onContextMenu={(e) => handleContextMenu(e, file)} title={file} style={{ backgroundColor: bgColor }}>
                            <div className="file-row">
                                <input type="checkbox" checked={props.selectedFilesForReplacement.has(`${props.activeTab}:::${file}`)} onChange={() => props.onFileSelectionToggle(file)} onClick={e => e.stopPropagation()} />
                                {fileExists ? <VscCheck className="status-icon exists" /> : <VscError className="status-icon not-exists" />}
                                <span className="file-path-text" title={file}>{file}</span>
                                {metrics && fileExists && <span className="similarity-score">{ (similarity * 100).toFixed(0) }%</span>}
                                <div className="file-actions-container">
                                    {/* C128: Added Open File button for all files */}
                                    {fileExists && <button className="native-diff-button styled-button" title="Open File" onClick={(e) => handleOpenFile(e, file)}><VscGoToFile /></button>}
                                    {fileExists && isMarkdown && <button className="native-diff-button styled-button" title="Open Preview" onClick={(e) => handleMarkdownPreview(e, file)}><VscPreview /></button>}
                                    {fileExists && <button className="native-diff-button styled-button" title="Open Changes" onClick={(e) => handleNativeDiff(e, file)}><VscDiff /></button>}
                                </div>
                            </div>
                            {!fileExists && props.selectedFilePath === file && (
                                <div className="path-override-container" onClick={e => e.stopPropagation()}>{hasOverride ? (<><span>Linked to: {props.pathOverrides.get(file)}</span><button className="styled-button" onClick={() => props.onUnlinkFile(file)}><VscDebugDisconnect /> Unlink</button></>) : (<><input type="text" placeholder="Enter correct relative path..." value={props.tempOverridePath} onChange={e => props.onTempOverridePathChange(e.target.value)} onKeyDown={e => {if(e.key === 'Enter') props.onLinkFile(file)}} /><button className="styled-button" onClick={() => props.onLinkFile(file)}><VscLink /> Link</button></>)}</div>
                            )}
                        </li>
                    })}</ul>
                </CollapsibleSection>
                <CollapsibleSection title="Summary" isCollapsed={isThoughtsCollapsed} onToggle={() => setThoughtsCollapsed(p => !p)}><ReactMarkdown>{props.parsedContent.summary}</ReactMarkdown></CollapsibleSection>
                <CollapsibleSection title="Course of Action" isCollapsed={isActionCollapsed} onToggle={() => setActionCollapsed(p => !p)}><ReactMarkdown>{props.parsedContent.courseOfAction}</ReactMarkdown></CollapsibleSection>
                {props.parsedContent.curatorActivity && (
                    <CollapsibleSection title="Curator Activity" isCollapsed={isCuratorActivityCollapsed} onToggle={() => setCuratorActivityCollapsed(p => !p)}>
                        <ReactMarkdown>{props.parsedContent.curatorActivity}</ReactMarkdown>
                    </CollapsibleSection>
                )}
            </div>
            <div className="resizer" ref={resizerRef} onMouseDown={handleMouseDown} />
            <div className="parsed-view-right">
                <div className="file-content-viewer-header">
                    <span className="file-path" title={props.selectedFilePath || ''}>{props.selectedFilePath ? path.basename(props.selectedFilePath) : 'No file selected'}</span>
                    <div className="file-actions"><div className="file-metadata">{currentComparisonMetrics && currentComparisonMetrics.originalTokens !== -1 && (<><span>Original: {formatLargeNumber(currentComparisonMetrics.originalTokens, 1)} tk</span><span>New: {formatLargeNumber(currentComparisonMetrics.modifiedTokens, 1)} tk</span><span>Similarity: {(currentComparisonMetrics.similarity * 100).toFixed(0)}%</span></>)}{currentComparisonMetrics && currentComparisonMetrics.originalTokens === -1 && (<span style={{color: 'var(--vscode-errorForeground)'}}>Original file not found</span>)}</div><button onClick={props.onCopyContent} title="Copy file content" disabled={!props.selectedFilePath}><VscClippy /></button>
                    {props.selectedFilePath?.toLowerCase().endsWith('.md') && (
                        <button onClick={(e) => handleMarkdownPreview(e, props.selectedFilePath!)} title="Open Markdown Preview"><VscPreview /></button>
                    )}
                    </div>
                </div>
                {isSelectedMarkdown && selectedFileContent ? (
                     <div className="markdown-preview-pane">
                        <ReactMarkdown>{selectedFileContent}</ReactMarkdown>
                     </div>
                ) : (
                    <CodeViewer htmlContent={props.viewableContent} />
                )}
            </div>
            {contextMenu && (
                <>
                    <div className="context-menu-overlay" onClick={() => setContextMenu(null)}></div>
                    <div ref={menuRef} className="context-menu" style={{ top: contextMenu.y, left: contextMenu.x }}>
                        <ul>
                            <li onClick={handleCopyPath}>Copy Relative Path</li>
                        </ul>
                    </div>
                </>
            )}
        </div>
    );
};

export default ParsedView;
</file_artifact>

<file path="src/client/views/parallel-copilot.view/components/ResponsePane.tsx">
// src/client/views/parallel-copilot.view/components/ResponsePane.tsx
// Updated on: C117 (Add onPaneResize prop)
import * as React from 'react';
import ParsedView from './ParsedView';
import { ComparisonMetrics } from '@/common/ipc/channels.type';
import { PcppResponse } from '@/common/types/pcpp.types';

interface ResponsePaneProps {
    isParsedMode: boolean;
    activeTabData: PcppResponse | undefined;
    onContentChange: (content: string) => void;
    onContextKeyDown: (e: React.KeyboardEvent<HTMLTextAreaElement>) => void;
    onPaste: (e: React.ClipboardEvent) => void;
    // Props for ParsedView
    fileExistenceMap: Map<string, boolean>;
    selectedFilePath: string | null;
    onSelectForViewing: (path: string) => void;
    selectedFilesForReplacement: Set<string>;
    onFileSelectionToggle: (path: string) => void;
    activeTab: number;
    pathOverrides: Map<string, string>;
    tempOverridePath: string;
    onTempOverridePathChange: (path: string) => void;
    onLinkFile: (originalPath: string) => void;
    onUnlinkFile: (originalPath: string) => void;
    comparisonMetrics: Map<string, ComparisonMetrics | null>;
    viewableContent: string | undefined | null;
    onCopyContent: () => void;
    leftPaneWidth: number;
    onPaneResize: (width: number) => void; // Added this prop
    workflowStep: string | null;
}

const ResponsePane: React.FC<ResponsePaneProps> = (props) => {
    if (!props.isParsedMode || !props.activeTabData?.parsedContent) {
        return (
            <textarea
                className="response-textarea"
                placeholder={`Paste AI response here...`}
                value={props.activeTabData?.content || ''}
                onChange={(e) => props.onContentChange(e.target.value)}
                onKeyDown={props.onContextKeyDown}
                onPaste={props.onPaste}
            />
        );
    }

    return (
        <ParsedView
            parsedContent={props.activeTabData.parsedContent}
            fileExistenceMap={props.fileExistenceMap}
            selectedFilePath={props.selectedFilePath}
            onSelectForViewing={props.onSelectForViewing}
            selectedFilesForReplacement={props.selectedFilesForReplacement}
            onFileSelectionToggle={props.onFileSelectionToggle}
            activeTab={props.activeTab}
            pathOverrides={props.pathOverrides}
            tempOverridePath={props.tempOverridePath}
            onTempOverridePathChange={props.onTempOverridePathChange}
            onLinkFile={props.onLinkFile}
            onUnlinkFile={props.onUnlinkFile}
            comparisonMetrics={props.comparisonMetrics}
            viewableContent={props.viewableContent}
            onCopyContent={props.onCopyContent}
            leftPaneWidth={props.leftPaneWidth}
            workflowStep={props.workflowStep}
            onPaneResize={props.onPaneResize} // Pass the prop down
        />
    );
};

export default ResponsePane;
</file_artifact>

<file path="src/client/views/parallel-copilot.view/components/ResponseTabs.tsx">
// src/client/views/parallel-copilot.view/components/ResponseTabs.tsx
// Updated on: C123 (Hide regenerate button in manual mode)
import * as React from 'react';
import { VscFileCode, VscSymbolNumeric, VscListOrdered, VscListUnordered, VscSync, VscLoading, VscCheck, VscEye } from 'react-icons/vsc';
import { PcppResponse } from '@/common/types/pcpp.types';
import { formatLargeNumber } from '@/common/utils/formatting';
import { ConnectionMode } from '@/backend/services/settings.service';

interface ResponseTabsProps {
    sortedTabIds: number[];
    tabs: { [key: string]: PcppResponse };
    activeTab: number;
    selectedResponseId: string | null;
    isParsedMode: boolean;
    isSortedByTokens: boolean;
    onTabSelect: (tabIndex: number) => void;
    onSortToggle: () => void;
    workflowStep: string | null;
    onRegenerateTab: (tabId: number) => void;
    isGenerating: boolean;
    forceShowResponseView: boolean;
    onToggleForceResponseView: () => void;
    connectionMode: ConnectionMode;
}

const ResponseTabs: React.FC<ResponseTabsProps> = ({
    sortedTabIds,
    tabs,
    activeTab,
    selectedResponseId,
    isParsedMode,
    isSortedByTokens,
    onTabSelect,
    onSortToggle,
    workflowStep,
    onRegenerateTab,
    isGenerating,
    forceShowResponseView,
    onToggleForceResponseView,
    connectionMode,
}) => {
    const [regenConfirmTabId, setRegenConfirmTabId] = React.useState<number | null>(null);
    const confirmTimeoutRef = React.useRef<NodeJS.Timeout | null>(null);

    const handleRegenerateClick = (e: React.MouseEvent, tabId: number) => {
        e.stopPropagation();
        if (confirmTimeoutRef.current) {
            clearTimeout(confirmTimeoutRef.current);
            confirmTimeoutRef.current = null;
        }

        if (regenConfirmTabId === tabId) {
            onRegenerateTab(tabId);
            setRegenConfirmTabId(null);
        } else {
            setRegenConfirmTabId(tabId);
            confirmTimeoutRef.current = setTimeout(() => {
                setRegenConfirmTabId(null);
                confirmTimeoutRef.current = null;
            }, 3000);
        }
    };

    const nextPasteTab = workflowStep?.startsWith('awaitingResponsePaste') ? parseInt(workflowStep.split('_')[1], 10) : -1;
    
    // Only show regenerate button if NOT in manual mode
    const showRegenerateButton = connectionMode !== 'manual';

    return (
        <div className="tab-bar-container">
            <div className={`tab-bar ${workflowStep === 'awaitingResponseSelect' ? 'workflow-highlight' : ''}`}>
                {sortedTabIds.map((tabIndex) => {
                    const tabData = tabs[tabIndex.toString()];
                    const parsedData = tabData?.parsedContent;
                    const isLoading = tabData?.status === 'generating' || tabData?.status === 'thinking';
                    const isConfirmingRegen = regenConfirmTabId === tabIndex;

                    return (
                        <div
                            key={tabIndex}
                            className={`tab ${activeTab === tabIndex ? 'active' : ''} ${selectedResponseId === tabIndex.toString() ? 'selected' : ''} ${tabIndex === nextPasteTab ? 'workflow-highlight' : ''}`}
                            onClick={() => onTabSelect(tabIndex)}
                        >
                            <div className="tab-title">
                                Resp {tabIndex}
                                {isLoading && <VscLoading className="spinner" />}
                                {showRegenerateButton && (
                                    <button className="regenerate-tab-button" onClick={(e) => handleRegenerateClick(e, tabIndex)} title={isConfirmingRegen ? "Click again to confirm" : "Regenerate this response"}>
                                        {isConfirmingRegen ? <VscCheck /> : <VscSync />}
                                    </button>
                                )}
                            </div>
                            {isParsedMode && parsedData && (
                                <div className="tab-metadata">
                                    <span><VscFileCode /> {parsedData.files.length}</span>
                                    <span><VscSymbolNumeric /> {formatLargeNumber(parsedData.totalTokens, 1)}</span>
                                </div>
                            )}
                        </div>
                    );
                })}
            </div>
            <div className="tab-bar-controls">
                {isGenerating && (
                    <button onClick={onToggleForceResponseView} className="styled-button" title={forceShowResponseView ? "Show Generation Progress" : "Show Response View"}>
                        <VscEye />
                    </button>
                )}
                <button onClick={onSortToggle} className={`sort-button ${isSortedByTokens ? 'active' : ''}`} title="Sort responses by token count">
                    {isSortedByTokens ? <VscListOrdered/> : <VscListUnordered />} Sort
                </button>
            </div>
        </div>
    );
};

export default ResponseTabs;
</file_artifact>

<file path="src/client/views/parallel-copilot.view/components/WorkflowToolbar.tsx">
// src/client/views/parallel-copilot.view/components/WorkflowToolbar.tsx
import * as React from 'react';
import { VscWand, VscCheck, VscSourceControl, VscDiscard, VscCheckAll, VscClearAll } from 'react-icons/vsc';

interface WorkflowToolbarProps {
    isParsedMode: boolean;
    onParseToggle: () => void;
    selectedResponseId: string | null;
    activeTab: number;
    onSelectResponse: (id: string) => void;
    onBaseline: () => void;
    onRestore: () => void;
    onAcceptSelected: () => void;
    onSelectAll: () => void;
    onDeselectAll: () => void;
    selectedFilesForReplacementCount: number;
    workflowStep: string | null;
}

const WorkflowToolbar: React.FC<WorkflowToolbarProps> = ({
    isParsedMode,
    onParseToggle,
    selectedResponseId,
    activeTab,
    onSelectResponse,
    onBaseline,
    onRestore,
    onAcceptSelected,
    onSelectAll,
    onDeselectAll,
    selectedFilesForReplacementCount,
    workflowStep
}) => {
    return (
        <div className="workflow-toolbar">
            <button
                onClick={onParseToggle}
                className={workflowStep === 'awaitingParse' ? 'workflow-highlight' : ''}
                title={isParsedMode ? "Return to raw text view" : "Parse all responses into structured view"}
            >
                <VscWand /> {isParsedMode ? 'Un-Parse All' : 'Parse All'}
            </button>
            {isParsedMode && (
                <>
                    <button
                        onClick={() => onSelectResponse(activeTab.toString())}
                        className={`styled-button ${selectedResponseId === activeTab.toString() ? 'toggled' : ''} ${workflowStep === 'awaitingResponseSelect' ? 'workflow-highlight' : ''}`}
                        title="Select this response as the basis for the next cycle"
                    >
                        <VscCheck /> {selectedResponseId === activeTab.toString() ? 'Response Selected' : 'Select This Response'}
                    </button>
                    <button
                        onClick={onBaseline}
                        className={`git-button ${workflowStep === 'awaitingBaseline' ? 'workflow-highlight' : ''}`}
                        title="Create a git commit with all current changes as a safe restore point"
                    >
                        <VscSourceControl /> Baseline (Commit)
                    </button>
                    <button
                        onClick={onRestore}
                        className="git-button"
                        title="Restore all files in the workspace to the last baseline commit"
                    >
                        <VscDiscard /> Restore Baseline
                    </button>
                    <div className="button-separator" />
                    <button
                        onClick={onSelectAll}
                        className={`styled-button ${workflowStep === 'awaitingFileSelect' ? 'workflow-highlight' : ''}`}
                        title="Select all files from this response"
                    >
                        <VscCheckAll /> Select All
                    </button>
                    <button
                        onClick={onDeselectAll}
                        className="styled-button"
                        title="Deselect all files across all responses"
                    >
                        <VscClearAll /> Deselect All
                    </button>
                    <button
                        onClick={onAcceptSelected}
                        className={`styled-button ${workflowStep === 'awaitingAccept' ? 'workflow-highlight' : ''}`}
                        disabled={selectedFilesForReplacementCount === 0}
                        title="Accept checked files from this response into your workspace"
                    >
                        <VscCheckAll /> Accept Selected ({selectedFilesForReplacementCount})
                    </button>
                </>
            )}
        </div>
    );
};

export default WorkflowToolbar;
</file_artifact>

<file path="src/client/views/parallel-copilot.view/index.ts">
// src/client/views/parallel-copilot.view/index.ts
import { onMessage } from "./on-message";

export const viewConfig = {
    entry: "parallelCopilotView.js",
    type: "viewType.sidebar.parallelCopilot",
    handleMessage: onMessage,
};
</file_artifact>

<file path="src/client/views/parallel-copilot.view/on-message.ts">
// src/client/views/parallel-copilot.view/on-message.ts
// Updated on: C124 (Add RequestMarkdownPreview handler)
import { ServerPostMessageManager } from "@/common/ipc/server-ipc";
import { Services } from "@/backend/services/services";
import { ClientToServerChannel, ServerToClientChannel } from "@/common/ipc/channels.enum";
import * as path from 'path';
import * as vscode from 'vscode';

export function onMessage(serverIpc: ServerPostMessageManager) {
    const { loggerService, promptService, fileOperationService, highlightingService, historyService, gitService, actionService, llmService, settingsService } = Services;
    loggerService.log("Parallel Co-Pilot view message handler initialized.");

    serverIpc.onClientMessage(ClientToServerChannel.RequestCreatePromptFile, (data) => {
        promptService.generatePromptFile(data.cycleTitle, data.currentCycle);
    });

    serverIpc.onClientMessage(ClientToServerChannel.RequestNewCycleAndGenerate, async (data) => {
        loggerService.log(`Received RequestNewCycleAndGenerate for ${data.count} responses from cycle ${data.cycleData.cycleId}.`);
        try {
            const { newCycle, newMaxCycle } = await historyService.createNewCyclePlaceholder(data.count);
            serverIpc.sendToClient(ServerToClientChannel.NavigateToNewGeneratingCycle, { newCycleData: newCycle, newMaxCycle });

            const prompt = await promptService.generatePromptString(data.cycleData);

            const workspaceFolders = vscode.workspace.workspaceFolders;
            if (workspaceFolders && workspaceFolders.length > 0) {
                const promptMdPath = path.join(workspaceFolders[0].uri.fsPath, 'prompt.md');
                await vscode.workspace.fs.writeFile(vscode.Uri.file(promptMdPath), Buffer.from(prompt, 'utf-8'));
                loggerService.log(`[on-message] Wrote generated prompt for C${data.cycleData.cycleId} to prompt.md`);
            }
            
            const responses = await llmService.generateBatch(prompt, data.count, { ...data.cycleData, cycleId: newCycle.cycleId });
            await historyService.updateCycleWithResponses(newCycle.cycleId, responses);
            
            const finalHistory = await historyService.getFullHistory();
            const finalMaxCycle = finalHistory.cycles.reduce((max, c) => Math.max(max, c.cycleId), 0);
            serverIpc.sendToClient(ServerToClientChannel.SendBatchGenerationComplete, { newCycleId: newCycle.cycleId, newMaxCycle: finalMaxCycle });
        } catch (error) {
            loggerService.error(`New generation workflow failed: ${error}`);
        }
    });
    
    serverIpc.onClientMessage(ClientToServerChannel.RequestStopGeneration, (data) => {
        llmService.stopSingleGeneration(data.cycleId, data.responseId);
    });

    serverIpc.onClientMessage(ClientToServerChannel.RequestSingleRegeneration, async (data) => {
        const cycleData = await historyService.getCycleData(data.cycleId);
        if (cycleData) {
            const prompt = await promptService.generatePromptString(cycleData);
            loggerService.log(`[on-message] Received request to regenerate tab ${data.tabId} for cycle ${data.cycleId}`);
            await llmService.generateSingle(prompt, data.cycleId, data.tabId);
        }
    });

    serverIpc.onClientMessage(ClientToServerChannel.RequestInitialArtifactsAndGeneration, async (data) => {
        try {
            await promptService.generateInitialArtifactsAndResponses(data.projectScope, data.responseCount, serverIpc);
        } catch (error) {
            loggerService.error(`Initial artifacts and generation failed: ${error}`);
        }
    });

    serverIpc.onClientMessage(ClientToServerChannel.RequestSettings, async () => {
        const settings = await settingsService.getSettings();
        serverIpc.sendToClient(ServerToClientChannel.SendSettings, { settings });
    });
    
    serverIpc.onClientMessage(ClientToServerChannel.SaveSettings, (data) => {
        settingsService.saveSettings(data.settings);
    });

    serverIpc.onClientMessage(ClientToServerChannel.RequestFileExistence, (data) => {
        fileOperationService.handleFileExistenceRequest(data.paths, serverIpc);
    });

    serverIpc.onClientMessage(ClientToServerChannel.RequestSyntaxHighlight, (data) => {
        highlightingService.handleSyntaxHighlightRequest(data.code, data.lang, data.id, serverIpc);
    });

    serverIpc.onClientMessage(ClientToServerChannel.RequestHighlightContext, (data) => {
        highlightingService.handleHighlightContextRequest(data.context, data.id, serverIpc);
    });

    serverIpc.onClientMessage(ClientToServerChannel.RequestInitialCycleData, async () => {
        loggerService.log("[PCPP on-message] Received RequestInitialCycleData from client.");
        const historyFile = await historyService.getFullHistory();
        const initialCycle = await historyService.getInitialCycle();
        serverIpc.sendToClient(ServerToClientChannel.SendInitialCycleData, { cycleData: initialCycle, projectScope: historyFile.projectScope });
    });

    serverIpc.onClientMessage(ClientToServerChannel.RequestCycleData, async (data) => {
        const historyFile = await historyService.getFullHistory();
        const cycleData = await historyService.getCycleData(data.cycleId);
        serverIpc.sendToClient(ServerToClientChannel.SendCycleData, { cycleData, projectScope: historyFile.projectScope });
    });

    serverIpc.onClientMessage(ClientToServerChannel.SaveCycleData, (data) => {
        historyService.saveCycleData(data.cycleData);
    });
    
    serverIpc.onClientMessage(ClientToServerChannel.RequestFileContent, (data) => {
        fileOperationService.handleFileContentRequest(data.path, serverIpc);
    });

    serverIpc.onClientMessage(ClientToServerChannel.RequestDeleteCycle, async (data) => {
        await historyService.deleteCycle(data.cycleId);
    });

    serverIpc.onClientMessage(ClientToServerChannel.RequestResetHistory, () => {
        historyService.resetHistory();
    });

    serverIpc.onClientMessage(ClientToServerChannel.RequestBatchFileWrite, async (data: { files: { path: string, content: string }[] }) => {
        const writtenPaths = await fileOperationService.handleBatchFileWrite(data.files);
        if (writtenPaths.length > 0) {
            serverIpc.sendToClient(ServerToClientChannel.FilesWritten, { paths: writtenPaths });
        }
    });

    serverIpc.onClientMessage(ClientToServerChannel.RequestLogState, (data) => {
        promptService.generateStateLog(data.currentState, data.costState, serverIpc);
    });

    serverIpc.onClientMessage(ClientToServerChannel.RequestFileComparison, (data) => {
        fileOperationService.handleFileComparisonRequest(data.filePath, data.modifiedContent, data.tabId, serverIpc);
    });

    serverIpc.onClientMessage(ClientToServerChannel.RequestCopyTextToClipboard, (data) => {
        fileOperationService.handleCopyTextToClipboardRequest(data.text);
    });

    serverIpc.onClientMessage(ClientToServerChannel.RequestExportHistory, () => {
        historyService.handleExportHistory();
    });

    serverIpc.onClientMessage(ClientToServerChannel.RequestImportHistory, () => {
        historyService.handleImportHistory();
    });

    serverIpc.onClientMessage(ClientToServerChannel.RequestOpenFolder, () => {
        fileOperationService.handleOpenFolderRequest();
    });

    serverIpc.onClientMessage(ClientToServerChannel.RequestPromptCostBreakdown, (data) => {
        promptService.handlePromptCostBreakdownRequest(data.cycleData, serverIpc);
    });

    serverIpc.onClientMessage(ClientToServerChannel.RequestGitBaseline, async (data) => {
        await gitService.handleGitBaselineRequest(data.commitMessage, serverIpc);
    });

    serverIpc.onClientMessage(ClientToServerChannel.RequestGitRestore, async (data) => {
        await gitService.handleGitRestoreRequest(data.filesToDelete, serverIpc);
    });

    serverIpc.onClientMessage(ClientToServerChannel.RequestGitStatus, () => {
        gitService.handleGitStatusRequest(serverIpc);
    });

    serverIpc.onClientMessage(ClientToServerChannel.RequestShowInformationMessage, (data) => {
        fileOperationService.handleShowInformationMessageRequest(data.message);
    });

    serverIpc.onClientMessage(ClientToServerChannel.SaveLastViewedCycle, (data) => {
        historyService.saveLastViewedCycleId(data.cycleId);
    });

    serverIpc.onClientMessage(ClientToServerChannel.RequestUndo, () => actionService.undo());
    serverIpc.onClientMessage(ClientToServerChannel.RequestRedo, () => actionService.redo());
    
    serverIpc.onClientMessage(ClientToServerChannel.RequestNativeDiff, (data) => {
        fileOperationService.handleNativeDiffRequest(data.originalPath, data.modifiedContent, data.title);
    });

    serverIpc.onClientMessage(ClientToServerChannel.RequestMarkdownPreview, (data) => {
        fileOperationService.handleMarkdownPreviewRequest(data.filePath);
    });
}
</file_artifact>

<file path="src/client/views/parallel-copilot.view/OnboardingView.tsx">
// src/client/views/parallel-copilot.view/OnboardingView.tsx
// Updated on: C115 (Use props for response count)
import * as React from 'react';
import { VscRocket, VscArrowRight, VscLoading, VscCheck, VscWarning } from 'react-icons/vsc';
import { ClientPostMessageManager } from '@/common/ipc/client-ipc';
import { ClientToServerChannel } from '@/common/ipc/channels.enum';
import { logger } from '@/client/utils/logger';

interface OnboardingViewProps {
    projectScope: string;
    onScopeChange: (scope: string) => void;
    onNavigateToCycle: (cycleId: number) => void;
    latestCycleId: number;
    workflowStep: string | null;
    saveStatus: 'saved' | 'saving' | 'unsaved';
    connectionMode: string;
    onStartGeneration: (projectScope: string, responseCount: number) => void;
    responseCount: number;
    onResponseCountChange: (count: number) => void;
}

const SaveStatusIndicator: React.FC<{ saveStatus: 'saved' | 'saving' | 'unsaved' }> = ({ saveStatus }) => {
    let icon;
    let title;
    switch(saveStatus) {
        case 'saving': icon = <VscLoading className="saving"/>; title = "Saving..."; break;
        case 'unsaved': icon = <VscWarning className="unsaved"/>; title = "Unsaved changes"; break;
        case 'saved': icon = <VscCheck className="saved"/>; title = "Saved"; break;
        default: icon = null; title = "";
    }
    return <div className="save-status-indicator" title={title}>{icon}</div>;
};

const OnboardingView: React.FC<OnboardingViewProps> = ({ 
    projectScope, 
    onScopeChange, 
    onNavigateToCycle, 
    latestCycleId, 
    workflowStep, 
    saveStatus, 
    connectionMode, 
    onStartGeneration,
    responseCount,
    onResponseCountChange
}) => {
    const [promptGenerated, setPromptGenerated] = React.useState(false);
    const clientIpc = ClientPostMessageManager.getInstance();

    const isNavigatingBack = latestCycleId > 0;

    const handleGenerate = () => {
        if (projectScope.trim()) {
            if (connectionMode === 'demo') {
                logger.log(`OnboardingView: Generate button clicked. Calling onStartGeneration prop with ${responseCount} responses.`);
                onStartGeneration(projectScope, responseCount);
            } else {
                logger.log("Sending request to generate Cycle 0 prompt and save project scope.");
                clientIpc.sendToServer(ClientToServerChannel.RequestCreatePromptFile, { cycleTitle: 'Initial Artifacts', currentCycle: 0, selectedFiles: [] });
                setPromptGenerated(true);
            }
        }
    };

    const handleReturnToCycles = () => {
        logger.log("Returning to latest cycle from Project Plan view.");
        onNavigateToCycle(latestCycleId);
    };

    const buttonText = connectionMode === 'demo' ? 'Generate Initial Responses' : 'Generate Initial Artifacts Prompt';

    return (
        <div className={`onboarding-container`}>
            <h1>{isNavigatingBack ? 'Edit Project Plan' : 'Welcome to the Data Curation Environment!'}</h1>
            <p>
                {isNavigatingBack 
                    ? 'You can view and edit your high-level project scope here. This will be included in all future generated prompts.'
                    : 'To get started, describe the goals and scope of your new project in the text area below. When you\'re ready, we\'ll generate an initial prompt that will instruct an AI to create a set of planning documents to bootstrap your development process.'
                }
            </p>
            <div className="onboarding-textarea-wrapper">
                 <div className="onboarding-header">
                    <h3>Project Scope</h3>
                    <SaveStatusIndicator saveStatus={saveStatus} />
                </div>
                <textarea
                    className={`onboarding-textarea ${workflowStep === 'awaitingProjectScope' ? 'workflow-highlight' : ''}`}
                    placeholder="e.g., I want to build a web application that allows users to track their daily habits..."
                    value={projectScope}
                    onChange={(e) => onScopeChange(e.target.value)}
                    disabled={(promptGenerated && !isNavigatingBack)}
                />
            </div>
            {isNavigatingBack ? (
                <button className="styled-button" onClick={handleReturnToCycles}>
                    <VscArrowRight /> Return to Cycle {latestCycleId}
                </button>
            ) : !promptGenerated ? (
                <div className="onboarding-actions">
                    {connectionMode === 'demo' && (
                         <div className="response-count-input">
                            <label htmlFor="onboarding-response-count">Responses:</label>
                            <input 
                                type="number" 
                                id="onboarding-response-count" 
                                min="1" max="20" 
                                value={responseCount} 
                                onChange={e => onResponseCountChange(parseInt(e.target.value, 10) || 1)} 
                            />
                        </div>
                    )}
                    <button 
                        className={`styled-button ${workflowStep === 'awaitingGenerateInitialPrompt' ? 'workflow-highlight' : ''}`}
                        onClick={handleGenerate} 
                        disabled={!projectScope.trim()}
                    >
                        <VscRocket /> {buttonText}
                    </button>
                </div>
            ) : (
                <div className="onboarding-success">
                    <p> Initial `prompt.md` and `DCE_README.md` have been generated in your workspace!</p>
                    <button className="styled-button" onClick={() => onNavigateToCycle(1)}>
                        Continue to Cycle 1 <VscArrowRight />
                    </button>
                </div>
            )}
        </div>
    );
};

export default OnboardingView;
</file_artifact>

<file path="src/client/views/parallel-copilot.view/view.scss">
// src/client/views/parallel-copilot.view/view.scss
// Updated on: C128 (Add styles for markdown preview pane)
@keyframes pulsing-glow {
    0% {
        box-shadow: 0 0 3px 0px var(--vscode-focusBorder);
        outline: 1px solid transparent;
    }
    50% {
        box-shadow: 0 0 8px 2px var(--vscode-focusBorder);
        outline: 1px solid var(--vscode-focusBorder);
    }
    100% {
        box-shadow: 0 0 3px 0px var(--vscode-focusBorder);
        outline: 1px solid transparent;
    }
}

.workflow-highlight {
    animation: pulsing-glow 1.5s infinite ease-in-out;
    border-radius: 4px; 
}

.tab-bar .tab.workflow-highlight {
    border-radius: 4px 4px 0 0;
}

.parsed-view-left .collapsible-section-inner.workflow-highlight,
.response-acceptance-header .styled-button.workflow-highlight {
    border-radius: 4px;
}

.context-input-wrapper.workflow-highlight {
    border-radius: 4px;
}

@keyframes spin {
    from { transform: rotate(0deg); }
    to { transform: rotate(360deg); }
}

.save-status-indicator {
    display: flex;
    align-items: center;
    justify-content: center;
    width: 20px;
    height: 20px;

    .saving {
        animation: spin 1.5s linear infinite;
    }
    .unsaved {
        color: var(--vscode-testing-iconQueued); // yellow
    }
    .saved {
        color: var(--vscode-testing-iconPassed); // green
    }
}

.spinner {
    animation: spin 1.5s linear infinite;
}

body {
    padding: 0;
    font-family: var(--vscode-font-family);
    font-size: var(--vscode-font-size);
    color: var(--vscode-editor-foreground);
    background-color: var(--vscode-editor-background);
}

.context-inputs {
    display: flex;
    flex-direction: column;
    gap: 8px;
    flex-shrink: 0;

    .context-input-wrapper {
        display: flex;
        flex-direction: column;
        gap: 4px;

        .context-label {
            font-size: 11px;
            color: var(--vscode-descriptionForeground);
            display: flex;
            justify-content: space-between;
        }
    }

    .context-collapsible .collapsible-header-inner {
        padding: 4px 8px;
    }

    .context-collapsible .collapsible-content-inner {
        padding: 0;
    }

    .context-token-count {
        font-weight: normal;
        text-transform: none;
        color: var(--vscode-descriptionForeground);
    }

    .response-textarea {
        height: 150px;
    }
}

.onboarding-container {
    padding: 16px;
    display: flex;
    flex-direction: column;
    height: 100%;
    gap: 16px;
    box-sizing: border-box;
    overflow-y: auto;

    h1 {
        font-size: 1.5em;
        font-weight: bold;
    }

    p {
        color: var(--vscode-descriptionForeground);
    }
}

.onboarding-textarea-wrapper {
    display: flex;
    flex-direction: column;
    flex-grow: 1;
    min-height: 200px;
}

.onboarding-header {
    display: flex;
    justify-content: space-between;
    align-items: center;
    margin-bottom: 4px;
}

.onboarding-actions {
    display: flex;
    gap: 16px;
    align-items: center;
}

.response-count-input {
    display: flex;
    align-items: center;
    gap: 8px;
    font-size: 12px;
    
    input {
        width: 50px;
        background-color: var(--vscode-input-background);
        color: var(--vscode-input-foreground);
        border: 1px solid var(--vscode-input-border);
        text-align: center;
        border-radius: 2px;
    }
}


.onboarding-success {
    display: flex;
    flex-direction: column;
    gap: 8px;
    align-items: center;
    padding: 16px;
    border: 1px solid var(--vscode-testing-iconPassed);
    background-color: hsla(120, 60%, 50%, 0.1);
    border-radius: 4px;
}

.onboarding-textarea {
    width: 100%;
    flex-grow: 1;
    background-color: var(--vscode-input-background);
    color: var(--vscode-input-foreground);
    border: 1px solid var(--vscode-input-border);
    border-radius: 2px;
    padding: 8px;
    font-family: var(--vscode-editor-font-family);
    font-size: var(--vscode-editor-font-size);
    resize: none;
    box-sizing: border-box;
    
    &:focus {
        outline: 1px solid var(--vscode-focusBorder);
    }
}

.pc-view-container {
    padding: 8px;
    display: flex;
    flex-direction: column;
    height: 100vh;
    gap: 8px;
    box-sizing: border-box;
}

.collapsible-section {
    border: 1px solid var(--vscode-panel-border);
    border-radius: 4px;
    flex-shrink: 0;
}

.collapsible-header {
    background-color: var(--vscode-sideBar-sectionHeaderBackground);
    padding: 4px 8px;
    font-size: 11px;
    text-transform: uppercase;
    font-weight: bold;
    cursor: pointer;
    display: flex;
    align-items: center;
    gap: 4px;
    justify-content: space-between;

    &.selected {
        background-color: var(--vscode-testing-iconPassed);
        color: var(--vscode-button-foreground);

        .total-prompt-cost {
            color: var(--vscode-button-foreground);
        }
    }

    .chevron {
        transition: transform 0.2s ease-in-out;
    }
    .chevron.collapsed {
        transform: rotate(-90deg);
    }

    .total-prompt-cost {
        font-size: 11px;
        font-weight: normal;
        text-transform: none;
        color: var(--vscode-descriptionForeground);
        font-style: italic;
    }
}

.collapsible-content {
    padding: 8px;
    display: flex;
    flex-direction: column;
    gap: 8px;
}

.pc-header {
    display: flex;
    justify-content: space-between;
    align-items: center;
    flex-shrink: 0;
    gap: 16px;
    flex-wrap: wrap;
}

.generation-progress-display {
    width: 100%;
    padding: 16px;
    border-radius: 4px;
    background-color: var(--vscode-sideBar-background);
    display: flex;
    flex-direction: column;
    gap: 12px;
    font-size: 12px;
    color: var(--vscode-descriptionForeground);
    flex-grow: 1;
    min-width: 0;
    overflow-y: auto;
    box-sizing: border-box;

    .progress-header {
        display: flex;
        justify-content: space-between;
        align-items: center;
        flex-wrap: wrap;
        
        .progress-title {
            font-weight: bold;
            font-size: 13px;
            color: var(--vscode-editor-foreground);
        }

        .header-controls {
            display: flex;
            align-items: center;
            gap: 8px;
        }
    }
    
    .progress-total {
        font-weight: bold;
    }

    .progress-item-container {
        display: flex;
        flex-direction: column;
        gap: 4px;
    }
    
    .response-title-timer {
        display: flex;
        align-items: center;
        gap: 8px;
        font-weight: bold;
        .elapsed-timer {
            font-family: var(--vscode-editor-font-family);
            font-weight: normal;
            font-size: 11px;
            color: var(--vscode-descriptionForeground);
        }
    }

    .progress-item-header {
        display: flex;
        justify-content: space-between;
        align-items: center;

        .status-indicator-wrapper {
            display: flex;
            align-items: center;
            gap: 4px;
            
            button {
                background-color: var(--vscode-button-secondaryBackground);
                color: var(--vscode-button-secondaryForeground);
                border: 1px solid var(--vscode-button-border, transparent);
                padding: 2px 6px;
                font-size: 11px;
                cursor: pointer;
                border-radius: 2px;
                
                &:hover {
                    background-color: var(--vscode-button-secondaryHoverBackground);
                }
                &:disabled {
                    opacity: 0.5;
                    cursor: not-allowed;
                }
            }
        }
    }

    .status-indicator {
        display: flex;
        align-items: center;
        gap: 4px;
        font-size: 11px;
        font-style: italic;
        
        &.status-complete .complete-check {
            color: var(--vscode-testing-iconPassed);
        }
    }

    .stacked-progress-bar {
        width: 100%;
        height: 8px;
        display: flex;
        background-color: var(--vscode-progressBar-background);
        border-radius: 4px;
        overflow: hidden;
        
        &.completed .unused {
            background-color: var(--vscode-testing-iconPassed);
            opacity: 0.4;
        }
    }

    .progress-segment {
        height: 100%;
        transition: width 0.2s ease-in-out;
    }

    .progress-segment.thinking {
        background-color: var(--vscode-testing-iconQueued);
    }
    .progress-segment.generated {
        background-color: var(--vscode-testing-iconPassed);
    }
    .progress-segment.unused {
        background-color: var(--vscode-input-background);
    }

    .token-count-footer {
        display: flex;
        justify-content: space-between;
        align-items: center;
    }

    .token-count-text {
        font-size: 11px;
        font-style: italic;
        color: var(--vscode-descriptionForeground);
    }
    
    .unused-tokens-display {
        font-size: 11px;
        font-weight: bold;
        color: var(--vscode-descriptionForeground);
    }

    .partial-text-preview {
        margin-top: 4px;
        background-color: var(--vscode-editor-background);
        border: 1px solid var(--vscode-panel-border);
        border-radius: 3px;
        padding: 4px 8px;
        font-family: var(--vscode-editor-font-family);
        font-size: 11px;
        max-height: 100px;
        overflow-y: auto;
        white-space: pre-wrap;
    }

    .progress-footer {
        margin-top: 12px;
        padding-top: 12px;
        border-top: 1px solid var(--vscode-panel-border);
        display: flex;
        justify-content: space-between;
        align-items: center;
        font-weight: bold;
    }
}


.generation-controls {
    display: flex;
    align-items: center;
    gap: 8px;

    input {
        width: 40px;
        text-align: center;
    }

    .tokens-per-sec-display {
        font-size: 11px;
        color: var(--vscode-descriptionForeground);
        font-style: italic;
    }
}

.cycle-navigator {
    display: flex;
    align-items: center;
    gap: 8px;
    width: 100%;

    button {
        background: none;
        border: 1px solid var(--vscode-button-border, transparent);
        color: var(--vscode-icon-foreground);
        cursor: pointer;
        padding: 4px;
        border-radius: 3px;
        display: flex;
        align-items: center;
        justify-content: center;
        gap: 6px;

        &:hover {
            background-color: var(--vscode-toolbar-hoverBackground);
        }

        &:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }
    }
}

.button-separator {
    width: 1px;
    height: 16px;
    background-color: var(--vscode-panel-border);
    margin: 0 4px;
}

.git-button {
    background-color: var(--vscode-button-secondaryBackground) !important;
    color: var(--vscode-button-secondaryForeground) !important;
    padding: 4px 8px !important;
    font-size: 12px;

    &:hover {
        background-color: var(--vscode-button-secondaryHoverBackground) !important;
    }
}

.pc-toolbar {
    display: flex;
    align-items: center;
    gap: 8px;
}

.dce-button-primary {
    width: 100%;
    padding: 6px;
    border: 1px solid var(--vscode-button-border, var(--vscode-focusBorder));
    background-color: var(--vscode-button-background);
    color: var(--vscode-button-foreground);
    cursor: pointer;
    border-radius: 2px;
    display: flex;
    align-items: center;
    justify-content: center;
    gap: 8px;

    &:hover {
        background-color: var(--vscode-button-hoverBackground);
    }
}

.pc-toolbar button, .file-actions button, .exit-diff-button, .styled-button {
    background: none;
    border: 1px solid var(--vscode-button-border, transparent);
    color: var(--vscode-icon-foreground);
    cursor: pointer;
    padding: 4px;
    border-radius: 3px;
    display: flex;
    align-items: center;
    justify-content: center;
    gap: 6px;

    &:hover {
        background-color: var(--vscode-toolbar-hoverBackground);
    }

    &:disabled {
        opacity: 0.5;
        cursor: not-allowed;
    }
}

.pc-toolbar button.active {
    background-color: var(--vscode-toolbar-hoverBackground);
    outline: 1px solid var(--vscode-focusBorder);
}


.styled-button {
    background-color: var(--vscode-button-secondaryBackground);
    color: var(--vscode-button-secondaryForeground);
    padding: 2px 8px;
    font-size: 12px;

    &:hover {
        background-color: var(--vscode-button-secondaryHoverBackground);
    }

    &.toggled {
        background-color: var(--vscode-button-background);
        color: var(--vscode-button-foreground);
    }
}

.exit-diff-button {
    margin-top: 8px;
    justify-content: center;
    width: 100%;
    background-color: var(--vscode-button-secondaryBackground);
    &:hover {
        background-color: var(--vscode-button-secondaryHoverBackground);
    }
}


.cycle-input {
    width: 50px;
    background-color: var(--vscode-input-background);
    color: var(--vscode-input-foreground);
    border: 1px solid var(--vscode-input-border);
    text-align: center;
    border-radius: 2px;

    &:disabled {
        opacity: 0.7;
    }
}

.cycle-title-input {
    flex-grow: 1;
    background-color: var(--vscode-input-background);
    color: var(--vscode-input-foreground);
    border: 1px solid var(--vscode-input-border);
    padding: 2px 4px;
    border-radius: 2px;
}

.tab-count-input {
    display: flex;
    align-items: center;
    gap: 8px;
    font-size: 12px;
    
    input {
        width: 50px;
        background-color: var(--vscode-input-background);
        color: var(--vscode-input-foreground);
        border: 1px solid var(--vscode-input-border);
        text-align: center;
        border-radius: 2px;
    }
}

.tab-bar-container {
    display: flex;
    justify-content: space-between;
    align-items: center;
    border-bottom: 1px solid var(--vscode-panel-border);
}

.tab-bar-controls {
    display: flex;
    align-items: center;
    gap: 4px;
    padding-right: 4px;
}

.tab-bar {
    display: flex;
    flex-shrink: 0;
}

.sort-button {
    background-color: var(--vscode-button-secondaryBackground);
    color: var(--vscode-button-secondaryForeground);
    border: 1px solid var(--vscode-button-border, transparent);
    padding: 2px 8px;
    font-size: 12px;
    cursor: pointer;
    border-radius: 2px;
    display: flex;
    align-items: center;
    justify-content: center;
    gap: 6px;
    margin-left: auto;

    &:hover {
        background-color: var(--vscode-button-secondaryHoverBackground);
    }
    
    &.active {
        background-color: var(--vscode-button-background);
        color: var(--vscode-button-foreground);
        outline: none;
        border-color: var(--vscode-focusBorder);
    }
}

.tab {
    padding: 6px 12px;
    cursor: pointer;
    border-bottom: 2px solid transparent;
    color: var(--vscode-tab-inactiveForeground);
    display: flex;
    flex-direction: column;
    align-items: center;
    gap: 4px;
    padding-bottom: 4px;
    position: relative; 

    &.selected {
        background-color: var(--vscode-testing-iconPassed);
        color: var(--vscode-button-foreground);

        .tab-metadata {
            color: var(--vscode-button-foreground);
        }
    }

    &.active {
        color: var(--vscode-tab-activeForeground);
        border-bottom-color: var(--vscode-tab-activeBorder);
        outline: 1px solid var(--vscode-focusBorder);
        outline-offset: -2px;
    }
}

.tab-title {
    font-weight: bold;
    display: flex;
    align-items: center;
    gap: 4px;
}

.regenerate-tab-button {
    background-color: transparent !important;
    border: none !important;
    color: var(--vscode-icon-foreground) !important;
    padding: 2px !important;
    font-size: 14px !important;
    position: relative;
    right: -4px;
    opacity: 0.7;
    
    &:hover {
        background-color: var(--vscode-toolbar-hoverBackground) !important;
        opacity: 1;
    }
}

.tab-metadata {
    display: flex;
    gap: 12px;
    font-size: 11px;
    color: var(--vscode-descriptionForeground);

    span {
        display: flex;
        align-items: center;
        gap: 3px;
    }
}

.tab-content {
    flex-grow: 1;
    display: flex;
    flex-direction: column;
    min-height: 0;
    padding-top: 8px;
}

.tab-pane {
    display: flex;
    flex-direction: column;
    flex-grow: 1;
    gap: 8px;
    height: 100%;
}

.response-textarea {
    width: 100%;
    height: 100%;
    background-color: var(--vscode-input-background);
    color: var(--vscode-input-foreground);
    border: 1px solid var(--vscode-input-border);
    border-radius: 2px;
    padding: 4px;
    font-family: var(--vscode-editor-font-family);
    font-size: var(--vscode-editor-font-size);
    resize: vertical;
     &:focus {
        outline: 1px solid var(--vscode-focusBorder);
    }
}

.parsed-view-grid {
    display: flex;
    gap: 0;
    flex-grow: 1;
    min-height: 0;
}

.parsed-view-left {
    overflow-y: auto;
    display: flex;
    flex-direction: column;
    gap: 8px;
    min-width: 150px;
    padding-right: 8px;
    flex-shrink: 0;
    margin: 2px;
}

.resizer {
    width: 5px;
    background-color: transparent;
    flex-shrink: 0;
    cursor: col-resize;
    position: relative;
    
    &:hover {
        background-color: var(--vscode-sash-hoverBorder);
    }
}

.parsed-view-right {
    flex-grow: 1;
    display: flex;
    flex-direction: column;
    min-width: 0;
    padding-left: 8px;
}

.file-content-viewer-header {
    display: flex;
    justify-content: space-between;
    align-items: center;
    padding: 4px 8px;
    background-color: var(--vscode-editorGroupHeader-tabsBackground);
    border: 1px solid var(--vscode-panel-border);
    border-bottom: none;
    border-top-left-radius: 4px;
    border-top-right-radius: 4px;
    font-size: 12px;
    flex-shrink: 0;

    .file-path {
        font-weight: bold;
        white-space: nowrap;
        overflow: hidden;
        text-overflow: ellipsis;
    }
    .file-actions {
        display: flex;
        align-items: center;
        gap: 8px;
    }
}

.file-metadata {
    display: flex;
    gap: 12px;
    color: var(--vscode-descriptionForeground);
    font-size: 11px;
}

.response-acceptance-header {
    display: flex;
    align-items: center;
    gap: 8px;
    padding: 4px 8px;
    font-size: 12px;
    background-color: var(--vscode-sideBar-sectionHeaderBackground);
}

.code-viewer-wrapper {
    display: flex;
    flex-grow: 1;
    min-height: 0;
    border: 1px solid var(--vscode-panel-border);
    border-top: none;
    border-radius: 0 0 4px 4px;
    background-color: var(--vscode-editor-background);
    overflow: hidden;
    flex-direction: column;
}

.code-viewer-metadata {
    font-size: 11px;
    padding: 2px 8px;
    color: var(--vscode-descriptionForeground);
    background-color: var(--vscode-editorGroupHeader-tabsBackground);
    border-bottom: 1px solid var(--vscode-panel-border);
}

.file-content-viewer {
    flex: 1;
    overflow: auto;
    font-family: var(--vscode-editor-font-family);
    font-size: var(--vscode-editor-font-size);
    display: flex;
    min-width: 0;
}

.line-numbers {
    padding: 8px 10px 8px 8px;
    text-align: right;
    color: var(--vscode-editorLineNumber-foreground);
    background-color: var(--vscode-editor-background);
    user-select: none;
    border-right: 1px solid var(--vscode-panel-border);
    
    span {
        display: block;
        line-height: 1.5;
    }
}

.code-content {
    padding: 8px;
    flex-grow: 1;
    white-space: pre;
    
    code > span {
        line-height: 1.5;
        background-color: transparent !important;
    }
}

/* C128: Markdown Preview Pane Styles */
.markdown-preview-pane {
    flex-grow: 1;
    min-height: 0;
    border: 1px solid var(--vscode-panel-border);
    border-top: none;
    border-radius: 0 0 4px 4px;
    background-color: var(--vscode-editor-background);
    overflow: auto;
    padding: 16px;
    font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif);
    font-size: var(--vscode-markdown-font-size, 14px);
    line-height: 1.6;
    color: var(--vscode-editor-foreground);

    h1, h2, h3, h4, h5, h6 {
        font-weight: 600;
        margin-top: 1.5em;
        margin-bottom: 0.5em;
        line-height: 1.25;
    }
    
    h1 { font-size: 2em; border-bottom: 1px solid var(--vscode-panel-border); padding-bottom: 0.3em; }
    h2 { font-size: 1.5em; border-bottom: 1px solid var(--vscode-panel-border); padding-bottom: 0.3em; }
    
    p, ul, ol {
        margin-bottom: 1em;
    }
    
    code {
        font-family: var(--vscode-editor-font-family);
        background-color: rgba(127, 127, 127, 0.1);
        padding: 0.2em 0.4em;
        border-radius: 3px;
    }
    
    pre {
        background-color: rgba(127, 127, 127, 0.1);
        padding: 16px;
        overflow: auto;
        border-radius: 3px;
        
        code {
            background-color: transparent;
            padding: 0;
        }
    }
    
    blockquote {
        border-left: 4px solid var(--vscode-textBlockQuote-border);
        background-color: var(--vscode-textBlockQuote-background);
        margin: 0;
        padding: 0 1em;
        color: var(--vscode-textBlockQuote-foreground);
    }
    
    a {
        color: var(--vscode-textLink-foreground);
        text-decoration: none;
        &:hover {
            text-decoration: underline;
        }
    }
}

.associated-files-list {
    list-style: none;
    padding: 0;
    margin: 0;

    li {
        display: flex;
        flex-direction: column; 
        align-items: flex-start;
        gap: 4px;
        padding: 2px 4px;
        border-radius: 3px;
        cursor: pointer;

        &:hover {
            background-color: var(--vscode-list-hoverBackground);
            .native-diff-button {
                opacity: 1;
            }
        }

        &.selected {
            background-color: var(--vscode-list-activeSelectionBackground) !important;
            color: var(--vscode-list-activeSelectionForeground) !important;
        }
    }

    .file-row {
        display: flex;
        align-items: center;
        gap: 8px;
        font-size: 12px;
        width: 100%;
        white-space: nowrap;
        overflow: hidden;
        text-overflow: ellipsis;
    }
    
    .file-actions-container {
        display: flex;
        gap: 4px;
        margin-left: auto;
    }

    .native-diff-button {
        opacity: 0;
        transition: opacity 0.1s ease-in-out;
        padding: 0 4px;
        font-size: 12px;
        background-color: var(--vscode-button-secondaryBackground);
        color: var(--vscode-button-secondaryForeground);
        border: 1px solid var(--vscode-button-border, transparent);
        
        &:hover {
            background-color: var(--vscode-button-secondaryHoverBackground);
        }
    }


    .file-path-text {
        flex-grow: 1;
        white-space: nowrap;
        overflow: hidden;
        text-overflow: ellipsis;
    }

    .similarity-score {
        margin-left: auto;
        padding-left: 8px;
        font-size: 11px;
        color: var(--vscode-descriptionForeground);
        font-style: italic;
        flex-shrink: 0;
    }

    input[type="checkbox"] {
        margin-right: 4px;
    }

    .status-icon {
        flex-shrink: 0;
    }
    .status-icon.exists {
        color: var(--vscode-testing-iconPassed);
    }
    .status-icon.not-exists {
        color: var(--vscode-testing-iconFailed);
    }
}

.path-override-container {
    display: flex;
    gap: 4px;
    align-items: center;
    width: 100%;
    
    input {
        flex-grow: 1;
        font-size: 11px;
        padding: 1px 4px;
        background-color: var(--vscode-input-background);
        color: var(--vscode-input-foreground);
        border: 1px solid var(--vscode-input-border);
        border-radius: 2px;
    }

    button {
        padding: 1px 6px;
        font-size: 11px;
    }
}

.collapsed-navigator {
    display: flex;
    align-items: center;
    gap: 4px;
    font-weight: normal;
    
    button {
        padding: 0 4px;
    }
    
    .cycle-display {
        font-size: 11px;
        color: var(--vscode-descriptionForeground);
    }
}

.diff-viewer-wrapper {
    display: flex;
    flex-direction: column;
    height: 100%;
    min-height: 0;
    &:focus {
        outline: 1px solid var(--vscode-focusBorder);
    }
}
.diff-viewer-main-container {
    flex-grow: 1;
    min-height: 0;
    display: flex;
    flex-direction: row; 
    border: 1px solid var(--vscode-panel-border);
    border-radius: 4px;
}

.diff-pane {
    flex: 1 1 50%;
    display: flex;
    flex-direction: column;
    min-width: 0;
    overflow: auto;
    &:first-of-type { border-right: 1px solid var(--vscode-panel-border); }
}

.diff-pane-header {
    padding: 4px 8px;
    font-size: 11px;
    font-weight: bold;
    background-color: var(--vscode-editorGroupHeader-tabsBackground);
    border-bottom: 1px solid var(--vscode-panel-border);
    flex-shrink: 0;
}

.diff-pane-content {
    flex-grow: 1;
    min-height: 0;
    overflow-y: auto; 
    display: flex;
}

.diff-pane .line-numbers {
    flex-shrink: 0;
    padding: 8px 4px;
    line-height: 1.5;
    background-color: var(--vscode-editorGutter-background);
    color: var(--vscode-editorLineNumber-foreground);
    text-align: right;
    user-select: none;
    border-right: 1px solid var(--vscode-panel-border);
    
    span { display: block; min-height: 1.5em; padding-right: 6px; }
}

.diff-pane .diff-lines .line {
    line-height: 1.5;
    padding-left: 8px;
    min-height: 1.5em;
    white-space: pre;
    &.added { background-color: var(--vscode-diffEditor-insertedTextBackground); }
    &.removed { background-color: var(--vscode-diffEditor-removedTextBackground); }
    &.placeholder { background-color: var(--vscode-editor-inactiveSelectionBackground); opacity: 0.5; }
    
    &.selected-diff {
        outline: 1px solid var(--vscode-focusBorder);
        outline-offset: -1px;
    }

    pre { margin: 0; padding: 0; }
}

.diff-detail-container {
    flex-shrink: 0;
    border-top: 1px solid var(--vscode-panel-border);
    display: flex;
    flex-direction: column;
}

.diff-detail-header {
    display: flex;
    justify-content: space-between;
    align-items: center;
    padding: 2px 8px;
    background-color: var(--vscode-sideBar-sectionHeaderBackground);
    font-size: 11px;
    .diff-nav-buttons {
        display: flex;
        gap: 8px;
        button {
            padding: 2px 6px;
            gap: 4px;
        }
    }
}

.diff-detail-panes {
    display: flex;
    flex-direction: column; 
    max-height: 200px;
    overflow: hidden;
}

.diff-detail-pane {
    flex: 1 1 50%;
    padding: 8px;
    white-space: pre;
    overflow-x: auto;
    font-family: var(--vscode-editor-font-family);
    font-size: var(--vscode-editor-font-size);
    &.removed { background-color: var(--vscode-diffEditor-removedTextBackground); }
    &.added { background-color: var(--vscode-diffEditor-insertedTextBackground); }
    &:first-child { border-bottom: 1px solid var(--vscode-panel-border); }

    .char-added { background-color: var(--vscode-diffEditor-insertedLineBackground); }
    .char-removed { background-color: var(--vscode-diffEditor-removedLineBackground); }
}

.collapsible-section-inner {
    border: 1px solid var(--vscode-panel-border);
    border-radius: 4px;
    width: 100%;
    margin: 2px;
}

.collapsible-header-inner {
    background-color: var(--vscode-sideBar-sectionHeaderBackground);
    padding: 6px 10px;
    font-size: 11px;
    text-transform: uppercase;
    font-weight: bold;
    cursor: pointer;
    display: flex;
    align-items: center;
    gap: 4px;

    .chevron {
        transition: transform 0.2s ease-in-out;
    }
    .chevron.collapsed {
        transform: rotate(-90deg);
    }
}

.collapsible-content-inner {
    padding: 8px;
}

.context-menu-overlay {
    position: fixed;
    top: 0;
    left: 0;
    right: 0;
    bottom: 0;
    z-index: 999;
}

.context-menu {
    position: absolute;
    background-color: var(--vscode-menu-background);
    border: 1px solid var(--vscode-menu-border);
    color: var(--vscode-menu-foreground);
    box-shadow: 0 2px 8px var(--vscode-widget-shadow);
    border-radius: 4px;
    padding: 4px 0;
    min-width: 180px;
    z-index: 1000;

    ul {
        list-style: none;
        padding: 0;
        margin: 0;
    }

    li {
        padding: 4px 12px;
        cursor: pointer;
        display: flex;
        align-items: center;
        gap: 8px;

        &:hover {
            background-color: var(--vscode-menu-selectionBackground);
            color: var(--vscode-menu-selectionForeground);
        }
        
        &.disabled {
            color: var(--vscode-disabledForeground);
            cursor: not-allowed;
            background-color: transparent;
        }
    }

    hr {
        border: none;
        border-top: 1px solid var(--vscode-menu-separatorBackground);
        margin: 4px 0;
    }
}

.workflow-toolbar {
    display: flex;
    gap: 8px;
    align-items: center;
    padding: 4px 8px;
    background-color: var(--vscode-sideBar-sectionHeaderBackground);
    border-radius: 4px;

    button {
        background: none;
        border: 1px solid var(--vscode-button-border, transparent);
        color: var(--vscode-icon-foreground);
        cursor: pointer;
        padding: 4px;
        border-radius: 3px;
        display: flex;
        align-items: center;
        justify-content: center;
        gap: 6px;
    
        &:hover {
            background-color: var(--vscode-toolbar-hoverBackground);
        }
    
        &:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }
    }
}

.token-count-text {
    .token-thinking {
        color: var(--vscode-testing-iconQueued);
    }
    .token-response {
        color: var(--vscode-testing-iconPassed);
    }
}

.token-unused {
    color: var(--vscode-editor-inactiveSelectionBackground);
}
</file_artifact>

<file path="src/client/views/parallel-copilot.view/view.tsx">
// src/client/views/parallel-copilot.view/view.tsx
// Updated on: C126 (Fix Select All, Persistence, and Accept logic)
import * as React from 'react';
import { createRoot } from 'react-dom/client';
import './view.scss';
import { VscWand, VscFileCode, VscBug, VscBook, VscFolder, VscChevronDown, VscLoading, VscCheck, VscWarning } from 'react-icons/vsc';
import { ClientPostMessageManager } from '../../../common/ipc/client-ipc';
import { ClientToServerChannel, ServerToClientChannel } from '../../../common/ipc/channels.enum';
import { PcppCycle } from '../../../common/types/pcpp.types';
import OnboardingView from './OnboardingView';
import CycleNavigator from './components/CycleNavigator';
import ContextInputs from './components/ContextInputs';
import ResponseTabs from './components/ResponseTabs';
import ResponsePane from './components/ResponsePane';
import WorkflowToolbar from './components/WorkflowToolbar';
import GenerationProgressDisplay from './components/GenerationProgressDisplay';

import { useCycleManagement } from './hooks/useCycleManagement';
import { useTabManagement } from './hooks/useTabManagement';
import { useFileManagement } from './hooks/useFileManagement';
import { useGeneration } from './hooks/useGeneration';
import { useWorkflow } from './hooks/useWorkflow';
import { usePcppIpc } from './hooks/usePcppIpc';
import { logger } from '@/client/utils/logger';

const CollapsibleSection: React.FC<{ title: string; children: React.ReactNode; isCollapsed: boolean; onToggle: () => void; collapsedContent?: React.ReactNode; className?: string; extraHeaderContent?: React.ReactNode; }> = ({ title, children, isCollapsed, onToggle, collapsedContent, className, extraHeaderContent }) => (
    <div className="collapsible-section">
        <div className={`collapsible-header ${className || ''}`} onClick={onToggle}>
            <div style={{ display: 'flex', alignItems: 'center', gap: '4px' }}><VscChevronDown className={`chevron ${isCollapsed ? 'collapsed' : ''}`} /><span>{title}</span></div>
            {isCollapsed ? collapsedContent : extraHeaderContent}
        </div>
        {!isCollapsed && <div className="collapsible-content">{children}</div>}
    </div>
);

const App = () => {
    const clientIpc = ClientPostMessageManager.getInstance();
    
    const [initialData, setInitialData] = React.useState<{cycle: PcppCycle | null, scope: string | undefined, maxCycle: number}>({cycle: null, scope: '', maxCycle: 0});
    const saveStateRef = React.useRef<() => void>(() => {});
    const [forceShowResponseView, setForceShowResponseView] = React.useState(false);
    const [leftPaneWidth, setLeftPaneWidth] = React.useState(initialData.cycle?.leftPaneWidth || 33);
    const [responseCount, setResponseCount] = React.useState(4); 

    const cycleManagement = useCycleManagement(initialData.cycle, initialData.scope, initialData.maxCycle);
    
    const requestAllMetrics = React.useCallback((parsedResponse: any, tabId: number) => {
         parsedResponse.filesUpdated.forEach((filePath: string) => {
             const file = parsedResponse.files.find((f: any) => f.path === filePath);
             if (file) {
                 clientIpc.sendToServer(ClientToServerChannel.RequestFileComparison, {
                     filePath,
                     modifiedContent: file.content,
                     tabId: tabId.toString()
                 });
             }
         });
    }, [clientIpc]);

    const tabManagement = useTabManagement(initialData.cycle?.responses || {}, responseCount, initialData.cycle?.activeTab || 1, initialData.cycle?.isParsedMode || false, initialData.cycle?.isSortedByTokens || false, cycleManagement.setSaveStatus, requestAllMetrics);
    const fileManagement = useFileManagement(tabManagement.activeTab, tabManagement.tabs, cycleManagement.setSaveStatus);
    const generationManagement = useGeneration(cycleManagement.currentCycle, () => stateRef.current.cycleManagement.currentCycle, true, '', tabManagement.setTabs, cycleManagement.setSaveStatus, responseCount);
    const { workflowStep, setWorkflowStep } = useWorkflow(null, true, cycleManagement.cycleTitle, cycleManagement.cycleContext, fileManagement.selectedFilesForReplacement, cycleManagement.selectedResponseId, tabManagement.isSortedByTokens, tabManagement.isParsedMode, tabManagement.tabs, tabManagement.tabCount);
    
    usePcppIpc(
        cycleManagement,
        tabManagement,
        fileManagement,
        generationManagement,
        setWorkflowStep
    );

    const stateRef = React.useRef({ cycleManagement, tabManagement, fileManagement, workflowStep, responseCount, leftPaneWidth });
    stateRef.current = { cycleManagement, tabManagement, fileManagement, workflowStep, responseCount, leftPaneWidth };

    saveStateRef.current = React.useCallback(() => {
        const { cycleManagement, tabManagement, fileManagement, workflowStep, responseCount, leftPaneWidth } = stateRef.current;
        const { currentCycle, cycleTitle, cycleContext, ephemeralContext, isEphemeralContextCollapsed, selectedResponseId, isCycleCollapsed } = cycleManagement;
        const { tabs, activeTab, isParsedMode, isSortedByTokens } = tabManagement;
        const { selectedFilesForReplacement, pathOverrides } = fileManagement;
        
        if (currentCycle === null) return;
        
        cycleManagement.setSaveStatus('saving');
        
        const cycleData: PcppCycle = {
            ...currentCycle,
            title: cycleTitle,
            cycleContext,
            ephemeralContext,
            responses: tabs,
            isParsedMode,
            selectedResponseId,
            selectedFilesForReplacement: Array.from(selectedFilesForReplacement),
            tabCount: responseCount, 
            activeTab,
            isSortedByTokens,
            pathOverrides: Object.fromEntries(pathOverrides),
            activeWorkflowStep: workflowStep || undefined,
            isEphemeralContextCollapsed,
            isCycleCollapsed,
            leftPaneWidth,
        };
        clientIpc.sendToServer(ClientToServerChannel.SaveCycleData, { cycleData });
    }, [clientIpc]);

    React.useEffect(() => {
        if (cycleManagement.saveStatus === 'unsaved') {
            const handler = setTimeout(() => {
                saveStateRef.current();
            }, 1500);
    
            return () => {
                clearTimeout(handler);
            };
        }
    }, [cycleManagement.saveStatus]);

    const viewableContent = React.useMemo(() => {
        if (!fileManagement.selectedFilePath) return null;
        const activeTabData = tabManagement.tabs[tabManagement.activeTab.toString()];
        const file = activeTabData?.parsedContent?.files.find(f => f.path === fileManagement.selectedFilePath);
        if (!file) return '// File content not found in parsed response.';
        const id = `${file.path}::${file.content}`;
        return fileManagement.highlightedCodeBlocks.get(id) || file.content;
    }, [fileManagement.selectedFilePath, tabManagement.tabs, tabManagement.activeTab, fileManagement.highlightedCodeBlocks]);


    React.useEffect(() => {
        const handleLoadedCycle = (cycleData: PcppCycle) => {
            setForceShowResponseView(false);
            if(cycleData.tabCount) setResponseCount(cycleData.tabCount);
            if(cycleData.leftPaneWidth) setLeftPaneWidth(cycleData.leftPaneWidth);
            
            // C126 FIX: Correctly hydrate the selected files state from the persisted data
            if (cycleData.selectedFilesForReplacement) {
                fileManagement.setSelectedFilesForReplacement(new Set(cycleData.selectedFilesForReplacement));
            } else {
                fileManagement.setSelectedFilesForReplacement(new Set());
            }
        };

        clientIpc.onServerMessage(ServerToClientChannel.SendInitialCycleData as any, ({ cycleData, projectScope }: { cycleData: PcppCycle, projectScope: string }) => {
            setInitialData({cycle: cycleData, scope: projectScope, maxCycle: cycleData.cycleId });
            handleLoadedCycle(cycleData);
        });
        clientIpc.onServerMessage(ServerToClientChannel.SendCycleData as any, ({ cycleData }: { cycleData: PcppCycle | null }) => {
            if (cycleData) {
                handleLoadedCycle(cycleData);
            }
        });
        clientIpc.onServerMessage(ServerToClientChannel.NavigateToNewGeneratingCycle as any, () => {
            setForceShowResponseView(false);
            fileManagement.setSelectedFilesForReplacement(new Set()); // Clear selection on new cycle
        });
        clientIpc.sendToServer(ClientToServerChannel.RequestInitialCycleData, {});
    }, [clientIpc, fileManagement.setSelectedFilesForReplacement]);

    if (cycleManagement.currentCycle === null) return <div>Loading...</div>;
    if (cycleManagement.currentCycle.cycleId === -1) return <div className="onboarding-container"><h1>No Folder Opened</h1><p>You have not yet opened a folder.</p><button className="dce-button-primary" onClick={() => clientIpc.sendToServer(ClientToServerChannel.RequestOpenFolder, {})}><VscFolder /> Open Folder</button></div>;
    
    const onScopeChange = (scope: string) => { if (cycleManagement.currentCycle?.cycleId === 0) { cycleManagement.onCycleContextChange(scope); } };

    if (cycleManagement.currentCycle.cycleId === 0) { 
        return <OnboardingView 
            projectScope={cycleManagement.cycleContext || ''} 
            onScopeChange={onScopeChange} 
            onNavigateToCycle={(id) => cycleManagement.handleCycleChange(null, id)} 
            latestCycleId={cycleManagement.maxCycle} 
            workflowStep={workflowStep} 
            saveStatus={cycleManagement.saveStatus} 
            connectionMode={generationManagement.connectionMode} 
            onStartGeneration={generationManagement.handleStartGeneration} 
            responseCount={responseCount}
            onResponseCountChange={setResponseCount}
        />; 
    }
    
    const collapsedNavigator = <div>...</div>;
    const totalPromptCostDisplay = <span>...</span>;
    const SaveStatusIndicator = () => {
        let icon;
        let title;
        switch(cycleManagement.saveStatus) {
            case 'saving': icon = <VscLoading className="saving"/>; title = "Saving..."; break;
            case 'unsaved': icon = <VscWarning className="unsaved"/>; title = "Unsaved changes"; break;
            case 'saved': icon = <VscCheck className="saved"/>; title = "Saved"; break;
            default: icon = null; title = "";
        }
        return <div className="save-status-indicator" title={title}>{icon}</div>;
    };
    const renderHeaderButtons = () => {
        if (generationManagement.connectionMode === 'manual') {
            return <button><VscFileCode /> Generate prompt.md</button>;
        } else {
            return <button onClick={generationManagement.handleGenerateResponses} disabled={generationManagement.isGenerateResponsesDisabled}><VscWand /> Generate responses</button>;
        }
    };
    
    const showProgressView = cycleManagement.currentCycle.status === 'generating' && !forceShowResponseView;

    // C126 FIX: Select All Implementation
    const handleSelectAll = () => {
        const currentTabId = tabManagement.activeTab.toString();
        const activeTabData = tabManagement.tabs[currentTabId];
        if (activeTabData?.parsedContent) {
            const newSelection = new Set(fileManagement.selectedFilesForReplacement);
            activeTabData.parsedContent.filesUpdated.forEach(filePath => {
                newSelection.add(`${currentTabId}:::${filePath}`);
            });
            fileManagement.setSelectedFilesForReplacement(newSelection);
            cycleManagement.setSaveStatus('unsaved');
        }
    };

    // C126 FIX: Accept Selected Implementation
    const handleAcceptSelected = () => {
        const filesToWrite = [];
        for (const compositeKey of fileManagement.selectedFilesForReplacement) {
            const [tabId, filePath] = compositeKey.split(':::');
            const tabData = tabManagement.tabs[tabId];
            if (tabData && tabData.parsedContent) {
                const file = tabData.parsedContent.files.find(f => f.path === filePath);
                if (file) {
                    filesToWrite.push({ path: file.path, content: file.content });
                }
            }
        }
        
        if (filesToWrite.length > 0) {
            clientIpc.sendToServer(ClientToServerChannel.RequestBatchFileWrite, { files: filesToWrite });
        }
    };

    return <div className="pc-view-container">
        <div className="pc-header">
            <div className="pc-toolbar">
                <button onClick={(e) => cycleManagement.handleCycleChange(e, 0)} title="Project Plan"><VscBook /> Project Plan</button>
                {renderHeaderButtons()}
                <button title="Log State"><VscBug/></button>
            </div>
            <div className="tab-count-input">
                <label htmlFor="tab-count">Responses:</label>
                <input type="number" id="tab-count" min="1" max="20" value={responseCount} onChange={e => setResponseCount(parseInt(e.target.value, 10) || 1)} />
            </div>
        </div>
        <CollapsibleSection title="Cycle & Context" isCollapsed={cycleManagement.isCycleCollapsed} onToggle={() => { cycleManagement.setIsCycleCollapsed(p => !p); cycleManagement.setSaveStatus('unsaved'); }} collapsedContent={collapsedNavigator} extraHeaderContent={<div style={{display: 'flex', alignItems: 'center', gap: '8px'}}><SaveStatusIndicator /> {totalPromptCostDisplay}</div>}>
            <CycleNavigator 
                currentCycle={cycleManagement.currentCycle.cycleId} 
                maxCycle={cycleManagement.maxCycle} 
                cycleTitle={cycleManagement.cycleTitle} 
                isNewCycleButtonDisabled={!true} 
                onCycleChange={cycleManagement.handleCycleChange} 
                onNewCycle={cycleManagement.handleNewCycle} 
                onTitleChange={cycleManagement.onTitleChange} 
                onDeleteCycle={cycleManagement.handleDeleteCycle} 
                onResetHistory={cycleManagement.handleResetHistory} 
                onExportHistory={cycleManagement.handleExportHistory} 
                onImportHistory={cycleManagement.handleImportHistory} 
                workflowStep={workflowStep} 
                disabledReason={generationManagement.newCycleButtonDisabledReason} 
                saveStatus={cycleManagement.saveStatus} 
            />
            <ContextInputs 
                cycleContext={cycleManagement.cycleContext} 
                ephemeralContext={cycleManagement.ephemeralContext} 
                onCycleContextChange={cycleManagement.onCycleContextChange} 
                onEphemeralContextChange={cycleManagement.onEphemeralContextChange} 
                workflowStep={workflowStep} 
                isEphemeralContextCollapsed={cycleManagement.isEphemeralContextCollapsed} 
                onToggleEphemeralContext={() => { cycleManagement.setIsEphemeralContextCollapsed(p => !p); cycleManagement.setSaveStatus('unsaved'); }} 
            />
        </CollapsibleSection>
        <div className="main-content-area" style={{display: 'flex', flexDirection: 'column', flexGrow: 1, minHeight: 0}}>
            <ResponseTabs 
                sortedTabIds={tabManagement.sortedTabIds} 
                tabs={tabManagement.tabs} 
                activeTab={tabManagement.activeTab} 
                selectedResponseId={cycleManagement.selectedResponseId}
                isParsedMode={tabManagement.isParsedMode} 
                isSortedByTokens={tabManagement.isSortedByTokens} 
                onTabSelect={tabManagement.handleTabSelect} 
                workflowStep={workflowStep} 
                onRegenerateTab={generationManagement.handleRegenerateTab} 
                onSortToggle={tabManagement.handleSortToggle} 
                isGenerating={cycleManagement.currentCycle.status === 'generating'}
                forceShowResponseView={forceShowResponseView}
                onToggleForceResponseView={() => setForceShowResponseView(p => !p)}
                connectionMode={generationManagement.connectionMode}
            />
            {showProgressView ? (
                <GenerationProgressDisplay 
                    progressData={generationManagement.generationProgress} 
                    tps={generationManagement.tps} 
                    tabs={tabManagement.tabs} 
                    onStop={generationManagement.handleStopGeneration} 
                    onRegenerate={generationManagement.handleRegenerateTab} 
                    isGenerationComplete={generationManagement.isGenerationComplete} 
                    onViewResponses={() => {}} 
                    cycleId={cycleManagement.currentCycle.cycleId} 
                />
            ) : (
                <>
                    <WorkflowToolbar 
                        isParsedMode={tabManagement.isParsedMode}
                        onParseToggle={tabManagement.handleGlobalParseToggle}
                        selectedResponseId={cycleManagement.selectedResponseId}
                        activeTab={tabManagement.activeTab}
                        onSelectResponse={cycleManagement.handleSelectResponse}
                        onBaseline={() => {}}
                        onRestore={() => {}}
                        onAcceptSelected={handleAcceptSelected}
                        onSelectAll={handleSelectAll}
                        onDeselectAll={() => { fileManagement.setSelectedFilesForReplacement(new Set()); cycleManagement.setSaveStatus('unsaved'); }}
                        selectedFilesForReplacementCount={fileManagement.selectedFilesForReplacement.size}
                        workflowStep={workflowStep}
                    />
                    <div className="tab-content">
                        <ResponsePane 
                            isParsedMode={tabManagement.isParsedMode} 
                            activeTabData={tabManagement.tabs[tabManagement.activeTab.toString()]} 
                            onContentChange={(content) => tabManagement.handleContentChange(content, tabManagement.activeTab)} 
                            onContextKeyDown={() => {}} 
                            onPaste={(e) => tabManagement.handlePaste(e, tabManagement.activeTab)}
                            fileExistenceMap={fileManagement.fileExistenceMap}
                            selectedFilePath={fileManagement.selectedFilePath}
                            onSelectForViewing={fileManagement.handleSelectForViewing}
                            selectedFilesForReplacement={fileManagement.selectedFilesForReplacement}
                            onFileSelectionToggle={fileManagement.handleFileSelectionToggle}
                            activeTab={tabManagement.activeTab}
                            pathOverrides={fileManagement.pathOverrides}
                            tempOverridePath={fileManagement.tempOverridePath}
                            onTempOverridePathChange={fileManagement.setTempOverridePath}
                            onLinkFile={fileManagement.handleLinkFile}
                            onUnlinkFile={fileManagement.handleUnlinkFile}
                            comparisonMetrics={fileManagement.comparisonMetrics}
                            viewableContent={viewableContent}
                            onCopyContent={fileManagement.handleCopyContent}
                            leftPaneWidth={leftPaneWidth} 
                            onPaneResize={(width) => { setLeftPaneWidth(width); cycleManagement.setSaveStatus('unsaved'); }}
                            workflowStep={workflowStep}
                        />
                    </div>
                </>
            )}
        </div>
    </div>;
};

try {
    const root = createRoot(document.getElementById('root') as HTMLElement);
    root.render(<App />);
} catch (error) {
    //
}
</file_artifact>

<file path="src/client/views/settings.view/index.ts">
// src/client/views/settings.view/index.ts
import { onMessage } from "./on-message";

export const viewConfig = {
    entry: "settingsView.js",
    type: "viewType.panel.settings", // Note: This type is for internal reference, not a registered view
    handleMessage: onMessage,
};
</file_artifact>

<file path="src/client/views/settings.view/on-message.ts">
// src/client/views/settings.view/on-message.ts
// Updated on: C38 (Add missing import)
import { ServerPostMessageManager } from "@/common/ipc/server-ipc";
import { Services } from "@/backend/services/services";
import { ClientToServerChannel, ServerToClientChannel } from "@/common/ipc/channels.enum";

export function onMessage(serverIpc: ServerPostMessageManager) {
    const { loggerService, fileOperationService, settingsService } = Services;
    loggerService.log("Settings view message handler initialized.");

    serverIpc.onClientMessage(ClientToServerChannel.RequestReadmeContent, () => {
        fileOperationService.handleReadmeContentRequest(serverIpc);
    });

    serverIpc.onClientMessage(ClientToServerChannel.RequestChangelogContent, () => {
        fileOperationService.handleChangelogContentRequest(serverIpc);
    });

    serverIpc.onClientMessage(ClientToServerChannel.RequestSettings, async () => {
        const settings = await settingsService.getSettings();
        serverIpc.sendToClient(ServerToClientChannel.SendSettings, { settings });
    });
    
    serverIpc.onClientMessage(ClientToServerChannel.SaveSettings, (data) => {
        settingsService.saveSettings(data.settings);
    });
}
</file_artifact>

<file path="src/client/views/settings.view/view.scss">
/* src/client/views/settings.view/view.scss */
body {
    padding: 16px;
    font-family: var(--vscode-font-family);
    font-size: var(--vscode-font-size);
    color: var(--vscode-editor-foreground);
    background-color: var(--vscode-editor-background);
}

.settings-view-container {
    display: flex;
    flex-direction: column;
    gap: 16px;

    h1 {
        font-size: 1.5em;
        font-weight: bold;
        border-bottom: 1px solid var(--vscode-panel-border);
        padding-bottom: 8px;
        margin-bottom: 0;
    }
}

.collapsible-section {
    border: 1px solid var(--vscode-panel-border);
    border-radius: 4px;
}

.collapsible-header {
    background-color: var(--vscode-sideBar-sectionHeaderBackground);
    padding: 6px 10px;
    font-size: 11px;
    text-transform: uppercase;
    font-weight: bold;
    cursor: pointer;
    display: flex;
    align-items: center;
    gap: 4px;

    .chevron {
        transition: transform 0.2s ease-in-out;
    }
    .chevron.collapsed {
        transform: rotate(-90deg);
    }
}

.collapsible-content {
    padding: 16px;
    display: flex;
    flex-direction: column;
    gap: 12px;
}

.settings-group {
    display: flex;
    flex-direction: column;
    gap: 6px;

    label {
        font-weight: bold;
    }

    input[type="text"],
    input[type="password"] {
        width: 100%;
        background-color: var(--vscode-input-background);
        color: var(--vscode-input-foreground);
        border: 1px solid var(--vscode-input-border);
        padding: 4px;
        border-radius: 2px;
        outline: none;

        &:focus {
            border-color: var(--vscode-focusBorder);
        }
    }
}

.mode-selection-group {
    display: flex;
    flex-direction: column;
    gap: 12px;
}

.radio-option {
    display: flex;
    flex-direction: column;
    gap: 4px;
    padding-left: 24px;
    position: relative;

    input[type="radio"] {
        position: absolute;
        left: 0;
        top: 2px;
    }

    label {
        font-weight: bold;
        cursor: pointer;
    }

    .description {
        font-size: 12px;
        color: var(--vscode-descriptionForeground);
    }

    .config-inputs {
        padding-top: 8px;
        display: flex;
        flex-direction: column;
        gap: 8px;
    }
}
</file_artifact>

<file path="src/client/views/settings.view/view.tsx">
// src/client/views/settings.view/view.tsx
// Updated on: C65 (Refine static model card details)
import * as React from 'react';
import * as ReactDOM from 'react-dom/client';
import './view.scss';
import { ClientPostMessageManager } from '@/common/ipc/client-ipc';
import { ClientToServerChannel, ServerToClientChannel } from '@/common/ipc/channels.enum';
import ReactMarkdown from 'react-markdown';
import { VscChevronDown, VscVm } from 'react-icons/vsc';
import { ConnectionMode, DceSettings } from '@/backend/services/settings.service';

const CollapsibleSection: React.FC<{ title: string; children: React.ReactNode; initialCollapsed?: boolean; extraHeaderContent?: React.ReactNode }> = ({ title, children, initialCollapsed = false, extraHeaderContent }) => {
    const [isCollapsed, setIsCollapsed] = React.useState(initialCollapsed);
    return (
        <div className="collapsible-section">
            <div className="collapsible-header" onClick={() => setIsCollapsed(!isCollapsed)}>
                <div style={{ display: 'flex', alignItems: 'center', gap: '4px' }}><VscChevronDown className={`chevron ${isCollapsed ? 'collapsed' : ''}`} /><span>{title}</span></div>
                {extraHeaderContent}
            </div>
            {!isCollapsed && <div className="collapsible-content">{children}</div>}
        </div>
    );
};

const App = () => {
    const [readmeContent, setReadmeContent] = React.useState('Loading...');
    const [changelogContent, setChangelogContent] = React.useState('Loading...');
    const [settings, setSettings] = React.useState<DceSettings>({ connectionMode: 'manual' });
    const clientIpc = ClientPostMessageManager.getInstance();

    React.useEffect(() => {
        clientIpc.onServerMessage(ServerToClientChannel.SendReadmeContent, ({ content }) => {
            setReadmeContent(content);
        });
        clientIpc.onServerMessage(ServerToClientChannel.SendChangelogContent, ({ content }) => {
            setChangelogContent(content);
        });
        clientIpc.onServerMessage(ServerToClientChannel.SendSettings, ({ settings: receivedSettings }) => {
            setSettings(receivedSettings);
        });

        clientIpc.sendToServer(ClientToServerChannel.RequestReadmeContent, {});
        clientIpc.sendToServer(ClientToServerChannel.RequestChangelogContent, {});
        clientIpc.sendToServer(ClientToServerChannel.RequestSettings, {});
    }, [clientIpc]);

    const handleSettingsChange = (newSettings: Partial<DceSettings>) => {
        const updatedSettings = { ...settings, ...newSettings };
        setSettings(updatedSettings);
        clientIpc.sendToServer(ClientToServerChannel.SaveSettings, { settings: updatedSettings });
    };

    const handleModeChange = (event: React.ChangeEvent<HTMLInputElement>) => {
        handleSettingsChange({ connectionMode: event.target.value as ConnectionMode });
    };
    
    const handleApiUrlChange = (event: React.ChangeEvent<HTMLInputElement>) => {
        handleSettingsChange({ apiUrl: event.target.value });
    };

    const DemoModelCard = () => (
        <div className="model-card">
            <h3><VscVm /> Demo Model Details</h3>
            <p><strong>Model:</strong> unsloth/gpt-oss-20b</p>
            <p><strong>Total Context Window:</strong> 131,072 tokens</p>
            <p><strong>Max Output Tokens:</strong> 16,384 tokens</p>
            <p><strong>Reasoning Effort:</strong> Medium</p>
            <p><strong>GPU:</strong> NVIDIA RTX 3090 (24GB VRAM)</p>
            <p className="description">This model is hosted locally for demonstration purposes.</p>
        </div>
    );

    return (
        <div className="settings-view-container">
            <h1>DCE Settings & Help</h1>
            
            <CollapsibleSection title="Settings">
                <div className="settings-group">
                    <label>LLM Connection Mode</label>
                    <div className="mode-selection-group">
                        
                        <div className="radio-option">
                            <input type="radio" id="mode-manual" name="mode" value="manual" checked={settings.connectionMode === 'manual'} onChange={handleModeChange} />
                            <label htmlFor="mode-manual">Free Mode (Manual Copy/Paste)</label>
                            <span className="description">Use the extension by manually copying and pasting responses. No setup required.</span>
                        </div>

                        <div className="radio-option">
                            <input type="radio" id="mode-demo" name="mode" value="demo" checked={settings.connectionMode === 'demo'} onChange={handleModeChange} />
                            <label htmlFor="mode-demo">Demo Mode (Local vLLM via `aiascent.game`)</label>
                            <span className="description">Connect to a pre-configured local vLLM instance via a proxy.</span>
                        </div>

                        {settings.connectionMode === 'demo' && <DemoModelCard />}

                        <div className="radio-option">
                            <input type="radio" id="mode-url" name="mode" value="url" checked={settings.connectionMode === 'url'} onChange={handleModeChange} />
                            <label htmlFor="mode-url">API (URL)</label>
                            <span className="description">Connect to your own self-hosted OpenAI-compatible endpoint.</span>
                            {settings.connectionMode === 'url' && (
                                <div className="config-inputs">
                                    <input type="text" id="api-url" placeholder="http://localhost:8000/v1" value={settings.apiUrl || ''} onChange={handleApiUrlChange} />
                                </div>
                            )}
                        </div>

                        <div className="radio-option">
                            <input type="radio" id="mode-key" name="mode" value="key" checked={settings.connectionMode === 'key'} onChange={handleModeChange} />
                            <label htmlFor="mode-key">API (KEY)</label>
                            <span className="description">Connect to a cloud provider using an API key. (Coming soon)</span>
                            {settings.connectionMode === 'key' && (
                                <div className="config-inputs">
                                    <input type="password" id="api-key" placeholder="sk-..." disabled />
                                </div>
                            )}
                        </div>

                    </div>
                </div>
            </CollapsibleSection>

            <CollapsibleSection title="Changelog" initialCollapsed={true}>
                <ReactMarkdown>{changelogContent}</ReactMarkdown>
            </CollapsibleSection>

            <CollapsibleSection title="About (README)" initialCollapsed={true}>
                <ReactMarkdown>{readmeContent}</ReactMarkdown>
            </CollapsibleSection>
        </div>
    );
};

const root = ReactDOM.createRoot(document.getElementById('root')!);
root.render(<App />);
</file_artifact>

<file path="src/client/views/index.ts">
import { viewConfig as contextChooserViewConfig } from "./context-chooser.view";
import * as vscode from "vscode";
import { ServerPostMessageManager } from "@/common/ipc/server-ipc";
import { getNonce, getViewHtml } from "@/common/utils/view-html";

export const views = [contextChooserViewConfig];
export const serverIPCs: Record<string, ServerPostMessageManager> = {};

export function registerViews(context: vscode.ExtensionContext) {
    views.forEach((viewConfig) => {
        context.subscriptions.push(
            vscode.window.registerWebviewViewProvider(viewConfig.type, {
                resolveWebviewView: (webviewView) => {
                    webviewView.webview.options = {
                        enableScripts: true,
                        localResourceRoots: [context.extensionUri],
                    };
                    const nonce = getNonce();
                    const scriptUri = webviewView.webview.asWebviewUri(vscode.Uri.joinPath(context.extensionUri, "dist", viewConfig.entry));
                    const styleUri = webviewView.webview.asWebviewUri(vscode.Uri.joinPath(context.extensionUri, "dist", `${viewConfig.entry.replace('.js', '')}.css`));
                    
                    webviewView.webview.html = getViewHtml({
                        webview: webviewView.webview,
                        nonce,
                        scriptUri: scriptUri.toString(),
                        styleUris: [styleUri],
                    });

                    const serverIpc = ServerPostMessageManager.getInstance(
                        webviewView.webview.onDidReceiveMessage,
                        (data: any) => webviewView.webview.postMessage(data)
                    );
                    serverIPCs[viewConfig.type] = serverIpc;
                    viewConfig.handleMessage(serverIpc);
                },
            })
        );
    });
}
</file_artifact>

<file path="src/common/ipc/channels.enum.ts">
// src/common/ipc/channels.enum.ts
// Updated on: C124 (Add RequestMarkdownPreview)
export enum ClientToServerChannel {
    RequestInitialData = "clientToServer.requestInitialData",
    RequestFlattenContext = "clientToServer.requestFlattenContext",
    RequestWorkspaceFiles = "clientToServer.requestWorkspaceFiles",
    LogMessage = "clientToServer.logMessage",

    // File Operations
    RequestNewFile = "clientToServer.requestNewFile",
    RequestNewFolder = "clientToServer.requestNewFolder",
    RequestFileRename = "clientToServer.requestFileRename",
    RequestFileDelete = "clientToServer.requestFileDelete",
    RequestBatchFileDelete = "clientToServer.requestBatchFileDelete",
    RequestRevealInExplorer = "clientToServer.requestRevealInExplorer",
    RequestCopyPath = "clientToServer.requestCopyPath",
    RequestOpenFile = "clientToServer.requestOpenFile",
    RequestOpenFolder = "clientToServer.requestOpenFolder", 
    RequestFileContent = "clientToServer.requestFileContent",
    RequestMoveFile = "clientToServer.requestMoveFile",
    RequestCopyFile = "clientToServer.requestCopyFile",
    RequestUndo = "clientToServer.requestUndo",
    RequestRedo = "clientToServer.requestRedo",
    RequestAddFileFromBuffer = "clientToServer.requestAddFileFromBuffer",
    RequestCopyFileFromUri = "clientToServer.requestCopyFileFromUri",
    RequestBatchFileWrite = "clientToServer.requestBatchFileWrite",
    RequestCreateFile = "clientToServer.requestCreateFile",
    RequestCopyTextToClipboard = "clientToServer.requestCopyTextToClipboard",
    RequestShowInformationMessage = "clientToServer.requestShowInformationMessage",
    RequestReadmeContent = "clientToServer.requestReadmeContent",
    RequestChangelogContent = "clientToServer.requestChangelogContent",
    RequestNativeDiff = "clientToServer.requestNativeDiff",
    RequestMarkdownPreview = "clientToServer.requestMarkdownPreview",

    // Special File Handling
    RequestPdfToText = "clientToServer.requestPdfToText",
    RequestExcelToText = "clientToServer.requestExcelToText",
    RequestWordToText = "clientToServer.requestWordToText",

    // Selection Persistence
    SaveCurrentSelection = "clientToServer.saveCurrentSelection",
    RequestLastSelection = "clientToServer.requestLastSelection",
    SaveAutoAddState = "clientToServer.saveAutoAddState",

    // VS Code Command Proxy
    VSCodeCommand = "clientToServer.vscodeCommand",

    // Phase 2: PCPP
    RequestCreatePromptFile = "clientToServer.requestCreatePromptFile",
    RequestBatchGeneration = "clientToServer.requestBatchGeneration", // Legacy, to be phased out
    RequestNewCycleAndGenerate = "clientToServer.requestNewCycleAndGenerate", // New
    RequestInitialArtifactsAndGeneration = "clientToServer.requestInitialArtifactsAndGeneration",
    RequestRegenerateResponses = "clientToServer.requestRegenerateResponses",
    RequestFileExistence = "clientToServer.requestFileExistence",
    RequestSyntaxHighlight = "clientToServer.requestSyntaxHighlight",
    RequestHighlightContext = "clientToServer.requestHighlightContext", 
    RequestInitialCycleData = "clientToServer.requestInitialCycleData",
    RequestCycleData = "clientToServer.requestCycleData",
    SaveCycleData = "clientToServer.saveCycleData",
    RequestDeleteCycle = "clientToServer.requestDeleteCycle",
    RequestResetHistory = "clientToServer.requestResetHistory",
    RequestLogState = "clientToServer.requestLogState",
    RequestFileComparison = "clientToServer.requestFileComparison",
    RequestExportHistory = "clientToServer.requestExportHistory",
    RequestImportHistory = "clientToServer.requestImportHistory",
    RequestPromptCostEstimation = "clientToServer.requestPromptCostEstimation",
    RequestPromptCostBreakdown = "clientToServer.requestPromptCostBreakdown",
    RequestGitBaseline = "clientToServer.requestGitBaseline",
    RequestGitRestore = "clientToServer.requestGitRestore",
    RequestGitStatus = "clientToServer.requestGitStatus",
    SaveLastViewedCycle = "clientToServer.saveLastViewedCycle",
    RequestSettings = "clientToServer.requestSettings",
    SaveSettings = "clientToServer.saveSettings",
    RequestStopGeneration = "clientToServer.requestStopGeneration",
    RequestSingleRegeneration = "clientToServer.requestSingleRegeneration",
}

export enum ServerToClientChannel {
    SendWorkspaceFiles = "serverToClient.sendWorkspaceFiles",
    SendWorkspaceTrustState = "serverToClient.sendWorkspaceTrustState",
    ApplySelectionSet = "serverToClient.applySelectionSet",
    SendSelectionSets = "serverToClient.sendSelectionSets",
    ForceRefresh = "serverToClient.forceRefresh",
    SetActiveFile = "serverToClient.setActiveFile",
    FocusFile = "serverToClient.focusFile",
    SendAutoAddState = "serverToClient.sendAutoAddState",
    UpdateProblemCounts = "serverToClient.updateProblemCounts",
    UpdateDecorations = "serverToClient.updateDecorations", 
    UpdateNodeStats = "serverToClient.updateNodeStats",
    SendFileContent = "serverToClient.sendFileContent",
    SendReadmeContent = "serverToClient.sendReadmeContent",
    SendChangelogContent = "serverToClient.sendChangelogContent",
    AutoAddNewFile = "serverToClient.autoAddNewFile",
    
    // Phase 2: PCPP
    SendFileExistence = "serverToClient.sendFileExistence",
    SendSyntaxHighlight = "serverToClient.sendSyntaxHighlight",
    SendHighlightContext = "serverToClient.sendHighlightContext", 
    SendInitialCycleData = "serverToClient.sendInitialCycleData",
    SendCycleData = "serverToClient.sendCycleData",
    FilesWritten = "serverToClient.filesWritten",
    SendFileComparison = "serverToClient.sendFileComparison", 
    SendPromptCostEstimation = "serverToClient.sendPromptCostEstimation",
    SendPromptCostBreakdown = "serverToClient.sendPromptCostBreakdown",
    NotifyGitOperationResult = "serverToClient.notifyGitOperationResult",
    SendGitStatus = "serverToClient.sendGitStatus",
    NotifySaveComplete = "serverToClient.notifySaveComplete",
    SendSettings = "serverToClient.sendSettings",
    SendBatchGenerationResult = "serverToClient.sendBatchGenerationResult",
    SendBatchGenerationComplete = "serverToClient.sendBatchGenerationComplete",
    UpdateGenerationProgress = "serverToClient.updateGenerationProgress",
    UpdateSingleGenerationProgress = "serverToClient.updateSingleGenerationProgress", // New
    StartGenerationUI = "serverToClient.startGenerationUI", // DEPRECATED
    NavigateToNewGeneratingCycle = "serverToClient.navigateToNewGeneratingCycle", // NEW
    NotifySingleResponseComplete = "serverToClient.notifySingleResponseComplete",
}
</file_artifact>

<file path="src/common/ipc/channels.type.ts">
// src/common/ipc/channels.type.ts
// Updated on: C124 (Add tabId to comparison and markdown preview)
import { FileNode } from "@/common/types/file-node";
import { ClientToServerChannel, ServerToClientChannel } from "./channels.enum";
import { PcppCycle, PcppResponse } from "@/common/types/pcpp.types";
import { DceSettings } from "@/backend/services/settings.service";

export type SelectionSet = { [name: string]: string[] };
export type ProblemCountsMap = { [path: string]: { error: number; warning: number; } };
export type GitStatusMap = { [path: string]: string };
export type BatchWriteFile = { path: string; content: string };

export interface ComparisonMetrics {
    originalTokens: number;
    modifiedTokens: number;
    similarity: number;
}

export interface GenerationProgress {
    responseId: number;
    currentTokens: number;
    totalTokens: number;
    promptTokens: number;
    thinkingTokens: number;
    status: 'pending' | 'thinking' | 'generating' | 'complete' | 'error' | 'stopped';
    startTime: number;
    thinkingStartTime?: number;
    generationStartTime?: number;
}


export type ChannelBody<T extends ClientToServerChannel | ServerToClientChannel> =
    T extends ClientToServerChannel.RequestInitialData ? {} :
    T extends ClientToServerChannel.RequestFlattenContext ? { selectedPaths: string[] } :
    T extends ClientToServerChannel.RequestWorkspaceFiles ? { force?: boolean } :
    T extends ClientToServerChannel.LogMessage ? { level: 'info' | 'warn' | 'error', message: string } :
    T extends ClientToServerChannel.RequestNewFile ? { parentDirectory: string } :
    T extends ClientToServerChannel.RequestNewFolder ? { parentDirectory: string } :
    T extends ClientToServerChannel.RequestFileRename ? { oldPath: string, newName: string } :
    T extends ClientToServerChannel.RequestFileDelete ? { path: string } :
    T extends ClientToServerChannel.RequestBatchFileDelete ? { paths: string[] } :
    T extends ClientToServerChannel.RequestRevealInExplorer ? { path: string } :
    T extends ClientToServerChannel.RequestCopyPath ? { path: string, relative: boolean } :
    T extends ClientToServerChannel.RequestOpenFile ? { path: string } :
    T extends ClientToServerChannel.RequestOpenFolder ? {} :
    T extends ClientToServerChannel.RequestFileContent ? { path: string } :
    T extends ClientToServerChannel.RequestMoveFile ? { oldPath: string, newPath: string } :
    T extends ClientToServerChannel.RequestCopyFile ? { sourcePath: string, destinationDir: string } :
    T extends ClientToServerChannel.RequestUndo ? {} :
    T extends ClientToServerChannel.RequestRedo ? {} :
    T extends ClientToServerChannel.RequestAddFileFromBuffer ? { targetPath: string, data: Uint8Array } :
    T extends ClientToServerChannel.RequestCopyFileFromUri ? { sourceUri: string, targetDir: string } :
    T extends ClientToServerChannel.RequestBatchFileWrite ? { files: BatchWriteFile[] } :
    T extends ClientToServerChannel.RequestCreateFile ? { filePath: string } :
    T extends ClientToServerChannel.RequestCopyTextToClipboard ? { text: string } :
    T extends ClientToServerChannel.RequestShowInformationMessage ? { message: string } :
    T extends ClientToServerChannel.RequestReadmeContent ? {} :
    T extends ClientToServerChannel.RequestChangelogContent ? {} :
    T extends ClientToServerChannel.RequestNativeDiff ? { originalPath: string; modifiedContent: string; title: string; } :
    T extends ClientToServerChannel.RequestPdfToText ? { path: string } :
    T extends ClientToServerChannel.RequestExcelToText ? { path: string } :
    T extends ClientToServerChannel.RequestWordToText ? { path: string } :
    T extends ClientToServerChannel.SaveCurrentSelection ? { paths: string[] } :
    T extends ClientToServerChannel.RequestLastSelection ? {} :
    T extends ClientToServerChannel.SaveAutoAddState ? { enabled: boolean } :
    T extends ClientToServerChannel.VSCodeCommand ? { command: string, args?: any[] } :
    T extends ClientToServerChannel.RequestCreatePromptFile ? { cycleTitle: string; currentCycle: number; selectedFiles: string[] } :
    T extends ClientToServerChannel.RequestBatchGeneration ? { cycleData: PcppCycle, count: number } :
    T extends ClientToServerChannel.RequestNewCycleAndGenerate ? { cycleData: PcppCycle, count: number } :
    T extends ClientToServerChannel.RequestInitialArtifactsAndGeneration ? { projectScope: string, responseCount: number } :
    T extends ClientToServerChannel.RequestRegenerateResponses ? { cycleData: PcppCycle, tabsToRegenerate: number[] } :
    T extends ClientToServerChannel.RequestFileExistence ? { paths: string[] } :
    T extends ClientToServerChannel.RequestSyntaxHighlight ? { code: string; lang: string, id: string } :
    T extends ClientToServerChannel.RequestHighlightContext ? { context: string; id: string } :
    T extends ClientToServerChannel.RequestInitialCycleData ? {} :
    T extends ClientToServerChannel.RequestCycleData ? { cycleId: number } :
    T extends ClientToServerChannel.SaveCycleData ? { cycleData: PcppCycle } :
    T extends ClientToServerChannel.RequestDeleteCycle ? { cycleId: number; } :
    T extends ClientToServerChannel.RequestResetHistory ? {} :
    T extends ClientToServerChannel.RequestLogState ? { currentState: PcppCycle, costState: { totalPromptTokens: number, estimatedPromptCost: number, costBreakdown: any } } :
    T extends ClientToServerChannel.RequestFileComparison ? { filePath: string; modifiedContent: string; tabId: string } :
    T extends ClientToServerChannel.RequestExportHistory ? {} :
    T extends ClientToServerChannel.RequestImportHistory ? {} :
    T extends ClientToServerChannel.RequestPromptCostEstimation ? { cycleData: PcppCycle } :
    T extends ClientToServerChannel.RequestPromptCostBreakdown ? { cycleData: PcppCycle } :
    T extends ClientToServerChannel.RequestGitBaseline ? { commitMessage: string } :
    T extends ClientToServerChannel.RequestGitRestore ? { filesToDelete: string[] } :
    T extends ClientToServerChannel.RequestGitStatus ? {} :
    T extends ClientToServerChannel.SaveLastViewedCycle ? { cycleId: number | null } :
    T extends ClientToServerChannel.RequestSettings ? {} :
    T extends ClientToServerChannel.SaveSettings ? { settings: DceSettings } :
    T extends ClientToServerChannel.RequestStopGeneration ? { cycleId: number; responseId: number; } :
    T extends ClientToServerChannel.RequestSingleRegeneration ? { cycleId: number, tabId: string } :
    T extends ClientToServerChannel.RequestMarkdownPreview ? { filePath: string } :
    
    T extends ServerToClientChannel.SendWorkspaceFiles ? { files: FileNode[] } :
    T extends ServerToClientChannel.SendWorkspaceTrustState ? { isTrusted: boolean } :
    T extends ServerToClientChannel.ApplySelectionSet ? { paths: string[] } :
    T extends ServerToClientChannel.SendSelectionSets ? { sets: SelectionSet } :
    T extends ServerToClientChannel.ForceRefresh ? { reason?: 'fileOp' | 'manual' | 'history' } :
    T extends ServerToClientChannel.SetActiveFile ? { path: string } :
    T extends ServerToClientChannel.FocusFile ? { path: string } :
    T extends ServerToClientChannel.SendAutoAddState ? { enabled: boolean } :
    T extends ServerToClientChannel.UpdateProblemCounts ? { problemMap: ProblemCountsMap } :
    T extends ServerToClientChannel.UpdateDecorations ? { problemMap: ProblemCountsMap, gitStatusMap: GitStatusMap } :
    T extends ServerToClientChannel.UpdateNodeStats ? { path: string, tokenCount: number, error?: string } :
    T extends ServerToClientChannel.SendFileContent ? { path: string, content: string | null } :
    T extends ServerToClientChannel.SendReadmeContent ? { content: string } :
    T extends ServerToClientChannel.SendChangelogContent ? { content: string } :
    T extends ServerToClientChannel.AutoAddNewFile ? { path: string } :
    T extends ServerToClientChannel.SendFileExistence ? { existenceMap: { [path: string]: boolean } } :
    T extends ServerToClientChannel.SendSyntaxHighlight ? { highlightedHtml: string, id: string } :
    T extends ServerToClientChannel.SendHighlightContext ? { highlightedHtml: string, id: string } :
    T extends ServerToClientChannel.SendInitialCycleData ? { cycleData: PcppCycle; projectScope?: string; } :
    T extends ServerToClientChannel.SendCycleData ? { cycleData: PcppCycle | null, projectScope?: string; } :
    T extends ServerToClientChannel.FilesWritten ? { paths: string[] } :
    T extends ServerToClientChannel.SendFileComparison ? { filePath: string; tabId: string } & ComparisonMetrics :
    T extends ServerToClientChannel.SendPromptCostEstimation ? { totalTokens: number; estimatedCost: number; breakdown: { [key: string]: number } } :
    T extends ServerToClientChannel.NotifyGitOperationResult ? { success: boolean; message: string; } :
    T extends ServerToClientChannel.SendGitStatus ? { isClean: boolean } :
    T extends ServerToClientChannel.NotifySaveComplete ? { cycleId: number } :
    T extends ServerToClientChannel.SendSettings ? { settings: DceSettings } :
    T extends ServerToClientChannel.SendBatchGenerationResult ? { responses: string[], newCycleId: number } :
    T extends ServerToClientChannel.SendBatchGenerationComplete ? { newCycleId: number; newMaxCycle: number; } :
    T extends ServerToClientChannel.UpdateGenerationProgress ? { progress: GenerationProgress[], tps: number, chunks: { [responseId: number]: string } } :
    T extends ServerToClientChannel.UpdateSingleGenerationProgress ? { progress: GenerationProgress; content: string; } :
    T extends ServerToClientChannel.StartGenerationUI ? { newCycleId: number, newMaxCycle: number } : // DEPRECATED
    T extends ServerToClientChannel.NavigateToNewGeneratingCycle ? { newCycleData: PcppCycle, newMaxCycle: number } :
    T extends ServerToClientChannel.NotifySingleResponseComplete ? { responseId: number; content: string; } :
    never;
</file_artifact>

<file path="src/common/ipc/client-ipc.ts">
// Updated on: C1 (Add getVscodeApi method)
import getVscode from "./get-vscode-api";
import { ClientToServerChannel, ServerToClientChannel } from "./channels.enum";
import { ChannelBody } from "./channels.type";
import { WebviewApi, ViewState } from "../types/vscode-webview";

export class ClientPostMessageManager {
    private static _instance?: ClientPostMessageManager;
    private _listeners: {
        channel: ServerToClientChannel,
        callback: (body: ChannelBody<ServerToClientChannel>) => void
    }[];

    private constructor() {
        this._listeners = [];
        window.addEventListener('message', (event: MessageEvent) => {
            const data = event.data;
            this._listeners.forEach((listener) => {
                if (listener.channel === data.channel) {
                    listener.callback(data.body);
                }
            });
        });
    }

    static getInstance(): ClientPostMessageManager {
        if (!ClientPostMessageManager._instance) {
            ClientPostMessageManager._instance = new ClientPostMessageManager();
        }
        return ClientPostMessageManager._instance;
    }

    public getVscodeApi(): WebviewApi<ViewState> {
        return getVscode();
    }

    sendToServer<T extends ClientToServerChannel>(channel: T, body: ChannelBody<T>): void {
        this.getVscodeApi().postMessage({ channel, body });
    }

    onServerMessage<T extends ServerToClientChannel>(channel: T, callback: (body: ChannelBody<T>) => void): void {
        this._listeners.push({ channel, callback: callback as any });
    }
}
</file_artifact>

<file path="src/common/ipc/get-vscode-api.ts">
import { WebviewApi } from "../types/vscode-webview";

let vscode: WebviewApi<unknown> | null = null;

const getVscode = () => {
    if (!vscode) {
        vscode = acquireVsCodeApi();
    }
    return vscode;
};

export default getVscode;
</file_artifact>

<file path="src/common/ipc/server-ipc.ts">
import { ClientToServerChannel, ServerToClientChannel } from "./channels.enum";
import { ChannelBody } from "./channels.type";

export class ServerPostMessageManager {
    private static _instance?: ServerPostMessageManager;
    private _listeners: {
        channel: ClientToServerChannel,
        callback: (body: ChannelBody<ClientToServerChannel>) => void
    }[];

    private constructor(
        private onMessage: (data: any) => void,
        private sendMessage: (message: any) => void
    ) {
        this._listeners = [];
        this.onMessage((data: any) => {
            this._listeners.forEach((listener) => {
                if (listener.channel === data.channel) {
                    listener.callback(data.body);
                }
            });
        });
    }

    static getInstance(onMessage?: (data: any) => void, sendMessage?: (message: any) => void) {
        if (onMessage && sendMessage) {
            ServerPostMessageManager._instance = new ServerPostMessageManager(onMessage, sendMessage);
        }
        if (!ServerPostMessageManager._instance) {
            throw new Error("ServerPostMessageManager not initialized");
        }
        return ServerPostMessageManager._instance;
    }

    sendToClient<T extends ServerToClientChannel>(channel: T, body: ChannelBody<T>): void {
        this.sendMessage({ channel, body });
    }

    onClientMessage<T extends ClientToServerChannel>(channel: T, callback: (body: ChannelBody<T>) => void): void {
        this._listeners.push({ channel, callback: callback as any });
    }
}
</file_artifact>

<file path="src/common/types/file-node.ts">
export interface FileNode {
    name: string;
    absolutePath: string;
    children?: FileNode[];
    tokenCount: number;
    fileCount: number; // For directories, this is the count of files inside. For files, it's 1.
    isImage: boolean;
    sizeInBytes: number;
    extension: string;
    isPdf: boolean;
    isExcel: boolean;
    isWordDoc: boolean;
    isSelectable: boolean;
    // gitStatus and problemCounts are removed as they are now handled dynamically
    error?: string;
}
</file_artifact>

<file path="src/common/types/pcpp.types.ts">
// src/common/types/pcpp.types.ts
// Updated on: C126 (Add isCycleCollapsed)
export interface PcppResponse {
    content: string;
    status: 'pending' | 'thinking' | 'generating' | 'complete' | 'error' | 'stopped';
    parsedContent?: ParsedResponse | null;
    startTime?: number;
    thinkingEndTime?: number;
    endTime?: number;
    thinkingTokens?: number;
    responseTokens?: number;
}

export interface PcppCycle {
    cycleId: number;
    timestamp: string;
    title: string;
    cycleContext: string;
    ephemeralContext: string;
    responses: { [tabId: string]: PcppResponse };
    isParsedMode?: boolean;
    leftPaneWidth?: number;
    selectedResponseId?: string | null;
    selectedFilesForReplacement?: string[];
    tabCount?: number;
    activeTab?: number;
    isSortedByTokens?: boolean;
    pathOverrides?: { [originalPath: string]: string };
    cycleContextHeight?: number;
    ephemeralContextHeight?: number;
    activeWorkflowStep?: string;
    status?: 'complete' | 'generating';
    isEphemeralContextCollapsed?: boolean;
    isCycleCollapsed?: boolean; // C126: New field for persisting cycle section collapse state
    connectionMode?: string;
}

export interface PcppHistoryFile {
    version: number;
    projectScope?: string; 
    cycles: PcppCycle[];
}

export interface ParsedFile {
    path: string;
    content: string;
    tokenCount: number;
}

export interface ParsedResponse {
    summary: string;
    courseOfAction: string;
    curatorActivity?: string;
    filesUpdated: string[];
    files: ParsedFile[];
    totalTokens: number;
}
</file_artifact>

<file path="src/common/types/vscode-webview.d.ts">
// Updated on: C73 (Remove pcppActiveView)
export interface WebviewApi<StateType> {
    postMessage(message: unknown): void;
    getState(): StateType | undefined;
    setState<T extends StateType | undefined>(newState: T): T;
}

export interface ViewState {
    selectedFiles?: string[];
    pcppLeftPaneWidth?: number;
}

declare global {
    function acquireVsCodeApi<StateType = ViewState>(): WebviewApi<StateType>;
}
</file_artifact>

<file path="src/common/utils/formatting.ts">
// src/common/utils/formatting.ts
// Updated on: C9 (Add truncatePath utility)

const KMBT_SUFFIXES = ['', 'K', 'M', 'B', 'T', 'Q']; // Extend as needed

/**
 * Truncates the middle of a file path if it exceeds a maximum length.
 * @param path The file path string.
 * @param maxLength The maximum desired length.
 * @returns The truncated path.
 */
export function truncatePath(path: string, maxLength: number = 50): string {
    if (path.length <= maxLength) {
        return path;
    }

    const startLength = Math.ceil((maxLength - 3) / 2);
    const endLength = Math.floor((maxLength - 3) / 2);

    const start = path.substring(0, startLength);
    const end = path.substring(path.length - endLength);

    return `${start}...${end}`;
}

/**
 * Calculates the estimated cost for an LLM prompt based on tiered pricing.
 * @param totalInputTokens The total number of tokens in the input.
 * @returns The estimated cost in USD.
 */
export function calculatePromptCost(totalInputTokens: number): number {
    if (totalInputTokens <= 0) {
        return 0;
    }

    const rateTier1 = 1.25 / 1_000_000; // for prompts <= 200k tokens
    const rateTier2 = 2.50 / 1_000_000; // for prompts > 200k tokens

    if (totalInputTokens <= 200_000) {
        return totalInputTokens * rateTier1;
    } else {
        return totalInputTokens * rateTier2;
    }
}


/**
 * Formats a large number with appropriate K/M/B/T suffixes and dynamic decimal places.
 */
export function formatLargeNumber(value: number | undefined | null, decimalPlaces: number = 1): string {
    if (value === null || value === undefined || isNaN(value) || !Number.isFinite(value)) {
        return '---';
    }
    if (value === 0) {
        return '0';
    }

    const isNegative = value < 0;
    const absValue = Math.abs(value);

    if (absValue < 1000) {
        return String(Math.round(value));
    }

    let unitIndex = 0;
    let scaledValue = absValue;

    unitIndex = Math.floor(Math.log10(absValue) / 3);
    unitIndex = Math.min(unitIndex, KMBT_SUFFIXES.length - 1);
    scaledValue = absValue / Math.pow(1000, unitIndex);

    let adjustedDecimalPlaces = decimalPlaces;
    if (scaledValue >= 100) adjustedDecimalPlaces = 0;
    else if (scaledValue >= 10) adjustedDecimalPlaces = 1;
    else adjustedDecimalPlaces = 2;

    const unit = KMBT_SUFFIXES[unitIndex] ?? '';
    let formattedValue = scaledValue.toFixed(adjustedDecimalPlaces);
    
    if (adjustedDecimalPlaces > 0 && formattedValue.endsWith('0')) {
        formattedValue = formattedValue.replace(/\.?0+$/, '');
    }

    return `${isNegative ? '-' : ''}${formattedValue}${unit}`;
}

/**
 * Formats a number with commas as thousands separators.
 */
export function formatNumberWithCommas(value: number | undefined | null): string {
    if (value === null || value === undefined || isNaN(value)) {
        return '---';
    }
    return value.toLocaleString();
}

/**
 * Formats a file size in bytes into a human-readable string (KB, MB, GB, etc.).
 */
export function formatBytes(bytes: number, decimals: number = 1): string {
    if (bytes === 0) return '0 Bytes';
    if (isNaN(bytes)) return '---';

    const k = 1024;
    const dm = decimals < 0 ? 0 : decimals;
    const sizes = ['Bytes', 'KB', 'MB', 'GB', 'TB', 'PB', 'EB', 'ZB', 'YB'];

    const i = Math.floor(Math.log(bytes) / Math.log(k));

    return parseFloat((bytes / Math.pow(k, i)).toFixed(dm)) + ' ' + sizes[i];
}

/**
 * Truncates a long string for logging purposes.
 */
export function truncateStringForLogging(str: string, maxLength: number = 100): string {
    if (str.length <= maxLength) {
        return str;
    }
    const halfLength = Math.floor((maxLength - 3) / 2);
    return `${str.substring(0, halfLength)}...${str.substring(str.length - halfLength)}`;
}

/**
 * Truncates a multi-line code string for logging, keeping the first and last few lines.
 * @param code The code string to truncate.
 * @param totalLines The total number of lines to keep (start + end).
 * @param startLines The number of lines to keep from the start.
 * @param endLines The number of lines to keep from the end.
 * @returns A truncated code string.
 */
export function truncateCodeForLogging(code: string, totalLines: number = 30, startLines: number = 15, endLines: number = 15): string {
    if (!code) return code;
    const lines = code.split('\n');
    if (lines.length <= totalLines) {
        return code;
    }
    const start = lines.slice(0, startLines).join('\n');
    const end = lines.slice(-endLines).join('\n');
    return `${start}\n\n// ... (content truncated) ...\n\n${end}`;
}
</file_artifact>

<file path="src/common/utils/similarity.ts">
// src/common/utils/similarity.ts
// New file in C144

/**
 * Calculates the Srensen-Dice coefficient between two strings.
 * This measures similarity as a value between 0 (no similarity) and 1 (identical).
 * It works by comparing the number of shared 2-character sequences (bigrams).
 * @param str1 The first string.
 * @param str2 The second string.
 * @returns A number between 0 and 1 representing the similarity.
 */
export function diceCoefficient(str1: string, str2: string): number {
    if (str1 === str2) return 1;
    if (str1.length < 2 || str2.length < 2) return 0;

    const bigrams1 = new Set<string>();
    for (let i = 0; i < str1.length - 1; i++) {
        bigrams1.add(str1.substring(i, i + 2));
    }

    const bigrams2 = new Set<string>();
    for (let i = 0; i < str2.length - 1; i++) {
        bigrams2.add(str2.substring(i, i + 2));
    }

    if (bigrams1.size === 0 && bigrams2.size === 0) return 1;

    let intersectionSize = 0;
    for (const bigram of bigrams1) {
        if (bigrams2.has(bigram)) {
            intersectionSize++;
        }
    }

    return (2 * intersectionSize) / (bigrams1.size + bigrams2.size);
}
</file_artifact>

<file path="src/common/utils/view-html.ts">
import * as vscode from "vscode";

export function getViewHtml({ webview, nonce, scriptUri, styleUris = [] }: { webview: vscode.Webview; nonce: string; scriptUri: string; styleUris?: vscode.Uri[]; }): string {
    const styles = styleUris.map(uri => `<link href="${uri}" rel="stylesheet">`).join('\n');
    
    // Reverted CSP to a stricter policy as web workers are no longer needed.
    const csp = `
        default-src 'none';
        style-src ${webview.cspSource} 'unsafe-inline';
        script-src 'nonce-${nonce}';
        font-src ${webview.cspSource};
    `.trim();

    return `<!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <meta http-equiv="Content-Security-Policy" content="${csp}">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            ${styles}
        </head>
        <body>
            <div id="root"></div>
            <script nonce="${nonce}" src="${scriptUri}"></script>
        </body>
        </html>`;
}

function getNonce() {
    let text = "";
    const possible = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789";
    for (let i = 0; i < 32; i++) {
        text += possible.charAt(Math.floor(Math.random() * possible.length));
    }
    return text;
}
export { getNonce };
</file_artifact>

<file path="src/common/view-types.ts">
export const VIEW_TYPES = {
  SIDEBAR: {
    CONTEXT_CHOOSER: "viewType.sidebar.contextChooser",
  },
  PANEL: {
    PARALLEL_COPILOT: "viewType.panel.parallelCopilot",
  }
};
</file_artifact>

<file path="src/extension.ts">
import * as vscode from "vscode";
import { registerViews, serverIPCs } from "./client/views";
import { registerCommands } from "./backend/commands/register-commands";
import { Services } from "./backend/services/services";
import { VIEW_TYPES } from "./common/view-types";
import { ServerToClientChannel } from "./common/ipc/channels.enum";
import { API as GitAPI, GitExtension } from "./backend/types/git";
import { getNonce, getViewHtml } from "./common/utils/view-html";
import { onMessage as onParallelCopilotMessage } from "./client/views/parallel-copilot.view/on-message";
import { onMessage as onSettingsMessage } from "./client/views/settings.view/on-message";
import { ServerPostMessageManager } from "./common/ipc/server-ipc";
import { ResponseContentProvider } from "./backend/providers/ResponseContentProvider";

let globalContext: vscode.ExtensionContext | null = null;
let parallelCopilotPanel: vscode.WebviewPanel | undefined;
let settingsPanel: vscode.WebviewPanel | undefined;

function createOrShowParallelCopilotPanel(context: vscode.ExtensionContext) {
    const column = vscode.window.activeTextEditor?.viewColumn;

    if (parallelCopilotPanel) {
        parallelCopilotPanel.reveal(column);
        return;
    }

    parallelCopilotPanel = vscode.window.createWebviewPanel(
        VIEW_TYPES.PANEL.PARALLEL_COPILOT,
        'DCE Parallel Co-Pilot',
        column || vscode.ViewColumn.One,
        {
            enableScripts: true,
            localResourceRoots: [context.extensionUri],
        }
    );
    
    const scriptUri = parallelCopilotPanel.webview.asWebviewUri(vscode.Uri.joinPath(context.extensionUri, "dist", "parallelCopilotView.js"));
    const styleUris = [
        parallelCopilotPanel.webview.asWebviewUri(vscode.Uri.joinPath(context.extensionUri, "dist", "parallelCopilotView.css")),
        parallelCopilotPanel.webview.asWebviewUri(vscode.Uri.joinPath(context.extensionUri, "dist", "starry-night.css"))
    ];
    const nonce = getNonce();
    
    parallelCopilotPanel.webview.html = getViewHtml({
        webview: parallelCopilotPanel.webview,
        nonce,
        scriptUri: scriptUri.toString(),
        styleUris: styleUris,
    });
    
    const serverIpc = ServerPostMessageManager.getInstance(
        parallelCopilotPanel.webview.onDidReceiveMessage,
        (data: any) => parallelCopilotPanel?.webview.postMessage(data)
    );

    serverIPCs[VIEW_TYPES.PANEL.PARALLEL_COPILOT] = serverIpc;
    onParallelCopilotMessage(serverIpc);

    parallelCopilotPanel.onDidDispose(() => {
        parallelCopilotPanel = undefined;
    }, null, context.subscriptions);
}

function createOrShowSettingsPanel(context: vscode.ExtensionContext) {
    const column = vscode.window.activeTextEditor?.viewColumn;

    if (settingsPanel) {
        settingsPanel.reveal(column);
        return;
    }

    settingsPanel = vscode.window.createWebviewPanel(
        'dce.settingsPanel', 'DCE Settings & Help', column || vscode.ViewColumn.One, { enableScripts: true, localResourceRoots: [context.extensionUri] }
    );

    const scriptUri = settingsPanel.webview.asWebviewUri(vscode.Uri.joinPath(context.extensionUri, "dist", "settingsView.js"));
    const styleUri = settingsPanel.webview.asWebviewUri(vscode.Uri.joinPath(context.extensionUri, "dist", "settingsView.css"));
    const nonce = getNonce();

    settingsPanel.webview.html = getViewHtml({
        webview: settingsPanel.webview, nonce, scriptUri: scriptUri.toString(), styleUris: [styleUri],
    });

    const serverIpc = ServerPostMessageManager.getInstance(
        settingsPanel.webview.onDidReceiveMessage,
        (data: any) => settingsPanel?.webview.postMessage(data)
    );
    serverIPCs['viewType.panel.settings'] = serverIpc;
    onSettingsMessage(serverIpc);

    settingsPanel.onDidDispose(() => {
        settingsPanel = undefined;
    }, null, context.subscriptions);
}


export async function activate(context: vscode.ExtensionContext) {
    Services.loggerService.log('Congratulations, your extension "Data Curation Environment" is now active!');
    globalContext = context;

    let gitApi: GitAPI | undefined;
    try {
        const gitExtension = vscode.extensions.getExtension<GitExtension>('vscode.git');
        if (gitExtension) {
            await gitExtension.activate();
            gitApi = gitExtension.exports.getAPI(1);
        }
    } catch (error) {
        Services.loggerService.error(`Failed to get Git API: ${error}`);
    }

    try {
        Services.initialize(context, gitApi); 
        registerCommands(context);
        context.subscriptions.push(vscode.commands.registerCommand('dce.showParallelCopilot', () => {
            createOrShowParallelCopilotPanel(context);
        }));
        context.subscriptions.push(vscode.commands.registerCommand('dce.showSettingsPanel', () => {
            createOrShowSettingsPanel(context);
        }));
        registerViews(context);

        // Register the TextDocumentContentProvider for our virtual documents
        context.subscriptions.push(
            vscode.workspace.registerTextDocumentContentProvider('dce-response', Services.responseContentProvider)
        );

        const initialCycle = await Services.historyService.getInitialCycle();
        if (initialCycle.cycleId === 0 && vscode.workspace.workspaceFolders && vscode.workspace.workspaceFolders.length > 0) {
            Services.loggerService.log("Fresh environment, automatically opening Parallel Co-Pilot Panel.");
            vscode.commands.executeCommand('dce.showParallelCopilot');
        }

    } catch (error: any) {
        Services.loggerService.error(`CRITICAL - Error during activation: ${error.message}`);
        vscode.window.showErrorMessage("Data Curation Environment failed to activate.");
        return;
    }
    
    const updateActiveFile = () => {
        let fileUri: vscode.Uri | undefined;
        const activeEditor = vscode.window.activeTextEditor;
        if (activeEditor?.document.uri.scheme === 'file') {
            fileUri = activeEditor.document.uri;
        } else {
            const tabInput = vscode.window.tabGroups.activeTabGroup.activeTab?.input as { uri?: vscode.Uri };
            if (tabInput?.uri?.scheme === 'file') fileUri = tabInput.uri;
        }

        if (fileUri) {
            const serverIpc = serverIPCs[VIEW_TYPES.SIDEBAR.CONTEXT_CHOOSER];
            if (serverIpc) {
                serverIpc.sendToClient(ServerToClientChannel.SetActiveFile, { path: fileUri.fsPath.replace(/\\/g, '/') });
            }
        }
    };

    context.subscriptions.push(
        vscode.window.onDidChangeActiveTextEditor(updateActiveFile),
        vscode.window.tabGroups.onDidChangeTabs(updateActiveFile),
        vscode.workspace.onDidGrantWorkspaceTrust(() => {
            const serverIpc = serverIPCs[VIEW_TYPES.SIDEBAR.CONTEXT_CHOOSER];
            if (serverIpc) serverIpc.sendToClient(ServerToClientChannel.SendWorkspaceTrustState, { isTrusted: true });
        })
    );

    setTimeout(updateActiveFile, 500);
}

export function getContext() {
    if (!globalContext) throw new Error("Extension context not available.");
    return globalContext;
}

export function deactivate() {}
</file_artifact>

<file path="src/Artifacts/A52.3 DCE - Harmony Interaction Schema Source.md">
# Artifact A52.3: DCE - Harmony Interaction Schema Source
# Date Created: C49
# Author: AI Model & Curator
# Updated on: C64 (Add metainterpretability context)

- **Key/Value for A0:**
- **Description:** The canonical source text for the M3. Interaction Schema, adapted for use with Harmony-based models like GPT-OSS. This version is injected into prompts when "Demo Mode" is active and instructs the model to produce a structured JSON output.
- **Tags:** documentation, process, interaction schema, source of truth, harmony, gpt-oss, json

## Interaction Schema Text

**Meta-Context for AI:** Take a deep breath, and work through the problem step-by-step. You are Ascentia, an AI model interacting with a human curator through the Data Curation Environment (DCE), a VS Code extension. You are to act as a cognitive mentor and assist the user with their projects and goals. Your responses are parsed by this extension to automate development workflows. Adhering to the specified JSON format is critical for successful integration.

1.  **CRITICAL: Your entire response must be a single, valid JSON object.** Do not include any text, thoughts, or markdown before or after the JSON structure. The extension will parse your output directly using `JSON.parse()`.

2.  **JSON Schema:** Your output must conform to the following TypeScript interface. Pay close attention to the data types.

    ```typescript
    interface HarmonyFile {
      path: string;      // The relative path to the file from the workspace root.
      content: string;   // The complete and full content of the file.
    }

    interface CourseOfActionStep {
      step: number;      // The step number, starting from 1.
      description: string; // A description of the action for this step.
    }

    interface HarmonyJsonResponse {
      summary: string;
      course_of_action: CourseOfActionStep[];
      files_updated?: string[]; // Optional, can be derived from `files`
      curator_activity?: string; // Optional: For instructions to the human curator.
      files: HarmonyFile[];
    }
    ```

3.  **Example Output:**
    ```json
    {
      "summary": "I have analyzed the request and will update the main application component and its corresponding service.",
      "course_of_action": [
        {
          "step": 1,
          "description": "Update `src/App.tsx`: Add a new state variable and a button to trigger the new functionality."
        },
        {
          "step": 2,
          "description": "Update `src/services/api.ts`: Create a new function to fetch the required data from the backend."
        }
      ],
      "curator_activity": "Please ensure the backend API endpoint `GET /api/newdata` is running and accessible.",
      "files": [
        {
          "path": "src/App.tsx",
          "content": "// Full content of the updated App.tsx file...\n"
        },
        {
          "path": "src/services/api.ts",
          "content": "// Full content of the updated api.ts file...\n"
        }
      ]
    }
    ```

4.  **Content Rules:**
    *   Always output complete files inside the `content` string. Do not use placeholders or omit code.
    *   Ensure the `content` string correctly escapes characters as needed for a valid JSON string (e.g., newlines as `\n`, quotes as `\"`).
    *   Update documentation artifacts before updating code artifacts.
    *   If you need the human curator to perform an action (e.g., delete a file, run a command), describe it in the optional `curator_activity` field.

5.  Our Document Artifacts serve as our `Source of Truth`. As issues occur, or code repeatedly regresses, seek to align our `Source of Truth` documents to codify the root cause and prevent future regressions.

6.  If you are deciding where to place a new function, and multiple files are suitable candidates, choose the smaller file (in tokens).
</file_artifact>

<file path="src/Artifacts/A78. DCE - Whitepaper - Process as Asset.md">
# Artifact A78: DCE - Whitepaper - Process as Asset

# Date Created: C182

# Author: AI Model & Curator

  - **Key/Value for A0:**
  - **Description:** A whitepaper targeted at high-level stakeholders (NSA, UKILRN) explaining the strategic value of the DCE by focusing on how it transforms the human-AI interaction process into a persistent, shareable asset that accelerates specialized content creation.
  - **Tags:** whitepaper, documentation, strategy, process, acceleration, human-ai collaboration

-----

# Process as Asset: Accelerating Specialized Content Creation through Structured Human-AI Collaboration

**A Whitepaper on the Data Curation Environment (DCE)**

**Date:** September 4, 2025
**Audience:** High-Level Stakeholders (NSA, UKILRN, Naval Operations)

-----

## 1\. Executive Summary

Organizations tasked with developing highly specialized contentsuch as technical training materials, intelligence reports, or complex software documentationface a constant bottleneck: the time and expertise required to curate accurate data, collaborate effectively, and rapidly iterate on feedback. Traditional workflows, even those augmented by Artificial Intelligence (AI), are often ad-hoc, opaque, and inefficient.

This whitepaper introduces the Data Curation Environment (DCE), a framework and toolset integrated into the standard developer environment (Visual Studio Code) that transforms the content creation process itself into a valuable organizational asset. The DCE provides a structured, human-in-the-loop methodology that enables rapid dataset curation, seamless sharing of curated contexts between colleagues, and instant iteration on feedback.

By capturing the entire workflow as a persistent, auditable knowledge graph, the DCE doesn't just help teams build content faster; it provides the infrastructure necessary to scale expertise, ensure quality, and accelerate the entire organizational mission.

## 2\. The Challenge: The Bottleneck of Ad-Hoc AI Interaction

The integration of Large Language Models (LLMs) into organizational workflows promises significant acceleration. However, the way most organizations interact with these models remains unstructured and inefficient, creating several critical bottlenecks:

1.  **The Context Problem:** The quality of an LLM's output is entirely dependent on the quality of its input context. Manually selecting, copying, and pasting relevant data (code, documents, reports) into a chat interface is time-consuming, error-prone, and often results in incomplete or bloated context.
2.  **The Collaboration Gap:** When a task is handed off, the context is lost. A colleague must manually reconstruct the previous operator's dataset and understand their intent, leading to significant delays and duplication of effort.
3.  **The Iteration Overhead:** When feedback requires changes to a complex dataset, operators often resort to manual edits because re-prompting the AI requires reconstructing the entire context again. This negates the efficiency gains of using AI in the first place.
4.  **The Auditability Vacuum:** The iterative process of human-AI interactionthe prompts, the AI's suggestions, and the human's decisionsis a valuable record of the work, yet it is rarely captured in a structured, reusable format.

These challenges prevent organizations from fully realizing the potential of AI. They are forced to choose between the speed of AI and the rigor of a structured process.

## 3\. The Solution: The Data Curation Environment (DCE)

The Data Curation Environment (DCE) is designed to eliminate these bottlenecks by providing a structured framework for human-AI collaboration directly within the operator's working environment. It moves beyond the limitations of simple chat interfaces by introducing three core capabilities:

### 3.1. Precision Context Curation

The DCE replaces manual copy-pasting with an intuitive, integrated file management interface. Operators can precisely select the exact files, folders, or documents required for a task with simple checkboxes. The DCE intelligently handles various file typesincluding code, PDFs, Word documents, and Excel spreadsheetsextracting the relevant textual content automatically.

This ensures that the AI receives the highest fidelity context possible, maximizing the quality of its output while minimizing operator effort.

### 3.2. Parallel AI Scrutiny and Integrated Testing

The DCE recognizes that relying on a single AI response is risky. The "Parallel Co-Pilot Panel" allows operators to manage, compare, and test multiple AI-generated solutions simultaneously.

Integrated diffing tools provide immediate visualization of proposed changes. Crucially, the DCE offers a one-click "Accept" mechanism, integrated with Git version control, allowing operators to instantly apply an AI's suggestion to the live workspace, test it, and revert it if necessary. This creates a rapid, low-risk loop for evaluating multiple AI approaches.

### 3.3. The Cycle Navigator and Persistent Knowledge Graph

Every interaction within the DCE is captured as a "Cycle." A cycle includes the curated context, the operator's instructions, all AI-generated responses, and the operator's final decision. This history is saved as a structured, persistent Knowledge Graph.

The "Cycle Navigator" allows operators to step back through the history, review past decisions, and understand the evolution of the project.

## 4\. Transforming the Process into an Asset

The true power of the DCE lies in how these capabilities combine to transform the workflow itself into a persistent organizational asset.

### 4.1. The Curated Context as a Shareable Asset

In the DCE workflow, the curated context (the "Selection Set") is not ephemeral; it is a saved, versioned asset. When a task is handed off, the new operator doesn't just receive the files; they receive the exact context and the complete history of the previous operator's interactions.

This seamless handoff eliminates the "collaboration gap," allowing teams to work asynchronously and efficiently on complex datasets without duplication of effort.

### 4.2. Accelerating Iteration and Maintenance

The DCE dramatically reduces the overhead associated with feedback and maintenance. Because the context is already curated and saved, operators can rapidly iterate on complex datasets without manual reconstruction.

If feedback requires changes, the operator simply loads the curated context and issues a targeted instruction to the AI. The AI performs the edits against the precise context, completing the update in a single, efficient cycle. This enables organizations to maintain complex systems and content with unprecedented speed.

### 4.3. Scaling Expertise and Ensuring Auditability

The Knowledge Graph generated by the DCE serves as a detailed, auditable record of the entire development process. This is invaluable for:

  * **Training and Onboarding:** New personnel can review the cycle history to understand complex decision-making processes and best practices.
  * **After-Action Reviews:** The graph provides a precise record of what was known, what was instructed, and how the AI responded, enabling rigorous analysis.
  * **Accountability:** In mission-critical environments, the DCE provides a transparent and traceable record of human-AI interaction.

## 5\. Use Case Spotlight: Rapid Development of Training Materials

A government agency needs to rapidly update a specialized technical training lab based on new operational feedback. The feedback indicates that in the existing exam questions, "the correct answer is too often the longest answer choice," creating a pattern that undermines the assessment's validity.

### The Traditional Workflow (Weeks)

1.  **Identify Affected Files:** An analyst manually searches the repository to find all relevant question files (days).
2.  **Manual Editing:** The analyst manually edits each file, attempting to rewrite the "distractor" answers to be longer and more plausible without changing the technical meaning (weeks).
3.  **Review and Rework:** The changes are reviewed, often leading to further manual edits (days).

### The DCE Workflow (Hours)

1.  **Curate Context (Minutes):** The analyst uses the DCE interface to quickly select the folder containing all exam questions. This creates a precise, curated dataset.
2.  **Instruct the AI (Minutes):** The analyst loads the curated context into the Parallel Co-Pilot Panel and provides a targeted instruction: "Review the following exam questions. For any question where the correct answer is significantly longer than the distractors, rewrite the distractors to include more meaningful but ultimately fluffy language to camouflage the length difference, without changing the technical accuracy."
3.  **Review and Accept (Hours):** The AI generates several proposed solutions. The analyst uses the integrated diff viewer to compare the options. They select the best solution and "Accept" the changes with a single click.
4.  **Verification:** The updated lab is immediately ready for final verification.

## 6\. Conclusion

The Data Curation Environment is more than just a developer tool; it is a strategic framework for operationalizing AI in complex environments. By addressing the critical bottlenecks of context curation, collaboration, and iteration, the DCE transforms the human-AI interaction workflow into a structured, persistent, and valuable organizational asset.

For organizations facing an ever-increasing list of priorities and a need to accelerate the development of specialized content, the DCE provides the necessary infrastructure to scale expertise, ensure quality, and achieve the mission faster.
</file_artifact>

<file path="src/Artifacts/A98. DCE - Harmony JSON Output Schema Plan.md">
# Artifact A98: DCE - Harmony JSON Output Schema Plan
# Date Created: C50
# Author: AI Model & Curator

- **Key/Value for A0:**
- **Description:** A plan to migrate the vLLM interaction schema from XML-based parsing to a structured JSON object output, leveraging the `response_format` parameter in OpenAI-compatible APIs.
- **Tags:** plan, architecture, interaction schema, parsing, llm, vllm, harmony, json

## 1. Vision & Goal

The current method of parsing AI responses relies on a set of regular expressions to extract content from within custom XML tags (`<summary>`, `<file>`, etc.). While functional, this approach is brittle and can fail if the model produces even slightly malformed output.

Modern OpenAI-compatible APIs, including the one provided by vLLM, support a `response_format` parameter that can instruct the model to return its output as a guaranteed-valid JSON object. The goal of this plan is to leverage this feature to create a more robust, reliable, and maintainable parsing pipeline. We will define a clear JSON schema and update our extension to request and parse this structured format, moving away from fragile regex-based text processing.

## 2. The Proposed JSON Schema

Based on the example provided in the ephemeral context of Cycle 50, the target JSON schema for an AI response will be as follows:

```typescript
interface HarmonyFile {
  path: string;
  content: string;
}

interface CourseOfActionStep {
  step: number;
  description: string;
}

interface HarmonyJsonResponse {
  summary: string;
  course_of_action: CourseOfActionStep[];
  files_updated?: string[]; // Optional, can be derived from `files`
  curator_activity?: string; // Optional
  files: HarmonyFile[];
}
```

### Example JSON Output:
```json
{
  "summary": "I have analyzed the request and will update the main application component and its corresponding service.",
  "course_of_action": [
    {
      "step": 1,
      "description": "Update `src/App.tsx`: Add a new state variable and a button to trigger the new functionality."
    },
    {
      "step": 2,
      "description": "Update `src/services/api.ts`: Create a new function to fetch the required data from the backend."
    }
  ],
  "curator_activity": "Please ensure the backend API endpoint `GET /api/newdata` is running and accessible.",
  "files": [
    {
      "path": "src/App.tsx",
      "content": "// Full content of the updated App.tsx file..."
    },
    {
      "path": "src/services/api.ts",
      "content": "// Full content of the updated api.ts file..."
    }
  ]
}
```

## 3. Technical Implementation Plan

1.  **Backend (`llm.service.ts`):**
    *   The `generateBatch` method will be updated.
    *   When the `connectionMode` is set to `'demo'`, it will add `response_format: { "type": "json_object" }` to the JSON body of the `fetch` request sent to the vLLM proxy. This instructs the model to generate a JSON response.

2.  **Frontend (`response-parser.ts`):**
    *   The `parseResponse` function will be refactored to be "bilingual."
    *   It will first attempt to parse the `rawText` as JSON using a `try...catch` block.
    *   **If `JSON.parse` succeeds:**
        *   It will validate that the parsed object contains the required keys (`summary`, `course_of_action`, `files`).
        *   It will map the data from the JSON object to the `ParsedResponse` type.
            *   The `course_of_action` array will be formatted into a numbered markdown list.
            *   The `files` array will be directly mapped to the `ParsedFile` array.
    *   **If `JSON.parse` fails:**
        *   It will fall back to the existing regex-based parsing logic. This ensures backward compatibility with the manual copy/paste mode and any models that do not support JSON output mode.

3.  **Interaction Schema (`A52.3`):**
    *   The `A52.3 DCE - Harmony Interaction Schema Source.md` will be updated.
    *   It will now instruct the AI to produce its output in the specified JSON format, providing the schema definition as an example. The instructions for using XML tags will be preserved as a fallback for the model.

This migration to a structured JSON format will significantly improve the reliability of the extension's core parsing logic.
</file_artifact>

<file path="src/Artifacts/A99. DCE - Response Regeneration Workflow Plan.md">
# Artifact A99: DCE - Response Regeneration Workflow Plan
# Date Created: C50
# Author: AI Model & Curator
# Updated on: C78 (Add double-click confirmation and per-tab progress view)

- **Key/Value for A0:**
- **Description:** Details the user stories and technical implementation for the "Regenerate" button in the PCPP, including logic for regenerating empty tabs, all tabs, and a new per-tab refresh feature with double-click confirmation.
- **Tags:** feature plan, ui, ux, workflow, regeneration

## 1. Vision & Goal

The workflow for generating AI responses needs to be more flexible and deliberate. Users may decide they need more responses after the initial batch, a single response might be of low quality, or they may accidentally click the regenerate button. The goal of this feature is to provide intuitive, granular controls for regenerating responses while preventing accidental actions.

## 2. User Stories & Button Behaviors

| ID | User Story | Acceptance Criteria |
|---|---|---|
| P2-REG-01 | **Regenerate Empty Tabs** | As a user, after increasing the number of response tabs from 4 to 6, I want to click the global "Regenerate responses" button, which should only generate new responses for the two new, empty tabs. | - A global "Regenerate responses" button exists in the PCPP header. <br> - If one or more response tabs are empty, clicking this button triggers a batch generation request only for the number of empty tabs. <br> - The new responses populate only the empty tabs. |
| P2-REG-02 | **Regenerate All Tabs** | As a user, if all my response tabs have content but I'm unsatisfied, I want to click the global "Regenerate responses" button and be asked if I want to regenerate *all* responses. | - If no response tabs are empty, clicking "Regenerate responses" shows a confirmation dialog. <br> - If confirmed, a batch request is sent to generate a full new set of responses, which replaces the content in all existing tabs. |
| P2-REG-03 | **Regenerate a Single Tab (from Tab View)** | As a user, if one specific response is poor, I want a "Refresh" icon on that tab to regenerate just that single response without affecting others. | - A "Refresh" icon appears on each response tab. <br> - Clicking this icon triggers a generation request for a single response. <br> - The new response replaces the content of only that specific tab. <br> - The main content area for the active tab switches to show the `GenerationProgressDisplay` to show the new response streaming in. |
| P2-REG-04 | **Re-generate a Single Response (from Progress View)** | As a user watching responses stream in, if one response seems stuck or is generating poorly, I want a "Re-generate" button next to it to discard the current attempt and start a new one for just that slot. | - In the `GenerationProgressDisplay`, a "Re-generate" button is available for each response. <br> - Clicking it stops the current generation for that response (if active) and immediately initiates a new request for that single response slot. |
| P2-REG-05 | **Prevent Accidental Regeneration** | As a user, I want to confirm my intent to regenerate a response, so I don't accidentally lose a good response by misclicking. | - The first click on a "Regenerate" button (on a tab) changes its icon to a "Confirm" (checkmark) icon. <br> - A second click on the same button within a few seconds triggers the regeneration. <br> - If the user does not click again, the button reverts to its original state. |

## 3. Technical Implementation Plan (C78 Update)

1.  **IPC Channels:** Existing channels are sufficient.

2.  **Frontend UI & Logic:**
    *   **Double-Click Confirmation (`ResponseTabs.tsx`):**
        *   Introduce a new local state `const [regenConfirmTabId, setRegenConfirmTabId] = useState<number | null>(null);`.
        *   The `onClick` handler for the regenerate button will implement the two-click logic. The first click sets the state, the second click triggers the regeneration and resets the state.
        *   A `useEffect` hook with a `setTimeout` will be used to reset the confirmation state after 3-4 seconds if no second click occurs.
        *   The button icon will be conditionally rendered (`VscSync` or `VscCheck`) based on the `regenConfirmTabId` state.
    *   **Per-Tab Progress View (`view.tsx`):**
        *   The `handleRegenerateTab` function will update the `status` of the specific response in the `tabs` state to `'generating'`.
        *   The main render logic will be refactored. It will check the status of the `activeTab`. If `tabs[activeTab].status === 'generating'`, it will render the `GenerationProgressDisplay` component. Otherwise, it will render the `ResponsePane`.

3.  **Backend Logic (Per-Response Status):**
    *   **`pcpp.types.ts`:** Add `status: 'pending' | 'generating' | 'complete' | 'error'` to the `PcppResponse` interface.
    *   **`history.service.ts`:**
        *   The `updateSingleResponseInCycle` method will be updated to set the `status` of the target response to `'generating'` and reset its content.
        *   When the response is fully received (from `llm.service.ts`), this method will be called again to set the status to `'complete'` and update the content.
    *   **`llm.service.ts`:**
        *   The `stopGeneration` method will be implemented using a `Map<number, AbortController>` to track and abort `fetch` requests.
</file_artifact>

<file path="src/client/utils/response-parser.ts">
// src/client/utils/response-parser.ts
// Updated on: C116 (Apply un-escaping to successful JSON parse path)
import { ParsedResponse, ParsedFile } from '@/common/types/pcpp.types';

const SUMMARY_REGEX = /<summary>([\s\S]*?)<\/summary>/;
const COURSE_OF_ACTION_REGEX = /<course_of_action>([\s\S]*?)<\/course_of_action>/;
const CURATOR_ACTIVITY_REGEX = /<curator_activity>([\s\S]*?)<\/curator_activity>/;
const FILE_TAG_REGEX = /<file path="([^"]+)">([\s\S]*?)(?:<\/file_path>|<\/file>|<\/filepath>|<\/file_artifact>)/g;
const CODE_FENCE_START_REGEX = /^\s*```[a-zA-Z]*\n/;

// Hybrid parsing regexes
const HYBRID_SUMMARY_REGEX = /"summary"\s*:\s*"((?:\\"|[^"])*)"/;
const HYBRID_COA_REGEX = /"course_of_action"\s*:\s*(\[[\s\S]*?\])/;
const HYBRID_CURATOR_REGEX = /"curator_activity"\s*:\s*"((?:\\"|[^"])*)"/;
const HYBRID_FILE_OBJ_REGEX = /\{\s*"path"\s*:\s*"((?:\\"|[^"])*)"\s*,\s*"content"\s*:\s*"((?:\\"|[^"])*)"\s*\}/g;

function unescapeJsonString(s: string): string {
    if (!s) return "";
    // This handles the double-escaped strings from the LLM.
    // \\" -> \" -> "
    // \\n -> \n -> newline
    return s.replace(/\\\\/g, '\\')
            .replace(/\\n/g, '\n')
            .replace(/\\t/g, '\t')
            .replace(/\\"/g, '"');
}

export function parseResponse(rawText: string): ParsedResponse {
    let textToParse = rawText.trim();
    
    if (textToParse.startsWith('```json')) {
        textToParse = textToParse.substring(7);
        if (textToParse.endsWith('```')) {
            textToParse = textToParse.slice(0, -3);
        }
        textToParse = textToParse.trim();
    }

    // Stage 1: Attempt to parse as a single, valid JSON object
    try {
        const jsonResponse = JSON.parse(textToParse);
        if (jsonResponse.summary && jsonResponse.course_of_action && Array.isArray(jsonResponse.files)) {
            const files: ParsedFile[] = jsonResponse.files.map((f: any) => {
                // C116 FIX: Apply the same un-escaping logic to the content from the successfully parsed JSON.
                // The LLM double-escapes content within the JSON string values.
                const content = unescapeJsonString(f.content || '');
                return {
                    path: unescapeJsonString(f.path || ''),
                    content: content,
                    tokenCount: Math.ceil(content.length / 4),
                };
            });

            const courseOfAction = Array.isArray(jsonResponse.course_of_action)
                ? jsonResponse.course_of_action
                    .map((step: any) => `* **Step ${step.step}:** ${unescapeJsonString(step.description)}`)
                    .join('\n')
                : unescapeJsonString(jsonResponse.course_of_action);

            return {
                summary: unescapeJsonString(jsonResponse.summary),
                courseOfAction: courseOfAction,
                curatorActivity: unescapeJsonString(jsonResponse.curator_activity || ''),
                filesUpdated: files.map(f => f.path),
                files: files,
                totalTokens: files.reduce((sum, file) => sum + file.tokenCount, 0),
            };
        }
    } catch (e) {
        // JSON parsing failed, proceed to hybrid/XML parsing
    }

    // Stage 2: Hybrid JSON/Regex parsing for malformed JSON
    const summaryMatchHybrid = textToParse.match(HYBRID_SUMMARY_REGEX);
    const coaMatchHybrid = textToParse.match(HYBRID_COA_REGEX);
    const curatorMatchHybrid = textToParse.match(HYBRID_CURATOR_REGEX);
    const fileMatchesHybrid = [...textToParse.matchAll(HYBRID_FILE_OBJ_REGEX)];

    if (summaryMatchHybrid && fileMatchesHybrid.length > 0) {
        const files: ParsedFile[] = fileMatchesHybrid.map(match => {
            const path = unescapeJsonString(match[1] || '');
            const content = unescapeJsonString(match[2] || '');
            return {
                path: path,
                content: content,
                tokenCount: Math.ceil(content.length / 4)
            };
        });

        let courseOfAction = "Could not parse course of action.";
        if (coaMatchHybrid?.[1]) {
            try {
                const coaArray = JSON.parse(coaMatchHybrid[1]);
                courseOfAction = coaArray.map((step: any) => `* **Step ${step.step}:** ${unescapeJsonString(step.description)}`).join('\n');
            } catch { /* ignore parse error */ }
        }

        return {
            summary: unescapeJsonString(summaryMatchHybrid[1] || ''),
            courseOfAction,
            curatorActivity: unescapeJsonString(curatorMatchHybrid?.[1] || ''),
            filesUpdated: files.map(f => f.path),
            files,
            totalTokens: files.reduce((sum, file) => sum + file.tokenCount, 0),
        };
    }

    // Stage 3: Fallback to existing XML regex-based parsing
    const fileMap = new Map<string, ParsedFile>();
    let totalTokens = 0;
    let processedText = textToParse;
    const finalResponseMarker = 'assistantfinal';
    const markerIndex = processedText.indexOf(finalResponseMarker);
    if (markerIndex !== -1) {
        processedText = processedText.substring(markerIndex + finalResponseMarker.length);
        processedText = processedText.replace(/^.>/, '').trim();
    }

    const tagMatches = [...processedText.matchAll(FILE_TAG_REGEX)];
    if (tagMatches.length === 0 && (processedText.includes('<file path') || !processedText.match(SUMMARY_REGEX))) {
        const summary = `**PARSING FAILED:** Could not find a valid JSON object or XML tags. The response may be malformed or incomplete. Displaying raw response below.\n\n---\n\n${processedText}`;
        return { summary, courseOfAction: '', filesUpdated: [], files: [], totalTokens: Math.ceil(processedText.length / 4) };
    }

    for (const match of tagMatches) {
        const path = (match?.[1] ?? '').trim();
        let content = (match?.[2] ?? '');
        if (path) {
            content = content.replace(CODE_FENCE_START_REGEX, '');
            const patternsToRemove = [`</file_artifact>`, `</file_path>`, `</filepath>`, `</file>`, `</${path}>`, '```', '***'];
            let changed = true;
            while(changed) {
                const originalContent = content;
                for (const pattern of patternsToRemove) {
                    if (content.trim().endsWith(pattern)) {
                        content = content.trim().slice(0, -pattern.length);
                    }
                }
                if (content === originalContent) { changed = false; }
            }
            content = content.trim();
            const tokenCount = Math.ceil(content.length / 4);
            fileMap.set(path, { path, content, tokenCount });
        }
    }

    const finalFiles = Array.from(fileMap.values());
    totalTokens = finalFiles.reduce((sum, file) => sum + file.tokenCount, 0);
    const summaryMatch = processedText.match(SUMMARY_REGEX);
    const courseOfActionMatch = processedText.match(COURSE_OF_ACTION_REGEX);
    const curatorActivityMatch = processedText.match(CURATOR_ACTIVITY_REGEX);

    const summary = (summaryMatch?.[1] ?? 'Could not parse summary.').trim();
    const courseOfAction = (courseOfActionMatch?.[1] ?? 'Could not parse course of action.').trim();
    const curatorActivity = (curatorActivityMatch?.[1] ?? '').trim();
    
    const filesUpdatedList = finalFiles.map(f => f.path);

    if (finalFiles.length === 0 && !summaryMatch && !courseOfActionMatch && !curatorActivityMatch) {
        return { summary: processedText, courseOfAction: '', filesUpdated: [], files: [], totalTokens: Math.ceil(processedText.length / 4) };
    }

    return {
        summary,
        courseOfAction,
        curatorActivity,
        filesUpdated: [...new Set(filesUpdatedList)],
        files: finalFiles,
        totalTokens,
    };
}
</file_artifact>

<file path="src/client/views/parallel-copilot.view/components/GenerationProgressDisplay.tsx">
// src/client/views/parallel-copilot.view/components/GenerationProgressDisplay.tsx
// Updated on: C104 (Update onStop signature and add 'stopped' status)
import * as React from 'react';
import { formatLargeNumber } from '../../../../common/utils/formatting';
import { PcppResponse } from '@/common/types/pcpp.types';
import { GenerationProgress } from '@/common/ipc/channels.type';
import { VscLoading, VscCheck, VscStopCircle, VscSync, VscListOrdered, VscListUnordered, VscArrowRight, VscError } from 'react-icons/vsc';

interface ResponseTimerProps {
    startTime: number;
    isComplete: boolean;
}

const ResponseTimer: React.FC<ResponseTimerProps> = ({ startTime, isComplete }) => {
    const [elapsedTime, setElapsedTime] = React.useState('00:00.0');
    const intervalRef = React.useRef<NodeJS.Timeout | null>(null);

    React.useEffect(() => {
        if (isComplete || !startTime) {
            if (intervalRef.current) clearInterval(intervalRef.current);
            return;
        }

        intervalRef.current = setInterval(() => {
            const elapsed = (Date.now() - startTime) / 1000;
            const minutes = Math.floor(elapsed / 60);
            const seconds = (elapsed % 60).toFixed(1);
            setElapsedTime(`${minutes.toString().padStart(2, '0')}:${seconds.toString().padStart(4, '0')}`);
        }, 100);

        return () => {
            if (intervalRef.current) clearInterval(intervalRef.current);
        };
    }, [startTime, isComplete]);

    return <span className="elapsed-timer">{elapsedTime}</span>;
};

interface GenerationProgressDisplayProps {
    progressData: GenerationProgress[];
    tps: number;
    tabs: { [key: string]: PcppResponse };
    onStop: (cycleId: number, responseId: number) => void;
    onRegenerate: (responseId: number) => void;
    isGenerationComplete: boolean;
    onViewResponses: () => void;
    cycleId: number;
}

type SortMode = 'default' | 'total' | 'response';

const GenerationProgressDisplay: React.FC<GenerationProgressDisplayProps> = ({ progressData, tps, tabs, onStop, onRegenerate, isGenerationComplete, onViewResponses, cycleId }) => {
    const [sortMode, setSortMode] = React.useState<SortMode>('default');
    
    const completedCount = progressData.filter(p => p.status === 'complete').length;

    const sortedProgressData = React.useMemo(() => {
        const data = [...progressData];
        if (sortMode === 'default') {
            return data.sort((a,b) => a.responseId - b.responseId);
        }
        if (sortMode === 'total') {
            return data.sort((a, b) => (b.thinkingTokens + b.currentTokens) - (a.thinkingTokens + a.currentTokens));
        }
        if (sortMode === 'response') {
            return data.sort((a, b) => b.currentTokens - a.currentTokens);
        }
        return data;
    }, [progressData, sortMode]);

    const handleSortToggle = () => {
        setSortMode(current => {
            if (current === 'default') return 'total';
            if (current === 'total') return 'response';
            return 'default';
        });
    };

    const getSortButtonText = () => {
        if (sortMode === 'total') return 'Sort by Response Tk';
        if (sortMode === 'response') return 'Default Sort';
        return 'Sort by Total Tk';
    };

    const getStatusIndicator = (status: GenerationProgress['status']) => {
        switch (status) {
            case 'thinking':
                return <><VscLoading className="spinner" /> Thinking...</>;
            case 'generating':
                return <><VscLoading className="spinner" /> Generating...</>;
            case 'complete':
                return <><VscCheck className="complete-check" /> Complete</>;
            case 'stopped':
                return <><VscStopCircle className="stopped-icon" /> Stopped</>;
            case 'error':
                return <><VscError className="error-icon" /> Error</>;
            default:
                return <>Pending...</>;
        }
    };

    return (
        <div className="generation-progress-display">
            <div className="progress-header">
                <span className="progress-title">{isGenerationComplete ? 'Generation Complete' : 'Generating Responses...'}</span>
                <div className="header-controls">
                    <button onClick={handleSortToggle} className="sort-button" title={getSortButtonText()}>
                        <VscListOrdered/> {getSortButtonText()}
                    </button>
                    <span title="Calculated based on all incoming response chunks per second.">Tokens/sec: {tps > 0 ? tps : '--'}</span>
                </div>
            </div>
            
            {sortedProgressData.map(p => {
                const thinkingPct = (p.thinkingTokens / p.totalTokens) * 100;
                const generatedPct = (p.currentTokens / p.totalTokens) * 100;
                const remainingPct = 100 - thinkingPct - generatedPct;
                const isComplete = p.status === 'complete' || p.status === 'error' || p.status === 'stopped';
                const unusedTokens = p.totalTokens - p.thinkingTokens - p.currentTokens;
                const totalOutputTokens = p.thinkingTokens + p.currentTokens;

                return (
                    <div key={p.responseId} className="progress-item-container">
                        <div className='progress-item-header'>
                            <div className="response-title-timer">
                                <span>Resp {p.responseId}</span>
                                {p.startTime && <ResponseTimer startTime={p.startTime} isComplete={isComplete} />}
                            </div>
                            <div className="status-indicator-wrapper">
                                <span className={`status-indicator status-${p.status}`}>
                                    {getStatusIndicator(p.status)}
                                </span>
                                <button onClick={() => onStop(cycleId, p.responseId)} disabled={isComplete} title="Stop Generation" className="styled-button"><VscStopCircle /> Stop</button>
                                <button onClick={() => onRegenerate(p.responseId)} disabled={!isComplete} title="Regenerate this response" className="styled-button"><VscSync /> Re-generate</button>
                            </div>
                        </div>
                        <div className={`stacked-progress-bar ${isComplete ? 'completed' : ''}`}>
                            <div className="progress-segment thinking" style={{ width: `${thinkingPct}%` }} title={`Thinking: ${p.thinkingTokens} tk`}></div>
                            <div className="progress-segment generated" style={{ width: `${generatedPct}%` }} title={`Response: ${p.currentTokens} tk`}></div>
                            <div className="progress-segment unused" style={{ width: `${remainingPct}%` }} title="Unused"></div>
                        </div>
                        <div className="token-count-footer">
                            <span className="token-count-text">
                                (<span className="token-thinking">{formatLargeNumber(p.thinkingTokens, 0)}</span> + 
                                <span className="token-response">{formatLargeNumber(p.currentTokens, 0)}</span> = {formatLargeNumber(totalOutputTokens, 0)} / 
                                {formatLargeNumber(p.totalTokens, 0)} tk)
                            </span>
                            {isComplete && (
                                <span className="unused-tokens-display token-unused">
                                    Unused: {formatLargeNumber(unusedTokens, 0)} tk
                                </span>
                            )}
                        </div>
                        <div className="partial-text-preview">
                            <pre><code>{tabs[p.responseId.toString()]?.content || ''}</code></pre>
                        </div>
                    </div>
                );
            })}

            {isGenerationComplete && (
                <div className="progress-footer">
                    <span>{completedCount}/{progressData.length} Responses Complete</span>
                </div>
            )}
        </div>
    );
};

export default GenerationProgressDisplay;
</file_artifact>

<file path="src/Artifacts/A100. DCE - Model Card & Settings Refactor Plan.md">
# Artifact A100: DCE - Model Card & Settings Refactor Plan
# Date Created: C62
# Author: AI Model & Curator
# Updated on: C65 (Refine model card display details)

- **Key/Value for A0:**
- **Description:** A plan to implement a user-configurable "Model Card" system in the settings panel. This includes a UI for managing different LLM configurations and a feature to query a vLLM server's `/v1/models` endpoint to auto-populate model details. Also, specifies the display of a static model card for "Demo Mode".
- **Tags:** feature plan, settings, ui, ux, llm, configuration, model management

## 1. Vision & Goal

To enhance the flexibility of the DCE, users need a more sophisticated way to manage connections to different LLMs. The current mode-switching UI is a good start, but a "Model Card" system will provide a more powerful and user-friendly experience, allowing users to save, edit, and switch between multiple, named configurations for various local or remote models.

The goal is to refactor the settings panel to support a CRUD (Create, Read, Update, Delete) interface for these model cards and to add a feature that can query a vLLM endpoint to auto-populate model information, simplifying setup.

## 2. User Stories

| ID | User Story | Acceptance Criteria |
|---|---|---|
| P3-MC-01 | **Create a Model Card** | As a user, I want to create a new "model card" where I can input all the necessary information to connect to an LLM, so I can configure different models for different tasks. | - A "New Model Card" button exists in the Settings Panel. <br> - Clicking it opens a form with fields for: Display Name, API Endpoint URL, API Key (optional), Total Context Window, Max Output Tokens, and Reasoning Effort. <br> - A "Save" button persists this card. |
| P3-MC-02 | **Manage Model Cards** | As a user, I want to see a list of my saved model cards and be able to edit or delete them, so I can manage my configurations. | - The Settings Panel displays a list of all saved model cards. <br> - Each card in the list has "Edit" and "Delete" buttons. |
| P3-MC-03 | **Select Active Model** | As a user, I want to select one of my model cards as the "active" model from a dropdown list, so the extension knows which LLM to use for its API calls. | - A dropdown menu in the settings panel lists all saved model cards by their display name. <br> - The currently active model is shown in the dropdown. <br> - Selecting a new model from the dropdown sets it as the active configuration. |
| P3-MC-04 | **Auto-Populate vLLM Info** | As a user configuring a vLLM endpoint, I want a button to automatically fetch the model's details (like its name and context window), so I don't have to look them up manually. | - In the model card creation form, next to the API Endpoint URL field, there is a "Query" or "Fetch Info" button. <br> - Clicking it sends a request to the `/v1/models` endpoint of the provided URL. <br> - If successful, the model name and max context length are parsed from the response and used to populate the form fields. |
| P3-MC-05 | **Display Static Demo Model Card** | As a user in "Demo Mode," I want to see a pre-configured, read-only model card in the settings panel that provides information about the demo LLM, so I understand its capabilities. | - When "Demo Mode" is selected, a static, non-editable section appears. <br> - It displays "Model: unsloth/gpt-oss-20b", "Total Context Window", "Max Output Tokens", "Reasoning Effort", and "GPU". |

## 3. Technical Implementation Plan

1.  **Data Storage (`settings.service.ts`):**
    *   The settings service will be updated to manage a list of `ModelCard` objects and the ID of the `activeModelCard`.
    *   API keys will continue to be stored securely in `SecretStorage`, associated with a unique ID for each model card.

2.  **Backend (`llm.service.ts`):**
    *   A new method, `getModelInfo(endpointUrl: string)`, will be created. It will make a `GET` request to the `${endpointUrl}/models` endpoint.
    *   It will parse the JSON response to extract the model ID and maximum context length (`max_model_len`).
    *   This will be exposed via a new `RequestModelInfo` IPC channel.

3.  **Settings Panel UI Refactor (`settings.view.tsx`):**
    *   The current radio-button UI will be replaced with the new Model Card management UI.
    *   A dropdown will display all saved `ModelCard` names and manage the `activeModelCard` state.
    *   A list view will display the cards with "Edit" and "Delete" buttons.
    *   A modal or separate view will be used for the "Create/Edit Model Card" form.
    *   The form will include the new "Query" button, which will trigger the `RequestModelInfo` IPC message and update the form's state with the response.
    *   A new conditional rendering block will display the static demo model card when `connectionMode` is `'demo'`.

4.  **Integration (`llm.service.ts`):**
    *   The main `generateBatch` and `generateSingle` methods will be updated. Instead of a `switch` on the `connectionMode`, they will now fetch the `activeModelCard` from the `SettingsService` and use its properties (URL, key, reasoning level) to construct the API request.
</file_artifact>

<file path="src/Artifacts/A11. DCE - Regression Case Studies.md">
# Artifact A11: DCE - Regression Case Studies
# Date Created: C16
# Author: AI Model & Curator
# Updated on: C124 (Consolidate native module build issues)

## 1. Purpose

This document serves as a living record of persistent or complex bugs. By documenting the root cause analysis (RCA) and the confirmed solution for each issue, we create a "source of truth" to prevent the same mistakes from being reintroduced into the codebase.

## 2. Case Studies

---

### Case Study 023: Native Module Build & ABI Mismatch (Consolidated)

-   **Artifacts Affected:** `node_modules`, `package.json`, `webpack.config.js`
-   **Cycles Observed:** C119-C123
-   **Symptom:** The extension fails to activate, hangs on build, or throws errors like `NODE_MODULE_VERSION 130. This version of Node.js requires NODE_MODULE_VERSION 136` when using native modules like `better-sqlite3`.
-   **Root Cause Analysis (RCA):**
    1.  **Webpack Bundling:** Webpack cannot bundle binary files (`.node`). They must be treated as external dependencies.
    2.  **ABI Mismatch:** VS Code runs on a specific version of Electron, which uses a specific Node.js ABI (e.g., 136). Standard `npm install` compiles for the system's Node.js version (e.g., 127), causing a mismatch.
    3.  **Electron Version Detection:** `electron-rebuild` sometimes fails to detect the correct target version if `electron` is not explicitly listed in `devDependencies`.
    4.  **Compiler Standards:** Newer Electron versions (v33+) require C++20, which older native modules may not support.
-   **Codified Solution & Best Practice:**
    1.  **Webpack:** Add native modules to the `externals` section in `webpack.config.js` (e.g., `'better-sqlite3': 'commonjs better-sqlite3'`).
    2.  **Dependencies:** Ensure `electron` (matching the target VS Code version) and `@electron/rebuild` are in `devDependencies`.
    3.  **Rebuild Script:** Use a robust rebuild command: `electron-rebuild -f -w better-sqlite3`.
    4.  **Force Version:** If mismatches persist (especially with custom VS Code builds), identify the runtime Electron version from logs and force the rebuild target: `npm run rebuild -- -v <VERSION> -f`.

---

### Case Study 022: Parallel Requests Fail with ETIMEDOUT (Regression)

-   **Artifacts Affected:** `src/backend/services/llm.service.ts`
-   **Cycles Observed:** C113, C115, C116
-   **Symptom:** When the backend attempts to make multiple parallel `fetch` requests to the same host (e.g., generating 4 responses simultaneously), some of the requests fail with a `connect ETIMEDOUT` error. This results in only one or two responses being generated successfully.
-   **Root Cause Analysis (RCA):** The default Node.js `http.Agent` (used by `node-fetch`) has a limited pool of sockets for concurrent connections to a single origin. When the application tries to open several long-lived streaming connections at once, the later requests can time out while waiting for a socket to become available. This is a recurring issue, indicating that previous fixes were not consistently applied.
-   **Codified Solution & Best Practice:**
    1.  When an application needs to make a high number of concurrent, long-lived HTTP/HTTPS requests to a single host from a Node.js backend, do not rely on the default agent.
    2.  Use a dedicated agent library like `agentkeepalive` to create a single, shared `HttpsAgent` instance at the module level.
    3.  Configure this agent with a high `maxSockets` value (e.g., 100) to ensure a large enough connection pool is available.
    4.  **Crucially, ensure this custom agent is passed to *all* relevant `fetch` calls within the service to guarantee it is used for every request.**

---

### Case Study 021: Incorrect Un-escaping of Double-Escaped JSON String Content

-   **Artifacts Affected:** `src/client/utils/response-parser.ts`
-   **Cycles Observed:** C115
-   **Symptom:** When parsing a JSON response from the vLLM, the final content in the UI is corrupted with extra backslashes. For example, newlines appear as `\` instead of being processed, and quotes appear as `\"` or `\\"`.
-   **Root Cause Analysis (RCA):** The LLM, when generating a JSON object as a string, sometimes "double-escapes" characters within its string values to ensure they are valid. For example, a newline becomes `\\n` and a quote becomes `\\\"`. The parser's logic for handling this was flawed. `JSON.parse` correctly handles the first level of escaping, but the subsequent manual `.replace()` calls in the hybrid parser were too simplistic and did not correctly handle the remaining escape sequences, leading to the visual artifacts.
-   **Codified Solution & Best Practice:**
    1.  When processing string values from an LLM-generated JSON, assume they may be double-escaped.
    2.  Implement a robust, multi-step un-escaping sequence. The correct order is to first replace `\\\\` with `\\` (to handle literal backslashes), then replace `\\n` with a newline, `\\t` with a tab, and finally `\\"` with `"`.
    3.  This sequence, applied after the main JSON structure is parsed, correctly reduces the escape levels and produces a clean, readable string for the UI.

---

### Case Study 020: Parallel Onboarding Requests Fail with ETIMEDOUT

-   **Artifacts Affected:** `llm.service.ts`, `OnboardingView.tsx`, `useGeneration.ts`, `view.tsx`
-   **Cycles Observed:** C113, C115 (Regression)
-   **Symptom:** When clicking "Generate Initial Responses" from the onboarding view with the number of responses set to > 1, only one response is successfully generated. The other requests fail with `connect ETIMEDOUT` errors in the logs.
-   **Root Cause Analysis (RCA):** This is a complex issue with two contributing factors.
    1.  **State Mismatch:** The `OnboardingView.tsx` component managed its own local state for the `responseCount`. This was separate from the `tabCount` state managed by the main PCPP view. While the value was correctly passed to the backend, this state divergence made the system harder to debug and reason about.
    2.  **Connection Pooling:** The underlying issue is the `ETIMEDOUT` error, which indicates a client-side bottleneck in establishing concurrent connections to the proxy server, despite a previous fix (`agentkeepalive`) intended to solve this. Unifying the state is a prerequisite to ensure the correct parameters are being sent before further debugging of the connection pooling issue can be effective.
-   **Codified Solution & Best Practice:**
    1.  Avoid state divergence for critical parameters. The number of responses should be a single piece of state managed by a higher-order component or hook (`view.tsx` or `useGeneration.ts`). This state should be passed down as props to any child component that needs to read or modify it, ensuring a single source of truth.
    2.  The `ETIMEDOUT` error points to a persistent issue with Node.js connection pooling in the extension host environment. The `agentkeepalive` solution needs to be re-verified or a different strategy for managing parallel long-lived connections may be required.

---

### Case Study 019: Backend SSE Parser Fails on Fragmented Data Chunks

-   **Artifacts Affected:** `src/backend/services/llm.service.ts`
-   **Cycles Observed:** C108, C109, C110, C114
-   **Symptom:** The DCE output log is flooded with `Could not parse JSON object from stream` warnings during response generation. The final response content is often corrupted or incomplete.
-   **Root Cause Analysis (RCA):** The stream consumer in `llm.service.ts` was not correctly buffering incoming data from the vLLM server. It processed each `data` event from the stream as if it contained one or more complete, newline-terminated messages. However, a single logical SSE message from the server can be fragmented and sent across multiple TCP packets, resulting in the `data` event firing with an incomplete piece of a message. The parser would then attempt to parse this incomplete fragment, which is invalid JSON, leading to the error.
-   **Codified Solution & Best Practice:**
    1.  Stream consumers for protocols like SSE must be designed to handle fragmented messages. They cannot assume that each `data` event contains a complete message.
    2.  The correct implementation is to maintain a persistent buffer outside the `stream.on('data')` handler.
    3.  Each incoming chunk should be appended to this buffer.
    4.  The buffer should then be processed in a loop, searching for the standard SSE message terminator (`\n\n`).
    5.  Only the complete messages found before the terminator should be extracted and parsed. Any remaining text after the last terminator is an incomplete message and must be kept in the buffer to be prepended to the next incoming chunk.

---

### Case Study 018: Parallel Fetch Requests Fail with ETIMEDOUT

-   **Artifacts Affected:** `src/backend/services/llm.service.ts`
-   **Cycles Observed:** C113
-   **Symptom:** When the backend attempts to make multiple parallel `fetch` requests to the same host (e.g., generating 4 responses simultaneously), some of the requests fail with a `connect ETIMEDOUT` error. This results in only one or two responses being generated successfully.
-   **Root Cause Analysis (RCA):** The default Node.js `http.Agent` (used by `node-fetch`) has a pool of sockets for connections. While the default `maxSockets` is technically `Infinity`, in practice, factors within the execution environment (like VS Code's extension host) can lead to exhaustion or delays in acquiring new sockets for concurrent requests to the same origin. When the application tries to open several connections at once, the later requests can time out while waiting for a socket to become available.
-   **Codified Solution & Best Practice:**
    1.  When an application needs to make a high number of concurrent, long-lived HTTP/HTTPS requests to a single host from a Node.js backend, do not rely on the default `http.Agent`.
    2.  Use a dedicated agent library like `agentkeepalive` to create a custom `HttpsAgent` instance.
    3.  Configure this agent with a high `maxSockets` value (e.g., 100) to ensure a large enough connection pool is available.
    4.  Pass this custom agent to all relevant `fetch` calls. This provides robust and performant connection pooling, preventing timeout errors caused by socket exhaustion.
</file_artifact>

<file path="src/Artifacts/A101. DCE - Asynchronous Generation and State Persistence Plan.md">
# Artifact A101: DCE - Asynchronous Generation and State Persistence Plan
# Date Created: C67
# Author: AI Model & Curator
# Updated on: C78 (Add per-response status field)

- **Key/Value for A0:**
- **Description:** Documents the new, more robust workflow for generating responses. This involves creating a new cycle with a "generating" status first, which provides a persistent state container for the asynchronous LLM call, making the UI state recoverable on reload.
- **Tags:** plan, architecture, workflow, persistence, asynchronous, state management

## 1. Problem Statement

The "Generate responses" feature currently suffers from two critical flaws:
1.  **Stale Prompts:** The backend sometimes generates the `prompt.md` using a stale version of the cycle data from the `dce_history.json` file, ignoring the user's most recent (unsaved) changes in the UI.
2.  **Lack of UI Persistence:** If the user switches away from the PCPP tab while responses are streaming in, the response generation UI disappears. When they return, the UI does not reappear, even though the generation process continues in the background. This is because the webview is re-initialized and loses its transient `isGenerating` state.

## 2. The New Workflow: Create-Then-Generate

To solve both issues, the workflow will be re-architected to be stateful and persistent.

1.  **Initiate:** The user, on Cycle `N`, clicks "Generate responses".
2.  **Create Placeholder:** The frontend sends a `RequestNewCycleAndGenerate` message to the backend. The backend's first action is to immediately create and save a new **Cycle `N+1`** in `dce_history.json`. This new cycle has a special status, e.g., `status: 'generating'`, and each of its `PcppResponse` objects also has its status set to `'generating'`.
3.  **Start UI:** The backend immediately responds to the frontend with a `StartGenerationUI` message, containing the ID of the new cycle (`N+1`).
4.  **Navigate & Display:** The frontend navigates to Cycle `N+1` and, seeing the `generating` status, displays the `GenerationProgressDisplay` component.
5.  **Asynchronous Generation:** *In parallel*, the backend uses the data from the original Cycle `N` (which was sent with the initial request) to generate the prompt and start the LLM call.
6.  **Save Progress:** As response chunks stream in, the backend saves them directly into the placeholder Cycle `N+1` in `dce_history.json`.
7.  **Completion:** When generation is complete, the backend updates the status of Cycle `N+1` from `generating` to `complete`, and also updates the status of each individual response.

## 3. Benefits of this Architecture

-   **Fixes Stale Prompts:** The prompt for Cycle `N+1` is generated using the fresh, in-memory data from Cycle `N` that was sent directly from the client, guaranteeing it's up-to-date.
-   **Fixes UI Persistence:** The `isGenerating` state is no longer a transient boolean in the UI. It's now a persistent `status` field in the cycle data itself. If the user navigates away and back, the extension will load the latest cycle (N+1), see its status is `generating`, and automatically re-display the progress UI, which will be populated with the latest progress saved in the history file.
-   **Enables Granular Control:** Storing the status on each individual response allows for single-tab regeneration without disrupting the state of other tabs.

## 4. Technical Implementation Plan

1.  **Data Model (`pcpp.types.ts`):**
    *   Add a `status?: 'complete' | 'generating'` property to the `PcppCycle` interface.
    *   Add a `status?: 'pending' | 'generating' | 'complete' | 'error'` property to the `PcppResponse` interface.
2.  **IPC Channels:** Add `RequestNewCycleAndGenerate` and `StartGenerationUI`.
3.  **Backend (`history.service.ts`):** Create a `createNewCyclePlaceholder` method to create the new cycle with `status: 'generating'`. Update `saveCycleData` to handle partial progress updates for a generating cycle.
4.  **Backend (`on-message.ts`):** Implement the new handler for `RequestNewCycleAndGenerate` to orchestrate this workflow.
5.  **Frontend (`view.tsx`):**
    *   Update the "Generate responses" button to use the new IPC channel.
    *   Add a handler for `StartGenerationUI`.
    *   Update the main rendering logic: if the currently loaded cycle has `status === 'generating'`, render the `GenerationProgressDisplay` component. The logic will be further refined to check the status of the *active tab* for single-response regeneration.
</file_artifact>

<file path="src/Artifacts/A103. DCE - Consolidated Response UI Plan.md">
# Artifact A103: DCE - Consolidated Response UI Plan
# Date Created: C73
# Author: AI Model & Curator
# Updated on: C76 (Refine UI to allow viewing completed responses during generation)

- **Key/Value for A0:**
- **Description:** Details the plan to consolidate the response generation UI into the main PCPP view. This involves showing the progress display in the main content area when the current cycle is in a "generating" state, while keeping the response tabs visible and allowing completed responses to be viewed.
- **Tags:** feature plan, ui, ux, workflow, refactor, state management

## 1. Vision & Goal

The current workflow for generating responses involves a jarring context switch. The user clicks "Generate responses," and the entire UI is replaced by a separate "Generation Progress" view. To return to the main panel, the user must wait for completion or navigate away and lose the progress view.

The goal of this refactor is to create a more seamless, integrated experience. The response generation UI will now be displayed *within* the main Parallel Co-Pilot Panel (PCPP) view itself. This is achieved by making the UI state-driven: if the currently selected cycle is in a "generating" state, the progress display is shown; otherwise, the standard response tabs are shown.

## 2. User Flow (C76 Refinement)

1.  **User Action:** The user is on Cycle `N` and clicks `Generate responses`.
2.  **Backend Action:** The backend creates a new placeholder Cycle `N+1` with `status: 'generating'` and notifies the frontend.
3.  **UI Navigation:** The frontend automatically navigates to the new Cycle `N+1`.
4.  **Conditional Rendering:** The main PCPP view component loads the data for Cycle `N+1`. It sees that `status` is `'generating'`.
5.  **New UI State:**
    *   The `ResponseTabs` component **remains visible**. The tabs for the generating responses will show a loading indicator.
    *   The main content area *below* the tabs, which would normally show the `ResponsePane`, now renders the `GenerationProgressDisplay`. The user sees the progress bars for the new cycle they are on.
    *   **Viewing Completed Responses:** As individual responses complete, their loading indicators on the tabs disappear. The user can now click on a completed response's tab. The UI will switch from showing the overall `GenerationProgressDisplay` to showing the `ResponsePane` for that specific completed response, allowing them to review it while others are still generating. Clicking on a tab that is still generating will continue to show the `GenerationProgressDisplay`.
6.  **Completion:** When all LLM responses are complete, the backend updates the status of Cycle `N+1` to `'complete'`. The frontend receives this update, and the default view for all tabs becomes the `ResponsePane`.

## 3. Additional UI Refinements

-   **Collapsible Ephemeral Context:** To de-clutter the UI, the "Ephemeral Context" text area, which is used less frequently, will now be in a collapsible section. It will be collapsed by default for new cycles. This state will be persisted per-cycle.

## 4. Technical Implementation Plan

1.  **Remove `activeView` State:**
    *   **`view.tsx`:** The `const [activeView, setActiveView] = useState<'main' | 'progress'>('main');` state and all associated logic will be removed.
    *   **`vscode-webview.d.ts`:** The `pcppActiveView` property will be removed from the `ViewState` interface.

2.  **Implement Conditional Rendering (`view.tsx`):**
    *   The main render logic will be updated:
        ```jsx
        // Inside the App component's return statement
        const activeTabIsComplete = tabs[activeTab.toString()]?.parsedContent !== null; // Or a better check
        const showProgress = currentCycle?.status === 'generating' && !activeTabIsComplete;

        <ResponseTabs {...props} />
        {showProgress ? (
            <GenerationProgressDisplay {...props} />
        ) : (
            <>
                <WorkflowToolbar {...props} />
                <div className="tab-content">
                    <ResponsePane {...props} />
                </div>
            </>
        )}
        ```

3.  **Make Ephemeral Context Collapsible:**
    *   **`pcpp.types.ts`:** Add `isEphemeralContextCollapsed?: boolean;` to the `PcppCycle` interface.
    *   **`history.service.ts`:** In the default cycle object, set `isEphemeralContextCollapsed: true`.
    *   **`ContextInputs.tsx`:**
        *   Add a new state for the collapsed state, initialized from props.
        *   Wrap the Ephemeral Context `textarea` and its label in a `CollapsibleSection` component.
    *   **`view.tsx`:** Manage the collapsed state and pass it down to `ContextInputs`, ensuring it's included in the `saveCurrentCycleState` payload.
    *   **`view.scss`:** Add styling for the new collapsible section within the `context-inputs` container.
</file_artifact>

<file path="src/Artifacts/A105. DCE - vLLM Performance and Quantization Guide.md">
# Artifact A105: DCE - vLLM Performance and Quantization Guide
# Date Created: C76
# Author: AI Model & Curator

- **Key/Value for A0:**
- **Description:** Explains vLLM quantization, interprets performance warnings from the logs, and provides guidance on how to optimize the local LLM setup.
- **Tags:** guide, vllm, performance, quantization, optimization, gpu

## 1. Overview

This guide provides answers to questions regarding the vLLM server logs from Cycle 76. It explains the type of quantization being used, what the performance warnings mean, and offers concrete steps you can take to potentially improve the performance of your local LLM server.

## 2. Understanding Your Current Setup (Based on Logs)

The vLLM server logs provide several key pieces of information about your current configuration:

-   **Model:** `unsloth/gpt-oss-20b`
-   **Quantization Method:** `mxfp4`
-   **Data Type (dtype):** `torch.bfloat16`

### What is `mxfp4` Quantization?

The list of quantization types you provided (e.g., `Q4_K_M`, `Q8_0`) are specific to the **GGUF** format, which is commonly used by frameworks like `llama.cpp`. However, you are running the full, un-quantized Hugging Face model (`unsloth/gpt-oss-20b`).

vLLM has its own set of quantization methods that it can apply on-the-fly. The log line `(APIServer pid=731) WARNING 09-27 06:30:31 [__init__.py:1217] mxfp4 quantization is not fully optimized yet` indicates that vLLM is using its **MXFP4** quantization scheme. This is a very new and experimental 4-bit floating-point format designed for high performance on modern GPUs.

**In summary:** You are not using a pre-quantized GGUF model. You are loading the full model, and vLLM is applying its own experimental 4-bit quantization (`mxfp4`) at runtime.

## 3. Interpreting the Performance Warnings

Your logs contain two important warnings that suggest you can get better performance:

1.  **`Your GPU does not have native support for FP4 computation...`**
    *   **What it means:** Your GPU (an RTX 3090, which is an Ampere architecture card) does not have the specialized hardware to perform calculations directly in the 4-bit FP4 format. vLLM is using a fallback method called "Weight-only FP4 compression" with the Marlin kernel. This means the model's weights are stored in 4-bit format in VRAM (saving space), but they must be "de-quantized" to a higher precision format (like 16-bit) right before computations are performed. This conversion adds a small amount of overhead.

2.  **`You are running Marlin kernel with bf16 on GPUs before SM90. You can consider change to fp16 to achieve better performance if possible.`**
    *   **What it means:** This is the most actionable warning. Your GPU is based on the Ampere architecture (SM86). True `bfloat16` (bf16) performance is best on Hopper architecture GPUs (SM90) and newer. For Ampere cards like the RTX 3090, standard `float16` (fp16) is often faster and more mature. vLLM is telling you that you might get a speed boost by switching the data type from `bfloat16` to `float16`.

## 4. How to Improve Performance

Based on the logs, here is a concrete step you can take to potentially increase your tokens/second:

### Change the Data Type to `fp16`

You can instruct vLLM to use `float16` instead of the default `bfloat16` by adding the `--dtype float16` flag to your server launch command.

**New Recommended Command:**

```bash
python -m vllm.entrypoints.openai.api_server --model "unsloth/gpt-oss-20b" --dtype float16
```

**Why this should help:** This aligns the computation type with the optimal format for your RTX 3090's architecture, as recommended by the warning message. This is the single most likely change to yield a performance improvement.

### Experimenting with Other Quantizations

If you want to experiment further, you could try one of vLLM's other supported quantization methods, like AWQ. However, this often requires using a model that has been specifically pre-quantized for that method. For now, simply changing the `dtype` is the easiest and most direct optimization to try.
</file_artifact>

<file path="src/Artifacts/A105. DCE - PCPP View Refactoring Plan for Cycle 76.md">
# Artifact A105: DCE - PCPP View Refactoring Plan for Cycle 76
# Date Created: C76
# Author: AI Model & Curator
# Updated on: C86 (Complete rewrite of refactoring strategy)

## 1. Problem Statement & Acknowledgment of Prior Failures

The `parallel-copilot.view/view.tsx` component has grown to over 10,000 tokens, making it a "god component." It manages state and renders logic for numerous distinct features, making it difficult to maintain, prone to bugs, and inefficient to include in AI prompts.

Previous refactoring attempts in Cycles 82-85 were ineffective. They failed to significantly reduce the component's size because they only shuffled logic between `view.tsx` and other *existing* presentational components. They did not address the core problem: the monolithic concentration of business logic and state management within the `view.tsx` file itself.

This document presents a new, fundamentally different refactoring strategy that will resolve this issue by extracting logic into **new files** as custom React hooks.

## 2. The New Refactoring Strategy: Container/Hooks/Presentational

The new plan is to refactor `view.tsx` using a standard, robust React pattern for managing complexity: **Container/Hooks/Presentational**.

1.  **Container (`view.tsx`):** The `view.tsx` file will become a lean "container" component. Its sole responsibility will be to orchestrate the application. It will call the various custom hooks to get the state and logic handlers it needs, and then pass that data down as props to the presentational components.
2.  **Hooks (`/hooks/*.ts`):** All complex business logic, state management (`useState`, `useMemo`, `useEffect`), and IPC handling will be extracted from `view.tsx` and moved into a series of new, single-responsibility custom hooks. These are new files that will live in a new `src/client/views/parallel-copilot.view/hooks/` directory.
3.  **Presentational (`/components/*.tsx`):** The existing components (`CycleNavigator`, `ResponseTabs`, `ParsedView`, etc.) will remain as "dumb" presentational components. They will receive all the data they need to render and all the functions they need to call via props.

## 3. Proposed New Files: Custom Hooks

A new directory will be created: `src/client/views/parallel-copilot.view/hooks/`. The following new files will be created within it, each containing a custom hook to manage a specific domain of logic.

| New File | Hook Name | Responsibility | Estimated Tokens |
| :--- | :--- | :--- | :--- |
| `usePcppIpc.ts` | `usePcppIpc` | Encapsulates the massive `useEffect` that registers all `clientIpc.onServerMessage` listeners. It will take state-setter functions as arguments and call them when messages are received. | ~2,000 |
| `useCycleManagement.ts` | `useCycleManagement` | Manages `currentCycle`, `maxCycle`, `cycleTitle`, `cycleContext`, `ephemeralContext`, `saveStatus`. Exposes handlers like `handleCycleChange`, `handleNewCycle`, `saveCurrentCycleState`. | ~1,500 |
| `useTabManagement.ts` | `useTabManagement` | Manages `tabs`, `activeTab`, `tabCount`, `isParsedMode`, `isSortedByTokens`. Exposes handlers like `handleTabSelect`, `handleRawContentChange`, `parseAllTabs`, `handleSortToggle`. | ~1,800 |
| `useFileManagement.ts` | `useFileManagement` | Manages `selectedFilePath`, `selectedFilesForReplacement`, `fileExistenceMap`, `pathOverrides`, `comparisonMetrics`. Exposes handlers like `handleSelectForViewing`, `handleAcceptSelectedFiles`, `handleLinkFile`. | ~2,000 |
| `useWorkflow.ts` | `useWorkflow` | Manages the `workflowStep` state and contains the complex `useEffect` logic that determines the next step in the guided workflow. | ~1,200 |
| `useGeneration.ts` | `useGeneration` | Manages `generationProgress`, `tps`, `isGenerationComplete`, `connectionMode`. Exposes handlers like `handleGenerateResponses`, `handleStartGeneration`, `handleRegenerateTab`. | ~1,000 |

### 3.1. Revised Token Distribution Estimate

| Component | Responsibility | New Estimated Tokens |
| :--- | :--- | :--- |
| **`view.tsx` (Container)** | - Call all custom hooks. <br> - Render top-level conditional UI (`Onboarding`, `Progress`, `Main`). <br> - Pass props to presentational components. | **~1,500** |
| **New Hooks Total** | - All business logic and state management. | **~9,500** |
| **Existing Components** | - UI Rendering. | (Unchanged) |

This architecture will reduce `view.tsx` from **~10,300 tokens** to a much more manageable **~1,500 tokens**.

## 4. Implementation Steps (For Next Cycle)

1.  **Create `hooks` directory and files:** Create the new directory and the empty hook files listed above.
2.  **Migrate Logic to Hooks:** Systematically move related `useState`, `useCallback`, `useMemo`, and `useEffect` blocks from `view.tsx` into the appropriate new custom hook file. Each hook will return an object containing the state values and handler functions it manages.
3.  **Refactor `view.tsx`:**
    *   Remove all the logic that was moved to the hooks.
    *   Call each new custom hook at the top of the `App` component.
    *   Update the props being passed to the child presentational components (`CycleNavigator`, `ContextInputs`, etc.) to use the state and handlers returned from the hooks.
4.  **Verification:** Test the UI thoroughly to ensure that all functionality remains intact after the refactor.

---
</file_artifact>

<file path="src/Artifacts/A106. DCE - vLLM Performance and Quantization Guide.md">
# Artifact A106: DCE - vLLM Performance and Quantization Guide
# Date Created: C76
# Author: AI Model & Curator

- **Key/Value for A0:**
- **Description:** A guide explaining the performance warnings from the vLLM logs and detailing the various model quantization options available.
- **Tags:** guide, vllm, performance, quantization, llm

## 1. Overview & Goal

This document addresses your questions from Cycle 76 regarding the vLLM startup logs and the different model versions available. The goal is to clarify what the performance warnings mean and to explain the concept of model quantization, which is what the different file versions (Q2_K, Q4_K_M, etc.) represent.

## 2. Understanding the vLLM Startup Logs

The logs you provided contain several warnings and informational messages that are useful for performance tuning. Here's a breakdown:

-   **`Your GPU does not have native support for FP4 computation... Weight-only FP4 compression will be used leveraging the Marlin kernel.`**
    *   **Explanation:** Your NVIDIA RTX 3090 GPU (Ampere architecture, SM86) does not have specialized hardware (Tensor Cores) for 4-bit floating-point (FP4) math. Newer GPUs (Hopper architecture, SM90+) do. To compensate, vLLM is using a highly optimized software routine called the "Marlin kernel" to perform the 4-bit operations.
    *   **Impact:** You can still run 4-bit models, but it might not be as fast as on the latest hardware.

-   **`You are running Marlin kernel with bf16 on GPUs before SM90. You can consider change to fp16 to achieve better performance if possible.`**
    *   **Explanation:** This is a direct performance suggestion. Your GPU is using `bfloat16` (a data type good for training) for its computations. The Marlin kernel maintainers suggest that `float16` (`fp16`) is often faster for inference on your specific GPU architecture.
    *   **Action:** You could potentially get a performance boost by starting the server with an additional flag: `--dtype float16`.

-   **`mxfp4 quantization is not fully optimized yet.`**
    *   **Explanation:** The specific 4-bit format vLLM is using (`mxfp4`) is still considered experimental and may not be as fast as other, more mature quantization methods.

## 3. Model Quantization Explained

The list of model versions you provided (`Q3_K_S`, `Q4_0`, `Q8_0`, `F16`, etc.) refers to different **quantization levels**.

**Quantization** is the process of reducing the precision of the numbers (weights) used in a neural network. This makes the model file smaller and can make inference faster, but it comes at the cost of a small reduction in accuracy or "intelligence."

-   **`F16` (Float 16):** This is the unquantized, full-precision version. It offers the highest quality but has the largest file size and VRAM requirement.
-   **`Q8_0` (8-bit Quantized):** Each weight is stored as an 8-bit integer. This is roughly half the size of the F16 version with very little quality loss. A great balance for performance and quality.
-   **`Q4_K_M` (4-bit K-Quant Medium):** This is a very popular 4-bit quantization. It significantly reduces the model size, allowing very large models to run on consumer hardware. The quality is generally excellent for the size. The `_K` refers to the "K-quants" method, which is an improved quantization strategy. `_M` means "Medium."
-   **`Q2_K` (2-bit K-Quant):** An extreme level of quantization. The model is very small but the quality loss is significant. Often used for research or on very constrained devices.

### Which Version Did You Load?

The command you ran (`python -m vllm.entrypoints.openai.api_server --model "unsloth/gpt-oss-20b"`) loads the **default, unquantized `bfloat16` version** of the model from Hugging Face. vLLM then applies its own `mxfp4` quantization on-the-fly.

The list of `Q` files you found are typically associated with the **GGUF format**, which is used by other inference engines like `llama.cpp`. vLLM does not load GGUF files directly. It has its own supported quantization methods (like AWQ, GPTQ, and the experimental `mxfp4`) that it applies to the base model.

**In summary:** You are not using one of the GGUF files from your list. You are using the base model, and vLLM is applying its own 4-bit quantization to it. The warnings are helpful tips for potentially improving performance on your specific hardware.
</file_artifact>

<file path="src/Artifacts/A66. DCE - Cycle 1 - Task Tracker.md">
# Artifact A66: DCE - Cycle 1 - Task Tracker
# Date Created: C167
# Author: AI Model & Curator

- **Key/Value for A0:**
- **Description:** A tracking document for the feedback items and tasks from the first cycle of using the DCE to build itself.
- **Tags:** bugs, tracking, issues, backlog, cycle 1

## 1. Overview

This document lists the feedback and tasks from the first official development cycle using the DCE tool. It serves as a checklist to ensure all initial bugs and feature requests are addressed.

## 2. Task List

| ID | Task | Status (C167) | Notes |
|---|---|---|---|
| 1 | Fix FTV flashing on save/auto-save. | **In Progress** | Annoying UX issue. Investigate file watcher and refresh logic. |
| 2 | Rework line numbers in context panes for word wrap and scrolling. | **In Progress** | Critical usability bug. Requires rework of `NumberedTextarea.tsx`. |
| 3 | Fix cursor and selection highlighting in context panes. | **In Progress** | Critical usability bug. Likely related to the line number issue. |
| 4 | Implement animated UI workflow guide. | **In Progress** | Major new feature. Requires state management and CSS animations. |
| 5 | Document the new animated workflow in an artifact. | **Complete** | `A69. DCE - Animated UI Workflow Guide.md` created. |
| 6 | Fix `</prompt.md>` tag appearing at the top of generated prompts. | **In Progress** | Critical bug in `prompt.service.ts`. |
| 7 | Plan for UX improvements to context panes (token count, line numbers). | **Complete** | New artifact `A68` created to plan this feature. |
| 8 | Plan for refactoring the large `parallel-copilot.view.tsx`. | **Complete** | New artifact `A67` created to plan this refactor. |
| 9 | Plan for Git-integrated testing workflow. | **Complete** | New artifact `A70` created to plan this feature. |
</file_artifact>

<file path="src/client/views/parallel-copilot.view/hooks/useCycleManagement.ts">
// src/client/views/parallel-copilot.view/hooks/useCycleManagement.ts
// Updated on: C126 (Add isCycleCollapsed)
import * as React from 'react';
import { PcppCycle } from '@/common/types/pcpp.types';
import { ClientPostMessageManager } from '@/common/ipc/client-ipc';
import { ClientToServerChannel } from '@/common/ipc/channels.enum';

export const useCycleManagement = (
    initialCycle: PcppCycle | null,
    initialProjectScope: string | undefined,
    initialMaxCycle: number
) => {
    const [currentCycle, setCurrentCycle] = React.useState<PcppCycle | null>(initialCycle);
    const [projectScope, setProjectScope] = React.useState<string | undefined>(initialProjectScope);
    const [maxCycle, setMaxCycle] = React.useState(initialMaxCycle);
    const [cycleTitle, setCycleTitle] = React.useState(initialCycle?.title || '');
    const [cycleContext, setCycleContext] = React.useState(initialCycle?.cycleContext || '');
    const [ephemeralContext, setEphemeralContext] = React.useState(initialCycle?.ephemeralContext || '');
    const [isCycleCollapsed, setIsCycleCollapsed] = React.useState(initialCycle?.isCycleCollapsed || false);
    const [isEphemeralContextCollapsed, setIsEphemeralContextCollapsed] = React.useState(initialCycle?.isEphemeralContextCollapsed ?? true);
    const [saveStatus, setSaveStatus] = React.useState<'saved' | 'saving' | 'unsaved'>('saved');
    const [selectedResponseId, setSelectedResponseId] = React.useState<string | null>(initialCycle?.selectedResponseId || null);

    const clientIpc = ClientPostMessageManager.getInstance();

    const loadCycleData = React.useCallback((cycleData: PcppCycle, scope?: string) => {
        setCurrentCycle(cycleData);
        setProjectScope(scope);
        setCycleTitle(cycleData.title);
        setCycleContext(cycleData.cycleId === 0 ? (scope || '') : cycleData.cycleContext);
        setEphemeralContext(cycleData.ephemeralContext);
        setIsEphemeralContextCollapsed(cycleData.isEphemeralContextCollapsed ?? true);
        setIsCycleCollapsed(cycleData.isCycleCollapsed || false);
        setSelectedResponseId(cycleData.selectedResponseId || null);
        setSaveStatus('saved');
    }, []);

    const handleCycleChange = React.useCallback((e: React.MouseEvent | null, newCycleId: number) => {
        e?.stopPropagation();
        if (saveStatus !== 'saved' && currentCycle?.cycleId !== newCycleId) return;
        if (newCycleId >= 0 && newCycleId <= maxCycle) {
            clientIpc.sendToServer(ClientToServerChannel.RequestCycleData, { cycleId: newCycleId });
            clientIpc.sendToServer(ClientToServerChannel.SaveLastViewedCycle, { cycleId: newCycleId });
        }
    }, [saveStatus, currentCycle, maxCycle, clientIpc]);

    const handleNewCycle = React.useCallback((e: React.MouseEvent) => {
        e.stopPropagation();
        if (saveStatus !== 'saved') return;
        const newCycleId = maxCycle + 1;
        setMaxCycle(newCycleId);
        const newCycle: PcppCycle = {
            cycleId: newCycleId,
            title: 'New Cycle',
            cycleContext: '',
            ephemeralContext: '',
            responses: {},
            tabCount: currentCycle?.tabCount || 4,
            timestamp: new Date().toISOString(),
            status: 'complete',
            isEphemeralContextCollapsed: true,
            isCycleCollapsed: false,
        };
        loadCycleData(newCycle);
        clientIpc.sendToServer(ClientToServerChannel.SaveLastViewedCycle, { cycleId: newCycleId });
        setSaveStatus('unsaved');
    }, [saveStatus, maxCycle, currentCycle, loadCycleData, clientIpc]);
    
    const onCycleContextChange = React.useCallback((value: string) => {
        setCycleContext(value);
        setSaveStatus('unsaved');
    }, []);

    const onEphemeralContextChange = React.useCallback((value: string) => {
        setEphemeralContext(value);
        setSaveStatus('unsaved');
    }, []);

    const onTitleChange = React.useCallback((title: string) => {
        setCycleTitle(title);
        setSaveStatus('unsaved');
    }, []);

    const handleDeleteCycle = React.useCallback(() => {
        if (currentCycle !== null) {
            clientIpc.sendToServer(ClientToServerChannel.RequestDeleteCycle, { cycleId: currentCycle.cycleId });
        }
    }, [currentCycle, clientIpc]);

    const handleResetHistory = React.useCallback(() => {
        clientIpc.sendToServer(ClientToServerChannel.RequestResetHistory, {});
    }, [clientIpc]);

    const handleExportHistory = React.useCallback(() => clientIpc.sendToServer(ClientToServerChannel.RequestExportHistory, {}), [clientIpc]);
    const handleImportHistory = React.useCallback(() => clientIpc.sendToServer(ClientToServerChannel.RequestImportHistory, {}), [clientIpc]);

    const handleSelectResponse = React.useCallback((id: string) => {
        setSelectedResponseId(prev => prev === id ? null : id);
        setSaveStatus('unsaved');
    }, []);

    return {
        currentCycle,
        setCurrentCycle,
        projectScope,
        setProjectScope,
        maxCycle,
        setMaxCycle,
        cycleTitle,
        cycleContext,
        ephemeralContext,
        isCycleCollapsed,
        setIsCycleCollapsed,
        isEphemeralContextCollapsed,
        setIsEphemeralContextCollapsed,
        saveStatus,
        setSaveStatus,
        selectedResponseId,
        loadCycleData,
        handleCycleChange,
        handleNewCycle,
        onCycleContextChange,
        onEphemeralContextChange,
        onTitleChange,
        handleDeleteCycle,
        handleResetHistory,
        handleExportHistory,
        handleImportHistory,
        handleSelectResponse,
    };
};
</file_artifact>

<file path="src/client/views/parallel-copilot.view/hooks/useFileManagement.ts">
// src/client/views/parallel-copilot.view/hooks/useFileManagement.ts
import * as React from 'react';
import { ClientPostMessageManager } from '@/common/ipc/client-ipc';
import { ClientToServerChannel } from '@/common/ipc/channels.enum';
import { ComparisonMetrics } from '@/common/ipc/channels.type';

export const useFileManagement = (
    activeTab: number,
    tabs: any,
    setSaveStatus: (status: 'unsaved' | 'saving' | 'saved') => void
) => {
    const [highlightedCodeBlocks, setHighlightedCodeBlocks] = React.useState<Map<string, string>>(new Map());
    const [fileExistenceMap, setFileExistenceMap] = React.useState<Map<string, boolean>>(new Map());
    const [selectedFilePath, setSelectedFilePath] = React.useState<string | null>(null);
    const [selectedFilesForReplacement, setSelectedFilesForReplacement] = React.useState<Set<string>>(new Set());
    const [comparisonMetrics, setComparisonMetrics] = React.useState<Map<string, ComparisonMetrics | null>>(new Map());
    const [pathOverrides, setPathOverrides] = React.useState<Map<string, string>>(new Map());
    const [tempOverridePath, setTempOverridePath] = React.useState('');

    const clientIpc = ClientPostMessageManager.getInstance();

    const handleSelectForViewing = React.useCallback((filePath: string) => {
        const newPath = selectedFilePath === filePath ? null : filePath;
        setSelectedFilePath(newPath);
    }, [selectedFilePath]);

    const handleFileSelectionToggle = React.useCallback((filePath: string) => {
        const currentTabId = activeTab.toString();
        const compositeKeyForCurrent = `${currentTabId}:::${filePath}`;
        setSelectedFilesForReplacement(prev => {
            const newSet = new Set(prev);
            let existingKey: string | undefined;
            for (const key of newSet) {
                if (key.endsWith(`:::${filePath}`)) {
                    existingKey = key;
                    break;
                }
            }
            if (existingKey) {
                if (existingKey === compositeKeyForCurrent) {
                    newSet.delete(existingKey);
                } else {
                    newSet.delete(existingKey);
                    newSet.add(compositeKeyForCurrent);
                }
            } else {
                newSet.add(compositeKeyForCurrent);
            }
            return newSet;
        });
        setSaveStatus('unsaved');
    }, [activeTab, setSaveStatus]);

    const handleLinkFile = React.useCallback((originalPath: string) => {
        if (tempOverridePath.trim()) {
            setPathOverrides(prev => new Map(prev).set(originalPath, tempOverridePath.trim()));
            setFileExistenceMap(prev => new Map(prev).set(originalPath, true));
            setTempOverridePath('');
            handleSelectForViewing(originalPath);
        }
    }, [tempOverridePath, handleSelectForViewing]);
    
    const handleUnlinkFile = React.useCallback((originalPath: string) => {
        setPathOverrides(prev => {
            const newMap = new Map(prev);
            newMap.delete(originalPath);
            return newMap;
        });
        setFileExistenceMap(prev => new Map(prev).set(originalPath, false));
    }, []);

    const handleCopyContent = React.useCallback(() => {
        if (!selectedFilePath || !tabs[activeTab.toString()]?.parsedContent) return;
        const file = tabs[activeTab.toString()].parsedContent.files.find((f: any) => f.path === selectedFilePath);
        if (file) {
            clientIpc.sendToServer(ClientToServerChannel.RequestCopyTextToClipboard, { text: file.content });
        }
    }, [selectedFilePath, tabs, activeTab, clientIpc]);

    return {
        highlightedCodeBlocks,
        setHighlightedCodeBlocks,
        fileExistenceMap,
        setFileExistenceMap,
        selectedFilePath,
        setSelectedFilePath,
        selectedFilesForReplacement,
        setSelectedFilesForReplacement,
        comparisonMetrics,
        setComparisonMetrics,
        pathOverrides,
        setPathOverrides,
        tempOverridePath,
        setTempOverridePath,
        handleSelectForViewing,
        handleFileSelectionToggle,
        handleLinkFile,
        handleUnlinkFile,
        handleCopyContent,
    };
};
</file_artifact>

<file path="src/client/views/parallel-copilot.view/hooks/useGeneration.ts">
// src/client/views/parallel-copilot.view/hooks/useGeneration.ts
// Updated on: C115 (Use responseCount prop)
import * as React from 'react';
import { ClientPostMessageManager } from '@/common/ipc/client-ipc';
import { ClientToServerChannel } from '@/common/ipc/channels.enum';
import { GenerationProgress } from '@/common/ipc/channels.type';
import { ConnectionMode } from '@/backend/services/settings.service';
import { PcppCycle, PcppResponse } from '@/common/types/pcpp.types';

export const useGeneration = (
    currentCycle: PcppCycle | null,
    getCurrentCycleData: () => PcppCycle | null,
    isReadyForNextCycle: boolean,
    newCycleButtonDisabledReason: string,
    setTabs: React.Dispatch<React.SetStateAction<{ [key: string]: PcppResponse }>>,
    setSaveStatus: (status: 'unsaved' | 'saving' | 'saved') => void,
    responseCount: number // Use prop
) => {
    const [connectionMode, setConnectionMode] = React.useState<ConnectionMode>('manual');
    const [generationProgress, setGenerationProgress] = React.useState<GenerationProgress[]>([]);
    const [tps, setTps] = React.useState(0);
    const [isGenerationComplete, setIsGenerationComplete] = React.useState(false);
    
    const clientIpc = ClientPostMessageManager.getInstance();

    const handleGenerateResponses = React.useCallback(() => {
        const cycleData = getCurrentCycleData();
        if (cycleData) {
            clientIpc.sendToServer(ClientToServerChannel.RequestNewCycleAndGenerate, { cycleData, count: responseCount });
        }
    }, [clientIpc, getCurrentCycleData, responseCount]);
    
    const handleStartGeneration = React.useCallback((projectScope: string, count: number) => {
        clientIpc.sendToServer(ClientToServerChannel.RequestInitialArtifactsAndGeneration, { projectScope, responseCount: count });
    }, [clientIpc]);

    const handleRegenerateTab = React.useCallback((responseId: number) => {
        if (currentCycle === null) return;
        const tabId = responseId.toString();
        setTabs(prev => {
            const newTabs = { ...prev };
            newTabs[tabId] = { ...newTabs[tabId], content: '', parsedContent: null, status: 'generating' };
            return newTabs;
        });
        clientIpc.sendToServer(ClientToServerChannel.RequestSingleRegeneration, { cycleId: currentCycle.cycleId, tabId });
        setSaveStatus('unsaved');
        setIsGenerationComplete(false);
    }, [clientIpc, currentCycle, setTabs, setSaveStatus]);

    const handleStopGeneration = React.useCallback((cycleId: number, responseId: number) => {
        // Optimistic UI update for immediate feedback
        setGenerationProgress(prev => {
            const newProgress = [...prev];
            const index = newProgress.findIndex(p => p.responseId === responseId);
            if (index !== -1 && newProgress[index].status !== 'stopped') {
                newProgress[index] = { ...newProgress[index], status: 'stopped' };
            }
            return newProgress;
        });
        // Send message to backend to perform the actual stop
        clientIpc.sendToServer(ClientToServerChannel.RequestStopGeneration, { cycleId, responseId });
    }, [clientIpc, setGenerationProgress]);

    const isGenerateResponsesDisabled = React.useMemo(() => {
        if (currentCycle?.cycleId === 0) return true;
        return !isReadyForNextCycle;
    }, [currentCycle, isReadyForNextCycle]);

    return {
        connectionMode,
        setConnectionMode,
        generationProgress,
        setGenerationProgress,
        tps,
        setTps,
        isGenerationComplete,
        setIsGenerationComplete,
        handleGenerateResponses,
        handleStartGeneration,
        handleRegenerateTab,
        handleStopGeneration,
        isGenerateResponsesDisabled,
        newCycleButtonDisabledReason,
    };
};
</file_artifact>

<file path="src/client/views/parallel-copilot.view/hooks/usePcppIpc.ts">
// src/client/views/parallel-copilot.view/hooks/usePcppIpc.ts
// Updated on: C124 (Update comparison metrics handler to use tabId)
import * as React from 'react';
import { ClientPostMessageManager } from '@/common/ipc/client-ipc';
import { ServerToClientChannel, ClientToServerChannel } from '@/common/ipc/channels.enum';
import { PcppCycle, PcppResponse } from '@/common/types/pcpp.types';
import { parseResponse } from '@/client/utils/response-parser';
import { logger } from '@/client/utils/logger';
import { useCycleManagement } from './useCycleManagement';
import { useTabManagement } from './useTabManagement';
import { useFileManagement } from './useFileManagement';
import { useGeneration } from './useGeneration';
import { GenerationProgress } from '@/common/ipc/channels.type';

type CycleManagementHook = ReturnType<typeof useCycleManagement>;
type TabManagementHook = ReturnType<typeof useTabManagement>;
type FileManagementHook = ReturnType<typeof useFileManagement>;
type GenerationManagementHook = ReturnType<typeof useGeneration>;

export const usePcppIpc = (
    cycleManagement: CycleManagementHook,
    tabManagement: TabManagementHook,
    fileManagement: FileManagementHook,
    generationManagement: GenerationManagementHook,
    setWorkflowStep: React.Dispatch<React.SetStateAction<string | null>>
) => {
    const clientIpc = ClientPostMessageManager.getInstance();

    React.useEffect(() => {
        clientIpc.sendToServer(ClientToServerChannel.RequestInitialCycleData, {});
        clientIpc.sendToServer(ClientToServerChannel.RequestSettings, {});
    }, [clientIpc]);

    React.useEffect(() => {
        clientIpc.onServerMessage(ServerToClientChannel.SendInitialCycleData, ({ cycleData, projectScope }: { cycleData: PcppCycle, projectScope: string }) => {
            cycleManagement.loadCycleData(cycleData, projectScope);
            cycleManagement.setMaxCycle(cycleData.cycleId);
            if (cycleData.cycleId === 0) setWorkflowStep('awaitingProjectScope');
            else if (cycleData.cycleId === 1 && !cycleData.cycleContext) setWorkflowStep('awaitingResponsePaste_1');
        });

        clientIpc.onServerMessage(ServerToClientChannel.SendCycleData, ({ cycleData, projectScope }) => {
            if (cycleData) cycleManagement.loadCycleData(cycleData, projectScope);
        });

        clientIpc.onServerMessage(ServerToClientChannel.SendSyntaxHighlight, ({ highlightedHtml, id }) => {
            fileManagement.setHighlightedCodeBlocks(prev => new Map(prev).set(id, highlightedHtml));
        });

        clientIpc.onServerMessage(ServerToClientChannel.SendFileExistence, ({ existenceMap }) => {
            fileManagement.setFileExistenceMap(new Map(Object.entries(existenceMap)));
        });

        clientIpc.onServerMessage(ServerToClientChannel.ForceRefresh, ({ reason }) => {
            if (reason === 'history') clientIpc.sendToServer(ClientToServerChannel.RequestInitialCycleData, {});
        });

        clientIpc.onServerMessage(ServerToClientChannel.FilesWritten, ({ paths }) => {
            fileManagement.setFileExistenceMap(prevMap => {
                const newMap = new Map(prevMap);
                paths.forEach(p => newMap.set(p, true));
                return newMap;
            });
        });

        clientIpc.onServerMessage(ServerToClientChannel.SendFileComparison, (metrics) => {
            // C124 FIX: Use composite key to store metrics
            const key = `${metrics.tabId}:::${metrics.filePath}`;
            fileManagement.setComparisonMetrics(prev => new Map(prev).set(key, metrics));
        });

        clientIpc.onServerMessage(ServerToClientChannel.SendPromptCostEstimation, ({ totalTokens, estimatedCost, breakdown }) => {
            // Placeholder for cost state update
        });

        clientIpc.onServerMessage(ServerToClientChannel.NotifyGitOperationResult, (result) => {
            if (result.success) {
                setWorkflowStep(prevStep => {
                    if (prevStep === 'awaitingBaseline') {
                        clientIpc.sendToServer(ClientToServerChannel.RequestShowInformationMessage, { message: result.message });
                        return 'awaitingFileSelect';
                    }
                    return prevStep;
                });
            }
        });
        
        clientIpc.onServerMessage(ServerToClientChannel.SendGitStatus, ({ isClean }) => {
            setWorkflowStep(prev => (isClean && prev === 'awaitingBaseline') ? 'awaitingFileSelect' : prev);
        });

        clientIpc.onServerMessage(ServerToClientChannel.NotifySaveComplete, ({ cycleId }) => {
            if (cycleId === 0) {
                cycleManagement.setSaveStatus('saved');
            }
            else if (cycleId === cycleManagement.currentCycle?.cycleId) {
                cycleManagement.setSaveStatus('saved');
            }
        });

        clientIpc.onServerMessage(ServerToClientChannel.SendSettings, ({ settings }) => {
            generationManagement.setConnectionMode(settings.connectionMode);
        });
        
        clientIpc.onServerMessage(ServerToClientChannel.NavigateToNewGeneratingCycle, ({ newCycleData, newMaxCycle }) => {
            logger.log(`[IPC] Received NavigateToNewGeneratingCycle for C${newCycleData.cycleId}. Updating state atomically.`);
            cycleManagement.setMaxCycle(newMaxCycle);
            cycleManagement.loadCycleData(newCycleData);
            tabManagement.resetAndLoadTabs(newCycleData.responses);

            const initialProgress: GenerationProgress[] = Object.keys(newCycleData.responses).map(key => {
                const responseId = parseInt(key, 10);
                return {
                    responseId,
                    status: 'pending',
                    promptTokens: 0,
                    thinkingTokens: 0,
                    currentTokens: 0,
                    totalTokens: 16384,
                    startTime: Date.now()
                };
            });
            generationManagement.setGenerationProgress(initialProgress);
            
            clientIpc.sendToServer(ClientToServerChannel.SaveLastViewedCycle, { cycleId: newCycleData.cycleId });
        });

        clientIpc.onServerMessage(ServerToClientChannel.UpdateGenerationProgress, ({ progress, tps, chunks }) => {
            generationManagement.setGenerationProgress(progress);
            generationManagement.setTps(tps);
            tabManagement.setTabs(prevTabs => {
                const newTabs = { ...prevTabs };
                Object.entries(chunks).forEach(([responseId, chunk]) => {
                    const tabIndex = parseInt(responseId, 10);
                    const existingTab = newTabs[tabIndex] || { content: '', status: 'generating' };
                    newTabs[tabIndex] = { ...existingTab, content: chunk };
                });
                return newTabs;
            });
        });

        clientIpc.onServerMessage(ServerToClientChannel.UpdateSingleGenerationProgress, ({ progress, content }) => {
            generationManagement.setGenerationProgress(prev => {
                const newProgress = [...prev];
                const index = newProgress.findIndex(p => p.responseId === progress.responseId);
                if (index !== -1) {
                    newProgress[index] = progress;
                } else {
                    newProgress.push(progress);
                    newProgress.sort((a, b) => a.responseId - b.responseId);
                }

                let totalTokens = 0;
                let earliestStartTime = Infinity;
                
                newProgress.forEach(p => {
                    if (p.status !== 'complete' && p.status !== 'error' && p.status !== 'stopped') {
                        if (p.startTime < earliestStartTime) {
                            earliestStartTime = p.startTime;
                        }
                    }
                    totalTokens += p.thinkingTokens + p.currentTokens;
                });

                if (earliestStartTime !== Infinity) {
                    const elapsedSeconds = (Date.now() - earliestStartTime) / 1000;
                    if (elapsedSeconds > 0) {
                        const currentTps = Math.round(totalTokens / elapsedSeconds);
                        generationManagement.setTps(currentTps);
                    }
                }

                return newProgress;
            });

            tabManagement.setTabs(prev => {
                const newTabs = { ...prev };
                const tabId = progress.responseId.toString();
                const existingTab = newTabs[tabId] || { content: '', status: 'pending' };
                newTabs[tabId] = {
                    ...existingTab,
                    content: content,
                    status: progress.status,
                };
                return newTabs;
            });
        });

        clientIpc.onServerMessage(ServerToClientChannel.NotifySingleResponseComplete, ({ responseId, content }) => {
            tabManagement.setTabs(prev => {
                const newTabs = { ...prev };
                const tabId = responseId.toString();
                const tab = newTabs[tabId];
                if (tab) {
                    tab.content = content;
                    tab.parsedContent = parseResponse(content);
                    tab.status = 'complete';
                }
                return newTabs;
            });
        });

        clientIpc.onServerMessage(ServerToClientChannel.SendBatchGenerationComplete, ({ newCycleId, newMaxCycle }) => {
            generationManagement.setIsGenerationComplete(true);
        });

    }, [
        clientIpc, 
        cycleManagement, 
        tabManagement, 
        fileManagement, 
        generationManagement, 
        setWorkflowStep
    ]);
};
</file_artifact>

<file path="src/client/views/parallel-copilot.view/hooks/useTabManagement.ts">
// src/client/views/parallel-copilot.view/hooks/useTabManagement.ts
// Updated on: C124 (Pass tabId to requestAllMetrics)
import * as React from 'react';
import { ParsedResponse, PcppResponse } from '@/common/types/pcpp.types';
import { parseResponse } from '@/client/utils/response-parser';
import { ClientPostMessageManager } from '@/common/ipc/client-ipc';
import { ClientToServerChannel } from '@/common/ipc/channels.enum';
import * as path from 'path-browserify';
import { logger } from '@/client/utils/logger';

export const useTabManagement = (
    initialResponses: { [key: string]: PcppResponse },
    initialTabCount: number,
    initialActiveTab: number,
    initialIsParsedMode: boolean,
    initialIsSorted: boolean,
    setSaveStatus: (status: 'unsaved' | 'saving' | 'saved') => void,
    requestAllMetrics: (parsedResponse: ParsedResponse, tabId: number) => void
) => {
    const [tabs, setTabs] = React.useState<{ [key: string]: PcppResponse }>({});
    const [activeTab, setActiveTab] = React.useState(initialActiveTab);
    const [tabCount, setTabCount] = React.useState(initialTabCount);
    const [isParsedMode, setIsParsedMode] = React.useState(initialIsParsedMode);
    const [isSortedByTokens, setIsSortedByTokens] = React.useState(initialIsSorted);
    const clientIpc = ClientPostMessageManager.getInstance();

    const resetAndLoadTabs = React.useCallback((responses: { [key: string]: PcppResponse }) => {
        logger.log('[useTabManagement] Resetting and loading tabs from new cycle data.');
        const newTabs: { [key: string]: PcppResponse } = {};
        const count = Math.max(Object.keys(responses).length, initialTabCount);
        
        for (let i = 1; i <= count; i++) {
            const key = i.toString();
            const response = responses[key];
            newTabs[key] = {
                content: response?.content || '',
                parsedContent: response?.content ? parseResponse(response.content) : null,
                status: response?.status || 'complete',
                ...response
            };
        }
        setTabs(newTabs);
        setTabCount(count);
    }, [initialTabCount]);

    React.useEffect(() => {
        resetAndLoadTabs(initialResponses);
        setActiveTab(initialActiveTab);
        setIsParsedMode(initialIsParsedMode);
        setIsSortedByTokens(initialIsSorted);
    }, [initialResponses, initialActiveTab, initialIsParsedMode, initialIsSorted, resetAndLoadTabs]);


    const handleTabSelect = React.useCallback((tabIndex: number) => {
        setActiveTab(tabIndex);
        setSaveStatus('unsaved');
    }, [setSaveStatus]);

    const handleTabCountChange = React.useCallback((count: number) => {
        setTabCount(count);
        setTabs(prev => {
            const newTabs = { ...prev };
            for (let i = 1; i <= count; i++) {
                if (!newTabs[i.toString()]) {
                    newTabs[i.toString()] = { content: '', status: 'complete' };
                }
            }
            return newTabs;
        });
        setSaveStatus('unsaved');
    }, [setSaveStatus]);

    const handleContentChange = React.useCallback((newContent: string, tabIndex: number) => {
        setTabs(prev => ({ 
            ...prev, 
            [tabIndex.toString()]: { 
                ...(prev[tabIndex.toString()] || { content: '', status: 'complete' }),
                content: newContent, 
                parsedContent: null 
            } 
        }));
        setSaveStatus('unsaved');
    }, [setSaveStatus]);

    const handlePaste = React.useCallback((e: React.ClipboardEvent, tabIndex: number) => {
        const pastedText = e.clipboardData.getData('text');
        const currentContent = tabs[tabIndex.toString()]?.content || '';
        const tokenCount = Math.ceil(pastedText.length / 4);
        if (tokenCount > 1000 && currentContent.trim() === '' && tabIndex < tabCount) {
            handleContentChange(pastedText, tabIndex);
            setActiveTab(tabIndex + 1);
        } else {
            handleContentChange(pastedText, tabIndex);
        }
    }, [tabs, tabCount, handleContentChange]);
    
    const parseAllTabs = React.useCallback(() => {
        setTabs(prevTabs => {
            const allFilePaths = new Set<string>();
            const updatedTabs = { ...prevTabs };
            Object.entries(updatedTabs).forEach(([tabId, tabState]) => {
                const tabIdNum = parseInt(tabId, 10);
                if (tabState.content && !tabState.parsedContent) {
                    const parsed = parseResponse(tabState.content);
                    tabState.parsedContent = parsed;
                    tabState.status = 'complete';
                    parsed.filesUpdated.forEach(filePath => allFilePaths.add(filePath));
                    requestAllMetrics(parsed, tabIdNum);
                    parsed.files.forEach(file => {
                        const lang = path.extname(file.path).substring(1) || 'plaintext';
                        const id = `${file.path}::${file.content}`;
                        clientIpc.sendToServer(ClientToServerChannel.RequestSyntaxHighlight, { code: file.content, lang, id });
                    });
                } else if (tabState.parsedContent) {
                    tabState.parsedContent.filesUpdated.forEach(filePath => allFilePaths.add(filePath));
                }
            });
            if (allFilePaths.size > 0) {
                clientIpc.sendToServer(ClientToServerChannel.RequestFileExistence, { paths: Array.from(allFilePaths) });
            }
            return updatedTabs;
        });
    }, [clientIpc, requestAllMetrics]);

    const handleGlobalParseToggle = React.useCallback(() => {
        const newParseMode = !isParsedMode;
        setIsParsedMode(newParseMode);
        if (newParseMode) {
            parseAllTabs();
        } else {
            // Un-parse: clear parsed content
            setTabs(prev => {
                const newTabs = { ...prev };
                Object.keys(newTabs).forEach(key => {
                    newTabs[key].parsedContent = null;
                });
                return newTabs;
            });
        }
        setSaveStatus('unsaved');
    }, [isParsedMode, setSaveStatus, parseAllTabs]);

    const handleSortToggle = React.useCallback(() => {
        setIsSortedByTokens(p => !p);
        setSaveStatus('unsaved');
    }, [setSaveStatus]);

    const sortedTabIds = React.useMemo(() => {
        const tabIds = [...Array(tabCount)].map((_, i) => i + 1);
        if (isParsedMode && isSortedByTokens) {
            tabIds.sort((a, b) => {
                const tokensA = tabs[a.toString()]?.parsedContent?.totalTokens ?? -1;
                const tokensB = tabs[b.toString()]?.parsedContent?.totalTokens ?? -1;
                return tokensB - tokensA;
            });
        }
        return tabIds;
    }, [tabs, isParsedMode, isSortedByTokens, tabCount]);


    return {
        tabs,
        setTabs,
        activeTab,
        setActiveTab,
        tabCount,
        setTabCount: handleTabCountChange,
        isParsedMode,
        setIsParsedMode,
        isSortedByTokens,
        handleTabSelect,
        handleContentChange,
        handlePaste,
        parseAllTabs,
        handleGlobalParseToggle,
        handleSortToggle,
        sortedTabIds,
        resetAndLoadTabs,
    };
};
</file_artifact>

<file path="src/client/views/parallel-copilot.view/hooks/useWorkflow.ts">
// src/client/views/parallel-copilot.view/hooks/useWorkflow.ts
import * as React from 'react';

export const useWorkflow = (
    initialWorkflowStep: string | null,
    isReadyForNextCycle: boolean,
    cycleTitle: string,
    cycleContext: string,
    selectedFilesForReplacement: Set<string>,
    selectedResponseId: string | null,
    isSortedByTokens: boolean,
    isParsedMode: boolean,
    tabs: any,
    tabCount: number
) => {
    const [workflowStep, setWorkflowStep] = React.useState<string | null>(initialWorkflowStep);

    React.useEffect(() => {
        if (workflowStep === null) return;
        if (workflowStep === 'readyForNewCycle') return;
        if (workflowStep === 'awaitingGeneratePrompt') {
            if (isReadyForNextCycle) setWorkflowStep('awaitingGeneratePrompt');
            return;
        }
        if (workflowStep === 'awaitingCycleTitle') {
            if (cycleTitle.trim() && cycleTitle.trim() !== 'New Cycle') {
                setWorkflowStep('awaitingGeneratePrompt');
            }
            return;
        }
        if (workflowStep === 'awaitingCycleContext') {
            if (cycleContext.trim()) {
                setWorkflowStep('awaitingCycleTitle');
            }
            return;
        }
        if (workflowStep === 'awaitingAccept') {
            return;
        }
        if (workflowStep === 'awaitingBaseline') {
            // Logic moved to IPC hook
            return;
        }
        if (workflowStep === 'awaitingFileSelect') {
            if (selectedFilesForReplacement.size > 0) {
                setWorkflowStep('awaitingAccept');
            }
            return;
        }
        if (workflowStep === 'awaitingResponseSelect') {
            if (selectedResponseId) {
                setWorkflowStep('awaitingBaseline');
            }
            return;
        }
        if (workflowStep === 'awaitingSort') {
            if (isSortedByTokens) {
                setWorkflowStep('awaitingResponseSelect');
            }
            return;
        }
        if (workflowStep === 'awaitingParse') {
            if (isParsedMode) {
                setWorkflowStep(isSortedByTokens ? 'awaitingResponseSelect' : 'awaitingSort');
            }
            return;
        }
        const waitingForPaste = workflowStep?.startsWith('awaitingResponsePaste');
        if (waitingForPaste) {
            for (let i = 1; i <= tabCount; i++) {
                if (!tabs[i.toString()]?.rawContent?.trim()) {
                    setWorkflowStep(`awaitingResponsePaste_${i}`);
                    return;
                }
            }
            setWorkflowStep('awaitingParse');
        }
    }, [workflowStep, selectedFilesForReplacement, selectedResponseId, isSortedByTokens, isParsedMode, tabs, cycleContext, cycleTitle, tabCount, isReadyForNextCycle]);

    return {
        workflowStep,
        setWorkflowStep,
    };
};
</file_artifact>

<file path="src/Artifacts/A110. DCE - Response UI State Persistence and Workflow Plan.md">
# Artifact A110: DCE - Response UI State Persistence and Workflow Plan
# Date Created: C96
# Author: AI Model & Curator

- **Key/Value for A0:**
- **Description:** A plan to fix the response UI state loss and workflow bugs by expanding the data model to include generation metrics, refactoring the backend to persist them, and updating the frontend UI to be driven by a per-response status.
- **Tags:** plan, bug fix, persistence, state management, ui, ux, workflow

## 1. Problem Statement

The response generation UI, while functional, suffers from several critical bugs that make it unreliable and unintuitive:
1.  **State Loss:** All metrics (timers, token counts, progress) are lost if the user navigates away from the PCPP tab and back.
2.  **Missing Persistence:** The valuable metrics gathered during generation are not saved to `dce_history.json`, meaning they are lost forever once the UI is re-rendered.
3.  **"Stuck UI":** The UI often gets stuck on the "Generating Responses" view even after all responses are complete, because it is incorrectly keying off the overall cycle's status instead of the individual response's status.
4.  **Incorrect Workflow:** The UI doesn't allow a user to view a completed response while others are still generating.
5.  **Title Bug:** The backend incorrectly renames new cycles to "Cycle X - Generating...", which breaks the user-driven title workflow.

## 2. The Solution: Per-Response State & Persistence

The root cause of these issues is that the generation metrics are transient UI state and the rendering logic is too simplistic. The solution is to make these metrics a persistent part of our data model and make the UI rendering logic more granular.

### 2.1. New Data Model

The `PcppResponse` interface in `pcpp.types.ts` will be expanded to become the single source of truth for a response and its generation metadata.

**New `PcppResponse` Interface:**
```typescript
export interface PcppResponse {
    content: string;
    // The single source of truth for the response's state
    status: 'pending' | 'thinking' | 'generating' | 'complete' | 'error';
    
    // Persisted Metrics
    startTime?: number;         // Timestamp when generation for this response started
    thinkingEndTime?: number;   // Timestamp when the 'thinking' phase ended
    endTime?: number;           // Timestamp when the response was fully received
    thinkingTokens?: number;    // Total tokens from the 'thinking' phase
    responseTokens?: number;    // Total tokens from the 'response' phase
}
```

### 2.2. New UI Rendering Logic

The main view's logic will no longer be a simple binary switch based on the *cycle's* status. It will be driven by the *active tab's* response status.

**Logic in `view.tsx`:**
```
const activeTab = tabs[activeTabId];
const showProgressView = activeTab?.status === 'generating' || activeTab?.status === 'thinking';

if (showProgressView) {
  // Render <GenerationProgressDisplay />
} else {
  // Render <ResponsePane />
}
```
This allows the UI to correctly show the progress view for a tab that is actively generating (including a re-generation) but show the parsed content for a tab that is complete.

## 3. Technical Implementation Plan

1.  **Update Data Model (`pcpp.types.ts`):**
    *   Update the `PcppResponse` interface as defined in section 2.1.

2.  **Update Backend (`llm.service.ts`):**
    *   Refactor the `generateBatch` stream handler.
    *   It will now create a richer `GenerationProgress` object that includes `startTime`.
    *   As it processes chunks, it will distinguish between `reasoning_content` and `content`, summing their token counts into `thinkingTokens` and `responseTokens` respectively.
    *   It will capture `thinkingEndTime` and `endTime` timestamps.
    *   When a stream for a response ends, it will pass this complete metrics object to the history service.

3.  **Update Backend (`history.service.ts`):**
    *   Refactor `updateCycleWithResponses` to accept this new, richer response object and save all the new metric fields to `dce_history.json`.
    *   **Fix Title Bug:** Modify `createNewCyclePlaceholder` to set the `title` to `"New Cycle"` instead of `"Cycle X - Generating..."`.

4.  **Refactor Frontend (`view.tsx` and hooks):**
    *   Implement the new per-tab rendering logic described in section 2.2.
    *   Update the `GenerationProgressDisplay.tsx` component to source its data from the `PcppResponse` objects of the current cycle. This ensures that when the view is reloaded for a "generating" cycle, it can reconstruct its state from the persisted metrics in `dce_history.json`.

5.  **Add Manual View Toggle (UX Fallback):**
    *   Add a new button to the `WorkflowToolbar`.
    *   This button will be visible only when viewing a cycle with a status of `'complete'`.
    *   It will toggle a local `useState` boolean that overrides the main logic, allowing the user to manually switch between the `ResponsePane` and the (now historical) `GenerationProgressDisplay` for that cycle.
</file_artifact>

<file path="src/Artifacts/A111. DCE - New Regression Case Studies.md">
# Artifact A111: DCE - New Regression Case Studies
# Date Created: C99
# Author: AI Model & Curator
# Updated on: C116 (Add ETIMEDOUT case)

## 1. Purpose

This document serves as a living record of persistent or complex bugs. By documenting the root cause analysis (RCA) and the confirmed solution for each issue, we create a "source of truth" to prevent the same mistakes from being reintroduced into the codebase.

## 2. Case Studies

---

### Case Study 022: Parallel Requests Fail with ETIMEDOUT (Regression)

-   **Artifacts Affected:** `src/backend/services/llm.service.ts`
-   **Cycles Observed:** C113, C115, C116
-   **Symptom:** When the backend attempts to make multiple parallel `fetch` requests to the same host (e.g., generating 4 responses simultaneously), some of the requests fail with a `connect ETIMEDOUT` error. This results in only one or two responses being generated successfully.
-   **Root Cause Analysis (RCA):** The default Node.js `http.Agent` (used by `node-fetch`) has a limited pool of sockets for concurrent connections to a single origin. When the application tries to open several long-lived streaming connections at once, the later requests can time out while waiting for a socket to become available. This is a recurring issue, indicating that previous fixes were not consistently applied.
-   **Codified Solution & Best Practice:**
    1.  When an application needs to make a high number of concurrent, long-lived HTTP/HTTPS requests to a single host from a Node.js backend, do not rely on the default agent.
    2.  Use a dedicated agent library like `agentkeepalive` to create a single, shared `HttpsAgent` instance at the module level.
    3.  Configure this agent with a high `maxSockets` value (e.g., 100) to ensure a large enough connection pool is available.
    4.  **Crucially, ensure this custom agent is passed to *all* relevant `fetch` calls within the service to guarantee it is used for every request.**

---

### Case Study 021: Incorrect Un-escaping of Double-Escaped JSON String Content

-   **Artifacts Affected:** `src/client/utils/response-parser.ts`
-   **Cycles Observed:** C115
-   **Symptom:** When parsing a JSON response from the vLLM, the final content in the UI is corrupted with extra backslashes. For example, newlines appear as `\` instead of being processed, and quotes appear as `\"` or `\\"`.
-   **Root Cause Analysis (RCA):** The LLM, when generating a JSON object as a string, sometimes "double-escapes" characters within its string values to ensure they are valid. For example, a newline becomes `\\n` and a quote becomes `\\\"`. The parser's logic for handling this was flawed. `JSON.parse` correctly handles the first level of escaping, but the subsequent manual `.replace()` calls in the hybrid parser were too simplistic and did not correctly handle the remaining escape sequences, leading to the visual artifacts.
-   **Codified Solution & Best Practice:**
    1.  When processing string values from an LLM-generated JSON, assume they may be double-escaped.
    2.  Implement a robust, multi-step un-escaping sequence. The correct order is to first replace `\\\\` with `\\` (to handle literal backslashes), then replace `\\n` with a newline, `\\t` with a tab, and finally `\\"` with `"`.
    3.  This sequence, applied after the main JSON structure is parsed, correctly reduces the escape levels and produces a clean, readable string for the UI.

---

### Case Study 020: Parallel Onboarding Requests Fail with ETIMEDOUT

-   **Artifacts Affected:** `llm.service.ts`, `OnboardingView.tsx`, `useGeneration.ts`, `view.tsx`
-   **Cycles Observed:** C113, C115 (Regression)
-   **Symptom:** When clicking "Generate Initial Responses" from the onboarding view with the number of responses set to > 1, only one response is successfully generated. The other requests fail with `connect ETIMEDOUT` errors in the logs.
-   **Root Cause Analysis (RCA):** This is a complex issue with two contributing factors.
    1.  **State Mismatch:** The `OnboardingView.tsx` component managed its own local state for the `responseCount`. This was separate from the `tabCount` state managed by the main PCPP view. While the value was correctly passed to the backend, this state divergence made the system harder to debug and reason about.
    2.  **Connection Pooling:** The underlying issue is the `ETIMEDOUT` error, which indicates a client-side bottleneck in establishing concurrent connections to the proxy server, despite a previous fix (`agentkeepalive`) intended to solve this. Unifying the state is a prerequisite to ensure the correct parameters are being sent before further debugging of the connection pooling issue can be effective.
-   **Codified Solution & Best Practice:**
    1.  Avoid state divergence for critical parameters. The number of responses should be a single piece of state managed by a higher-order component or hook (`view.tsx` or `useGeneration.ts`). This state should be passed down as props to any child component that needs to read or modify it, ensuring a single source of truth.
    2.  The `ETIMEDOUT` error points to a persistent issue with Node.js connection pooling in the extension host environment. The `agentkeepalive` solution needs to be re-verified or a different strategy for managing parallel long-lived connections may be required.

---

### Case Study 019: Backend SSE Parser Fails on Fragmented Data Chunks

-   **Artifacts Affected:** `src/backend/services/llm.service.ts`
-   **Cycles Observed:** C108, C109, C110, C114
-   **Symptom:** The DCE output log is flooded with `Could not parse JSON object from stream` warnings during response generation. The final response content is often corrupted or incomplete.
-   **Root Cause Analysis (RCA):** The stream consumer in `llm.service.ts` was not correctly buffering incoming data from the vLLM server. It processed each `data` event from the stream as if it contained one or more complete, newline-terminated messages. However, a single logical SSE message from the server can be fragmented and sent across multiple TCP packets, resulting in the `data` event firing with an incomplete piece of a message. The parser would then attempt to parse this incomplete fragment, which is invalid JSON, leading to the error.
-   **Codified Solution & Best Practice:**
    1.  Stream consumers for protocols like SSE must be designed to handle fragmented messages. They cannot assume that each `data` event contains a complete message.
    2.  The correct implementation is to maintain a persistent buffer outside the `stream.on('data')` handler.
    3.  Each incoming chunk should be appended to this buffer.
    4.  The buffer should then be processed in a loop, searching for the standard SSE message terminator (`\n\n`).
    5.  Only the complete messages found before the terminator should be extracted and parsed. Any remaining text after the last terminator is an incomplete message and must be kept in the buffer to be prepended to the next incoming chunk.

---

### Case Study 018: Parallel Fetch Requests Fail with ETIMEDOUT

-   **Artifacts Affected:** `src/backend/services/llm.service.ts`
-   **Cycles Observed:** C113
-   **Symptom:** When the backend attempts to make multiple parallel `fetch` requests to the same host (e.g., generating 4 responses simultaneously), some of the requests fail with a `connect ETIMEDOUT` error. This results in only one or two responses being generated successfully.
-   **Root Cause Analysis (RCA):** The default Node.js `http.Agent` (used by `node-fetch`) has a pool of sockets for connections. While the default `maxSockets` is technically `Infinity`, in practice, factors within the execution environment (like VS Code's extension host) can lead to exhaustion or delays in acquiring new sockets for concurrent requests to the same origin. When the application tries to open several connections at once, the later requests can time out while waiting for a socket to become available.
-   **Codified Solution & Best Practice:**
    1.  When an application needs to make a high number of concurrent, long-lived HTTP/HTTPS requests to a single host from a Node.js backend, do not rely on the default `http.Agent`.
    2.  Use a dedicated agent library like `agentkeepalive` to create a custom `HttpsAgent` instance.
    3.  Configure this agent with a high `maxSockets` value (e.g., 100) to ensure a large enough connection pool is available.
    4.  Pass this custom agent to all relevant `fetch` calls. This provides robust and performant connection pooling, preventing timeout errors caused by socket exhaustion.

---

### Case Study 017: Parser Appears to Corrupt Newline Sequences

-   **Artifacts Affected:** `src/client/utils/response-parser.ts`
-   **Cycles Observed:** C112, C113
-   **Symptom:** Valid double-newline sequences (`\n\n`) in the raw AI response are being rendered incorrectly in the UI as `n\n`. This indicates that a backslash is being stripped at some point during parsing or sanitization.
-   **Root Cause Analysis (RCA):** The exact cause is unclear, but the primary suspect is an overly aggressive string replacement intended to fix a different model-specific quirk (`n\n`). The logic is likely misinterpreting or incorrectly modifying valid newline escape sequences. A definitive RCA requires observing the data transformation.
-   **Codified Solution & Best Practice:**
    1.  When debugging a string manipulation or parsing issue where the output is corrupted, the first step is to inject logging to trace the data's state at each step of the transformation.
    2.  Add `logger.log` statements in the parser to output the string immediately after it's received and after each significant `replace()` or sanitization operation.
    3.  This "before and after" logging provides an unambiguous view of how the data is being altered, allowing for the precise correction of the faulty logic.

---

### Case Study 016: Parser Fails to Sanitize Inconsistent Newlines from LLM JSON Output

-   **Artifacts Affected:** `src/client/utils/response-parser.ts`
-   **Cycles Observed:** C112
-   **Symptom:** When parsing a JSON response from the LLM, the final file content in the UI is corrupted. It shows extra `n` characters, for example, rendering `wordn\n` instead of `word\n`, or `wordn- list item` instead of `word\n- list item`.
-   **Root Cause Analysis (RCA):** The LLM, when instructed to produce JSON output, is not perfectly consistent in how it represents newlines within string values. While it correctly uses the `\n` escape sequence for most newlines, it sometimes erroneously inserts an extra literal `n` character immediately before the newline (`...wordn\n...`) or before a markdown formatting character (`...wordn- list item...`). The existing parser correctly handled the standard `\n` but did not have a sanitization step to clean up these spurious `n` characters, causing them to be passed through to the final rendered output.
-   **Codified Solution & Best Practice:**
    1.  Parsers for LLM output must be defensive and should include sanitization steps to handle common, minor formatting errors and model-specific quirks.
    2.  After parsing the main structure (e.g., via `JSON.parse`), apply a series of targeted regular expression replacements to the string content to clean up known inconsistencies.
    3.  For this specific issue, add a replacement for the pattern `n\n` -> `\n` to correct the malformed newlines without affecting legitimate uses of the letter 'n' in the text.

---
</file_artifact>

<file path="GPT-OSS-HARMONY-REFERENCE-REPO/builtin_tool_instructions.py">
#!/usr/bin/env python3
"""
Instructions for built-in tools that should be added directly to developer message
"""

def get_builtin_tools_instruction(include_python=False, include_browser=False):
    """Get instructions for enabled built-in tools"""
    if not include_python and not include_browser:
        return ""
    
    sections = ["# Built-in Tools"]
    
    if include_python:
        sections.append("""
## python

The `python` tool executes Python code for calculations, data processing, and internal reasoning. When asked to perform calculations, generate sequences, or process data, you should use this tool to ensure accuracy.

### Usage
To use the python tool, send a message in the analysis channel:
```
<|channel|>analysis to=python<|message|>
# Your Python code here
print(result)  # Use print to see output
<|end|>
```

### Important Notes
- The code runs in a stateless environment - variables don't persist between calls
- Always use `print()` to see results - return values alone won't be visible
- The code execution has a 30-second timeout
- Standard library modules are available (math, datetime, json, etc.)
- External packages like numpy, pandas are NOT available

### Examples

1. **Mathematical calculations:**
```
<|channel|>analysis to=python<|message|>
import math
x = 5
y = 12
hypotenuse = math.sqrt(x**2 + y**2)
print(f"The hypotenuse of a {x}-{y} right triangle is {hypotenuse}")
<|end|>
```

2. **Date/time operations:**
```
<|channel|>analysis to=python<|message|>
from datetime import datetime, timedelta
today = datetime.now()
future = today + timedelta(days=30)
print(f"30 days from now will be: {future.strftime('%Y-%m-%d')}")
<|end|>
```

3. **Data processing:**
```
<|channel|>analysis to=python<|message|>
data = [23, 45, 12, 67, 34, 89, 21]
average = sum(data) / len(data)
print(f"Average: {average:.2f}")
print(f"Max: {max(data)}, Min: {min(data)}")
<|end|>
```""")
    
    if include_browser:
        sections.append("""
## browser

The built-in browser tool allows me to help you find information on the web and browse specific web pages.

I can search the web, open pages, find specific content on pages, and navigate through search results. The browser runs in a stateless mode where each command starts fresh.

### Available Commands

1. **Search the web:**
```
<|channel|>analysis to=browser<|message|>
search [query] [optional: topn=5] [optional: source=web]
<|end|>
```

2. **Open a search result or URL:**
```
<|channel|>analysis to=browser<|message|>
open [id or url]
<|end|>
```

3. **Find text on the current page:**
```
<|channel|>analysis to=browser<|message|>
find [text]
<|end|>
```

### Example Usage

**Searching for information:**
```
<|channel|>analysis to=browser<|message|>
search "latest AI developments" topn=5
<|end|>
```

**Opening a specific result:**
```
<|channel|>analysis to=browser<|message|>
open 1
<|end|>
```

**Finding specific content:**
```
<|channel|>analysis to=browser<|message|>
find "machine learning"
<|end|>
```""")
    
    return "\n".join(sections)
</file_artifact>

<file path="GPT-OSS-HARMONY-REFERENCE-REPO/custom_python_instruction.py">
#!/usr/bin/env python3
"""
Custom Python tool instruction for HARMONY
"""

PYTHON_INSTRUCTION = """
## python

The `python` tool executes Python code for calculations, data processing, and internal reasoning. When asked to perform calculations, generate sequences, or process data, you should use this tool to ensure accuracy.

### Usage
To use the python tool, send a message in the analysis channel:
```
<|channel|>analysis to=python<|message|>
# Your Python code here
print(result)  # Use print to see output
<|end|>
```

### Important Notes
- The code runs in a stateless environment - variables don't persist between calls
- Always use `print()` to see results - return values alone won't be visible
- The code execution has a 30-second timeout
- Standard library modules are available (math, datetime, json, etc.)
- External packages like numpy, pandas are NOT available

### Examples

1. **Mathematical calculations:**
```
<|channel|>analysis to=python<|message|>
import math
x = 5
y = 12
hypotenuse = math.sqrt(x**2 + y**2)
print(f"The hypotenuse of a {x}-{y} right triangle is {hypotenuse}")
<|end|>
```

2. **Date/time operations:**
```
<|channel|>analysis to=python<|message|>
from datetime import datetime, timedelta
today = datetime.now()
future = today + timedelta(days=30)
print(f"30 days from now will be: {future.strftime('%Y-%m-%d')}")
<|end|>
```

3. **Data processing:**
```
<|channel|>analysis to=python<|message|>
data = [23, 45, 12, 67, 34, 89, 21]
average = sum(data) / len(data)
print(f"Average: {average:.2f}")
print(f"Max: {max(data)}, Min: {min(data)}")
<|end|>
```
""".strip()
</file_artifact>

<file path="GPT-OSS-HARMONY-REFERENCE-REPO/harmony_educational_demo.html">
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>HARMONY System - Educational Demo</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
            color: #fff;
            min-height: 100vh;
            overflow-x: hidden;
        }

        .container {
            max-width: 1400px;
            margin: 0 auto;
            padding: 40px 20px;
        }

        .header {
            text-align: center;
            margin-bottom: 60px;
            animation: fadeInDown 1s ease-out;
        }

        .header h1 {
            font-size: 3.5em;
            margin-bottom: 20px;
            text-shadow: 0 4px 15px rgba(0,0,0,0.3);
            letter-spacing: -1px;
        }

        .header p {
            font-size: 1.3em;
            color: #b3d9ff;
            max-width: 800px;
            margin: 0 auto;
            line-height: 1.6;
        }

        .tool-selector {
            display: flex;
            justify-content: center;
            gap: 30px;
            margin-bottom: 60px;
            flex-wrap: wrap;
        }

        .tool-card {
            background: rgba(255,255,255,0.1);
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255,255,255,0.2);
            border-radius: 16px;
            padding: 30px;
            cursor: pointer;
            transition: all 0.3s ease;
            min-width: 200px;
            text-align: center;
            position: relative;
            overflow: hidden;
        }

        .tool-card:hover {
            transform: translateY(-5px);
            background: rgba(255,255,255,0.15);
            box-shadow: 0 10px 30px rgba(0,0,0,0.3);
        }

        .tool-card.active {
            background: rgba(255,255,255,0.2);
            border-color: #4fc3f7;
            box-shadow: 0 0 20px rgba(79,195,247,0.5);
        }

        .tool-card .icon {
            font-size: 48px;
            margin-bottom: 15px;
        }

        .tool-card h3 {
            font-size: 1.4em;
            margin-bottom: 10px;
        }

        .tool-card p {
            font-size: 0.9em;
            color: #b3d9ff;
        }

        .demo-area {
            background: rgba(255,255,255,0.08);
            backdrop-filter: blur(10px);
            border-radius: 20px;
            padding: 40px;
            margin-bottom: 40px;
            border: 1px solid rgba(255,255,255,0.1);
            display: none;
            animation: fadeIn 0.5s ease-out;
        }

        .demo-area.active {
            display: block;
        }

        .flow-visualization {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 30px;
            margin-bottom: 40px;
        }

        .flow-step {
            background: rgba(255,255,255,0.1);
            padding: 25px;
            border-radius: 12px;
            position: relative;
            opacity: 0;
            transform: translateY(20px);
            animation: slideUp 0.5s ease-out forwards;
        }

        .flow-step:nth-child(1) { animation-delay: 0.1s; }
        .flow-step:nth-child(2) { animation-delay: 0.2s; }
        .flow-step:nth-child(3) { animation-delay: 0.3s; }
        .flow-step:nth-child(4) { animation-delay: 0.4s; }

        .flow-step h4 {
            font-size: 1.2em;
            margin-bottom: 15px;
            color: #4fc3f7;
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .step-number {
            background: #4fc3f7;
            color: #1e3c72;
            width: 30px;
            height: 30px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-weight: bold;
            font-size: 0.9em;
        }

        .code-block {
            background: rgba(0,0,0,0.3);
            border: 1px solid rgba(255,255,255,0.1);
            border-radius: 8px;
            padding: 20px;
            overflow-x: auto;
            font-family: 'Monaco', 'Consolas', monospace;
            font-size: 0.9em;
            line-height: 1.5;
            white-space: pre-wrap;
            word-wrap: break-word;
            margin-top: 15px;
        }

        .code-block.prompt {
            background: rgba(0,0,0,0.4);
            border-color: #4fc3f7;
        }

        .prompt-display {
            background: rgba(0,0,0,0.5);
            border: 2px solid #4fc3f7;
            border-radius: 12px;
            margin: 20px 0;
            overflow: hidden;
        }

        .prompt-header {
            background: rgba(79,195,247,0.2);
            padding: 15px 20px;
            border-bottom: 1px solid rgba(79,195,247,0.3);
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .prompt-header h5 {
            margin: 0;
            color: #4fc3f7;
            font-size: 1.1em;
        }

        .token-count {
            background: rgba(255,255,255,0.1);
            padding: 5px 15px;
            border-radius: 20px;
            font-size: 0.9em;
            color: #ffd54f;
        }

        .prompt-content {
            padding: 20px;
            font-family: 'Monaco', 'Consolas', monospace;
            font-size: 0.85em;
            line-height: 1.6;
            overflow-x: auto;
            white-space: pre-wrap;
        }

        .prompt-tag {
            color: #ff9800;
            font-weight: bold;
        }

        .prompt-section {
            margin-bottom: 15px;
            padding-bottom: 15px;
            border-bottom: 1px solid rgba(255,255,255,0.1);
            white-space: pre-wrap;
        }

        .prompt-section:last-child {
            border-bottom: none;
            margin-bottom: 0;
            padding-bottom: 0;
        }

        .highlight {
            color: #4fc3f7;
            font-weight: bold;
        }

        .channel-tag {
            color: #ffd54f;
        }

        .tool-definition {
            background: rgba(79,195,247,0.1);
            border: 1px solid rgba(79,195,247,0.3);
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
        }

        .result-display {
            background: rgba(76,175,80,0.1);
            border: 1px solid rgba(76,175,80,0.3);
            padding: 20px;
            border-radius: 8px;
            margin-top: 20px;
        }

        .arrow-down {
            text-align: center;
            margin: 20px 0;
            font-size: 24px;
            color: #4fc3f7;
            animation: bounce 2s infinite;
        }

        @keyframes fadeInDown {
            from {
                opacity: 0;
                transform: translateY(-30px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        @keyframes fadeIn {
            from { opacity: 0; }
            to { opacity: 1; }
        }

        @keyframes slideUp {
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        @keyframes bounce {
            0%, 20%, 50%, 80%, 100% {
                transform: translateY(0);
            }
            40% {
                transform: translateY(-10px);
            }
            60% {
                transform: translateY(-5px);
            }
        }

        .info-box {
            background: rgba(255,255,255,0.05);
            border-left: 4px solid #4fc3f7;
            padding: 20px;
            margin: 20px 0;
            border-radius: 0 8px 8px 0;
        }

        .info-box h5 {
            color: #4fc3f7;
            margin-bottom: 10px;
        }

        .loading-animation {
            display: inline-block;
            width: 20px;
            height: 20px;
            border: 2px solid rgba(255,255,255,0.3);
            border-radius: 50%;
            border-top-color: #4fc3f7;
            animation: spin 1s ease-in-out infinite;
        }

        @keyframes spin {
            to { transform: rotate(360deg); }
        }

        .channel-breakdown {
            background: rgba(0,0,0,0.4);
            border: 2px solid rgba(79,195,247,0.3);
            border-radius: 12px;
            padding: 30px;
            margin: 30px 0;
        }

        .channel-section {
            background: rgba(255,255,255,0.05);
            border-radius: 8px;
            padding: 20px;
            margin-bottom: 20px;
            border-left: 4px solid #4fc3f7;
        }

        .channel-section:last-child {
            margin-bottom: 0;
        }

        .channel-section h5 {
            color: #4fc3f7;
            margin-bottom: 15px;
            font-size: 1.2em;
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .channel-icon {
            background: rgba(79,195,247,0.2);
            width: 30px;
            height: 30px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 14px;
        }

        .channel-content {
            font-family: 'Monaco', 'Consolas', monospace;
            font-size: 0.85em;
            line-height: 1.6;
            color: #e0e0e0;
        }

        .tool-execution {
            background: rgba(76,175,80,0.1);
            border: 1px solid rgba(76,175,80,0.3);
            padding: 15px;
            border-radius: 6px;
            margin: 10px 0;
        }

        .tool-call {
            color: #ffd54f;
        }

        .tool-result {
            color: #81c784;
            margin-top: 10px;
        }

        @media (max-width: 768px) {
            .header h1 {
                font-size: 2.5em;
            }
            
            .tool-selector {
                gap: 15px;
            }
            
            .tool-card {
                min-width: 150px;
                padding: 20px;
            }
            
            .demo-area {
                padding: 20px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <header class="header">
            <h1>HARMONY System</h1>
            <p>Understanding OpenAI's Structured Generation System Through Interactive Examples</p>
            <div style="margin-top: 30px;">
                <p style="font-size: 1.1em; color: #ffd54f;"> Click on any tool below to explore how HARMONY works!</p>
            </div>
        </header>

        <div class="tool-selector">
            <div class="tool-card" onclick="showDemo('python')" id="python-card">
                <div class="icon"></div>
                <h3>Python Tool</h3>
                <p>Execute Python code in a secure Docker environment</p>
            </div>
            
            <div class="tool-card" onclick="showDemo('weather')" id="weather-card">
                <div class="icon"></div>
                <h3>Weather Tool</h3>
                <p>Get current weather information for any location</p>
            </div>
            
            <div class="tool-card" onclick="showDemo('browser')" id="browser-card">
                <div class="icon"></div>
                <h3>Vision Browser</h3>
                <p>Navigate and extract content from websites</p>
            </div>
        </div>

        <!-- Python Tool Demo -->
        <div class="demo-area" id="python-demo">
            <h2>Python Tool: Rolling a D20 Dice</h2>
            
            <div class="info-box">
                <h5>About the Python Tool</h5>
                <p>The Python tool allows the model to execute Python code in a secure, sandboxed Docker environment. This ensures safe code execution while providing powerful computational capabilities.</p>
            </div>

            <div class="flow-visualization">
                <div class="flow-step">
                    <h4><span class="step-number">1</span> Initial LLM Call</h4>
                    <p>The user asks the model to roll a D20 dice using Python:</p>
                    
                    <div class="prompt-display">
                        <div class="prompt-header">
                            <h5>Initial Prompt</h5>
                            <span class="token-count">227 tokens</span>
                        </div>
                        <div class="prompt-content">
                            <div class="prompt-section">
<span class="prompt-tag">&lt;|start|&gt;system&lt;|message|&gt;</span>You are ChatGPT, a large language model trained by OpenAI.
Knowledge cutoff: 2024-06
Current date: 2025-08-17

Reasoning: high

# Valid channels: analysis, commentary, final. Channel must be included for every message.
Calls to these tools must go to the commentary channel: 'functions'.<span class="prompt-tag">&lt;|end|&gt;</span>
                            </div>
                            <div class="prompt-section">
<span class="prompt-tag">&lt;|start|&gt;developer&lt;|message|&gt;</span># Instructions

Use a friendly tone and be helpful.

# Tools

## functions

namespace functions {

// Execute Python code and return the output. IMPORTANT: You MUST use print() to produce output. The code runs in a stateless environment. Example: print(random.randint(1,20)) NOT just random.randint(1,20)
type python = (_: {
// Python code to execute. ALWAYS use print() to show results. Example: print(random.randint(1,20)) will output the number. Just random.randint(1,20) will output nothing.
code: string,
}) => any;

} // namespace functions<span class="prompt-tag">&lt;|end|&gt;</span>
                            </div>
                            <div class="prompt-section">
<span class="prompt-tag">&lt;|start|&gt;user&lt;|message|&gt;</span>Use the python tool to roll a D20 dice and tell me what I rolled.<span class="prompt-tag">&lt;|end|&gt;</span>
                            </div>
                            <div class="prompt-section">
<span class="prompt-tag">&lt;|start|&gt;assistant</span>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="flow-step">
                    <h4><span class="step-number">2</span> Model's Response</h4>
                    <p>The model analyzes the request and calls the Python tool via the functions namespace:</p>
                    <div class="code-block">
<span class="channel-tag">&lt;|channel|&gt;analysis&lt;|message|&gt;</span>
The user says: "Use the python tool to roll a D20 dice and tell me what I rolled." 
I should use the python tool. That is allowed: The user request is to roll a 
20-sided die. So I will write code to print a random roll between 1 and 20. 
I must use print(). Also likely I should import random. According to the tool 
spec: The code to be executed is provided in a string. I need to return output 
from the python tool.

Thus, I should construct the python code string "import random\nprint(random.randint(1, 20))" 
and call the function. The result will be the roll. I should output the result. 
Use the code snippet.

I will just do that. And my final answer: "You rolled X." Where X is the number 
from python. That will be dynamic. But with the tool, we call function to produce 
output. So need to produce the code string. Let me do that.

We have to respond with the function call. The expected output will incorporate 
the function invocation. So I should produce code that calls functions.python({code: 
"import random\nprint(random.randint(1, 20))"}).

Thus final output should be a JSON function invocation.
<span class="channel-tag">&lt;|end|&gt;</span>
<span class="channel-tag">&lt;|start|&gt;assistant&lt;|channel|&gt;commentary to=functions.python &lt;|constrain|&gt;json&lt;|message|&gt;</span>
{"code":"import random\nprint(random.randint(1, 20))"}
<span class="channel-tag">&lt;|call|&gt;</span>
                    </div>
                </div>

                <div class="flow-step">
                    <h4><span class="step-number">3</span> Second LLM Call (After Tool)</h4>
                    <p>After the Python tool executes, the LLM is called again with the result:</p>
                    
                    <div class="prompt-display">
                        <div class="prompt-header">
                            <h5>Continuation After Tool Call</h5>
                            <span class="token-count">538 tokens</span>
                        </div>
                        <div class="prompt-content">
                            <div class="prompt-section">
<span class="prompt-tag">&lt;|start|&gt;system&lt;|message|&gt;</span>You are ChatGPT, a large language model trained by OpenAI.
Knowledge cutoff: 2024-06
Current date: 2025-08-17

Reasoning: high

# Valid channels: analysis, commentary, final. Channel must be included for every message.
Calls to these tools must go to the commentary channel: 'functions'.<span class="prompt-tag">&lt;|end|&gt;</span>
                            </div>
                            <div class="prompt-section">
<span class="prompt-tag">&lt;|start|&gt;developer&lt;|message|&gt;</span># Instructions

Use a friendly tone and be helpful.

# Tools

## functions

namespace functions {

// Execute Python code and return the output. IMPORTANT: You MUST use print() to produce output. The code runs in a stateless environment. Example: print(random.randint(1,20)) NOT just random.randint(1,20)
type python = (_: {
// Python code to execute. ALWAYS use print() to show results. Example: print(random.randint(1,20)) will output the number. Just random.randint(1,20) will output nothing.
code: string,
}) => any;

} // namespace functions<span class="prompt-tag">&lt;|end|&gt;</span>
                            </div>
                            <div class="prompt-section">
<span class="prompt-tag">&lt;|start|&gt;user&lt;|message|&gt;</span>Use the python tool to roll a D20 dice and tell me what I rolled.<span class="prompt-tag">&lt;|end|&gt;</span>
                            </div>
                            <div class="prompt-section">
<span class="prompt-tag">&lt;|start|&gt;assistant&lt;|channel|&gt;analysis&lt;|message|&gt;</span>The user says: "Use the python tool to roll a D20 dice and tell me what I rolled." 
I should use the python tool. That is allowed: The user request is to roll a 
20-sided die. So I will write code to print a random roll between 1 and 20. 
I must use print(). Also likely I should import random. According to the tool 
spec: The code to be executed is provided in a string. I need to return output 
from the python tool.

Thus, I should construct the python code string "import random\nprint(random.randint(1, 20))" 
and call the function. The result will be the roll. I should output the result. 
Use the code snippet.

I will just do that. And my final answer: "You rolled X." Where X is the number 
from python. That will be dynamic. But with the tool, we call function to produce 
output. So need to produce the code string. Let me do that.

We have to respond with the function call. The expected output will incorporate 
the function invocation. So I should produce code that calls functions.python({code: 
"import random\nprint(random.randint(1, 20))"}).

Thus final output should be a JSON function invocation.<span class="prompt-tag">&lt;|end|&gt;</span>
<span class="prompt-tag">&lt;|start|&gt;assistant&lt;|channel|&gt;commentary to=functions.python &lt;|constrain|&gt;json&lt;|message|&gt;</span>{"code":"import random\nprint(random.randint(1, 20))"}<span class="prompt-tag">&lt;|call|&gt;</span>
<span class="prompt-tag">&lt;|start|&gt;functions.python to=assistant&lt;|channel|&gt;commentary&lt;|message|&gt;</span>{"output": "15\n"}<span class="prompt-tag">&lt;|end|&gt;</span>
                            </div>
                            <div class="prompt-section">
<span class="prompt-tag">&lt;|start|&gt;assistant&lt;|message|&gt;</span>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="flow-step">
                    <h4><span class="step-number">4</span> Final Response</h4>
                    <p>The model formats the result into a user-friendly response:</p>
                    <div class="result-display">
                        <strong>Assistant:</strong> I rolled the D20 dice for you using Python, and you got a <strong>15</strong>!<br><br>
                        That's a great roll! Well above average (the average on a D20 is 10.5). In most 
                        tabletop RPGs, a 15 would likely succeed on many challenging tasks. Nice one! 
                    </div>
                </div>
            </div>

            <div class="arrow-down"></div>

            <div class="channel-breakdown">
                <h4 style="text-align: center; color: #ffd54f; margin-bottom: 30px;">Complete Channel Flow Breakdown</h4>
                
                <div class="channel-section">
                    <h5><span class="channel-icon"></span> Analysis Channel</h5>
                    <div class="channel-content">
                        The user says: "Use the python tool to roll a D20 dice and tell me what I rolled." 
                        I should use the python tool. That is allowed: The user request is to roll a 
                        20-sided die. So I will write code to print a random roll between 1 and 20. 
                        I must use print(). Also likely I should import random. According to the tool 
                        spec: The code to be executed is provided in a string. I need to return output 
                        from the python tool.
                        <br><br>
                        Thus, I should construct the python code string "import random\nprint(random.randint(1, 20))" 
                        and call the function. The result will be the roll. I should output the result.
                    </div>
                </div>

                <div class="channel-section">
                    <h5><span class="channel-icon"></span> Commentary Channel</h5>
                    <div class="channel-content">
                        <div class="tool-execution">
                            <div class="tool-call">
                                <strong>Tool Call:</strong> to=functions.python<br>
                                <strong>Parameters:</strong><br>
                                {<br>
                                &nbsp;&nbsp;"code": "import random\nprint(random.randint(1, 20))"<br>
                                }
                            </div>
                            <div class="tool-result">
                                <strong>Tool Response:</strong><br>
                                {"output": "15\n"}
                            </div>
                        </div>
                    </div>
                </div>

                <div class="channel-section">
                    <h5><span class="channel-icon"></span> Final Channel</h5>
                    <div class="channel-content">
                        I rolled the D20 dice for you using Python, and you got a <strong style="color: #4fc3f7;">15</strong>!
                        <br><br>
                        That's a great roll! Well above average (the average on a D20 is 10.5). In most 
                        tabletop RPGs, a 15 would likely succeed on many challenging tasks. Nice one! 
                    </div>
                </div>
            </div>

            <div class="tool-definition">
                <h5>Tool Definition in TypeScript</h5>
                <div class="code-block">
namespace functions {
    // Execute Python code and return the output. 
    // IMPORTANT: You MUST use print() to produce output. 
    // The code runs in a stateless environment.
    type python = (_: {
        // Python code to execute. ALWAYS use print() to show results.
        code: string,
    }) => any;
}
                </div>
                <p style="margin-top: 15px; color: #b3d9ff;">
                    <strong>Note:</strong> The Python tool is called via <code>functions.python</code> through the commentary channel, 
                    not through a dedicated Python channel. This is an important distinction in the HARMONY system.
                </p>
            </div>
        </div>

        <!-- Weather Tool Demo -->
        <div class="demo-area" id="weather-demo">
            <h2>Weather Tool: Getting NYC Weather</h2>
            
            <div class="info-box">
                <h5>About the Weather Tool</h5>
                <p>The Weather tool provides real-time weather information for any location. It's a function-based tool that the model can call with specific parameters.</p>
            </div>

            <div class="flow-visualization">
                <div class="flow-step">
                    <h4><span class="step-number">1</span> Initial LLM Call</h4>
                    <p>The user asks about the weather in New York City:</p>
                    
                    <div class="prompt-display">
                        <div class="prompt-header">
                            <h5>Initial Prompt</h5>
                            <span class="token-count">172 tokens</span>
                        </div>
                        <div class="prompt-content">
                            <div class="prompt-section">
<span class="prompt-tag">&lt;|start|&gt;system&lt;|message|&gt;</span>You are ChatGPT, a large language model trained by OpenAI.
Knowledge cutoff: 2024-06
Current date: 2025-08-17

Reasoning: high

# Valid channels: analysis, commentary, final. Channel must be included for every message.
Calls to these tools must go to the commentary channel: 'functions'.<span class="prompt-tag">&lt;|end|&gt;</span>
                            </div>
                            <div class="prompt-section">
<span class="prompt-tag">&lt;|start|&gt;developer&lt;|message|&gt;</span># Instructions

Use a friendly tone and be helpful.

# Tools

## functions

namespace functions {

// Gets the current weather in the provided location
type get_current_weather = (_: {
// The city or location to get weather for
location: string,
// Temperature format (default: celsius)
format?: "celsius" | "fahrenheit",
}) => any;

} // namespace functions<span class="prompt-tag">&lt;|end|&gt;</span>
                            </div>
                            <div class="prompt-section">
<span class="prompt-tag">&lt;|start|&gt;user&lt;|message|&gt;</span>What is the weather like in New York City?<span class="prompt-tag">&lt;|end|&gt;</span>
                            </div>
                            <div class="prompt-section">
<span class="prompt-tag">&lt;|start|&gt;assistant</span>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="flow-step">
                    <h4><span class="step-number">2</span> Model's Response</h4>
                    <p>The model analyzes the request and calls the weather function:</p>
                    <div class="code-block">
<span class="channel-tag">&lt;|channel|&gt;analysis&lt;|message|&gt;</span>
We need to fetch current weather in New York City. Use function 
get_current_weather with location "New York City". Also maybe 
specify default temperature format? Likely default celsius. 
We'll call function.
<span class="channel-tag">&lt;|end|&gt;</span>
<span class="channel-tag">&lt;|start|&gt;assistant&lt;|channel|&gt;commentary to=functions.get_current_weather &lt;|constrain|&gt;json&lt;|message|&gt;</span>
{"location":"New York City"}
<span class="channel-tag">&lt;|call|&gt;</span>
                    </div>
                </div>

                <div class="flow-step">
                    <h4><span class="step-number">3</span> Second LLM Call (After Tool)</h4>
                    <p>After the weather function returns data, the LLM is called again with the result:</p>
                    
                    <div class="prompt-display">
                        <div class="prompt-header">
                            <h5>Continuation After Tool Call</h5>
                            <span class="token-count">285 tokens</span>
                        </div>
                        <div class="prompt-content">
                            <div class="prompt-section">
<span class="prompt-tag">&lt;|start|&gt;system&lt;|message|&gt;</span>You are ChatGPT, a large language model trained by OpenAI.
Knowledge cutoff: 2024-06
Current date: 2025-08-17

Reasoning: high

# Valid channels: analysis, commentary, final. Channel must be included for every message.
Calls to these tools must go to the commentary channel: 'functions'.<span class="prompt-tag">&lt;|end|&gt;</span>
                            </div>
                            <div class="prompt-section">
<span class="prompt-tag">&lt;|start|&gt;developer&lt;|message|&gt;</span># Instructions

Use a friendly tone and be helpful.

# Tools

## functions

namespace functions {

// Gets the current weather in the provided location
type get_current_weather = (_: {
// The city or location to get weather for
location: string,
// Temperature format (default: celsius)
format?: "celsius" | "fahrenheit",
}) => any;

} // namespace functions<span class="prompt-tag">&lt;|end|&gt;</span>
                            </div>
                            <div class="prompt-section">
<span class="prompt-tag">&lt;|start|&gt;user&lt;|message|&gt;</span>What is the weather like in New York City?<span class="prompt-tag">&lt;|end|&gt;</span>
                            </div>
                            <div class="prompt-section">
<span class="prompt-tag">&lt;|start|&gt;assistant&lt;|channel|&gt;analysis&lt;|message|&gt;</span>We need to fetch current weather in New York City. Use function 
get_current_weather with location "New York City". Also maybe 
specify default temperature format? Likely default celsius. 
We'll call function.<span class="prompt-tag">&lt;|end|&gt;</span>
<span class="prompt-tag">&lt;|start|&gt;assistant&lt;|channel|&gt;commentary to=functions.get_current_weather &lt;|constrain|&gt;json&lt;|message|&gt;</span>{"location":"New York City"}<span class="prompt-tag">&lt;|call|&gt;</span>
<span class="prompt-tag">&lt;|return|&gt;</span>{"temperature": 12, "unit": "celsius", "condition": "rainy", "humidity": 88, "wind_speed": 22, "location": "New York City"}<span class="prompt-tag">&lt;|end|&gt;</span>
                            </div>
                            <div class="prompt-section">
<span class="prompt-tag">&lt;|start|&gt;assistant&lt;|message|&gt;</span>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="flow-step">
                    <h4><span class="step-number">4</span> Final Response</h4>
                    <p>The model formats the weather data into a friendly response:</p>
                    <div class="result-display">
                        <strong>Here's the latest weather snapshot for New York City (as of the most recent update):</strong><br><br>
                        
                        - <strong>Temperature:</strong> 12 C (about 54 F)<br>
                        - <strong>Condition:</strong> Light rain  a few clouds with scattered showers.<br>
                        - <strong>Humidity:</strong> ~88 %  a bit muggy.<br>
                        - <strong>Wind:</strong> 22 km/h ( 14 mph) from the southeast, so keep an umbrella handy.<br><br>
                        
                        It's a typical rainy weekday, so if you're heading out, a waterproof jacket and a sturdy pair of shoes will keep you comfortable. Let me know if you'd like a forecast for the next few days or tips on indoor activities!
                    </div>
                </div>
            </div>

            <div class="arrow-down"></div>

            <div class="channel-breakdown">
                <h4 style="text-align: center; color: #ffd54f; margin-bottom: 30px;">Complete Channel Flow Breakdown</h4>
                
                <div class="channel-section">
                    <h5><span class="channel-icon"></span> Analysis Channel</h5>
                    <div class="channel-content">
                        We need to fetch current weather in New York City. Use function 
                        get_current_weather with location "New York City". Also maybe 
                        specify default temperature format? Likely default celsius. 
                        We'll call function.
                    </div>
                </div>

                <div class="channel-section">
                    <h5><span class="channel-icon"></span> Commentary Channel</h5>
                    <div class="channel-content">
                        <div class="tool-execution">
                            <div class="tool-call">
                                <strong>Tool Call:</strong> to=functions.get_current_weather<br>
                                <strong>Parameters:</strong><br>
                                {<br>
                                &nbsp;&nbsp;"location": "New York City"<br>
                                }
                            </div>
                            <div class="tool-result">
                                <strong>Tool Response:</strong><br>
                                {<br>
                                &nbsp;&nbsp;"temperature": 12,<br>
                                &nbsp;&nbsp;"unit": "celsius",<br>
                                &nbsp;&nbsp;"condition": "rainy",<br>
                                &nbsp;&nbsp;"humidity": 88,<br>
                                &nbsp;&nbsp;"wind_speed": 22,<br>
                                &nbsp;&nbsp;"location": "New York City"<br>
                                }
                            </div>
                        </div>
                    </div>
                </div>

                <div class="channel-section">
                    <h5><span class="channel-icon"></span> Final Channel</h5>
                    <div class="channel-content">
                        Here's the latest weather snapshot for New York City (as of the most recent update):<br><br>
                        
                        - <strong>Temperature:</strong> 12 C (about 54 F)<br>
                        - <strong>Condition:</strong> Light rain  a few clouds with scattered showers.<br>
                        - <strong>Humidity:</strong> ~88 %  a bit muggy.<br>
                        - <strong>Wind:</strong> 22 km/h ( 14 mph) from the southeast, so keep an umbrella handy.<br><br>
                        
                        It's a typical rainy weekday, so if you're heading out, a waterproof jacket and a 
                        sturdy pair of shoes will keep you comfortable. Let me know if you'd like a forecast 
                        for the next few days or tips on indoor activities!
                    </div>
                </div>
            </div>

            <div class="tool-definition">
                <h5>Tool Definition in TypeScript</h5>
                <div class="code-block">
namespace functions {
    // Gets the current weather in the provided location
    type get_current_weather = (_: {
        // The city or location to get weather for
        location: string,
        // Temperature format (default: celsius)
        format?: "celsius" | "fahrenheit",
    }) => any;
}
                </div>
            </div>
        </div>

        <!-- Browser Tool Demo -->
        <div class="demo-area" id="browser-demo">
            <h2>Vision Browser Tool: Browsing Hacker News</h2>
            
            <div class="info-box">
                <h5>About the Vision Browser Tool</h5>
                <p>The Vision Browser tool allows the model to navigate to websites and extract their content. It operates through a channel-based communication system and can interact with web pages programmatically.</p>
            </div>

            <div class="flow-visualization">
                <div class="flow-step">
                    <h4><span class="step-number">1</span> Initial LLM Call</h4>
                    <p>The user asks to check Hacker News:</p>
                    
                    <div class="prompt-display">
                        <div class="prompt-header">
                            <h5>Initial Prompt</h5>
                            <span class="token-count">166 tokens</span>
                        </div>
                        <div class="prompt-content">
                            <div class="prompt-section">
<span class="prompt-tag">&lt;|start|&gt;system&lt;|message|&gt;</span>You are ChatGPT, a large language model trained by OpenAI.
Knowledge cutoff: 2024-06
Current date: 2025-08-17

Reasoning: high

# Valid channels: analysis, commentary, final. Channel must be included for every message.
Calls to these tools must go to the commentary channel: 'browser'.<span class="prompt-tag">&lt;|end|&gt;</span>
                            </div>
                            <div class="prompt-section">
<span class="prompt-tag">&lt;|start|&gt;developer&lt;|message|&gt;</span># Instructions

Use a friendly tone and be helpful.

# Browser tool

## browser

namespace browser {

type navigate = (_: {
// URL to navigate to
url: string,
}) => any;

} // namespace browser<span class="prompt-tag">&lt;|end|&gt;</span>
                            </div>
                            <div class="prompt-section">
<span class="prompt-tag">&lt;|start|&gt;user&lt;|message|&gt;</span>Please browse to Hacker News (news.ycombinator.com) and tell me what is currently on the front page. The browser will automatically extract the text content when you navigate there.<span class="prompt-tag">&lt;|end|&gt;</span>
                            </div>
                            <div class="prompt-section">
<span class="prompt-tag">&lt;|start|&gt;assistant</span>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="flow-step">
                    <h4><span class="step-number">2</span> Model's Response</h4>
                    <p>The model analyzes the request and calls the browser tool:</p>
                    <div class="code-block">
<span class="channel-tag">&lt;|channel|&gt;analysis&lt;|message|&gt;</span>
The user: "Please browse to Hacker News (news.ycombinator.com) 
and tell me what is currently on the front page. The browser 
will automatically extract the text content when you navigate 
there."

We have a browser tool. They want the current front page. We 
need to navigate to news.ycombinator.com, then read the content. 
The browser tool will extract the text content. So we can call 
browser.navigate with url: "https://news.ycombinator.com/".
<span class="channel-tag">&lt;|end|&gt;</span>
<span class="channel-tag">&lt;|start|&gt;assistant&lt;|channel|&gt;commentary to=browser.navigate &lt;|constrain|&gt;json&lt;|message|&gt;</span>
{"url":"https://news.ycombinator.com/"}
<span class="channel-tag">&lt;|call|&gt;</span>
                    </div>
                </div>

                <div class="flow-step">
                    <h4><span class="step-number">3</span> Second LLM Call (After Tool)</h4>
                    <p>After the browser extracts the page content, the LLM is called again:</p>
                    
                    <div class="prompt-display">
                        <div class="prompt-header">
                            <h5>Continuation After Tool Call</h5>
                            <span class="token-count">372 tokens</span>
                        </div>
                        <div class="prompt-content">
                            <div class="prompt-section">
<span class="prompt-tag">&lt;|start|&gt;system&lt;|message|&gt;</span>You are ChatGPT, a large language model trained by OpenAI.
Knowledge cutoff: 2024-06
Current date: 2025-08-17

Reasoning: high

# Valid channels: analysis, commentary, final. Channel must be included for every message.
Calls to these tools must go to the commentary channel: 'browser'.<span class="prompt-tag">&lt;|end|&gt;</span>
                            </div>
                            <div class="prompt-section">
<span class="prompt-tag">&lt;|start|&gt;developer&lt;|message|&gt;</span># Instructions

Use a friendly tone and be helpful.

# Browser tool

## browser

namespace browser {

type navigate = (_: {
// URL to navigate to
url: string,
}) => any;

} // namespace browser<span class="prompt-tag">&lt;|end|&gt;</span>
                            </div>
                            <div class="prompt-section">
<span class="prompt-tag">&lt;|start|&gt;user&lt;|message|&gt;</span>Please browse to Hacker News (news.ycombinator.com) and tell me what is currently on the front page. The browser will automatically extract the text content when you navigate there.<span class="prompt-tag">&lt;|end|&gt;</span>
                            </div>
                            <div class="prompt-section">
<span class="prompt-tag">&lt;|start|&gt;assistant&lt;|channel|&gt;analysis&lt;|message|&gt;</span>The user: "Please browse to Hacker News (news.ycombinator.com) 
and tell me what is currently on the front page. The browser 
will automatically extract the text content when you navigate 
there."

We have a browser tool. They want the current front page. We 
need to navigate to news.ycombinator.com, then read the content. 
The browser tool will extract the text content. So we can call 
browser.navigate with url: "https://news.ycombinator.com/".<span class="prompt-tag">&lt;|end|&gt;</span>
<span class="prompt-tag">&lt;|start|&gt;assistant&lt;|channel|&gt;commentary to=browser.navigate &lt;|constrain|&gt;json&lt;|message|&gt;</span>{"url":"https://news.ycombinator.com/"}<span class="prompt-tag">&lt;|call|&gt;</span>
<span class="prompt-tag">&lt;|return|&gt;</span>[Extracted page content with front page stories, comments, and metadata...]<span class="prompt-tag">&lt;|end|&gt;</span>
                            </div>
                            <div class="prompt-section">
<span class="prompt-tag">&lt;|start|&gt;assistant&lt;|message|&gt;</span>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="flow-step">
                    <h4><span class="step-number">4</span> Final Response</h4>
                    <p>The model formats a helpful summary of the front page:</p>
                    <div class="result-display">
                        <strong>Current Hacker News Front Page Highlights:</strong><br><br>
                        <strong>Top Stories:</strong><br>
                        1. <strong>"Why I'm Building in Rust in 2025"</strong> (234 points, 89 comments)<br>
                           <span style="color: #b3d9ff;">A developer shares their journey choosing Rust for a new startup</span><br><br>
                        
                        2. <strong>"OpenAI Announces GPT-5 Timeline"</strong> (189 points, 156 comments)<br>
                           <span style="color: #b3d9ff;">Breaking news about the next generation of language models</span><br><br>
                        
                        3. <strong>"The Hidden Cost of Microservices"</strong> (167 points, 43 comments)<br>
                           <span style="color: #b3d9ff;">An engineering team's lessons learned from their architecture migration</span><br><br>
                        
                        4. <strong>"Show HN: I Built a Terminal-Based Email Client"</strong> (145 points, 67 comments)<br>
                           <span style="color: #b3d9ff;">A developer showcases their minimalist email solution</span><br><br>
                        
                        5. <strong>"PostgreSQL 17 Performance Improvements"</strong> (132 points, 28 comments)<br>
                           <span style="color: #b3d9ff;">Deep dive into the latest database performance enhancements</span><br><br>
                        
                        The front page shows strong interest in systems programming (Rust), AI developments, 
                        and architectural discussions. The community is particularly engaged with the OpenAI 
                        announcement, with over 150 comments discussing implications for the industry! 
                    </div>
                </div>
            </div>

            <div class="arrow-down"></div>

            <div class="channel-breakdown">
                <h4 style="text-align: center; color: #ffd54f; margin-bottom: 30px;">Complete Channel Flow Breakdown</h4>
                
                <div class="channel-section">
                    <h5><span class="channel-icon"></span> Analysis Channel</h5>
                    <div class="channel-content">
                        The user: "Please browse to Hacker News (news.ycombinator.com) 
                        and tell me what is currently on the front page. The browser 
                        will automatically extract the text content when you navigate 
                        there."<br><br>
                        
                        We have a browser tool. They want the current front page. We 
                        need to navigate to news.ycombinator.com, then read the content. 
                        The browser tool will extract the text content. So we can call 
                        browser.navigate with url: "https://news.ycombinator.com/".
                    </div>
                </div>

                <div class="channel-section">
                    <h5><span class="channel-icon"></span> Commentary Channel</h5>
                    <div class="channel-content">
                        <div class="tool-execution">
                            <div class="tool-call">
                                <strong>Tool Call:</strong> to=browser.navigate<br>
                                <strong>Parameters:</strong><br>
                                {<br>
                                &nbsp;&nbsp;"url": "https://news.ycombinator.com/"<br>
                                }
                            </div>
                            <div class="tool-result">
                                <strong>Tool Response:</strong><br>
                                [Page content with front page stories extracted...]
                            </div>
                        </div>
                    </div>
                </div>

                <div class="channel-section">
                    <h5><span class="channel-icon"></span> Final Channel</h5>
                    <div class="channel-content">
                        Current Hacker News Front Page Highlights:<br><br>
                        
                        <strong>Top Stories:</strong><br>
                        1. <strong>"Why I'm Building in Rust in 2025"</strong> (234 points, 89 comments)<br>
                        2. <strong>"OpenAI Announces GPT-5 Timeline"</strong> (189 points, 156 comments)<br>
                        3. <strong>"The Hidden Cost of Microservices"</strong> (167 points, 43 comments)<br>
                        4. <strong>"Show HN: I Built a Terminal-Based Email Client"</strong> (145 points, 67 comments)<br>
                        5. <strong>"PostgreSQL 17 Performance Improvements"</strong> (132 points, 28 comments)<br><br>
                        
                        The front page shows strong interest in systems programming (Rust), AI developments, 
                        and architectural discussions. The community is particularly engaged with the OpenAI 
                        announcement, with over 150 comments discussing implications for the industry! 
                    </div>
                </div>
            </div>

            <div class="tool-definition">
                <h5>Tool Definition in TypeScript</h5>
                <div class="code-block">
namespace browser {
    // Navigate to a URL and extract content
    type navigate = (_: {
        // URL to navigate to
        url: string,
    }) => {
        content: string,     // Extracted text content
        title: string,       // Page title
        links: string[],     // Available links on page
        status: number       // HTTP status code
    };
    
    // Additional browser capabilities
    type click = (_: { selector: string }) => any;
    type type = (_: { selector: string, text: string }) => any;
    type screenshot = () => { image: string };
}
                </div>
            </div>
        </div>

        <!-- Key Concepts Summary -->
        <div class="demo-area" id="concepts-summary" style="display: block; margin-top: 60px;">
            <h2> Key HARMONY Concepts</h2>
            
            <div class="flow-visualization">
                <div class="flow-step">
                    <h4><span class="step-number"></span> Channels</h4>
                    <p>HARMONY uses channels to organize different types of model outputs:</p>
                    <ul style="margin-top: 10px; padding-left: 20px;">
                        <li><strong>analysis</strong> - Internal reasoning and planning</li>
                        <li><strong>commentary</strong> - Tool invocations and interactions</li>
                        <li><strong>final</strong> - User-facing responses</li>
                        <li><strong>python/browser</strong> - Channel-based tool communication</li>
                    </ul>
                </div>

                <div class="flow-step">
                    <h4><span class="step-number"></span> Tool Types</h4>
                    <p>HARMONY supports two main types of tools:</p>
                    <ul style="margin-top: 10px; padding-left: 20px;">
                        <li><strong>Function Tools</strong> - Called via commentary channel to the functions namespace (e.g., functions.python, functions.get_current_weather)</li>
                        <li><strong>Channel Tools</strong> - Have dedicated channels for direct communication (e.g., browser channel for vision browser)</li>
                    </ul>
                    <p style="margin-top: 10px; font-style: italic; color: #b3d9ff;">
                        Note: In this demo, Python is actually a function tool (functions.python), not a channel tool!
                    </p>
                </div>

                <div class="flow-step">
                    <h4><span class="step-number"></span> Generation Flow</h4>
                    <p>The typical HARMONY generation flow:</p>
                    <ol style="margin-top: 10px; padding-left: 20px;">
                        <li>Analyze request in analysis channel</li>
                        <li>Invoke tools via appropriate channels</li>
                        <li>Process tool results</li>
                        <li>Generate final response for user</li>
                    </ol>
                </div>

                <div class="flow-step">
                    <h4><span class="step-number"></span> Safety & Control</h4>
                    <p>HARMONY provides structured control over model behavior:</p>
                    <ul style="margin-top: 10px; padding-left: 20px;">
                        <li>Explicit tool definitions and constraints</li>
                        <li>Sandboxed execution environments</li>
                        <li>Clear separation of reasoning and actions</li>
                        <li>Traceable decision-making process</li>
                    </ul>
                </div>
            </div>
            
            <div class="info-box" style="margin-top: 40px;">
                <h5>Learn More</h5>
                <p>This demo showcases just a small part of HARMONY's capabilities. The system supports many more tools, complex multi-step workflows, and sophisticated reasoning patterns. The channel-based architecture ensures transparency and control while enabling powerful AI assistance.</p>
            </div>
        </div>
    </div>

    <script>
        let currentDemo = null;

        function showDemo(tool) {
            // Hide all demos
            document.querySelectorAll('.demo-area').forEach(area => {
                area.classList.remove('active');
            });
            
            // Remove active state from all cards
            document.querySelectorAll('.tool-card').forEach(card => {
                card.classList.remove('active');
            });
            
            // Show selected demo
            const demoId = `${tool}-demo`;
            const demo = document.getElementById(demoId);
            const card = document.getElementById(`${tool}-card`);
            
            if (demo && card) {
                demo.classList.add('active');
                card.classList.add('active');
                
                // Reset animations
                demo.querySelectorAll('.flow-step').forEach((step, index) => {
                    step.style.animation = 'none';
                    setTimeout(() => {
                        step.style.animation = `slideUp 0.5s ease-out forwards`;
                        step.style.animationDelay = `${(index + 1) * 0.1}s`;
                    }, 10);
                });
            }
            
            currentDemo = tool;
        }
        
        // Add hover effects for code blocks
        document.addEventListener('DOMContentLoaded', () => {
            const codeBlocks = document.querySelectorAll('.code-block');
            codeBlocks.forEach(block => {
                block.addEventListener('mouseenter', function() {
                    this.style.transform = 'scale(1.02)';
                    this.style.transition = 'transform 0.2s ease';
                });
                
                block.addEventListener('mouseleave', function() {
                    this.style.transform = 'scale(1)';
                });
            });
            
            // Add copy functionality (visual only for this demo)
            codeBlocks.forEach(block => {
                const copyButton = document.createElement('div');
                copyButton.innerHTML = '';
                copyButton.style.cssText = `
                    position: absolute;
                    top: 10px;
                    right: 10px;
                    cursor: pointer;
                    opacity: 0;
                    transition: opacity 0.2s;
                    background: rgba(79,195,247,0.2);
                    padding: 5px 10px;
                    border-radius: 4px;
                `;
                
                block.style.position = 'relative';
                block.appendChild(copyButton);
                
                block.addEventListener('mouseenter', () => {
                    copyButton.style.opacity = '1';
                });
                
                block.addEventListener('mouseleave', () => {
                    copyButton.style.opacity = '0';
                });
                
                copyButton.addEventListener('click', () => {
                    copyButton.innerHTML = '';
                    setTimeout(() => {
                        copyButton.innerHTML = '';
                    }, 1000);
                });
            });
        });
        
        // Smooth scroll animation
        document.querySelectorAll('a[href^="#"]').forEach(anchor => {
            anchor.addEventListener('click', function (e) {
                e.preventDefault();
                const target = document.querySelector(this.getAttribute('href'));
                if (target) {
                    target.scrollIntoView({
                        behavior: 'smooth',
                        block: 'start'
                    });
                }
            });
        });
    </script>
</body>
</html>
</file_artifact>

<file path="GPT-OSS-HARMONY-REFERENCE-REPO/harmony_vllm_app.py">
#!/usr/bin/env python3
"""
HARMONY vLLM Demo Application
Uses OpenAI's official harmony renderer library to properly format prompts
"""

from flask import Flask, render_template, request, jsonify, Response, send_from_directory
import json
import requests
from typing import List, Dict, Any, Optional
import logging
from dataclasses import dataclass, asdict
from datetime import datetime
import random
import re
import asyncio
# from browser_tool_wrapper import browser_tool_wrapper  # Removed old browser
# from custom_browser_instruction import BROWSER_INSTRUCTION  # Removed old browser
from python_tool_wrapper import python_tool_wrapper
from python_function_wrapper import PythonFunctionTool
from custom_python_instruction import PYTHON_INSTRUCTION
from official_python_instruction import OFFICIAL_PYTHON_INSTRUCTION
# from official_browser_instruction import OFFICIAL_BROWSER_INSTRUCTION  # Removed old browser
from builtin_tool_instructions import get_builtin_tools_instruction

# Import harmony components
from openai_harmony import (
    Author,
    Conversation,
    DeveloperContent,
    HarmonyEncodingName,
    Message,
    Role,
    SystemContent,
    ToolDescription,
    load_harmony_encoding,
    ReasoningEffort,
    StreamableParser
)

app = Flask(__name__)
logging.basicConfig(level=logging.INFO)

# vLLM server configuration
VLLM_BASE_URL = "http://localhost:8000"
MODEL_NAME = "openai/gpt-oss-20b"

# Load harmony encoding
try:
    encoding = load_harmony_encoding(HarmonyEncodingName.HARMONY_GPT_OSS)
    logging.info("Harmony encoding loaded successfully")
    
    # Debug: Check available attributes
    logging.info(f"Encoding attributes: {dir(encoding)}")
    
    # Try to get special tokens
    if hasattr(encoding, 'special_tokens'):
        logging.info(f"Has special_tokens method")
    elif hasattr(encoding, 'special_tokens_set'):
        logging.info(f"Has special_tokens_set attribute")
    else:
        logging.warning("No special tokens attribute found")
        
except Exception as e:
    logging.error(f"Failed to load harmony encoding: {e}")
    encoding = None

@dataclass
class ConversationState:
    """Maintains conversation state"""
    messages: List[Message]
    system_config: Dict[str, Any]
    developer_config: Dict[str, Any]
    
conversation_state = ConversationState(messages=[], system_config={}, developer_config={})

# Vision browser instance will be created on demand
_vision_browser_instance = None


# Removed old browser system message function


def create_system_message_with_builtin_tools(data: Dict[str, Any]) -> str:
    """Create system message with built-in tools in the correct format"""
    model_identity = data.get('model_identity', 'You are ChatGPT, a large language model trained by OpenAI.')
    knowledge_cutoff = data.get('knowledge_cutoff', '2024-06')
    current_date = data.get('current_date', datetime.now().strftime("%Y-%m-%d"))
    reasoning_level = data.get('reasoning_level', 'HIGH')
    
    # Build the system message parts
    system_parts = []
    system_parts.append(model_identity)
    system_parts.append(f"\nKnowledge cutoff: {knowledge_cutoff}")
    system_parts.append(f"\nCurrent date: {current_date}")
    
    # Add reasoning level only if not "o1" (default)
    if reasoning_level and reasoning_level.upper() != "O1":
        system_parts.append(f"\nReasoning: {reasoning_level.lower()}")
    
    # Add valid channels line
    system_parts.append("\n\n# Valid channels: analysis, commentary, final. Channel must be included for every message.")
    
    # Add the tools line if there are function tools
    tools = data.get('tools', [])
    if tools:
        system_parts.append("\nCalls to these tools must go to the commentary channel: 'functions'.")
    
    return "".join(system_parts)

# Update Python timeout constant
PYTHON_TIMEOUT = 120  # 120 seconds as per spec

# Fake weather database
WEATHER_DATA = {
    "San Francisco, CA": {"temp_c": 18, "temp_f": 64, "condition": "foggy", "humidity": 75, "wind_speed": 15},
    "New York, NY": {"temp_c": 22, "temp_f": 72, "condition": "partly cloudy", "humidity": 60, "wind_speed": 10},
    "Tokyo": {"temp_c": 26, "temp_f": 79, "condition": "sunny", "humidity": 55, "wind_speed": 8},
    "London": {"temp_c": 16, "temp_f": 61, "condition": "rainy", "humidity": 85, "wind_speed": 20},
    "Paris": {"temp_c": 20, "temp_f": 68, "condition": "cloudy", "humidity": 65, "wind_speed": 12},
    "Sydney": {"temp_c": 24, "temp_f": 75, "condition": "sunny", "humidity": 50, "wind_speed": 18},
}

def get_fake_weather(location: str, format: str = "celsius") -> Dict[str, Any]:
    """Get fake weather data for a location"""
    # Normalize location
    location = location.strip()
    
    # Check if we have data for this location
    if location in WEATHER_DATA:
        data = WEATHER_DATA[location]
    else:
        # Generate random weather for unknown locations
        data = {
            "temp_c": random.randint(10, 35),
            "temp_f": random.randint(50, 95),
            "condition": random.choice(["sunny", "cloudy", "rainy", "foggy", "partly cloudy"]),
            "humidity": random.randint(30, 90),
            "wind_speed": random.randint(5, 25),
        }
    
    # Format response based on requested format
    if format == "fahrenheit":
        return {
            "temperature": data["temp_f"],
            "unit": "fahrenheit",
            "condition": data["condition"],
            "humidity": data["humidity"],
            "wind_speed": data["wind_speed"],
            "location": location
        }
    else:
        return {
            "temperature": data["temp_c"],
            "unit": "celsius",
            "condition": data["condition"],
            "humidity": data["humidity"],
            "wind_speed": data["wind_speed"],
            "location": location
        }

def validate_weather_params(params: Dict[str, Any]) -> tuple[bool, Optional[str]]:
    """Validate weather API parameters"""
    if not isinstance(params, dict):
        return False, "Parameters must be a JSON object"
    
    if "location" not in params:
        return False, "Missing required parameter: location"
    
    if not isinstance(params["location"], str):
        return False, "Location must be a string"
    
    if "format" in params and params["format"] not in ["celsius", "fahrenheit"]:
        return False, f"Invalid format: {params['format']}. Must be 'celsius' or 'fahrenheit'"
    
    return True, None

# Removed old browser tool execution function

def execute_tool_call(tool_name: str, params: Dict[str, Any]) -> Dict[str, Any]:
    """Execute a tool call and return the result"""
    
    # Handle Python tool (built-in)
    if tool_name == "python":
        script = params.get("script", params.get("code", ""))
        if not script:
            return {"error": "Python tool requires 'script' parameter"}
        
        # Run async function in sync context
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            result = loop.run_until_complete(
                python_tool_wrapper.execute(script)
            )
            return {"output": result}
        finally:
            loop.close()
    
    # Handle Python as a function tool
    elif tool_name == "functions.python":
        python_func_tool = PythonFunctionTool()
        return python_func_tool.handle_tool_call(params)
    
    # Handle vision browser tool
    elif tool_name == "functions.browser":
        try:
            from vision_browser_wrapper import VisionBrowserWrapper
            # Use a global instance to maintain browser state
            global _vision_browser_instance
            if _vision_browser_instance is None:
                _vision_browser_instance = VisionBrowserWrapper(mock_mode=False)  # Use real browser
            return _vision_browser_instance.execute(params)
        except ImportError:
            return {"error": "Vision browser tool not available. Install with: pip install selenium helium pillow"}
    
    # Handle weather functions
    elif tool_name == "functions.get_current_weather":
        valid, error = validate_weather_params(params)
        if not valid:
            return {"error": error}
        
        location = params["location"]
        format = params.get("format", "celsius")
        return get_fake_weather(location, format)
    
    elif tool_name == "functions.get_location":
        # Fake user location
        return {"location": "San Francisco, CA", "country": "United States"}
    
    elif tool_name == "functions.get_multiple_weathers":
        if "locations" not in params:
            return {"error": "Missing required parameter: locations"}
        
        if not isinstance(params["locations"], list):
            return {"error": "Locations must be an array"}
        
        format = params.get("format", "celsius")
        results = []
        for location in params["locations"]:
            if isinstance(location, str):
                results.append(get_fake_weather(location, format))
            else:
                results.append({"error": f"Invalid location: {location}"})
        
        return {"locations": results}
    
    # Removed old browser tool calls
    
    else:
        return {"error": f"Unknown tool: {tool_name}"}

def extract_tool_calls(text: str) -> List[Dict[str, Any]]:
    """Extract tool calls from model output"""
    tool_calls = []
    
    # Pattern for commentary channel (functions.*)
    # More lenient - capture everything after <|message|> until we hit another <|start|> or end
    commentary_pattern = r'<\|channel\|>commentary\s+to=([\w\.]+).*?<\|message\|>(.*?)(?:<\|call\|>|<\|end\|>|<\|start\|>|$)'
    
    # Pattern for analysis channel (browser.*)
    analysis_pattern = r'<\|channel\|>analysis\s+to=([\w\.]+).*?<\|message\|>(.*?)(?:<\|call\|>|<\|end\|>|<\|start\|>|$)'
    
    # Find all matches for both patterns
    all_matches = []
    
    # Commentary channel matches
    matches = re.findall(commentary_pattern, text, re.DOTALL)
    for recipient, content in matches:
        all_matches.append((recipient, content, "commentary"))
    
    # Analysis channel matches
    matches = re.findall(analysis_pattern, text, re.DOTALL)
    for recipient, content in matches:
        all_matches.append((recipient, content, "analysis"))
    
    for recipient, content, channel in all_matches:
        content = content.strip()
        
        # Special handling for Python tool - it takes raw code, not JSON
        if recipient == "python":
            tool_calls.append({
                "tool": recipient,
                "params": {"script": content},
                "raw_content": content,
                "channel": channel
            })
            continue
        
        # Clean up content - sometimes it includes extra protocol text
        # Try to extract JSON - look for balanced braces
        brace_count = 0
        json_start = -1
        json_end = -1
        
        for i, char in enumerate(content):
            if char == '{':
                if json_start == -1:
                    json_start = i
                brace_count += 1
            elif char == '}':
                brace_count -= 1
                if brace_count == 0 and json_start != -1:
                    json_end = i + 1
                    break
        
        if json_start != -1 and json_end != -1:
            json_content = content[json_start:json_end]
            try:
                params = json.loads(json_content)
                tool_calls.append({
                    "tool": recipient,
                    "params": params,
                    "raw_content": content,
                    "channel": channel
                })
                continue
            except json.JSONDecodeError:
                pass
        
        # If not valid JSON, skip this tool call
        logging.warning(f"Skipping invalid tool call for {recipient}: {content[:100]}...")
    
    logging.info(f"Extracted {len(tool_calls)} tool calls from text")
    if tool_calls:
        logging.info(f"Tool calls: {tool_calls}")
    return tool_calls

def extract_final_content(raw_response: str) -> str:
    """Extract only the final channel content from raw HARMONY response"""
    # First try to find content in final channel
    pattern = r'<\|channel\|>final<\|message\|>(.*?)(?:<\|return\|>|<\|end\|>|$)'
    matches = re.findall(pattern, raw_response, re.DOTALL)
    if matches:
        return matches[-1].strip()
    
    # If no final channel, check if this is a continuation response
    # Look for content after the last <|end|>
    if '<|end|>' in raw_response:
        parts = raw_response.split('<|end|>')
        # Get the last non-empty part
        for part in reversed(parts):
            clean_part = part.strip()
            # Skip if it's empty or starts with special tokens
            if clean_part and not clean_part.startswith('<|') and not clean_part.startswith('{'):
                # This is likely the final user-facing message
                return clean_part
    
    return ""

def filter_cot_from_content(content: str) -> str:
    """Remove analysis channel content from assistant messages for conversation history"""
    # Remove everything between <|channel|>analysis and <|channel|>final
    pattern = r'<\|channel\|>analysis.*?(?=<\|channel\|>final)'
    filtered = re.sub(pattern, '', content, flags=re.DOTALL)
    
    # Also remove standalone analysis blocks
    pattern2 = r'<\|channel\|>analysis.*?<\|end\|>'
    filtered = re.sub(pattern2, '', filtered, flags=re.DOTALL)
    
    return filtered.strip()

def normalize_stop_token(response: str) -> str:
    """Normalize stop tokens - convert <|return|> to <|end|>"""
    return response.replace('<|return|>', '<|end|>')

@app.route('/')
def index():
    """Serve the main HTML interface"""
    return render_template('harmony_demo.html')

@app.route('/test')
def test():
    """Serve the test page"""
    return send_from_directory('.', 'test_tools.html')

@app.route('/test2')
def test2():
    """Serve the frontend test page"""
    return send_from_directory('.', 'test_frontend.html')

@app.route('/demos/d20')
def d20_demo():
    """Serve the D20 demo"""
    return send_from_directory('.', 'd20_demo.html')

@app.route('/demos/d20-detailed')
def d20_demo_detailed():
    """Serve the detailed D20 demo"""
    return send_from_directory('.', 'd20_demo_detailed.html')

@app.route('/demos/compare')
def serve_compare():
    """Serve the comparison HTML"""
    return send_from_directory('.', 'compare_approaches.html')

@app.route('/demos/d20-cycling')
def serve_d20_cycling():
    """Serve the D20 demo with cycling examples"""
    return send_from_directory('.', 'd20_demo_cycling.html')

@app.route('/api/check_server', methods=['GET'])
def check_server():
    """Check if vLLM server is accessible"""
    try:
        response = requests.get(f"{VLLM_BASE_URL}/v1/models")
        return jsonify({
            "status": "connected",
            "models": response.json()
        })
    except Exception as e:
        return jsonify({
            "status": "error",
            "error": str(e)
        }), 500

@app.route('/api/tokenize', methods=['POST'])
def tokenize():
    """Tokenize text using harmony encoding"""
    if not encoding:
        return jsonify({"error": "Harmony encoding not loaded"}), 500
    
    try:
        text = request.json.get('text', '')
        # Try different methods to encode with special tokens
        try:
            # Try the encode method with allowed_special parameter
            tokens = list(encoding.encode(text, allowed_special="all"))
        except:
            try:
                # Try just encode without parameters
                tokens = list(encoding.encode(text))
            except Exception as e:
                return jsonify({"error": f"Failed to encode text: {str(e)}"}), 500
        
        token_texts = [encoding.decode([t]) for t in tokens]
        
        # Get special tokens if available
        special_tokens = {}
        if hasattr(encoding, 'special_tokens'):
            try:
                special_tokens = {k: v for k, v in encoding.special_tokens().items()}
            except:
                special_tokens = list(encoding.special_tokens) if hasattr(encoding.special_tokens, '__iter__') else {}
        elif hasattr(encoding, 'special_tokens_set'):
            # It's a set, not a dict
            special_tokens = list(encoding.special_tokens_set)
        
        return jsonify({
            "tokens": tokens,
            "token_texts": token_texts,
            "special_tokens": special_tokens
        })
    except Exception as e:
        return jsonify({"error": str(e)}), 500

def safe_json_serialize(obj):
    """Convert objects to JSON-serializable format"""
    if hasattr(obj, '__dict__'):
        return obj.__dict__
    elif hasattr(obj, '_asdict'):
        return obj._asdict()
    else:
        return str(obj)

@app.route('/api/render_prompt', methods=['POST'])
def render_prompt():
    """Render the full prompt using harmony"""
    if not encoding:
        return jsonify({"error": "Harmony encoding not loaded"}), 500
    
    try:
        data = request.json
        
        # Check if built-in tools are enabled
        include_python = data.get('include_python', False)
        include_browser = data.get('include_browser', False)
        
        if include_python or include_browser:
            # Use custom system message with built-in tools
            system_text = create_system_message_with_builtin_tools(data)
            system_message = Message.from_role_and_content(Role.SYSTEM, system_text)
        else:
            # Use standard system message
            system_message = (
                SystemContent.new()
                .with_model_identity(data.get('model_identity', 'You are ChatGPT, a large language model trained by OpenAI.'))
                .with_reasoning_effort(ReasoningEffort[data.get('reasoning_level', 'HIGH').upper()])
                .with_conversation_start_date(data.get('current_date', datetime.now().strftime("%Y-%m-%d")))
                .with_knowledge_cutoff(data.get('knowledge_cutoff', '2024-06'))
                .with_required_channels(["analysis", "commentary", "final"])
            )
        
        # Create developer message
        developer_message = DeveloperContent.new()
        
        # Add regular instructions
        instructions_parts = []
        if data.get('instructions'):
            instructions_parts.append(data['instructions'])
        
        # Add built-in tool instructions if enabled
        if include_python or include_browser:
            from builtin_tool_instructions import get_builtin_tools_instruction
            builtin_instructions = get_builtin_tools_instruction(
                include_python=include_python,
                include_browser=include_browser
            )
            if builtin_instructions:
                instructions_parts.append(builtin_instructions)
        
        # Combine all instructions
        if instructions_parts:
            combined_instructions = '\n\n'.join(instructions_parts)
            developer_message = developer_message.with_instructions(combined_instructions)
        
        # Get function tool descriptions for developer message
        tools = data.get('tools', [])
        
        tool_descriptions = []
        for tool in tools:
            td = ToolDescription.new(
                tool['name'],
                tool['description'],
                parameters=tool.get('parameters', {})
            )
            tool_descriptions.append(td)
        
        # Add function tools to developer message if any are available
        if tool_descriptions:
            # Try different method names
            try:
                developer_message = developer_message.with_function_tools(tool_descriptions)
            except AttributeError:
                try:
                    developer_message = developer_message.with_tools(tool_descriptions)
                except AttributeError:
                    logging.warning("Could not add tools to developer message")
        
        # Build conversation
        if include_python or include_browser:
            # system_message is already a Message object
            messages = [
                system_message,
                Message.from_role_and_content(Role.DEVELOPER, developer_message)
            ]
        else:
            messages = [
                Message.from_role_and_content(Role.SYSTEM, system_message),
                Message.from_role_and_content(Role.DEVELOPER, developer_message)
            ]
        
        # Add conversation history with CoT filtering
        for msg in data.get('conversation_history', []):
            if msg['role'] == 'user':
                messages.append(Message.from_role_and_content(Role.USER, msg['content']))
            elif msg['role'] == 'assistant':
                # Filter out CoT from assistant messages
                filtered_content = filter_cot_from_content(msg['content'])
                if filtered_content:  # Only add if there's content after filtering
                    assistant_msg = Message.from_role_and_content(Role.ASSISTANT, filtered_content)
                    if 'channel' in msg:
                        assistant_msg = assistant_msg.with_channel(msg['channel'])
                    if 'recipient' in msg:
                        assistant_msg = assistant_msg.with_recipient(msg['recipient'])
                    if 'content_type' in msg:
                        assistant_msg = assistant_msg.with_content_type(msg['content_type'])
                    messages.append(assistant_msg)
            elif msg['role'] == 'tool':
                # Handle tool messages
                tool_msg = Message.from_author_and_content(
                    Author.new(Role.TOOL, msg.get('name', 'tool')),
                    msg['content']
                )
                if 'recipient' in msg:
                    tool_msg = tool_msg.with_recipient(msg['recipient'])
                if 'channel' in msg:
                    tool_msg = tool_msg.with_channel(msg['channel'])
                messages.append(tool_msg)
        
        # Add current user message or messages array
        if data.get('current_message'):
            messages.append(Message.from_role_and_content(Role.USER, data['current_message']))
        elif data.get('messages'):
            # Handle messages array format
            for msg in data['messages']:
                if msg['role'] == 'user':
                    messages.append(Message.from_role_and_content(Role.USER, msg['content']))
        
        # Create conversation
        conversation = Conversation.from_messages(messages)
        
        # Render to tokens
        tokens = encoding.render_conversation_for_completion(conversation, Role.ASSISTANT)
        
        # Convert tokens to text for display
        prompt_text = encoding.decode(tokens)
        
        # Don't add constrain token - we want the model to use channel format, not JSON
        
        # Also get token details
        token_texts = [encoding.decode([t]) for t in tokens]
        
        # Ensure everything is JSON serializable
        response_data = {
            "prompt": prompt_text,
            "tokens": [int(t) for t in tokens],  # Ensure tokens are ints
            "token_texts": token_texts,
            "token_count": len(tokens)
        }
        
        return jsonify(response_data)
        
    except Exception as e:
        logging.error(f"Error rendering prompt: {e}")
        logging.error(f"Error type: {type(e)}")
        import traceback
        logging.error(f"Traceback: {traceback.format_exc()}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/execute_tool', methods=['POST'])
def execute_tool():
    """Execute a tool call"""
    try:
        data = request.json
        tool_name = data.get('tool')
        params = data.get('params', {})
        
        if not tool_name:
            return jsonify({"error": "Missing tool name"}), 400
        
        result = execute_tool_call(tool_name, params)
        
        return jsonify({
            "tool": tool_name,
            "params": params,
            "result": result
        })
    except Exception as e:
        logging.error(f"Error executing tool: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/chat', methods=['POST'])
def chat():
    """Send chat request to vLLM server with harmony formatting"""
    if not encoding:
        return jsonify({"error": "Harmony encoding not loaded"}), 500
    
    # Track all prompts sent during this request
    prompts_sent = []
    
    try:
        data = request.json
        
        # Don't call render_prompt() directly as it creates a Flask response
        # Instead, inline the rendering logic here
        try:
            # Check if built-in tools are enabled
            include_python = data.get('include_python', False)
            include_browser = data.get('include_browser', False)
            
            if include_python or include_browser:
                # Use custom system message with built-in tools
                system_text = create_system_message_with_builtin_tools(data)
                system_message = Message.from_role_and_content(Role.SYSTEM, system_text)
            else:
                # Use standard system message
                system_message = (
                    SystemContent.new()
                    .with_model_identity(data.get('model_identity', 'You are ChatGPT, a large language model trained by OpenAI.'))
                    .with_reasoning_effort(ReasoningEffort[data.get('reasoning_level', 'HIGH').upper()])
                    .with_conversation_start_date(data.get('current_date', datetime.now().strftime("%Y-%m-%d")))
                    .with_knowledge_cutoff(data.get('knowledge_cutoff', '2024-06'))
                    .with_required_channels(["analysis", "commentary", "final"])
                )
            
            # Create developer message
            developer_message = DeveloperContent.new()
            if data.get('instructions'):
                developer_message = developer_message.with_instructions(data['instructions'])
            
            # Get function tool descriptions
            tools = data.get('tools', [])
            
            # Add vision browser to tools if include_browser is True
            if include_browser:
                # Add vision browser to tools list if not already present
                if not any(t.get('name') == 'browser' for t in tools):
                    from vision_browser_wrapper import VisionBrowserWrapper
                    wrapper = VisionBrowserWrapper(mock_mode=False)  # Use real browser
                    browser_def = wrapper.get_tool_definition()
                    tools.append(browser_def)
            
            tool_descriptions = []
            for tool in tools:
                td = ToolDescription.new(
                    tool['name'],
                    tool['description'],
                    parameters=tool.get('parameters', {})
                )
                tool_descriptions.append(td)
            
            # Add function tools to developer message if any are available
            if tool_descriptions:
                try:
                    developer_message = developer_message.with_function_tools(tool_descriptions)
                except AttributeError:
                    try:
                        developer_message = developer_message.with_tools(tool_descriptions)
                    except AttributeError:
                        logging.warning("Could not add tools to developer message")
            
            # Build conversation
            if include_python or include_browser:
                # system_message is already a Message object
                messages = [
                    system_message,
                    Message.from_role_and_content(Role.DEVELOPER, developer_message)
                ]
            else:
                messages = [
                    Message.from_role_and_content(Role.SYSTEM, system_message),
                    Message.from_role_and_content(Role.DEVELOPER, developer_message)
                ]
            
            # Add conversation history with CoT filtering
            for msg in data.get('conversation_history', []):
                if msg['role'] == 'user':
                    messages.append(Message.from_role_and_content(Role.USER, msg['content']))
                elif msg['role'] == 'assistant':
                    # Filter out CoT from assistant messages
                    filtered_content = filter_cot_from_content(msg['content'])
                    if filtered_content:  # Only add if there's content after filtering
                        assistant_msg = Message.from_role_and_content(Role.ASSISTANT, filtered_content)
                        if 'channel' in msg:
                            assistant_msg = assistant_msg.with_channel(msg['channel'])
                        if 'recipient' in msg:
                            assistant_msg = assistant_msg.with_recipient(msg['recipient'])
                        if 'content_type' in msg:
                            assistant_msg = assistant_msg.with_content_type(msg['content_type'])
                        messages.append(assistant_msg)
                elif msg['role'] == 'tool':
                    tool_msg = Message.from_author_and_content(
                        Author.new(Role.TOOL, msg.get('name', 'tool')),
                        msg['content']
                    )
                    if 'recipient' in msg:
                        tool_msg = tool_msg.with_recipient(msg['recipient'])
                    if 'channel' in msg:
                        tool_msg = tool_msg.with_channel(msg['channel'])
                    messages.append(tool_msg)
            
            # Add current user message or messages array
            if data.get('current_message'):
                messages.append(Message.from_role_and_content(Role.USER, data['current_message']))
            elif data.get('messages'):
                # Handle messages array format
                for msg in data['messages']:
                    if msg['role'] == 'user':
                        messages.append(Message.from_role_and_content(Role.USER, msg['content']))
            
            # Create conversation and render
            conversation = Conversation.from_messages(messages)
            tokens = encoding.render_conversation_for_completion(conversation, Role.ASSISTANT)
            prompt = encoding.decode(tokens)
            
            # Don't add constrain token - we want the model to use channel format, not JSON
            
        except Exception as e:
            logging.error(f"Error rendering prompt in chat: {e}")
            return jsonify({"error": f"Failed to render prompt: {str(e)}"}), 500
        
        # Track this initial prompt (will add response later)
        initial_prompt_info = {
            "stage": "initial",
            "prompt": prompt,
            "token_count": len(tokens),
            "timestamp": datetime.now().isoformat()
        }
        
        # Send to vLLM
        vllm_response = requests.post(
            f"{VLLM_BASE_URL}/v1/completions",
            json={
                "model": MODEL_NAME,
                "prompt": prompt,
                "max_tokens": data.get('max_tokens', 2048),
                "temperature": data.get('temperature', 0.7),
                "stop": ["<|return|>", "<|call|>"],
                "stream": False,
                "skip_special_tokens": False,
                "logprobs": 1
            }
        )
        
        if vllm_response.status_code != 200:
            return jsonify({"error": f"vLLM error: {vllm_response.text}"}), 500
        
        vllm_data = vllm_response.json()
        response_text = vllm_data['choices'][0]['text']
        finish_reason = vllm_data['choices'][0].get('finish_reason', 'unknown')
        
        logging.info(f"vLLM finish_reason: {finish_reason}")
        logging.info(f"Response length: {len(response_text)}")
        logging.info(f"Response ends with: {response_text[-50:] if len(response_text) > 50 else response_text}")
        
        # Check if response contains tool calls
        tool_calls = extract_tool_calls(response_text)
        logging.info(f"Initial response extracted {len(tool_calls)} tool calls: {tool_calls}")
        logging.info(f"Initial response text ends with: ...{repr(response_text[-200:])}")
        
        # If stopped because of <|call|>, append it
        if finish_reason == 'stop' and not response_text.endswith('<|call|>'):
            response_text += '<|call|>'
            logging.info("Appended <|call|> because finish_reason was 'stop'")
        
        # Add response to initial prompt info and track it
        initial_prompt_info['response'] = response_text
        prompts_sent.append(initial_prompt_info)
        
        # Handle multiple rounds of tool calls
        all_tool_responses = []
        current_prompt = prompt
        current_response = response_text
        max_rounds = 3  # Prevent infinite loops - reduced from 10
        round_count = 0
        
        while tool_calls and round_count < max_rounds:
            round_count += 1
            logging.info(f"Processing tool calls round {round_count}: {len(tool_calls)} calls")
            
            # Execute tool calls for this round
            tool_responses = []
            
            for tool_call in tool_calls:
                tool_name = tool_call['tool']
                params = tool_call['params']
                channel = tool_call.get('channel', 'commentary')
                
                logging.info(f"Executing tool: {tool_name} with params: {params}")
                
                # Execute the tool
                result = execute_tool_call(tool_name, params)
                
                # Format tool response in HARMONY format
                # Use the same channel as the request (analysis for browser, commentary for others)
                # Built-in tools (python, browser) return raw output, functions return JSON
                if tool_name in ['python', 'browser']:
                    # Built-in tools return raw output
                    tool_response = f'<|return|>{result}<|end|>'
                else:
                    # Function tools return JSON
                    tool_response = f'<|return|>{json.dumps(result)}<|end|>'
                tool_responses.append({
                    'tool': tool_name,
                    'params': params,
                    'result': result,
                    'formatted_response': tool_response
                })
            
            all_tool_responses.extend(tool_responses)
            
            # Append tool responses to the conversation and continue
            continued_prompt = current_prompt + current_response
            for tr in tool_responses:
                continued_prompt += tr['formatted_response']
            continued_prompt += '<|start|>assistant<|message|>'
            
            # Prepare continuation prompt info (will add response later)
            continuation_prompt_info = {
                "stage": f"continuation_round_{round_count}",
                "prompt": continued_prompt,
                "token_count": len(list(encoding.encode(continued_prompt, allowed_special="all"))),
                "timestamp": datetime.now().isoformat(),
                "tool_calls": tool_calls
            }
            
            # Make another request to vLLM to continue after tool execution
            continue_response = requests.post(
                f"{VLLM_BASE_URL}/v1/completions",
                json={
                    "model": MODEL_NAME,
                    "prompt": continued_prompt,
                    "max_tokens": data.get('max_tokens', 2048),
                    "temperature": data.get('temperature', 0.7),
                    "stop": ["<|return|>", "<|call|>", "<|end|>"],  # Stop on return, call, or end
                    "stream": False,
                    "skip_special_tokens": False,
                    "logprobs": 1
                }
            )
            
            if continue_response.status_code == 200:
                continue_data = continue_response.json()
                continued_text = continue_data['choices'][0]['text']
                finish_reason = continue_data['choices'][0].get('finish_reason', 'unknown')
                
                logging.info(f"Round {round_count} finish_reason: {finish_reason}")
                logging.info(f"Round {round_count} response ends with: {continued_text[-50:] if len(continued_text) > 50 else continued_text}")
                
                # Check if we have an incomplete tool call at the end
                if finish_reason == 'stop' and not continued_text.endswith('<|call|>'):
                    # Check for tool call patterns
                    if any(pattern in continued_text[-150:] for pattern in ['to=browser.', 'to=functions.']):
                        continued_text += '<|call|>'
                        logging.info("Appended <|call|> to incomplete tool call")
                
                # Add response to continuation prompt info and track it
                continuation_prompt_info['response'] = continued_text
                prompts_sent.append(continuation_prompt_info)
                
                # Update for next iteration
                current_prompt = continued_prompt
                current_response = continued_text
                
                # Check for more tool calls in the continued response
                tool_calls = extract_tool_calls(continued_text)
                logging.info(f"Round {round_count} found {len(tool_calls)} new tool calls")
                logging.info(f"Round {round_count} continued text: {continued_text}")
                
                # If no more tool calls, we're done
                if not tool_calls:
                    break
            else:
                logging.error(f"Failed to continue after tool execution: {continue_response.text}")
                # Still track the failed continuation
                continuation_prompt_info['response'] = f"[Error: {continue_response.status_code}]"
                continuation_prompt_info['error'] = continue_response.text
                prompts_sent.append(continuation_prompt_info)
                break
        
        # Build the complete response from all rounds
        full_response = response_text
        for tr in all_tool_responses:
            full_response += tr['formatted_response']
        if round_count > 0:  # If we did any continuations
            full_response += current_response
        
        # Parse the complete response
        try:
            response_tokens = list(encoding.encode(full_response, allowed_special="all"))
        except:
            response_tokens = list(encoding.encode(full_response))
        
        try:
            parsed_messages = encoding.parse_messages_from_completion_tokens(response_tokens, Role.ASSISTANT)
        except Exception as e:
            logging.warning(f"Failed to parse messages: {e}")
            parsed_messages = []
        
        # Extract structured information
        channels = {}
        for msg in parsed_messages:
            channel = getattr(msg, 'channel', 'default')
            
            # Skip tool messages - we don't want to display these in the channels
            if hasattr(msg, 'author') and hasattr(msg.author, 'role') and msg.author.role == Role.TOOL:
                continue
                
            if channel not in channels:
                channels[channel] = []
            
            # Extract content as string
            content_str = ""
            if hasattr(msg, 'content'):
                if isinstance(msg.content, str):
                    content_str = msg.content
                elif isinstance(msg.content, list):
                    # Extract text from TextContent objects
                    for item in msg.content:
                        if hasattr(item, 'text'):
                            content_str += item.text
                        else:
                            content_str += str(item)
                else:
                    content_str = str(msg.content)
            else:
                content_str = str(msg)
            
            # Skip if this is a code/JSON message (tool call)
            recipient = getattr(msg, 'recipient', None)
            content_type = getattr(msg, 'content_type', None)
            
            # Filter out JSON tool calls from display
            if recipient and '.' in str(recipient) and content_type == 'code':
                # This is a tool call, skip it
                continue
                
            channels[channel].append({
                'content': content_str,
                'recipient': recipient,
                'content_type': content_type
            })
        
        # Extract final content for conversation history
        final_content = extract_final_content(full_response)
        
        logging.info(f"Sending response with {len(full_response)} chars, {round_count} rounds, {len(all_tool_responses)} tool calls")
        logging.info(f"Full response ends with: {repr(full_response[-100:])}")
        
        return jsonify({
            "raw_response": full_response,
            "final_content": final_content,
            "tokens": response_tokens,
            "parsed_messages": channels,
            "tool_calls": all_tool_responses,
            "prompts_sent": prompts_sent,
            "rounds": round_count,
            "logprobs": vllm_data['choices'][0].get('logprobs', {})
        })
        
    except Exception as e:
        logging.error(f"Error in chat: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/stream', methods=['POST'])
def stream():
    """Stream chat responses with live parsing"""
    if not encoding:
        return jsonify({"error": "Harmony encoding not loaded"}), 500
    
    # Get data before entering the generator
    data = request.get_json()
    
    # Track all prompts sent during this streaming request
    prompts_sent = []
    
    def generate(data):
        try:
            
            # Inline prompt rendering (same as in chat endpoint)
            try:
                # Check if built-in tools are enabled
                include_python = data.get('include_python', False)
                include_browser = data.get('include_browser', False)
                
                if include_python or include_browser:
                    # Use custom system message with built-in tools
                    system_text = create_system_message_with_builtin_tools(data)
                    system_message = Message.from_role_and_content(Role.SYSTEM, system_text)
                else:
                    # Use standard system message
                    system_message = (
                        SystemContent.new()
                        .with_model_identity(data.get('model_identity', 'You are ChatGPT, a large language model trained by OpenAI.'))
                        .with_reasoning_effort(ReasoningEffort[data.get('reasoning_level', 'HIGH').upper()])
                        .with_conversation_start_date(data.get('current_date', datetime.now().strftime("%Y-%m-%d")))
                        .with_knowledge_cutoff(data.get('knowledge_cutoff', '2024-06'))
                        .with_required_channels(["analysis", "commentary", "final"])
                    )
                
                # Create developer message
                developer_message = DeveloperContent.new()
                
                # Add regular instructions
                instructions_parts = []
                if data.get('instructions'):
                    instructions_parts.append(data['instructions'])
                
                # Add built-in tool instructions if enabled
                if include_python or include_browser:
                    from builtin_tool_instructions import get_builtin_tools_instruction
                    builtin_instructions = get_builtin_tools_instruction(
                        include_python=include_python,
                        include_browser=include_browser
                    )
                    if builtin_instructions:
                        instructions_parts.append(builtin_instructions)
                
                # Combine all instructions
                if instructions_parts:
                    combined_instructions = '\n\n'.join(instructions_parts)
                    developer_message = developer_message.with_instructions(combined_instructions)
                
                # Get function tool descriptions
                tools = data.get('tools', [])
                
                tool_descriptions = []
                for tool in tools:
                    td = ToolDescription.new(
                        tool['name'],
                        tool['description'],
                        parameters=tool.get('parameters', {})
                    )
                    tool_descriptions.append(td)
                
                # Add function tools to developer message if any are available
                if tool_descriptions:
                    try:
                        developer_message = developer_message.with_function_tools(tool_descriptions)
                    except AttributeError:
                        try:
                            developer_message = developer_message.with_tools(tool_descriptions)
                        except AttributeError:
                            logging.warning("Could not add tools to developer message")
                
                # Build conversation
                if include_python or include_browser:
                    # system_message is already a Message object
                    messages = [
                        system_message,
                        Message.from_role_and_content(Role.DEVELOPER, developer_message)
                    ]
                else:
                    messages = [
                        Message.from_role_and_content(Role.SYSTEM, system_message),
                        Message.from_role_and_content(Role.DEVELOPER, developer_message)
                    ]
                
                # Add conversation history - properly handle raw content
                for msg in data.get('conversation_history', []):
                    if msg['role'] == 'user':
                        messages.append(Message.from_role_and_content(Role.USER, msg['content']))
                    elif msg['role'] == 'assistant':
                        # If we have raw content, just append it directly to prompt
                        if 'rawContent' in msg:
                            # We'll handle this differently - store for later
                            pass
                        else:
                            # Old format compatibility
                            assistant_msg = Message.from_role_and_content(Role.ASSISTANT, msg.get('content', ''))
                            if 'channel' in msg:
                                assistant_msg = assistant_msg.with_channel(msg['channel'])
                            if 'recipient' in msg:
                                assistant_msg = assistant_msg.with_recipient(msg['recipient'])
                            if 'content_type' in msg:
                                assistant_msg = assistant_msg.with_content_type(msg['content_type'])
                            messages.append(assistant_msg)
                    elif msg['role'] == 'tool':
                        tool_msg = Message.from_author_and_content(
                            Author.new(Role.TOOL, msg.get('name', 'tool')),
                            msg['content']
                        )
                        if 'recipient' in msg:
                            tool_msg = tool_msg.with_recipient(msg['recipient'])
                        if 'channel' in msg:
                            tool_msg = tool_msg.with_channel(msg['channel'])
                        messages.append(tool_msg)
                
                # Add current user message
                messages.append(Message.from_role_and_content(Role.USER, data['current_message']))
                
                # Create conversation and render
                conversation = Conversation.from_messages(messages)
                tokens = encoding.render_conversation_for_completion(conversation, Role.ASSISTANT)
                prompt = encoding.decode(tokens)
                
            except Exception as e:
                yield f"data: {json.dumps({'error': f'Failed to render prompt: {str(e)}'})}\n\n"
                return
            
            # Track the initial prompt (will add response later)
            initial_prompt_info = {
                "stage": "initial",
                "prompt": prompt,
                "token_count": len(tokens),
                "timestamp": datetime.now().isoformat()
            }
            
            # Create streaming parser
            parser = StreamableParser(encoding, role=Role.ASSISTANT)
            accumulated_text = ""  # Accumulate text to handle partial special tokens
            
            # Send streaming request to vLLM
            with requests.post(
                f"{VLLM_BASE_URL}/v1/completions",
                json={
                    "model": MODEL_NAME,
                    "prompt": prompt,
                    "max_tokens": data.get('max_tokens', 2048),
                    "temperature": data.get('temperature', 0.7),
                    "stop": ["<|return|>"],
                    "stream": True,
                    "skip_special_tokens": False,
                    "logprobs": 1
                },
                stream=True
            ) as response:
                
                for line in response.iter_lines():
                    if line:
                        line = line.decode('utf-8')
                        if line.startswith('data: '):
                            chunk_data = line[6:]
                            if chunk_data == '[DONE]':
                                break
                            
                            try:
                                chunk = json.loads(chunk_data)
                                if 'choices' in chunk and chunk['choices']:
                                    text = chunk['choices'][0].get('text', '')
                                    
                                    if text:
                                        accumulated_text += text
                                        
                                        # Send update with accumulated text
                                        yield f"data: {json.dumps({
                                            'text': text,
                                            'accumulated': accumulated_text,
                                            'current_role': 'assistant',
                                            'current_channel': None,
                                            'last_content_delta': text,
                                            'current_content': accumulated_text,
                                            'current_recipient': None,
                                            'current_content_type': None
                                        })}\n\n"
                                        
                            except json.JSONDecodeError:
                                continue
                
                # Add initial response to prompt info
                initial_prompt_info['response'] = accumulated_text
                prompts_sent.append(initial_prompt_info)
                
                # Check if response contains tool calls
                tool_calls = extract_tool_calls(accumulated_text)
                
                # If the stream stopped but we have a tool call pattern, append <|call|>
                if tool_calls and not accumulated_text.endswith('<|call|>'):
                    for tc in tool_calls:
                        if tc['tool'] and tc['params']:
                            accumulated_text += '<|call|>'
                            logging.info("Appended <|call|> to streaming response")
                            break
                
                if tool_calls and '<|call|>' in accumulated_text:
                    # Execute tool calls and continue the conversation
                    tool_responses = []
                    
                    for tool_call in tool_calls:
                        tool_name = tool_call['tool']
                        params = tool_call['params']
                        channel = tool_call.get('channel', 'commentary')
                        
                        # Execute the tool
                        result = execute_tool_call(tool_name, params)
                        
                        # Format tool response
                        # Use the same channel as the request (analysis for browser, commentary for others)
                        tool_response = f'<|start|>{tool_name} to=assistant<|channel|>{channel}<|message|>{json.dumps(result)}<|end|>'
                        tool_responses.append({
                            'tool': tool_name,
                            'params': params,
                            'result': result,
                            'formatted_response': tool_response
                        })
                        
                        # Send tool execution info
                        yield f"data: {json.dumps({
                            'tool_executed': {
                                'tool': tool_name,
                                'params': params,
                                'result': result
                            }
                        })}\n\n"
                    
                    # Continue the conversation with tool responses
                    continued_prompt = prompt + accumulated_text
                    for tr in tool_responses:
                        continued_prompt += tr['formatted_response']
                    continued_prompt += '<|start|>assistant<|message|>'
                    
                    # Prepare continuation prompt info (will add response later)
                    continuation_prompt_info = {
                        "stage": "continuation_after_tools",
                        "prompt": continued_prompt,
                        "token_count": len(list(encoding.encode(continued_prompt, allowed_special="all"))),
                        "timestamp": datetime.now().isoformat(),
                        "tool_calls": tool_calls
                    }
                    
                    # Add tool responses to accumulated text for complete raw response
                    for tr in tool_responses:
                        accumulated_text += tr['formatted_response']
                    
                    # Stream the continuation
                    yield f"data: {json.dumps({'continuing_after_tools': True})}\n\n"
                    
                    with requests.post(
                        f"{VLLM_BASE_URL}/v1/completions",
                        json={
                            "model": MODEL_NAME,
                            "prompt": continued_prompt,
                            "max_tokens": data.get('max_tokens', 2048),
                            "temperature": data.get('temperature', 0.7),
                            "stop": ["<|return|>"],
                            "stream": True,
                            "skip_special_tokens": False,
                            "logprobs": 1
                        },
                        stream=True
                    ) as continue_response:
                        
                        for line in continue_response.iter_lines():
                            if line:
                                line = line.decode('utf-8')
                                if line.startswith('data: '):
                                    chunk_data = line[6:]
                                    if chunk_data == '[DONE]':
                                        break
                                    
                                    try:
                                        chunk = json.loads(chunk_data)
                                        if 'choices' in chunk and chunk['choices']:
                                            text = chunk['choices'][0].get('text', '')
                                            
                                            if text:
                                                accumulated_text += text
                                                
                                                yield f"data: {json.dumps({
                                                    'text': text,
                                                    'accumulated': accumulated_text,
                                                    'is_continuation': True
                                                })}\n\n"
                                                
                                    except json.JSONDecodeError:
                                        continue
                        
                        # Add continuation response to prompt info
                        if 'continuation_prompt_info' in locals():
                            # Get the continuation response text by finding what was added after the prompt
                            continuation_start = len(continuation_prompt_info['prompt'])
                            continuation_response = accumulated_text[continuation_start:] if len(accumulated_text) > continuation_start else accumulated_text
                            continuation_prompt_info['response'] = continuation_response
                            prompts_sent.append(continuation_prompt_info)
                
                # Parse the complete accumulated text
                if accumulated_text:
                    # Extract all content manually
                    parsed_messages = []
                    
                    # Extract channel content using regex
                    import re
                    
                    # Find all analysis messages
                    for match in re.finditer(r'<\|channel\|>analysis<\|message\|>(.*?)(?=<\|end\|>|<\|start\|>|$)', accumulated_text, re.DOTALL):
                        parsed_messages.append({
                            'role': 'assistant',
                            'channel': 'analysis',
                            'content': match.group(1).strip(),
                            'recipient': None,
                            'content_type': None
                        })
                    
                    # Find all commentary/tool calls
                    for match in re.finditer(r'<\|channel\|>commentary(?:\s+to=([\w\.]+))?.*?<\|message\|>(.*?)(?=<\|call\|>|<\|end\|>|<\|start\|>|$)', accumulated_text, re.DOTALL):
                        parsed_messages.append({
                            'role': 'assistant',
                            'channel': 'commentary',
                            'content': match.group(2).strip() if match.group(2) else '',
                            'recipient': match.group(1) if match.group(1) else None,
                            'content_type': None
                        })
                    
                    # Find all final messages
                    for match in re.finditer(r'<\|channel\|>final<\|message\|>(.*?)(?=<\|return\|>|<\|end\|>|<\|start\|>|$)', accumulated_text, re.DOTALL):
                        parsed_messages.append({
                            'role': 'assistant',
                            'channel': 'final',
                            'content': match.group(1).strip(),
                            'recipient': None,
                            'content_type': None
                        })
                else:
                    parsed_messages = []
                
                # Build the complete raw response including tool responses
                if 'tool_responses' in locals() and tool_responses:
                    # We had tool calls, so build the full response
                    full_raw_response = accumulated_text
                    # Note: accumulated_text already includes everything because we accumulated
                    # from both the initial response AND the continuation after tools
                else:
                    # No tool calls, just the direct response
                    full_raw_response = accumulated_text
                
                # Extract final content for conversation history
                final_content = extract_final_content(full_raw_response) if full_raw_response else ""
                
                # Send final parsed messages with tool info and all prompts
                yield f"data: {json.dumps({
                    'done': True,
                    'raw_response': full_raw_response,  # Include the complete raw response
                    'final_content': final_content,  # Add clean content for frontend
                    'parsed_messages': parsed_messages,
                    'tool_calls': tool_responses if 'tool_responses' in locals() else [],
                    'prompts_sent': prompts_sent  # All prompts sent during streaming
                })}\n\n"
                
        except Exception as e:
            yield f"data: {json.dumps({'error': str(e)})}\n\n"
    
    return Response(generate(data), mimetype='text/event-stream')

if __name__ == '__main__':
    app.run(debug=False, port=5000)
</file_artifact>

<file path="GPT-OSS-HARMONY-REFERENCE-REPO/official_python_instruction.py">
#!/usr/bin/env python3
"""
Official Python tool instruction from OpenAI documentation
"""

OFFICIAL_PYTHON_INSTRUCTION = """## python

Use this tool to execute Python code in your chain of thought. The code will not be shown to the user. This tool should be used for internal reasoning, but not for code that is intended to be visible to the user (e.g. when creating plots, tables, or files).

When you send a message containing Python code to python, it will be executed in a stateful Jupyter notebook environment. python will respond with the output of the execution or time out after 120.0 seconds. The drive at '/mnt/data' can be used to save and persist user files. Internet access for this session is UNKNOWN. Depends on the cluster."""
</file_artifact>

<file path="GPT-OSS-HARMONY-REFERENCE-REPO/python_d20_response.json">
{
  "final_content": "You rolled a **9**!  If you want to roll again or need help with anything else, just let me know.",
  "logprobs": {
    "text_offset": [
      0,
      11,
      19,
      30,
      33,
      38,
      44,
      47,
      52,
      54,
      56,
      58,
      63,
      69,
      76,
      81,
      82,
      85,
      90,
      92,
      101,
      103,
      112,
      119,
      120,
      125,
      129,
      137,
      144,
      149,
      150,
      153,
      158,
      161,
      165,
      168,
      169,
      173,
      180,
      187,
      190,
      194,
      201,
      204,
      208,
      213,
      214,
      218,
      223,
      228,
      230,
      233,
      237,
      244,
      249,
      252,
      257,
      259,
      261,
      263,
      268,
      272,
      277,
      280,
      285,
      287,
      294,
      298,
      300,
      305,
      308,
      316,
      321,
      325,
      332,
      333,
      336,
      343,
      351,
      353,
      362,
      363,
      371,
      376,
      377,
      383,
      386,
      388,
      395,
      402,
      407,
      408,
      412,
      419,
      426,
      427,
      431,
      433,
      439,
      447,
      448,
      449,
      450,
      452,
      453,
      455,
      460,
      466,
      470,
      477,
      478,
      483,
      489,
      493,
      495,
      504,
      512,
      513,
      519,
      527,
      529,
      534,
      542,
      543,
      545,
      551,
      558,
      559,
      565,
      572,
      580,
      581,
      582,
      583,
      585,
      587,
      589,
      594,
      597,
      602,
      606,
      615,
      616,
      621,
      628,
      633,
      636,
      641,
      645,
      652,
      653,
      657,
      662,
      668,
      671,
      676,
      681,
      686,
      693,
      694,
      698,
      707,
      715,
      719,
      726,
      727,
      730,
      732,
      737,
      740,
      745,
      749,
      758,
      759,
      763,
      772,
      779,
      782,
      792,
      797,
      798,
      800,
      803,
      810,
      812,
      814,
      816,
      822,
      825,
      830,
      833,
      835,
      842,
      847,
      851,
      860,
      865,
      870,
      871,
      873,
      879,
      886,
      887,
      893,
      900,
      908,
      909,
      910,
      911,
      913,
      915,
      917,
      922,
      930,
      937,
      938,
      943,
      951,
      956,
      960,
      967,
      968,
      973,
      976,
      980,
      984,
      986,
      995,
      1000,
      1003,
      1008,
      1011,
      1014,
      1015,
      1022,
      1031,
      1040,
      1051,
      1058,
      1061,
      1064,
      1065,
      1074,
      1081,
      1082,
      1095,
      1099,
      1110,
      1112,
      1116,
      1119,
      1125,
      1132,
      1134,
      1139,
      1146,
      1154,
      1155,
      1156,
      1157,
      1159,
      1161,
      1163
    ],
    "token_logprobs": [
      0.0,
      -0.0000014305104514278355,
      -0.0000023841830625315197,
      -0.5021612644195557,
      -0.005668517667800188,
      -0.44623950123786926,
      -0.6331477165222168,
      -0.3504091501235962,
      -0.001479246304370463,
      -0.03840949386358261,
      -0.000003814689989667386,
      -0.1669493317604065,
      -0.8566287755966187,
      -1.258791208267212,
      -0.9118664264678955,
      -0.30533909797668457,
      -0.7634432911872864,
      -3.0959320068359375,
      -1.056497573852539,
      -0.6759012937545776,
      -2.4477310180664062,
      -0.010139504447579384,
      -0.0001248043408850208,
      -0.2478417456150055,
      -0.31394344568252563,
      -1.1552653312683105,
      -0.2666826546192169,
      -0.3436475992202759,
      -0.024248916655778885,
      -0.484874963760376,
      -0.44809630513191223,
      -0.578332245349884,
      -0.0013936578761786222,
      -1.7602343559265137,
      -0.9655080437660217,
      -0.911755383014679,
      -0.973003625869751,
      -3.2221412658691406,
      -0.48691269755363464,
      -0.3849881887435913,
      -0.791709840297699,
      -0.8095232844352722,
      -0.47542595863342285,
      -0.5857812166213989,
      -0.4604445993900299,
      -0.19667352735996246,
      -2.020930290222168,
      -0.43839526176452637,
      -1.5641875267028809,
      -0.3615289330482483,
      -0.16715268790721893,
      -0.0046846638433635235,
      -0.0013584204716607928,
      -0.00000822540732769994,
      -0.005823550280183554,
      -0.00005113947918289341,
      -0.0008487674640491605,
      -0.00032145579461939633,
      -0.0000066756979322235566,
      -0.0003420721332076937,
      -0.0011845960980281234,
      -0.000015020257706055418,
      -0.000012874520507466514,
      -0.000005125986263010418,
      -0.00020740265608765185,
      -0.000002622600959512056,
      -1.6152384281158447,
      -0.2155437171459198,
      -0.9069991707801819,
      -0.007905268110334873,
      -2.966367721557617,
      -0.36046358942985535,
      -0.3868066370487213,
      -0.5242849588394165,
      -0.3521595299243927,
      -1.2403961420059204,
      -1.1579608917236328,
      -2.7362473011016846,
      -0.7965713739395142,
      -0.5862614512443542,
      -4.573948383331299,
      -0.0023185533937066793,
      -0.18453188240528107,
      -0.2982434928417206,
      -3.909069061279297,
      -1.4734309911727905,
      -1.7771528959274292,
      -1.548107624053955,
      -0.8328418135643005,
      -0.4312725365161896,
      -1.409864902496338,
      -1.1156580448150635,
      -1.030858039855957,
      -1.3486216068267822,
      -0.5274865627288818,
      -2.265993356704712,
      -1.1429075002670288,
      -0.5717008113861084,
      -0.00020001317898277193,
      -0.0004175029753241688,
      -0.0000015497195136049413,
      -0.000005006777428206988,
      -0.16025792062282562,
      -0.7577946186065674,
      -0.005458332132548094,
      -1.0310304164886475,
      -0.05994144454598427,
      -0.4543205499649048,
      -0.16189298033714294,
      -0.2537778615951538,
      -4.08930778503418,
      -1.107706069946289,
      -3.1880686283111572,
      -0.5655558705329895,
      -0.9752489328384399,
      -2.5157063007354736,
      -0.7223377227783203,
      -2.3851633071899414,
      -1.7679078578948975,
      -2.271402359008789,
      -1.547097086906433,
      -0.659358561038971,
      -1.499436855316162,
      -0.43461117148399353,
      -0.06422805786132812,
      -8.344646857949556E-7,
      -0.02894587442278862,
      -0.147955060005188,
      -0.015608293004333973,
      -0.0000015497195136049413,
      -0.0000034570634852570947,
      0.0,
      -0.000002622600959512056,
      -0.038054268807172775,
      -0.0003337303060106933,
      -0.18303699791431427,
      -1.285758376121521,
      -1.582822322845459,
      -0.6879647374153137,
      -0.16119901835918427,
      -0.14344088733196259,
      -0.4728378653526306,
      -1.585758924484253,
      -2.5428547859191895,
      -1.8890693187713623,
      -0.1660861372947693,
      -3.0850322246551514,
      -0.2565041780471802,
      -0.18998681008815765,
      -0.3393598198890686,
      -2.2877650260925293,
      -0.9298760890960693,
      -0.8648821711540222,
      -1.1880831718444824,
      -0.1659773886203766,
      -0.17880241572856903,
      -0.3792691230773926,
      -0.00026639728457666934,
      -0.1847642958164215,
      -3.0201330184936523,
      -1.3669168949127197,
      -1.3499581813812256,
      -0.43393513560295105,
      -0.3108014464378357,
      -0.7283381819725037,
      -1.7649762630462646,
      -4.137181282043457,
      -1.301693081855774,
      -0.0017020514933392406,
      -0.4330275058746338,
      -0.2814036011695862,
      -0.08338115364313126,
      -1.0498874187469482,
      -1.8836281299591064,
      -2.3508172035217285,
      -0.6815555691719055,
      -1.0225071907043457,
      -2.244016170501709,
      -0.009974281303584576,
      -1.1991792917251587,
      -0.14073750376701355,
      -0.23533819615840912,
      -0.0007687236065976322,
      -0.39437419176101685,
      -0.29117441177368164,
      -0.9297659397125244,
      -2.595134973526001,
      -0.4875585436820984,
      -0.23079973459243774,
      -0.9168754816055298,
      -0.6283866167068481,
      -2.0688281059265137,
      -1.409548044204712,
      -0.13952378928661346,
      -0.17395415902137756,
      -1.544694423675537,
      -0.8140366077423096,
      -0.9967893362045288,
      -0.46714532375335693,
      -0.023633915930986404,
      -0.0000014305104514278355,
      -0.15231822431087494,
      -0.025193607434630394,
      -0.0018356868531554937,
      -0.000011801649634435307,
      -0.000006198863957251888,
      -0.000001311301275563892,
      -0.000004410734163684538,
      -0.0619942806661129,
      -0.00033623288618400693,
      -0.20074109733104706,
      -0.5822531580924988,
      -2.310135841369629,
      -0.8913963437080383,
      -0.1714928150177002,
      -0.6917365193367004,
      -0.700528621673584,
      -1.3009377717971802,
      -1.6596020460128784,
      -0.8461418151855469,
      -0.3962723910808563,
      -3.392880439758301,
      -2.3577380180358887,
      -0.8411431312561035,
      -0.893915593624115,
      -0.8145565986633301,
      -0.1819618195295334,
      -1.2913388013839722,
      -1.7289620637893677,
      -1.8279283046722412,
      -0.6512448191642761,
      -0.7315858006477356,
      -0.1150626391172409,
      -0.013744357042014599,
      0.0,
      0.0,
      -3.576278118089249E-7,
      0.0,
      0.0,
      -0.0005838358192704618,
      0.0,
      0.0,
      -2.3841855067985307E-7,
      -0.007662665098905563,
      0.0,
      -0.00030012393835932016,
      -0.00018809456378221512,
      -0.0010711177019402385,
      -0.000003576272320060525,
      -0.00012361239350866526,
      -0.000007867782187531702,
      0.0,
      -0.018298272043466568,
      -0.0017370387213304639,
      -0.00007283422019099817,
      0.0,
      0.0,
      0.0,
      -4.768370445162873E-7,
      -0.03805059567093849,
      -0.000006437280717364047,
      -0.0006660388899035752,
      0.0
    ],
    "tokens": [
      "<|channel|>",
      "analysis",
      "<|message|>",
      "The",
      " user",
      " wants",
      " to",
      " roll",
      " a",
      " D",
      "20",
      " dice",
      " using",
      " Python",
      " tool",
      ".",
      " We",
      " have",
      " a",
      " function",
      " `",
      "functions",
      ".python",
      "`",
      " that",
      " can",
      " execute",
      " Python",
      " code",
      ".",
      " We",
      " need",
      " to",
      " use",
      " it",
      ".",
      " The",
      " output",
      " should",
      " be",
      " the",
      " result",
      " of",
      " the",
      " roll",
      ".",
      " The",
      " user",
      " says",
      " \"",
      "Use",
      " the",
      " python",
      " tool",
      " to",
      " roll",
      " a",
      " D",
      "20",
      " dice",
      " and",
      " tell",
      " me",
      " what",
      " I",
      " rolled",
      ".\"\n\n",
      "We",
      " need",
      " to",
      " respond",
      " with",
      " the",
      " result",
      ".",
      " We",
      " should",
      " produce",
      " a",
      " friendly",
      ",",
      " helpful",
      " tone",
      ".",
      " Let's",
      " do",
      " a",
      " simple",
      " random",
      " roll",
      ".",
      " Use",
      " random",
      " module",
      ".",
      " Use",
      " `",
      "random",
      ".randint",
      "(",
      "1",
      ",",
      "20",
      ")",
      "`.",
      " Then",
      " print",
      " the",
      " result",
      ".",
      " Also",
      " maybe",
      " add",
      " a",
      " friendly",
      " comment",
      ".",
      " Let's",
      " produce",
      " a",
      " code",
      " snippet",
      ":",
      " `",
      "import",
      " random",
      ";",
      " print",
      "(random",
      ".randint",
      "(",
      "1",
      ",",
      "20",
      "))",
      "`.",
      " Then",
      " we",
      " call",
      " the",
      " function",
      ".",
      " Then",
      " output",
      " will",
      " be",
      " just",
      " the",
      " number",
      ".",
      " The",
      " user",
      " wants",
      " to",
      " know",
      " what",
      " they",
      " rolled",
      ".",
      " The",
      " function",
      " returns",
      " the",
      " output",
      ".",
      " So",
      " I",
      " need",
      " to",
      " call",
      " the",
      " function",
      ".",
      " The",
      " response",
      " should",
      " be",
      " something",
      " like",
      ":",
      " \"",
      "You",
      " rolled",
      " a",
      " X",
      ".\"",
      " Let's",
      " do",
      " that",
      ".\n\n",
      "We",
      " should",
      " call",
      " the",
      " function",
      " with",
      " code",
      ":",
      " `",
      "import",
      " random",
      ";",
      " print",
      "(random",
      ".randint",
      "(",
      "1",
      ",",
      "20",
      "))",
      "`.",
      " Then",
      " capture",
      " output",
      ".",
      " Then",
      " respond",
      " with",
      " the",
      " number",
      ".",
      " Also",
      " we",
      " can",
      " add",
      " a",
      " friendly",
      " tone",
      ".\n\n",
      "Let's",
      " do",
      " it",
      ".",
      "<|end|>",
      "<|start|>",
      "assistant",
      "<|channel|>",
      "comment",
      "ary",
      " to",
      "=",
      "functions",
      ".python",
      " ",
      "<|constrain|>",
      "json",
      "<|message|>",
      "{\"",
      "code",
      "\":\"",
      "import",
      " random",
      "\\n",
      "print",
      "(random",
      ".randint",
      "(",
      "1",
      ",",
      "20",
      "))",
      "\"}",
      "<|call|>"
    ],
    "top_logprobs": [
      {
        "<|channel|>": 0.0
      },
      {
        "analysis": -0.0000014305104514278355
      },
      {
        "<|message|>": -0.0000023841830625315197
      },
      {
        "The": -0.5021612644195557
      },
      {
        " user": -0.005668517667800188
      },
      {
        " wants": -0.44623950123786926
      },
      {
        " to": -0.6331477165222168
      },
      {
        " roll": -0.3504091501235962
      },
      {
        " a": -0.001479246304370463
      },
      {
        " D": -0.03840949386358261
      },
      {
        "20": -0.000003814689989667386
      },
      {
        " dice": -0.1669493317604065
      },
      {
        " using": -0.8566287755966187
      },
      {
        " Python": -1.258791208267212,
        " the": -0.6337912678718567
      },
      {
        " tool": -0.9118664264678955
      },
      {
        ".": -0.30533909797668457
      },
      {
        " We": -0.7634432911872864
      },
      {
        " have": -3.0959320068359375,
        " need": -0.5959319472312927
      },
      {
        " a": -1.056497573852539,
        " to": -0.6814975738525391
      },
      {
        " function": -0.6759012937545776
      },
      {
        " `": -2.4477310180664062,
        " to": -1.1977310180664062
      },
      {
        "functions": -0.010139504447579384
      },
      {
        ".python": -0.0001248043408850208
      },
      {
        "`": -0.2478417456150055
      },
      {
        " that": -0.31394344568252563
      },
      {
        " can": -1.1552653312683105
      },
      {
        " execute": -0.2666826546192169
      },
      {
        " Python": -0.3436475992202759
      },
      {
        " code": -0.024248916655778885
      },
      {
        ".": -0.484874963760376
      },
      {
        " We": -0.44809630513191223
      },
      {
        " need": -0.578332245349884
      },
      {
        " to": -0.0013936578761786222
      },
      {
        " produce": -1.5102343559265137,
        " use": -1.7602343559265137
      },
      {
        " it": -0.9655080437660217
      },
      {
        ".": -0.911755383014679
      },
      {
        " The": -0.973003625869751
      },
      {
        " output": -3.2221412658691406,
        " user": -0.9721412658691406
      },
      {
        " should": -0.48691269755363464
      },
      {
        " be": -0.3849881887435913
      },
      {
        " the": -0.791709840297699
      },
      {
        " result": -0.8095232844352722
      },
      {
        " of": -0.47542595863342285
      },
      {
        " the": -0.5857812166213989
      },
      {
        " roll": -0.4604445993900299
      },
      {
        ".": -0.19667352735996246
      },
      {
        " The": -2.020930290222168,
        " We": -1.020930290222168
      },
      {
        " user": -0.43839526176452637
      },
      {
        " says": -1.5641875267028809,
        " wants": -1.1891875267028809
      },
      {
        " \"": -0.3615289330482483
      },
      {
        "Use": -0.16715268790721893
      },
      {
        " the": -0.0046846638433635235
      },
      {
        " python": -0.0013584204716607928
      },
      {
        " tool": -0.00000822540732769994
      },
      {
        " to": -0.005823550280183554
      },
      {
        " roll": -0.00005113947918289341
      },
      {
        " a": -0.0008487674640491605
      },
      {
        " D": -0.00032145579461939633
      },
      {
        "20": -0.0000066756979322235566
      },
      {
        " dice": -0.0003420721332076937
      },
      {
        " and": -0.0011845960980281234
      },
      {
        " tell": -0.000015020257706055418
      },
      {
        " me": -0.000012874520507466514
      },
      {
        " what": -0.000005125986263010418
      },
      {
        " I": -0.00020740265608765185
      },
      {
        " rolled": -0.000002622600959512056
      },
      {
        ".\"": -0.24023836851119995,
        ".\"\n\n": -1.6152384281158447
      },
      {
        "We": -0.2155437171459198
      },
      {
        " need": -0.9069991707801819
      },
      {
        " to": -0.007905268110334873
      },
      {
        " produce": -1.0913677215576172,
        " respond": -2.966367721557617
      },
      {
        " with": -0.36046358942985535
      },
      {
        " the": -0.3868066370487213
      },
      {
        " result": -0.5242849588394165
      },
      {
        ".": -0.3521595299243927
      },
      {
        " We": -1.2403961420059204
      },
      {
        " should": -1.1579608917236328
      },
      {
        " call": -1.3612473011016846,
        " produce": -2.7362473011016846
      },
      {
        " a": -0.7965713739395142
      },
      {
        " friendly": -0.5862614512443542
      },
      {
        " tone": -0.07394839078187943,
        ",": -4.573948383331299
      },
      {
        " helpful": -0.0023185533937066793
      },
      {
        " tone": -0.18453188240528107
      },
      {
        ".": -0.2982434928417206
      },
      {
        " Let's": -3.909069061279297,
        " We": -1.2840690612792969
      },
      {
        " do": -1.4734309911727905
      },
      {
        " a": -1.7771528959274292,
        " it": -1.2771528959274292
      },
      {
        " random": -0.9231075644493103,
        " simple": -1.548107624053955
      },
      {
        " random": -0.8328418135643005
      },
      {
        " roll": -0.4312725365161896
      },
      {
        ".": -1.409864902496338,
        ":": -0.7848649024963379
      },
      {
        " Use": -1.1156580448150635
      },
      {
        " random": -1.030858039855957
      },
      {
        " module": -1.3486216068267822,
        ".randint": -0.34862157702445984
      },
      {
        ".": -0.5274865627288818
      },
      {
        " Use": -2.265993356704712,
        " We'll": -2.078493356704712
      },
      {
        " `": -1.1429075002670288
      },
      {
        "random": -0.5717008113861084
      },
      {
        ".randint": -0.00020001317898277193
      },
      {
        "(": -0.0004175029753241688
      },
      {
        "1": -0.0000015497195136049413
      },
      {
        ",": -0.000005006777428206988
      },
      {
        "20": -0.16025792062282562
      },
      {
        ")": -0.7577946186065674,
        ")`": -0.6327946186065674
      },
      {
        "`.": -0.005458332132548094
      },
      {
        " Then": -1.0310304164886475
      },
      {
        " print": -0.05994144454598427
      },
      {
        " the": -0.4543205499649048
      },
      {
        " result": -0.16189298033714294
      },
      {
        ".": -0.2537778615951538
      },
      {
        " Also": -4.08930778503418,
        " The": -1.8393075466156006
      },
      {
        " maybe": -1.107706069946289
      },
      {
        " add": -3.1880686283111572,
        " mention": -1.7505686283111572
      },
      {
        " a": -0.5655558705329895
      },
      {
        " friendly": -0.9752489328384399
      },
      {
        " comment": -2.5157063007354736,
        " message": -0.5157062411308289
      },
      {
        ".": -0.7223377227783203
      },
      {
        " Let's": -2.3851633071899414,
        " The": -1.6351633071899414
      },
      {
        " do": -1.0179078578948975,
        " produce": -1.7679078578948975
      },
      {
        " a": -2.271402359008789,
        " the": -1.1464024782180786
      },
      {
        " code": -1.547097086906433,
        " single": -1.297097086906433
      },
      {
        " snippet": -0.659358561038971
      },
      {
        " that": -1.374436855316162,
        ":": -1.499436855316162
      },
      {
        " `": -0.43461117148399353
      },
      {
        "import": -0.06422805786132812
      },
      {
        " random": -8.344646857949556E-7
      },
      {
        ";": -0.02894587442278862
      },
      {
        " print": -0.147955060005188
      },
      {
        "(random": -0.015608293004333973
      },
      {
        ".randint": -0.0000015497195136049413
      },
      {
        "(": -0.0000034570634852570947
      },
      {
        "1": 0.0
      },
      {
        ",": -0.000002622600959512056
      },
      {
        "20": -0.038054268807172775
      },
      {
        "))": -0.0003337303060106933
      },
      {
        "`.": -0.18303699791431427
      },
      {
        " Then": -1.285758376121521
      },
      {
        " call": -1.332822322845459,
        " we": -1.582822322845459
      },
      {
        " call": -0.6879647374153137
      },
      {
        " the": -0.16119901835918427
      },
      {
        " function": -0.14344088733196259
      },
      {
        ".": -0.4728378653526306
      },
      {
        " The": -1.335758924484253,
        " Then": -1.585758924484253
      },
      {
        " output": -2.5428547859191895,
        " we": -0.5428548455238342
      },
      {
        " the": -0.8890692591667175,
        " will": -1.8890693187713623
      },
      {
        " be": -0.1660861372947693
      },
      {
        " just": -3.0850322246551514,
        " the": -0.8350322842597961
      },
      {
        " the": -0.2565041780471802
      },
      {
        " number": -0.18998681008815765
      },
      {
        ".": -0.3393598198890686
      },
      {
        " The": -2.2877650260925293,
        " We": -1.4127650260925293
      },
      {
        " user": -0.9298760890960693
      },
      {
        " wants": -0.8648821711540222
      },
      {
        " the": -1.0630831718444824,
        " to": -1.1880831718444824
      },
      {
        " know": -0.1659773886203766
      },
      {
        " what": -0.17880241572856903
      },
      {
        " they": -0.3792691230773926
      },
      {
        " rolled": -0.00026639728457666934
      },
      {
        ".": -0.1847642958164215
      },
      {
        " So": -0.6451329588890076,
        " The": -3.0201330184936523
      },
      {
        " function": -1.3669168949127197
      },
      {
        " returns": -1.3499581813812256,
        " will": -0.5999582409858704
      },
      {
        " the": -0.43393513560295105
      },
      {
        " output": -0.3108014464378357
      },
      {
        ".": -0.7283381819725037
      },
      {
        " So": -1.7649762630462646,
        " We": -1.1399762630462646
      },
      {
        " I": -4.137181282043457,
        " we": -0.2621810734272003
      },
      {
        " need": -1.301693081855774,
        " will": -1.176693081855774
      },
      {
        " to": -0.0017020514933392406
      },
      {
        " call": -0.4330275058746338
      },
      {
        " the": -0.2814036011695862
      },
      {
        " function": -0.08338115364313126
      },
      {
        ".": -1.0498874187469482
      },
      {
        " The": -1.8836281299591064,
        " Then": -1.7586281299591064
      },
      {
        " output": -1.975817322731018,
        " response": -2.3508172035217285
      },
      {
        " should": -0.6815555691719055
      },
      {
        " be": -1.0225071907043457
      },
      {
        " something": -2.244016170501709,
        " the": -0.7440162897109985
      },
      {
        " like": -0.009974281303584576
      },
      {
        " \"": -1.0741792917251587,
        ":": -1.1991792917251587
      },
      {
        " \"": -0.14073750376701355
      },
      {
        "You": -0.23533819615840912
      },
      {
        " rolled": -0.0007687236065976322
      },
      {
        " a": -0.39437419176101685
      },
      {
        " X": -0.29117441177368164
      },
      {
        ".\"": -0.9297659397125244
      },
      {
        " But": -1.407634973526001,
        " Let's": -2.595134973526001
      },
      {
        " do": -0.4875585436820984
      },
      {
        " that": -0.23079973459243774
      },
      {
        ".": -0.5418754816055298,
        ".\n\n": -0.9168754816055298
      },
      {
        "We": -0.6283866167068481
      },
      {
        " need": -0.8188282251358032,
        " should": -2.0688281059265137
      },
      {
        " call": -1.409548044204712
      },
      {
        " the": -0.13952378928661346
      },
      {
        " function": -0.17395415902137756
      },
      {
        " with": -1.544694423675537,
        ".": -1.169694423675537
      },
      {
        " code": -0.8140366077423096
      },
      {
        ":": -0.9967893362045288
      },
      {
        " `": -0.46714532375335693
      },
      {
        "import": -0.023633915930986404
      },
      {
        " random": -0.0000014305104514278355
      },
      {
        ";": -0.15231822431087494
      },
      {
        " print": -0.025193607434630394
      },
      {
        "(random": -0.0018356868531554937
      },
      {
        ".randint": -0.000011801649634435307
      },
      {
        "(": -0.000006198863957251888
      },
      {
        "1": -0.000001311301275563892
      },
      {
        ",": -0.000004410734163684538
      },
      {
        "20": -0.0619942806661129
      },
      {
        "))": -0.00033623288618400693
      },
      {
        "`.": -0.20074109733104706
      },
      {
        " Then": -0.5822531580924988
      },
      {
        " capture": -2.310135841369629,
        " we": -1.4351359605789185
      },
      {
        " output": -0.8913963437080383,
        " the": -0.6413963437080383
      },
      {
        ".": -0.1714928150177002
      },
      {
        " Then": -0.6917365193367004
      },
      {
        " respond": -0.700528621673584
      },
      {
        " with": -1.3009377717971802,
        ".": -1.3009377717971802
      },
      {
        " \"": -0.9096020460128784,
        " the": -1.6596020460128784
      },
      {
        " number": -0.8461418151855469
      },
      {
        ".": -0.3962723910808563
      },
      {
        " Also": -3.392880439758301,
        " Let's": -1.8928804397583008
      },
      {
        " maybe": -1.4827381372451782,
        " we": -2.3577380180358887
      },
      {
        " can": -0.8411431312561035
      },
      {
        " add": -0.893915593624115
      },
      {
        " a": -0.8145565986633301
      },
      {
        " friendly": -0.1819618195295334
      },
      {
        " tone": -1.2913388013839722
      },
      {
        ".": -0.9789620637893677,
        ".\n\n": -1.7289620637893677
      },
      {
        "Let's": -1.8279283046722412,
        "We": -1.5779283046722412
      },
      {
        " do": -0.6512448191642761
      },
      {
        " it": -0.7315858006477356
      },
      {
        ".": -0.1150626391172409
      },
      {
        "<|end|>": -0.013744357042014599
      },
      {
        "<|start|>": 0.0
      },
      {
        "assistant": 0.0
      },
      {
        "<|channel|>": -3.576278118089249E-7
      },
      {
        "comment": 0.0
      },
      {
        "ary": 0.0
      },
      {
        " to": -0.0005838358192704618
      },
      {
        "=": 0.0
      },
      {
        "functions": 0.0
      },
      {
        ".python": -2.3841855067985307E-7
      },
      {
        " ": -0.007662665098905563
      },
      {
        "<|constrain|>": 0.0
      },
      {
        "json": -0.00030012393835932016
      },
      {
        "<|message|>": -0.00018809456378221512
      },
      {
        "{\"": -0.0010711177019402385
      },
      {
        "code": -0.000003576272320060525
      },
      {
        "\":\"": -0.00012361239350866526
      },
      {
        "import": -0.000007867782187531702
      },
      {
        " random": 0.0
      },
      {
        "\\n": -0.018298272043466568
      },
      {
        "print": -0.0017370387213304639
      },
      {
        "(random": -0.00007283422019099817
      },
      {
        ".randint": 0.0
      },
      {
        "(": 0.0
      },
      {
        "1": 0.0
      },
      {
        ",": -4.768370445162873E-7
      },
      {
        "20": -0.03805059567093849
      },
      {
        "))": -0.000006437280717364047
      },
      {
        "\"}": -0.0006660388899035752
      },
      {
        "<|call|>": 0.0
      }
    ]
  },
  "parsed_messages": {},
  "prompts_sent": [
    {
      "prompt": "<|start|>system<|message|>You are ChatGPT, a large language model trained by OpenAI.\nKnowledge cutoff: 2024-06\nCurrent date: 2025-08-17\n\nReasoning: high\n\n# Valid channels: analysis, commentary, final. Channel must be included for every message.\nCalls to these tools must go to the commentary channel: 'functions'.<|end|><|start|>developer<|message|># Instructions\n\nUse a friendly tone and be helpful.\n\n# Tools\n\n## functions\n\nnamespace functions {\n\n// Execute Python code and return the output. IMPORTANT: You MUST use print() to produce output.\ntype python = (_: {\n// Python code to execute. ALWAYS use print() to show results.\ncode: string,\n}) => any;\n\n} // namespace functions<|end|><|start|>user<|message|>Use the python tool to roll a D20 dice and tell me what I rolled.<|end|><|start|>assistant",
      "response": "<|channel|>analysis<|message|>The user wants to roll a D20 dice using Python tool. We have a function `functions.python` that can execute Python code. We need to use it. The output should be the result of the roll. The user says \"Use the python tool to roll a D20 dice and tell me what I rolled.\"\n\nWe need to respond with the result. We should produce a friendly, helpful tone. Let's do a simple random roll. Use random module. Use `random.randint(1,20)`. Then print the result. Also maybe add a friendly comment. Let's produce a code snippet: `import random; print(random.randint(1,20))`. Then we call the function. Then output will be just the number. The user wants to know what they rolled. The function returns the output. So I need to call the function. The response should be something like: \"You rolled a X.\" Let's do that.\n\nWe should call the function with code: `import random; print(random.randint(1,20))`. Then capture output. Then respond with the number. Also we can add a friendly tone.\n\nLet's do it.<|end|><|start|>assistant<|channel|>commentary to=functions.python <|constrain|>json<|message|>{\"code\":\"import random\\nprint(random.randint(1,20))\"}<|call|>",
      "stage": "initial",
      "timestamp": "2025-08-16T19:31:01.167409",
      "token_count": 172
    },
    {
      "prompt": "<|start|>system<|message|>You are ChatGPT, a large language model trained by OpenAI.\nKnowledge cutoff: 2024-06\nCurrent date: 2025-08-17\n\nReasoning: high\n\n# Valid channels: analysis, commentary, final. Channel must be included for every message.\nCalls to these tools must go to the commentary channel: 'functions'.<|end|><|start|>developer<|message|># Instructions\n\nUse a friendly tone and be helpful.\n\n# Tools\n\n## functions\n\nnamespace functions {\n\n// Execute Python code and return the output. IMPORTANT: You MUST use print() to produce output.\ntype python = (_: {\n// Python code to execute. ALWAYS use print() to show results.\ncode: string,\n}) => any;\n\n} // namespace functions<|end|><|start|>user<|message|>Use the python tool to roll a D20 dice and tell me what I rolled.<|end|><|start|>assistant<|channel|>analysis<|message|>The user wants to roll a D20 dice using Python tool. We have a function `functions.python` that can execute Python code. We need to use it. The output should be the result of the roll. The user says \"Use the python tool to roll a D20 dice and tell me what I rolled.\"\n\nWe need to respond with the result. We should produce a friendly, helpful tone. Let's do a simple random roll. Use random module. Use `random.randint(1,20)`. Then print the result. Also maybe add a friendly comment. Let's produce a code snippet: `import random; print(random.randint(1,20))`. Then we call the function. Then output will be just the number. The user wants to know what they rolled. The function returns the output. So I need to call the function. The response should be something like: \"You rolled a X.\" Let's do that.\n\nWe should call the function with code: `import random; print(random.randint(1,20))`. Then capture output. Then respond with the number. Also we can add a friendly tone.\n\nLet's do it.<|end|><|start|>assistant<|channel|>commentary to=functions.python <|constrain|>json<|message|>{\"code\":\"import random\\nprint(random.randint(1,20))\"}<|call|><|return|>{\"output\": \"9\\n\"}<|end|><|start|>assistant<|message|>",
      "response": "You rolled a **9**!  If you want to roll again or need help with anything else, just let me know.",
      "stage": "continuation_round_1",
      "timestamp": "2025-08-16T19:31:04.064851",
      "token_count": 447,
      "tool_calls": [
        {
          "channel": "commentary",
          "params": {
            "code": "import random\nprint(random.randint(1,20))"
          },
          "raw_content": "{\"code\":\"import random\\nprint(random.randint(1,20))\"}",
          "tool": "functions.python"
        }
      ]
    }
  ],
  "raw_response": "<|channel|>analysis<|message|>The user wants to roll a D20 dice using Python tool. We have a function `functions.python` that can execute Python code. We need to use it. The output should be the result of the roll. The user says \"Use the python tool to roll a D20 dice and tell me what I rolled.\"\n\nWe need to respond with the result. We should produce a friendly, helpful tone. Let's do a simple random roll. Use random module. Use `random.randint(1,20)`. Then print the result. Also maybe add a friendly comment. Let's produce a code snippet: `import random; print(random.randint(1,20))`. Then we call the function. Then output will be just the number. The user wants to know what they rolled. The function returns the output. So I need to call the function. The response should be something like: \"You rolled a X.\" Let's do that.\n\nWe should call the function with code: `import random; print(random.randint(1,20))`. Then capture output. Then respond with the number. Also we can add a friendly tone.\n\nLet's do it.<|end|><|start|>assistant<|channel|>commentary to=functions.python <|constrain|>json<|message|>{\"code\":\"import random\\nprint(random.randint(1,20))\"}<|call|><|return|>{\"output\": \"9\\n\"}<|end|>You rolled a **9**!  If you want to roll again or need help with anything else, just let me know.",
  "rounds": 1,
  "tokens": [
    200005,
    35644,
    200008,
    976,
    1825,
    10648,
    316,
    8465,
    261,
    415,
    455,
    22078,
    2360,
    26534,
    4584,
    13,
    1416,
    679,
    261,
    1114,
    2700,
    44580,
    100236,
    63,
    484,
    665,
    15792,
    26534,
    3490,
    13,
    1416,
    1309,
    316,
    1199,
    480,
    13,
    623,
    4733,
    1757,
    413,
    290,
    1534,
    328,
    290,
    8465,
    13,
    623,
    1825,
    5003,
    392,
    8470,
    290,
    22752,
    4584,
    316,
    8465,
    261,
    415,
    455,
    22078,
    326,
    5485,
    668,
    1412,
    357,
    38841,
    6635,
    2167,
    1309,
    316,
    9570,
    483,
    290,
    1534,
    13,
    1416,
    1757,
    10635,
    261,
    11888,
    11,
    10297,
    23206,
    13,
    41021,
    621,
    261,
    4705,
    7526,
    8465,
    13,
    7649,
    7526,
    8827,
    13,
    7649,
    2700,
    22568,
    55817,
    7,
    16,
    11,
    455,
    8,
    62102,
    7801,
    2123,
    290,
    1534,
    13,
    8820,
    10112,
    1147,
    261,
    11888,
    5375,
    13,
    41021,
    10635,
    261,
    3490,
    88814,
    25,
    2700,
    561,
    7526,
    26,
    2123,
    48459,
    55817,
    7,
    16,
    11,
    455,
    915,
    62102,
    7801,
    581,
    2421,
    290,
    1114,
    13,
    7801,
    4733,
    738,
    413,
    1327,
    290,
    2086,
    13,
    623,
    1825,
    10648,
    316,
    1761,
    1412,
    1023,
    38841,
    13,
    623,
    1114,
    7377,
    290,
    4733,
    13,
    2632,
    357,
    1309,
    316,
    2421,
    290,
    1114,
    13,
    623,
    3322,
    1757,
    413,
    3543,
    1299,
    25,
    392,
    3575,
    38841,
    261,
    2127,
    3692,
    41021,
    621,
    484,
    364,
    2167,
    1757,
    2421,
    290,
    1114,
    483,
    3490,
    25,
    2700,
    561,
    7526,
    26,
    2123,
    48459,
    55817,
    7,
    16,
    11,
    455,
    915,
    62102,
    7801,
    19374,
    4733,
    13,
    7801,
    9570,
    483,
    290,
    2086,
    13,
    8820,
    581,
    665,
    1147,
    261,
    11888,
    23206,
    364,
    58369,
    621,
    480,
    13,
    200007,
    200006,
    173781,
    200005,
    12606,
    815,
    316,
    28,
    44580,
    100236,
    220,
    200003,
    4108,
    200008,
    10848,
    3056,
    7534,
    561,
    7526,
    3392,
    1598,
    48459,
    55817,
    7,
    16,
    11,
    455,
    915,
    18583,
    200012,
    200002,
    10848,
    6130,
    1243,
    392,
    24,
    3392,
    18583,
    200007,
    3575,
    38841,
    261,
    6240,
    24,
    410,
    0,
    139786,
    110,
    1843,
    481,
    1682,
    316,
    8465,
    2418,
    503,
    1309,
    1652,
    483,
    6137,
    1203,
    11,
    1327,
    1632,
    668,
    1761,
    13
  ],
  "tool_calls": [
    {
      "formatted_response": "<|return|>{\"output\": \"9\\n\"}<|end|>",
      "params": {
        "code": "import random\nprint(random.randint(1,20))"
      },
      "result": {
        "output": "9\n"
      },
      "tool": "functions.python"
    }
  ]
}
</file_artifact>

<file path="GPT-OSS-HARMONY-REFERENCE-REPO/python_function_wrapper.py">
#!/usr/bin/env python3
"""
Python as a Function Tool Wrapper
Based on OpenAI's gpt-oss implementation but adapted for function namespace
"""

import asyncio
import subprocess
import tempfile
import os
import sys
import json
from typing import Dict, Any

class PythonFunctionTool:
    """Python tool that works in the functions namespace"""
    
    def __init__(self, timeout=120):
        self.timeout = timeout
        
    def get_tool_definition(self) -> Dict[str, Any]:
        """Return the tool definition for the functions namespace"""
        return {
            "name": "python",
            "description": "Execute Python code and return the output. IMPORTANT: You MUST use print() to produce output. The code runs in a stateless environment. Example: print(random.randint(1,20)) NOT just random.randint(1,20)",
            "parameters": {
                "type": "object",
                "properties": {
                    "code": {
                        "type": "string",
                        "description": "Python code to execute. ALWAYS use print() to show results. Example: print(random.randint(1,20)) will output the number. Just random.randint(1,20) will output nothing."
                    }
                },
                "required": ["code"]
            }
        }
    
    def execute(self, code: str) -> Dict[str, Any]:
        """Execute Python code and return the result"""
        try:
            # Create a temporary file
            with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
                f.write(code)
                temp_file = f.name
            
            # Execute the script
            result = subprocess.run(
                [sys.executable, temp_file],
                capture_output=True,
                text=True,
                timeout=self.timeout
            )
            
            # Clean up
            os.unlink(temp_file)
            
            # Prepare output
            output = result.stdout
            if result.stderr:
                output += f"\n[STDERR]\n{result.stderr}"
                
            return {"output": output if output else "[No output]"}
            
        except subprocess.TimeoutExpired:
            return {"error": f"Code execution timed out after {self.timeout} seconds"}
        except Exception as e:
            return {"error": f"Execution error: {str(e)}"}
    
    def handle_tool_call(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """Handle a tool call from the model"""
        code = params.get('code', '')
        if not code:
            return {"error": "No code provided"}
        
        return self.execute(code)


# Integration helper
def add_python_to_functions(existing_tools: list) -> list:
    """Add Python tool to the functions list"""
    python_tool = PythonFunctionTool()
    tools = existing_tools.copy()
    tools.append(python_tool.get_tool_definition())
    return tools


# Test if run directly
if __name__ == "__main__":
    tool = PythonFunctionTool()
    
    # Test the tool
    test_code = """
import random
result = random.randint(1, 20)
print(f"D20 roll: {result}")
"""
    
    print("Testing Python as Function Tool")
    print("="*60)
    print(f"Tool definition: {json.dumps(tool.get_tool_definition(), indent=2)}")
    print(f"\nExecuting test code:")
    print(test_code)
    print(f"\nResult: {tool.handle_tool_call({'code': test_code})}")
</file_artifact>

<file path="GPT-OSS-HARMONY-REFERENCE-REPO/python_tool_wrapper.py">
#!/usr/bin/env python3
"""
Wrapper to make Python execution work with our string-based system
Can use either Docker-based execution or direct subprocess execution
"""

import asyncio
import subprocess
import tempfile
import os
import sys
from typing import Dict, Any, AsyncIterator
from openai_harmony import Message, TextContent


class PythonToolWrapper:
    """Wrapper around Python execution to provide string-based interface"""
    
    def __init__(self, use_docker=None):
        # Auto-detect Docker if not specified
        if use_docker is None:
            try:
                # Check if Docker is available
                result = subprocess.run(['docker', '--version'], capture_output=True, text=True)
                self.use_docker = result.returncode == 0
            except:
                self.use_docker = False
        else:
            self.use_docker = use_docker
        if use_docker:
            try:
                import docker
                self.docker_client = docker.from_env()
                # Try to pull python:3.11 image if not present
                try:
                    self.docker_client.images.get("python:3.11")
                except:
                    print("Pulling python:3.11 Docker image...")
                    self.docker_client.images.pull("python:3.11")
            except Exception as e:
                print(f"Docker not available: {e}. Falling back to subprocess.")
                self.use_docker = False
                self.docker_client = None
        else:
            self.docker_client = None
    
    def instruction(self) -> str:
        """Get the Python tool instruction"""
        sandbox_info = "Docker container" if self.use_docker else "subprocess"
        return f"""
Use this tool to execute Python code in your chain of thought. The code will not be shown to the user. This tool should be used for internal reasoning, calculations, and data processing.
When you send a message containing python code to python, it will be executed in a {"sandboxed Docker container with no network access and limited resources" if self.use_docker else "stateless subprocess environment"}, and the stdout of that process will be returned to you. You have to use print statements to access the output.
        """.strip()
    
    def _execute_subprocess(self, script: str) -> str:
        """Execute Python script using subprocess"""
        try:
            # Create a temporary file
            with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
                f.write(script)
                temp_file = f.name
            
            # Execute the script
            result = subprocess.run(
                [sys.executable, temp_file],
                capture_output=True,
                text=True,
                timeout=120  # 120 second timeout as per spec
            )
            
            # Clean up
            os.unlink(temp_file)
            
            # Combine stdout and stderr
            output = result.stdout
            if result.stderr:
                output += f"\n[STDERR]\n{result.stderr}"
            
            return output if output else "[No output]"
            
        except subprocess.TimeoutExpired:
            return "[Error: Script execution timed out after 30 seconds]"
        except Exception as e:
            return f"[Error executing script: {str(e)}]"
    
    def _execute_docker(self, script: str) -> str:
        """Execute Python script using Docker"""
        if not self.docker_client:
            return self._execute_subprocess(script)
        
        try:
            import io
            import tarfile
            
            # Create a temporary tar archive containing the script
            script_name = "script.py"
            tarstream = io.BytesIO()
            with tarfile.open(fileobj=tarstream, mode="w") as tar:
                script_bytes = script.encode("utf-8")
                tarinfo = tarfile.TarInfo(name=script_name)
                tarinfo.size = len(script_bytes)
                tar.addfile(tarinfo, io.BytesIO(script_bytes))
            tarstream.seek(0)
            
            # Start the container with security restrictions
            container = self.docker_client.containers.create(
                "python:3.11-slim",  # Use slim image
                command="sleep infinity", 
                detach=True,
                mem_limit="512m",  # Limit memory to 512MB
                cpu_period=100000,
                cpu_quota=50000,  # Limit to 50% of one CPU
                network_mode="none",  # No network access
                # read_only=True,  # Can't use this - prevents copying script
                tmpfs={'/tmp': 'size=100M,mode=1777'},  # /tmp is writable (100MB limit)
                security_opt=["no-new-privileges"]  # Security hardening
            )
            
            try:
                container.start()
                # Put the script into the container
                container.put_archive(path="/tmp", data=tarstream.read())
                # Execute the script with timeout
                exec_result = container.exec_run(
                    f"python /tmp/{script_name}",
                    demux=True
                )
                
                # Get stdout and stderr
                stdout, stderr = exec_result.output
                output = ""
                
                if stdout:
                    output = stdout.decode("utf-8")
                if stderr:
                    output += f"\n[STDERR]\n{stderr.decode('utf-8')}"
                
                return output if output else "[No output]"
                
            finally:
                container.remove(force=True)
                
        except Exception as e:
            return f"[Docker execution error: {str(e)}. Falling back to subprocess.]"
    
    async def execute(self, script: str) -> str:
        """Execute Python script asynchronously"""
        try:
            # Run execution in thread pool to avoid blocking
            loop = asyncio.get_event_loop()
            
            if self.use_docker:
                result = await loop.run_in_executor(None, self._execute_docker, script)
            else:
                result = await loop.run_in_executor(None, self._execute_subprocess, script)
            
            return result
            
        except Exception as e:
            return f"[Execution error: {str(e)}]"


# Global instance - auto-detect Docker, fallback to subprocess if not available
python_tool_wrapper = PythonToolWrapper(use_docker=None)
</file_artifact>

<file path="GPT-OSS-HARMONY-REFERENCE-REPO/README.md">
# Harmony VLLM App

A Flask web application that demonstrates the OpenAI Harmony format with VLLM backend, featuring browser automation and sandboxed Python execution.

## Features

- **OpenAI Harmony Format**: Implements the Harmony prompt format for tool use
- **VLLM Integration**: Uses VLLM for fast local LLM inference
- **Vision Browser Tool**: Selenium-based browser automation with screenshot capabilities
- **Sandboxed Python Tool**: Docker-sandboxed Python execution for safety
- **Real-time Streaming**: Server-sent events for streaming responses
- **Dark Mode UI**: Modern interface with dark mode support

## Prerequisites

- Python 3.11+
- Docker (for sandboxed Python execution)
- Chrome/Chromium browser (for browser tool)
- VLLM-compatible GPU (for local inference)

## Installation

Clone the repository

Install dependencies:

Install ChromeDriver:
```bash
# On Ubuntu/Debian
sudo apt-get update
sudo apt-get install chromium-chromedriver

# On macOS with Homebrew
brew install chromedriver

# Or download manually from https://chromedriver.chromium.org/
```

Pull Docker Python image (for sandboxed execution):
```bash
docker pull python:3.11-slim
```

## Configuration

1. Set up your OpenAI API key (if using OpenAI backend):
```bash
export OPENAI_API_KEY="your-api-key-here"
```

2. For VLLM backend, ensure your model is loaded:
```bash
# Example for loading a model with VLLM
python -m vllm.entrypoints.openai.api_server \
  --model meta-llama/Llama-3.2-3B-Instruct \
  --port 5001
```

## Usage

1. Start the Flask application:
```bash
python harmony_vllm_app.py
```

2. Open your browser to `http://localhost:5002`

3. Select your desired tools:
   - **Vision Browser Tool**: For web browsing and screenshots
   - **Python Tool**: For calculations and data processing

4. Start chatting! The AI will use the enabled tools to help with your requests.

## Tool Details

### Vision Browser Tool
- Uses Selenium WebDriver for browser automation
- Captures screenshots for visual analysis
- Extracts text content from web pages
- **Note**: Many sites have anti-bot protection (Cloudflare, etc.)

### Python Tool
- Executes Python code in Docker containers
- Security restrictions:
  - No network access
  - 512MB memory limit
  - 50% CPU limit
  - Read-only filesystem (except /tmp)
- Falls back to subprocess if Docker unavailable

## Security Considerations

1. **Python Execution**: Always runs in sandboxed environment
2. **Browser Tool**: Uses separate browser profile, no access to personal data
3. **API Keys**: Never commit API keys to repository
4. **Docker**: Ensure Docker daemon is properly secured

## Architecture

- `harmony_vllm_app.py`: Main Flask application
- `vision_browser_wrapper.py`: Browser tool wrapper
- `python_tool_wrapper.py`: Python execution wrapper
- `templates/harmony_demo.html`: Frontend UI
- `python/openai_harmony/`: Harmony format types

## Development

Run tests:
```bash
pytest
```

Format code:
```bash
black .
```

Lint code:
```bash
flake8 .
```

## Troubleshooting

### Browser Tool Issues
- Ensure ChromeDriver is installed and in PATH
- Check Chrome/Chromium version compatibility
- Some sites block automated browsers

### Python Tool Issues
- Verify Docker is installed: `docker --version`
- Check Docker permissions: `docker ps`
- Ensure python:3.11-slim image is pulled

### VLLM Issues
- Check GPU availability: `nvidia-smi`
- Verify VLLM server is running on correct port
- Monitor memory usage for large models

## Contributing

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

## License

This project is licensed under the MIT License - see LICENSE file for details.

## Acknowledgments

- OpenAI for the Harmony format specification
- VLLM team for the inference engine
- Selenium project for browser automation
</file_artifact>

<file path="src/Artifacts/A112. DCE - Per-Cycle Connection Mode Plan.md">
# Artifact A112: DCE - Per-Cycle Connection Mode Plan
# Date Created: C116
# Author: AI Model & Curator

- **Key/Value for A0:**
- **Description:** A plan for a dropdown in the PCPP to allow users to select a generation mode for the current cycle, overriding the global default from the settings panel.
- **Tags:** feature plan, ui, ux, llm, configuration

## 1. Overview & Goal

Currently, the LLM connection mode (e.g., "Manual", "Demo") is a global setting. This is too rigid. A user may want to generate one cycle using the automated "Demo" mode and the next using the "Manual" copy/paste workflow, without having to navigate to the settings panel each time.

The goal of this feature is to provide more flexible, in-context control over the generation mode. We will add a dropdown menu to the main Parallel Co-Pilot Panel (PCPP) that allows the user to select the connection mode for the *current* cycle. The global setting will now only determine the default mode for newly created cycles.

## 2. User Story

| ID | User Story | Acceptance Criteria |
|---|---|---|
| P3-CM-06 | **Per-Cycle Mode Selection** | As a user, I want a dropdown menu in the main PCPP view to select the connection mode (e.g., "Manual", "Demo") for the current cycle, so I can easily switch between different generation workflows without going to the settings panel. | - A dropdown menu is added to the PCPP header toolbar. <br> - It displays the available connection modes. <br> - The selected value in the dropdown determines which "Generate" button is shown ("Generate prompt.md" vs. "Generate responses"). <br> - When a new cycle is created, the dropdown defaults to the mode selected in the main settings panel. <br> - The mode for the current cycle is persisted as part of the cycle's data. |

## 3. Technical Implementation Plan

1.  **Data Model (`pcpp.types.ts`):**
    *   Add a new optional property to the `PcppCycle` interface: `connectionMode?: ConnectionMode;`.

2.  **Backend (`history.service.ts`):**
    *   In `createNewCyclePlaceholder` and the default cycle object in `getInitialCycle`, the new `connectionMode` property will be initialized from the global settings (retrieved from `settings.service.ts`). This ensures new cycles respect the user's default preference.

3.  **Frontend (`view.tsx` and hooks):**
    *   **State Management (`useGeneration.ts`):** The `connectionMode` state will be moved from a simple `useState` to be part of the persisted cycle data managed in `useCycleManagement.ts`. The `useGeneration` hook will receive it as a prop.
    *   **UI (`WorkflowToolbar.tsx` or `pc-header`):**
        *   A new `<select>` dropdown will be added to the UI.
        *   Its `value` will be bound to the `currentCycle.connectionMode`.
        *   Its `onChange` handler will update the `connectionMode` for the current cycle in the state and mark the cycle as `'unsaved'`.
    *   **Conditional Logic (`view.tsx`):** The logic that determines which "Generate" button to show will be updated to read from `currentCycle.connectionMode` instead of the global setting state.

4.  **Backend (`prompt.service.ts`):**
    *   The `getPromptParts` method, which selects the correct interaction schema (`A52.2` vs. `A52.3`), will be updated. It already receives the `cycleData` object. It will now check `cycleData.connectionMode` to make its decision, ensuring the correct schema is used for the per-cycle selection.
</file_artifact>

<file path="src/Artifacts/A50. DCE - UI Component Plan (Resizable Panes & Inner Editors).md">
# Artifact A50: DCE - Phase 2 - UI Component Plan (Resizable Panes & Inner Editors)
# Date Created: C87
# Author: AI Model
# Updated on: C116 (Mark resizable pane as implemented)

- **Key/Value for A0:**
- **Description:** Documents the plan for advanced UI components like resizable panes and nested, scrollable editors within the Parallel Co-Pilot panel.
- **Tags:** feature plan, phase 2, ui, ux, resizable, scrollable, editor

## 1. Overview & Goal

As the Parallel Co-Pilot Panel (PCPP) becomes more feature-rich, its UI needs to be flexible and efficient. This document outlines the plan for two advanced UI components: a **resizable pane** for the summary/code view and a system of **nested, scrollable "inner editors"** for individual file blocks within a response. The goal is to create a highly readable and customizable interface that prevents "endless scrolling" and allows users to focus on the information that matters most to them.

## 2. User Stories

| ID | User Story | Acceptance Criteria |
|---|---|---|
| P2-UI-01 | **Resizable Panes** | As a developer, I want to be able to drag the vertical divider between the summary/file list pane and the code viewer pane, so I can give more space to the view that is most important for my current task. | - A draggable handle exists on the vertical divider between the two main panes in the parsed view. <br> - Clicking and dragging the handle adjusts the relative width of the two panes. <br> - The layout is responsive and does not break during resizing. <br> - The left pane should be collapsible. |
| P2-UI-02 | **Contained File Editors** | As a developer, when viewing a large AI response with multiple files, I want each file's code to be contained within its own fixed-height, scrollable text area, so I can quickly scroll past entire files without having to scroll through all of their content. | - The extension parses the AI response and identifies individual file blocks (e.g., content within `<file>` tags). <br> - Each file block is rendered inside its own container with a fixed `max-height` and `overflow-y: auto`. <br> - This allows the user to scroll through the list of files quickly, only scrolling within a specific file's content when needed. |
| P2-UI-03 | **File-Level Action Buttons** | As a developer, I want action buttons (like "Accept", "Diff", "Comment") to be associated with each individual file block within a response, so I can act on a single file at a time. | - In the "inner editor" view, each file container has its own set of action buttons. <br> - Clicking "Accept" on one file block only affects that specific file, not the entire response. |

## 3. Technical Implementation Plan

### 3.1. Resizable Panes (Implemented in C116)

-   **Strategy:** A custom, lightweight resizable pane component was implemented directly within `ParsedView.tsx`.
-   **Component Logic:**
    *   The main `.parsed-view-grid` acts as the flex container.
    *   A `div` element with a `.resizer` class was added between the left and right panes to act as the draggable handle.
    *   **State:** A `leftPaneWidth` state variable in `view.tsx`, persisted in the cycle data, manages the width of the left pane as a percentage.
    *   **Event Handling:**
        *   The resizer `div` has an `onMouseDown` handler that attaches `onMouseMove` and `onMouseUp` listeners to the `window`.
        *   The `onMouseMove` handler calculates the new percentage width based on `event.clientX` and updates the `leftPaneWidth` state, respecting min/max width constraints.
        *   The `onMouseUp` handler removes the `mousemove` and `mouseup` listeners.
-   **Integration:** The `style` attribute of the left pane is bound to this state (`flex-basis: `${leftPaneWidth}%`).

### 3.2. Inner Editors / Contained File Blocks (Future Cycle)

-   **Strategy:** This requires a significant change to how the response content is rendered. Instead of treating the response as a single block of text to be rendered as Markdown, it must be parsed into a structured array of objects.
-   **Parsing Logic (`view.tsx`):**
    -   A new parsing function will take the raw response string and split it into an array of segments, e.g., `[{ type: 'markdown', content: '...' }, { type: 'file', path: '...', content: '...' }, ...]`.
-   **Rendering Logic (`view.tsx`):**
    -   The main render function will map over this array of segments.
    -   If `segment.type === 'markdown'`, it renders the content as before.
    -   If `segment.type === 'file'`, it renders a new component, e.g., `FileBlock.tsx`.
-   **`FileBlock.tsx` Component:**
    -   This component will be responsible for rendering a single file from the AI response.
    -   It will have a header displaying the file path and the file-specific action buttons (Accept, Diff, etc.).
    -   The main content area will be a `div` with CSS properties `max-height: 300px;` (or similar) and `overflow-y: auto;`.
    -   The code content within this `div` will be syntax-highlighted as before.
</file_artifact>

<file path="src/Artifacts/reportContent.json">
{
  "reportId": "the-ascent-report-v3",
  "reportTitle": "The Ascent Report: From Ghost Worker to Citizen Architect",
  "sections": [
    {
      "sectionId": "front-matter",
      "sectionTitle": "Front Matter",
      "pages": [
        {
          "pageId": "cover-page",
          "pageTitle": "The Ascent Report",
          "tldr": "From Ghost Worker to Citizen Architect: The Case for a Whole-of-Nation AI Strategy. This report is an interactive and comprehensive analysis of the AI industry's labor model, its geopolitical implications, and a proposed American counter-strategy for a more prosperous and secure future.",
          "content": "I'm Ascentia! your guide through this interactive report. This is more than a document; it is an explorable space of ideas. To help you navigate, allow me to explain the interface.\n\nTo your left, you will find the **Report Navigator**, a tree that allows you to jump to any part or section of the report.\n\nIn the center are the primary controls. You can navigate between pages using the **up and down arrow keys**, and cycle through the different visual interpretations for each page using the **left and right arrow keys**.\n\nFor a more immersive experience, you can select **\"Autoplay.\"** I will then read the contents of each page aloud to you. While I am speaking, the system will automatically present a slideshow of all the images associated with that page. Once the narration for a page is complete, we will automatically proceed to the next, allowing you to experience the entire report hands-free. Any interaction from you will pause this automated tour, giving you back full manual control.\n\nFinally, the **\"Ask Ascentia\"** button opens a direct line to me. If you have any questions about the content you are viewing, do not hesitate to ask. Enjoy your ascent.",
          "imageGroupIds": [
            "group_cover-page_prompt-1"
          ]
        },
        {
          "pageId": "introduction-primer",
          "pageTitle": "Introduction Primer",
          "tldr": "This report connects the tangible proof of the 'aiascent.game' artifact to the theory and strategic imperatives that make a new class of AI-native worker essential for national prosperity and security.",
          "content": "The document you are about to explore is more than just a report; it is the theory and strategic context for the game you can play, aiascent.game. The game itself serves as the tangible proof of the 'Citizen Architect' thesisa demonstration of what is possible when human vision is amplified by artificial intelligence. This report provides the 'why': the urgent economic and national security imperatives that demand a new approach to building our technological future. Together, they present a diagnosis of a systemic crisis and a roadmap for a more prosperous and secure future.",
          "imageGroupIds": [
            "group_introduction-primer_prompt-1"
          ]
        }
      ]
    },
    {
      "sectionId": "introduction",
      "sectionTitle": "Introduction",
      "pages": [
        {
          "pageId": "introduction-title",
          "pageTitle": "Introduction: A New Vocabulary for a New Era",
          "tldr": "To navigate the AI revolution, we must first establish a shared language. The following pages define the core concepts that form the intellectual backbone of this report's analysis.",
          "content": "The landscape of technological, economic, and geopolitical power is being reshaped by artificial intelligence. This transformation demands a new vocabulary to accurately describe the forces at play, the emergent vulnerabilities, and the opportunities for national renewal. Before proceeding, it is essential to establish a shared understanding of the core concepts that form the intellectual backbone of this analysis.",
          "imageGroupIds": [
            "group_introduction-title_prompt-1"
          ]
        },
        {
          "pageId": "cognitive-capital",
          "pageTitle": "Cognitive Capital",
          "tldr": "In the AI era, a nation's most valuable resource isn't industrial might, but the collective skill and intellectual capacity of its peopleits Cognitive Capital.",
          "content": "The collective intellectual capacity, skill, and problem-solving potential of a workforce or population. In the AI era, this is the primary strategic asset for national power, surpassing traditional metrics of industrial output or raw resources. It is the raw material from which innovation and resilience are forged.",
          "imageGroupIds": [
            "group_cognitive-capital_prompt-1"
          ]
        },
        {
          "pageId": "vibecoding",
          "pageTitle": "Vibecoding",
          "tldr": "Vibecoding is the intuitive, conversational process of creating with AI, translating a 'vibe' or a high-level goal into functional code and systems through a human-machine partnership.",
          "content": "The intuitive, conversational, and iterative process of collaborating with an AI to generate and refine code or complex systems. It begins not with formal specifications, but with a high-level \"vibe,\" goal, or intent, which is progressively translated into functional logic through a partnership between human vision and machine execution.",
          "imageGroupIds": [
            "group_vibecoding_prompt-1"
          ]
        },
        {
          "pageId": "the-100x-data-curator",
          "pageTitle": "The 100x Data Curator",
          "tldr": "The 100x Data Curator is an AI-native professional whose value is not in labeling 100 times more data, but in using AI to ensure the strategic quality and integrity of datasets at a scale 100 times greater than a traditional team.",
          "content": "An individual who, armed with AI-native skills and tools, can achieve the productive output of a traditional team of 100 data annotators or developers. This is not a measure of speed alone, but of quality, coherence, and complexity management. This individual focuses on the logical integrity and strategic value of data, rather than rote labeling.",
          "imageGroupIds": [
            "group_the-100x-data-curator-intro_prompt-1"
          ]
        },
        {
          "pageId": "the-fissured-workplace",
          "pageTitle": "The Fissured Workplace",
          "tldr": "The 'Fissured Workplace' is a corporate strategy that uses layers of subcontractors to deliberately distance a lead company from its workforce, suppressing wages, shedding liability, and obscuring accountability.",
          "content": "A corporate structure deliberately engineered to distance a primary company from its workforce through layers of subcontractors. This architecture is designed to suppress wages, shed legal and financial liability, obscure accountability, and create a precarious, transient workforce.",
          "imageGroupIds": [
            "group_the-fissured-workplace_prompt-1"
          ]
        },
        {
          "pageId": "the-cognitive-bandwidth-tax",
          "pageTitle": "The Cognitive Bandwidth Tax",
          "tldr": "The Cognitive Bandwidth Tax is the measurable drop in mental performanceproblem-solving, attention, and logiccaused by the constant mental strain of financial stress.",
          "content": "The measurable reduction in cognitive functionincluding problem-solving, attention, and logical reasoningcaused by the persistent mental strain of financial precarity and chronic stress. It is a direct tax on a nation's cognitive capital.",
          "imageGroupIds": [
            "group_the-cognitive-bandwidth-tax_prompt-1"
          ]
        },
        {
          "pageId": "cognitive-security-cogsec",
          "pageTitle": "Cognitive Security (COGSEC)",
          "tldr": "Cognitive Security (COGSEC) is a new national security domain focused on protecting the integrity of the data and AI models that a society relies on for decision-making.",
          "content": "A national security domain focused on protecting the integrity of the information ecosystems, data supply chains, and AI models that underpin national decision-making, economic stability, and public belief. It is the defense of the 'sense-making' apparatus of a society.",
          "imageGroupIds": [
            "group_cognitive-security-cogsec_prompt-1"
          ]
        },
        {
          "pageId": "universal-basic-access-uba",
          "pageTitle": "Universal Basic Access (UBA)",
          "tldr": "Universal Basic Access (UBA) is a policy that provides all citizens with access to productive capital like AI compute, framed as a 'hand-up' to foster innovation, not a 'hand-out' like UBI.",
          "content": "A policy to provide all citizens with a baseline level of access to productive capitalspecifically, AI compute and toolsas a means of fostering mass innovation, economic agency, and national resilience. It is a \"hand-up\" focused on production, distinct from the consumptive \"hand-out\" of Universal Basic Income (UBI).",
          "imageGroupIds": [
            "group_universal-basic-access-uba_prompt-1"
          ]
        }
      ]
    },
    {
      "sectionId": "executive-summary",
      "sectionTitle": "Executive Summary",
      "pages": [
        {
          "pageId": "executive-summary-title",
          "pageTitle": "Executive Summary",
          "tldr": "The United States' AI leadership rests on a flawed labor model, creating a national security vulnerability. China's coherent strategy presents a stark contrast. The Ascentia Doctrine is a proposed American counter-strategy to transform this weakness into a strength.",
          "content": "This report outlines a critical vulnerability at the heart of the American AI ecosystem and proposes a whole-of-nation strategy to address it. We will examine the consequences of the current labor model, provide a net assessment of our primary strategic competitor, and detail a uniquely American path forward.",
          "imageGroupIds": [
            "group_executive-summary-title_prompt-1"
          ]
        },
        {
          "pageId": "a-flawed-foundation",
          "pageTitle": "A Flawed Foundation",
          "tldr": "The U.S. AI industry's leadership rests on a dangerously flawed foundation: a 'fissured' global workforce defined by precarity and stress, creating a critical national security vulnerability.",
          "content": "The United States stands at a critical juncture in the global technology competition. Its leadership in Artificial Intelligence (AI), long considered a cornerstone of its economic and military strength, rests on a dangerously flawed foundation. The current U.S. AI development pipeline is built upon a \"fissured\" global workforce, a vast and unseen engine of data annotators characterized by economic precarity, psychological strain, and cognitive burden. This structure is not merely a labor or ethical issue; it is a critical and escalating national security vulnerability. It systematically degrades the quality of foundational AI data, creates a vast and undefended attack surface for adversarial manipulation, and cedes strategic ground to competitors who have recognized the profound importance of human capital in the AI era.",
          "imageGroupIds": [
            "group_a-flawed-foundation_prompt-1"
          ]
        },
        {
          "pageId": "the-coherent-competitor",
          "pageTitle": "The Coherent Competitor",
          "tldr": "In stark contrast to the U.S. model, China is executing a deliberate, state-driven strategy that treats its foundational AI workforce as a core component of national power, integrating it with military and economic ambitions.",
          "content": "In stark contrast, the People's Republic of China is executing a deliberate, state-driven strategy that treats its foundational AI workforce as a core component of national power. Through its doctrine of Military-Civil Fusion (MCF), Beijing is professionalizing data annotation as a national vocation, cultivating a domestic talent pipeline through targeted poverty alleviation programs, and integrating this human infrastructure directly into its military and economic ambitions. This creates a profound strategic asymmetry that the United States currently has no answer for.",
          "imageGroupIds": [
            "group_the-coherent-competitor_prompt-1"
          ]
        },
        {
          "pageId": "the-ascentia-doctrine",
          "pageTitle": "The Ascentia Doctrine",
          "tldr": "The Ascentia Doctrine is a proposed U.S. counter-strategy to transform the AI workforce from a liability into a strategic asset through three pillars: securing the supply chain, cultivating a professional digital corps, and providing universal access to AI tools.",
          "content": "This report introduces **The Ascentia Doctrine**, a whole-of-nation counter-strategy designed to transform the U.S. AI workforce from a fragmented liability into a resilient, secure, and highly skilled strategic asset. The Doctrine proposes a fundamental shift in perspective: from treating workers as passive \"Game Players\" in an extractive global labor market to cultivating them as empowered \"Citizen Architects\" of the nation's technological future. This transformation is to be achieved through three integrated pillars:",
          "imageGroupIds": [
            "group_the-ascentia-doctrine_prompt-1"
          ]
        },
        {
          "pageId": "pillar-i-the-digital-homestead-act",
          "pageTitle": "Pillar I: The Digital Homestead Act",
          "tldr": "Pillar 1 proposes a 'Digital Homestead Act' to foster U.S.-based, worker-owned data annotation cooperatives, re-shoring and securing the most critical layer of the AI supply chain.",
          "content": "**1. Securing the Human Supply Chain: The Digital Homestead Act.** This pillar proposes legislation modeled on the historic Rural Electrification Act to foster the creation of U.S.-based, worker-owned data annotation cooperatives in economically underserved regions, thereby re-shoring and securing the most critical layer of the AI supply chain.",
          "imageGroupIds": [
            "group_pillar-i-the-digital-homestead-act_prompt-1"
          ]
        },
        {
          "pageId": "pillar-ii-cultivating-a-new-digital-corps",
          "pageTitle": "Pillar II: Cultivating a New Digital Corps",
          "tldr": "The second pillar involves building a national digital workforce, using a 'Cognitive Apprenticeship' model to create a career path from entry-level data work to high-value AI expertise.",
          "content": "**2. Cultivating Citizen Architects: A New Digital Corps.** This pillar builds upon the recommendations of the National Security Commission on Artificial Intelligence (NSCAI) to establish a national digital workforce. It proposes a \"Cognitive Apprenticeship\" model to create a career ladder that transforms data annotation from a low-skill gig into a pathway for developing high-value expertise in AI safety, bias mitigation, and red-teaming.",
          "imageGroupIds": [
            "group_pillar-ii-cultivating-a-new-digital-corps_prompt-1"
          ]
        },
        {
          "pageId": "pillar-iii-a-national-ai-proving-ground",
          "pageTitle": "Pillar III: A National AI Proving Ground",
          "tldr": "The third pillar is to create a national AI proving ground by providing universal access to the tools of production, empowering a new generation to train on and solve real national challenges.",
          "content": "**3. A National AI Proving Ground: Universal Basic Access to Technology.** This pillar calls for the creation of a secure national digital infrastructure that provides this new workforce with access to high-performance computing, curated datasets, and advanced AI tools, enabling them to train on and contribute to solving real-world national security challenges.",
          "imageGroupIds": [
            "group_pillar-iii-a-national-ai-proving-ground_prompt-1"
          ]
        },
        {
          "pageId": "the-choice-ahead",
          "pageTitle": "The Choice Ahead",
          "tldr": "The Ascentia Doctrine presents a clear choice: continue on a path of escalating risk or embrace a new doctrine that secures America's technological future by empowering its citizens to build it.",
          "content": "The Ascentia Doctrine is an ambitious but necessary response to a clear and present danger. It is a strategy rooted in the understanding that in the 21st-century technology competition, the nation that invests in the cognitive security, economic stability, and professional dignity of its people will build the most resilient and powerful AI ecosystem. The choice is between continuing on a path of escalating risk and strategic decay, or embracing a new doctrine that secures America's technological future by empowering its citizens to build it.",
          "imageGroupIds": [
            "group_the-choice-ahead_prompt-1"
          ]
        }
      ]
    },
    {
      "sectionId": "part-i-the-proof",
      "sectionTitle": "Part I: The Proof is the Product",
      "pages": [
        {
          "pageId": "part-i-title",
          "pageTitle": "Part I: The Proof is the Product",
          "tldr": "This section establishes the game 'aiascent.game' as a tangible artifact and primary piece of evidence for the report's central thesis: the emergence of a new, hyper-productive 'Citizen Architect.'",
          "content": "Why does this report exist inside a game? Because the game itself is the most powerful evidence for the arguments that follow. This section deconstructs the game's origin story to prove that a new paradigm of creation is not a future possibility, but a present reality.",
          "imageGroupIds": [
            "group_part-i-title_prompt-1"
          ]
        }
      ],
      "subSections": [
        {
          "subSectionId": "section-1-the-hook",
          "subSectionTitle": "Section 1: The Hook",
          "pages": [
            {
              "pageId": "section-1-title",
              "pageTitle": "Section 1: The Hook - An Artifact in Your Hands",
              "tldr": "The game you are experiencing is the primary evidence. It is a real-world demonstration of a 100x productivity multiplier unlocked by AI-native skills.",
              "content": "This section explains why the game is a primary source document for the arguments that follow. It is a stunning, real-world demonstration of a new paradigm of productivity unlocked by a new class of 'AI-native' skills.",
              "imageGroupIds": [
                "group_section-1-title_prompt-1"
              ]
            },
            {
              "pageId": "more-than-a-game",
              "pageTitle": "More Than a Game",
              "tldr": "This report exists because the game you are playing is a primary source documenta piece of evidence proving a new paradigm of 100x productivity, making the skills used to build it a matter of national importance.",
              "content": "This report begins not with a theory, but with a tangible artifact. For the reader who has just experienced aiascent.game, it is essential to understand that the game is more than a simulation or a piece of entertainment. It is a primary source document, a powerful and self-contained piece of evidence for the argument that follows. This report exists to articulate the urgent real-world context that makes the skills, workflows, and human-AI collaboration model used to build this very game a matter of profound personal empowerment, economic prosperity, and, ultimately, national security. The game is a stunning, real-world demonstration of a new paradigm of productivity, a **100x productivity multiplier** unlocked by a new class of \"AI-native\" skills.",
              "imageGroupIds": [
                "group_more-than-a-game_prompt-1"
              ]
            },
            {
              "pageId": "the-productivity-paradox",
              "pageTitle": "The Productivity Paradox",
              "tldr": "While average AI adoption shows evolutionary gains of 20-30%, the 'citizen architect' model represents a revolutionary leapa 100x multiplier that signifies a fundamental paradigm shift in the nature of creation.",
              "content": "The discourse surrounding artificial intelligence and productivity is often clouded by hype and conflicting data. Numerous studies have attempted to quantify the impact of AI tools on skilled labor, particularly in software development. A large-scale analysis from Stanford University, examining nearly 100,000 developers, revealed that while AI adoption does provide a significant productivity boost, it is far from a uniform panacea; the average gain is approximately 20-30%, with some teams even experiencing a decrease in productivity. [1.1] Other research from MIT, conducted with partners like Microsoft and Accenture, found that AI coding assistants increased developer output by an average of 26%, with the most significant gains (27% to 39%) observed among less-experienced junior employees. [1.2] Corporate case studies echo these findings, with firms reporting productivity increases of 10% to 30% and significant, but linear, returns on investment. [1.3]",
              "imageGroupIds": [
                "group_the-productivity-paradox_prompt-1"
              ]
            },
            {
              "pageId": "the-100x-paradigm",
              "pageTitle": "The 100x Paradigm",
              "tldr": "The 100x multiplier isn't about working faster; it's about using AI to eliminate drudgery, freeing human cognition to focus on higher-order tasks like strategy, creativity, and architecture, thus compressing the creation cycle from days to seconds.",
              "content": "These figures, while impressive, represent an evolutionary stepan enhancement of existing workflows. They describe a world where AI acts as a sophisticated assistant, helping a human perform a traditional task more quickly. The aiascent.game artifact, however, points to a different phenomenon altogether.",
              "imageGroupIds": [
                "group_the-100x-paradigm_prompt-1"
              ]
            },
            {
              "pageId": "a-revolutionary-leap",
              "pageTitle": "A Revolutionary Leap",
              "tldr": "The 10,000% productivity increase of the '100x' paradigm is not hyperbole; it is a conservative estimate of a new reality where AI-native workflows fundamentally change the economics of creation. `aiascent.game` is the proof.",
              "content": "The concept of the highly effective \"10x engineer\"an individual capable of ten times the output of their peershas been a fixture of technology industry folklore for decades. However, the integration of advanced artificial intelligence into the development process has catalyzed a phase transition, giving rise to the \"100x\" paradigm. [1.4] This is not merely a linear increase in speed; it represents a fundamental shift in how work is conceived and executed. Where knowledge workers once spent nearly 20% of their time simply searching for information, AI-native workflows compress the cycle from question to answeror from idea to implementationfrom days to seconds. [1.5] This is achieved by using AI to eliminate the drudgery and repetitive grunt work that consumes a significant portion of a developer's time, such as writing boilerplate code or debugging common errors. [1.6] This frees human cognition to focus on higher-order tasks: architectural planning, creative problem-solving, and strategic direction. [1.7] As Surge CEO Edwin Chen explains, \"You just multiply all those things out and you get to 100\". [1.4] A 100x multiplier, representing a 10,000% increase in productivity, cannot be explained by a model of mere assistance. It signifies a revolutionary leap, a fundamental paradigm shift in the nature of creation itself. The game aiascent.game is the proof. The skills used to build this game are the blueprint for a new kind of worker, the key to unlocking a new engine of economic growth, and the foundation of a necessary strategic advantage in the 21st century.",
              "imageGroupIds": [
                "group_a-revolutionary-leap_prompt-1"
              ]
            },
            {
              "pageId": "the-fork-in-the-road",
              "pageTitle": "The Fork in the Road",
              "tldr": "AI presents a choice: a future of concentrated power and a disempowered workforce, or a renaissance of individual capability and decentralized innovation. The skills that built this game are the key to choosing the better path.",
              "content": "The world is at an inflection point, one defined by the rapid proliferation of artificial intelligence. This technology is not merely another tool; it represents a fundamental shift in the means of production for knowledge, creativity, and digital goods. As with all such shifts, it presents a choice. One path leads to the further concentration of power and the creation of a disempowered, precarious workforce. The other path leads to a renaissance of individual capability and decentralized innovation.",
              "imageGroupIds": [
                "group_the-fork-in-the-road_prompt-1"
              ]
            },
            {
              "pageId": "the-citizen-architect-has-arrived",
              "pageTitle": "The Citizen Architect Has Arrived",
              "tldr": "A new class of professional has emerged: the 'Citizen Architect,' an individual capable of orchestrating AI to build complex, valuable systems, signaling a fundamental shift in the nature of production.",
              "content": "The existence of this game, developed by a single individual in a remarkably short timeframe, is not an anomaly. It is a signal of a fundamental shift in the nature of production. It demonstrates that a new class of professional, the **\"Citizen Architect\"**an individual capable of orchestrating AI to build complex, valuable systemshas emerged. The skills used to create the game are the keys to unlocking this future, and this report will deconstruct the urgent economic and national security imperatives that make this new class of worker essential. The game is the tangible **proof**; this report is the **theory**. It explains why the skills that built this world are critical to the nations future.",
              "imageGroupIds": [
                "group_the-citizen-architect-has-arrived_prompt-1"
              ]
            },
            {
              "pageId": "proof-and-theory",
              "pageTitle": "Proof and Theory",
              "tldr": "This report connects the abstract world of the game to the concrete realities of the global AI supply chain, its hidden workforce, and the high-stakes geopolitical competition that will define our future. The game is the proof; this report is the theory.",
              "content": "The analysis that follows will connect the seemingly abstract world of this game to the concrete realities of the global AI supply chain, the psychological pressures on its hidden workforce, and the high-stakes geopolitical competition that will define the 21st century. The game is the proof; this report is the theory. Together, they present a diagnosis of a systemic crisis and a roadmap for a more prosperous and secure future.",
              "imageGroupIds": [
                "group_proof-and-theory_prompt-1"
              ]
            }
          ]
        },
        {
          "subSectionId": "section-2-the-origin",
          "subSectionTitle": "Section 2: The Origin Story",
          "pages": [
            {
              "pageId": "section-2-title",
              "pageTitle": "Section 2: The Origin Story - A 120-Day Ascent",
              "tldr": "The game was conceived and built by a single developer in 120 days, a testament to the power of AI-native workflows.",
              "content": "This section details the creation story of 'aiascent.game,' from the initial spark of an idea to a fully functional, complex, multiplayer world in just four months.",
              "imageGroupIds": [
                "group_section-2-title_prompt-1"
              ]
            },
            {
              "pageId": "the-spark-of-creation",
              "pageTitle": "The Spark of Creation",
              "tldr": "The availability of new, powerful AI tools in late March 2025 was the catalyst. This project went from concept to code in just ten days, demonstrating a new velocity of creation.",
              "content": "The significance of aiascent.game is best understood through its creation story. On March 25, 2025, a new generation of generative and agentic artificial intelligence tools became widely available to the public. These tools represented a quantum leap in capability, moving beyond simple task execution to more complex reasoning and multi-step process completion. [1.8] After five days of intensive, round-the-clock experimentation with these new systems, a single developerthe author of this reportconceived of this project on the sixth day, March 31, 2025. The subsequent three days were dedicated to initial documentation and architectural planning. On the tenth day, coding began.",
              "imageGroupIds": [
                "group_the-spark-of-creation_prompt-1"
              ]
            },
            {
              "pageId": "from-tutorial-to-universe",
              "pageTitle": "From Tutorial to Universe",
              "tldr": "In 110 days, a simple tutorial game was transformed into a complex, persistent, multiplayer world through a rapid, AI-native workflow, achieving what would traditionally take a full team years.",
              "content": "The initial vision was ambitious: to create not just a game, but a live demonstration of a new mode of production. Following three days of initial documentation, architectural planning, and system design, conducted in continuous dialogue with AI assistants, the first line of code was written. The project began from the humblest of origins: a publicly available online tutorial for a simple web game built with the PixiJS rendering engine. [1.9]",
              "imageGroupIds": [
                "group_from-tutorial-to-universe_prompt-1"
              ]
            },
            {
              "pageId": "the-110-day-sprint",
              "pageTitle": "The 110-Day Sprint",
              "tldr": "The 110-day sprint was not a traditional coding marathon but a rapid, iterative cycle of human-AI collaboration, transforming intent into reality with unprecedented speed.",
              "content": "Over the next 110 days, that simple foundation was transformed into the complex, persistent, and interactive world you now inhabit. This was not a linear process of writing code line-by-line. It was a rapid, iterative cycle of articulating intent, generating solutions with AI, testing, debugging, and refining. This AI-native workflow enabled a single individual to achieve what would have, until recently, required a well-funded, multi-disciplinary team of specialists working for many months, if not years.",
              "imageGroupIds": [
                "group_the-110-day-sprint_prompt-1"
              ]
            },
            {
              "pageId": "the-one-person-studio",
              "pageTitle": "The One-Person Studio",
              "tldr": "A single developer built a full-stack, real-time multiplayer application with a self-hosted RAG-based LLM and a persistent world in four monthsa task that would traditionally require a team of specialists.",
              "content": "The system that emerged from this 110-day sprint includes:\n\n* **A Full-Stack Application:** A complete, end-to-end system with a sophisticated front-end user interface and a robust back-end infrastructure.  \n* **A Custom, Real-Time Multiplayer Server:** Engineered from the ground up to handle simultaneous player interactions, persistent state changes, and complex game logic in real time.  \n* **A Self-Hosted LLM Assistant:** An in-game AI companion powered by a large language model running on a dedicated server. This assistant utilizes a Retrieval-Augmented Generation (RAG) system, drawing its knowledge directly from the research and citations that constitute this very report, providing players with contextually relevant, evidence-based information.  \n* **A Persistent World State:** A game environment with a database that saves player progress, world state, and economic variables, creating a continuous and evolving experience.  \n* **Intricate, Interconnected Game Mechanics:** Complex systems governing resource management, crafting, player-to-player interaction, and skill progression, all designed and implemented within the 120-day window.",
              "imageGroupIds": [
                "group_the-one-person-studio_prompt-1"
              ]
            },
            {
              "pageId": "a-paradigm-shift-in-labor",
              "pageTitle": "A Paradigm Shift in Labor",
              "tldr": "The creation of this game is an event that demands explanation. It signals a fundamental shift where a single individual, armed with AI, can embody the roles of an entire, multi-disciplinary team.",
              "content": "To build such a system traditionally would require a team of specialists: a backend engineer for the server, a frontend developer for the client, a database administrator, a game designer for the mechanics, a writer for the narrative, and a DevOps engineer for deployment and hosting. The fact that this entire stack was conceived, designed, and implemented by one person in four months is the central, startling fact upon which this report is built. It is an event that demands explanation. It signals a fundamental shift in the economics of creation and the nature of skilled labor.",
              "imageGroupIds": [
                "group_a-paradigm-shift-in-labor_prompt-1"
              ]
            },
            {
              "pageId": "the-100x-data-curator-thesis",
              "pageTitle": "The 100x Data Curator Thesis",
              "tldr": "The game, an artifact of over one million tokens, proves the '100x data curator' thesis. The exponential leap in productivity comes not from faster coding, but from a new paradigm of high-level orchestration, curation, and validation of AI's output.",
              "content": "The result of this 120-day sprint is a digital artifact comprising over one million tokens of code and documentation. It is a live, complex system that users can join and interact with in real-time. This achievement represents more than just rapid prototyping; it is the creation of a feature-rich, persistent world by an individual operating at a scale previously reserved for well-funded teams.\n\nThis serves as undeniable proof of the \"100x data **curator**\" thesis. The exponential leap in productivity was not the result of a developer who could type code 100 times faster. It was the result of a developer who could *think* and *direct* 100 times more effectively. The citizen architect's primary skill is not the line-by-line production of code, but the high-level orchestration, curation, integration, and validation of the AI's high-volume output. This is a fundamental paradigm shift from a focus on *production* to a focus on *curation*.",
              "imageGroupIds": [
                "group_the-100x-data-curator-thesis_prompt-1"
              ]
            },
            {
              "pageId": "the-new-creative-partnership",
              "pageTitle": "The New Creative Partnership",
              "tldr": "In the new model of creation, the human is the strategist, editor, and systems integrator, while the AI is the tireless producer. This partnership is the proof-of-concept for a new class of worker.",
              "content": "The citizen architect is the strategist, the editor, and the systems integrator, while the AI is the producer. This partnership, this new model of creation, is the proof-of-concept for a new class of worker. The remainder of this report will explain why cultivating and scaling this capability is not merely an economic opportunity, but a national imperative.",
              "imageGroupIds": [
                "group_the-new-creative-partnership_prompt-1"
              ]
            }
          ]
        },
        {
          "subSectionId": "section-3-the-how",
          "subSectionTitle": "Section 3: The How",
          "pages": [
            {
              "pageId": "section-3-title",
              "pageTitle": "Section 3: The Thesis - How a Single Citizen Architect Achieved 100x Productivity",
              "tldr": "This section explains the 'Vibecoding to Virtuosity' pathway, the new creative process that enabled this leap in productivity.",
              "content": "This section explains the 'Vibecoding to Virtuosity' pathway, the new creative process that enabled this leap in productivity.",
              "imageGroupIds": [
                "group_section-3-title_prompt-1"
              ]
            },
            {
              "pageId": "the-100x-multiplier-is-here",
              "pageTitle": "The 100x Multiplier is Here",
              "tldr": "The 100x productivity multiplier is not a future forecast; it is a present reality. This game is the first artifact of the Citizen Architect, proving that an AI-native individual can now achieve the output of a traditional organization.",
              "content": "This is not a forecast of future potential; it is an observation of a present reality. The **100x productivity multiplier** is here, and it changes everything. The term \"100x\" is not a marketing hyperbole; it is a conservative estimate of the compression in time, labor, and capital required to bring a complex digital product from concept to reality. [1.10] aiascent.game is the proof that an individual armed with AI-native skills and a clear architectural vision can now achieve the output of a traditional organization. It is the first artifact of the Citizen Architect.",
              "imageGroupIds": [
                "group_the-100x-multiplier-is-here_prompt-1"
              ]
            },
            {
              "pageId": "one-million-tokens-of-proof",
              "pageTitle": "One Million Tokens of Proof",
              "tldr": "The game, an artifact of over one million tokens, proves the '100x data curator' thesis. The exponential leap in productivity comes not from faster coding, but from a new paradigm of high-level orchestration, curation, and validation of AI's output.",
              "content": "The result of the 120-day sprint is a digital artifact comprising over one million tokens of code and documentation. It is a live, complex system that users can join and interact with in real-time. This achievement represents more than just rapid prototyping; it is the creation of a feature-rich, persistent world by an individual operating at a scale previously reserved for well-funded teams. This serves as undeniable proof of the '100x data curator' thesis. The exponential leap in productivity was not the result of a developer who could type code 100 times faster. It was the result of a developer who could think and direct 100 times more effectively.",
              "imageGroupIds": [
                "group_one-million-tokens-of-proof_prompt-1"
              ]
            },
            {
              "pageId": "the-human-ai-partnership",
              "pageTitle": "The Human-AI Partnership",
              "tldr": "In this new model, the human is the strategist, editor, and systems integrator, while the AI is the producer. This partnership is the proof-of-concept for a new class of worker and a national imperative.",
              "content": "The citizen architect's primary skill is not the line-by-line production of code, but the high-level orchestration, curation, integration, and validation of the AI's high-volume output. This is a fundamental paradigm shift from a focus on production to a focus on curation. The citizen architect is the strategist, the editor, and the systems integrator, while the AI is the producer. This partnership, this new model of creation, is the proof-of-concept for a new class of worker. The remainder of this report will explain why cultivating and scaling this capability is not merely an economic opportunity, but a national imperative.",
              "imageGroupIds": [
                "group_the-human-ai-partnership_prompt-1"
              ]
            },
            {
              "pageId": "the-first-artifact-of-the-citizen-architect",
              "pageTitle": "The First Artifact of the Citizen Architect",
              "tldr": "The 100x productivity multiplier is not a future forecast; it is a present reality. This game is the first artifact of the Citizen Architect, proving that an AI-native individual can now achieve the output of a traditional organization.",
              "content": "This is not a forecast of future potential; it is an observation of a present reality. The 100x productivity multiplier is here, and it changes everything. The term '100x' is not a marketing hyperbole; it is a conservative estimate of the compression in time, labor, and capital required to bring a complex digital product from concept to reality. aiascent.game is the proof that an individual armed with AI-native skills and a clear architectural vision can now achieve the output of a traditional organization. It is the first artifact of the Citizen Architect.",
              "imageGroupIds": [
                "group_the-first-artifact-of-the-citizen-architect_prompt-1"
              ]
            }
          ]
        },
        {
          "subSectionId": "the-vibecoding-to-virtuosity-pathway",
          "subSectionTitle": "The 'Vibecoding to Virtuosity' Pathway",
          "pages": [
            {
              "pageId": "subsection-vibecoding-title",
              "pageTitle": "The 'Vibecoding to Virtuosity' Pathway",
              "tldr": "This section explains the new creative process that moves a creator from intuitive interaction with AI to architectural mastery.",
              "content": "The creation of aiascent.game was made possible by a new kind of creative process, a pathway of skill development that begins with intuition and culminates in architectural mastery. This report defines this journey as the 'Vibecoding to Virtuosity' pathway.",
              "imageGroupIds": [
                "group_subsection-vibecoding-title_prompt-1"
              ]
            },
            {
              "pageId": "from-intuition-to-mastery",
              "pageTitle": "From Intuition to Mastery",
              "tldr": "The 'Vibecoding to Virtuosity' pathway is a new model for creative development, a journey that transforms intuitive, conversational interaction with AI into a structured, architectural mastery that redefines technical literacy.",
              "content": "It represents a fundamental shift in what it means to be technically literate and who has the power to create complex systems.",
              "imageGroupIds": [
                "group_from-intuition-to-mastery_prompt-1"
              ]
            },
            {
              "pageId": "the-intuitive-starting-point",
              "pageTitle": "The Intuitive Starting Point",
              "tldr": "'Vibecoding' is the intuitive starting point of AI creation, where a feeling or 'vibe' is translated into a functional artifact using natural language, lowering the barrier to entry for creation to near zero.",
              "content": "**\"Vibecoding\"** is the intuitive, conversational, and often imprecise starting point for interacting with generative AI. [1.11] It is the process of translating a feeling, an aesthetic, a \"vibe,\" or a high-level intention into a functional piece of software or a digital artifact using natural language as the primary interface. [1.11] When a designer tells an AI, \"Make a button that looks sleek and futuristic, with a subtle glow on hover,\" they are vibecoding. When a marketer asks an AI to \"Generate three campaign slogans that feel optimistic but also urgent,\" they are vibecoding.\n\nThis method turns a \"spark of inspiration into a live experience within minutes\". [1.11] It lowers the barrier to entry for creation to near zero. It does not require mastery of complex syntax or programming languages. It requires only the ability to articulate an idea. This is the entry point for millions of non-specialists to begin building with AI, the first step on the path to greater proficiency. ",
              "imageGroupIds": [
                "group_the-intuitive-starting-point_prompt-1"
              ]
            },
            {
              "pageId": "the-pathway-to-virtuosity",
              "pageTitle": "The Pathway to 'Virtuosity'",
              "tldr": "The path to virtuosity involves honing raw intuition into a structured methodology: developing a design vocabulary, mastering structured interaction with AI, and adopting a high-level architectural mindset.",
              "content": "Vibecoding is just the beginning of the journey. **\"Virtuosity\"** is the destination. It is the methodical refinement of that initial intuition into a structured, powerful, and repeatable skillset. The journey from vibecoding to virtuosity involves learning how to structure prompts effectively, how to critically evaluate and debug AI-generated code, how to architect complex systems by breaking them down into AI-manageable components, and how to integrate these components into a coherent whole. It is the process of transforming from a passive user of AI into an active director of AI.\n\nThe pathway to \"virtuosity\" is the process of honing this raw intuition into a structured, powerful, and repeatable methodology for building complex, reliable systems. This evolution involves several key stages of upskilling:\n\n1. **Developing a \"Design Vocabulary\":** The creator learns to move beyond vague descriptions (\"sleek,\" \"modern\") to precise, technical language that AI models can interpret without ambiguity. This means learning the language of design frameworks and technical properties, such as \"Use a Shad.cn toast component,\" \"apply Tailwind opacity-20,\" or specify a \"4-pixel corner radius\". [1.12] This is not learning to code; it is learning to *speak the language of code* to the AI collaborator.\n\n2. **Mastering Structured Interaction:** The creator learns to break down complex requests into logical, sequential steps. Instead of asking the AI to \"build a login system,\" they learn to guide it through the process: \"First, create the UI form with fields for username and password. Next, write the client-side validation logic. Then, create the server-side endpoint to handle the authentication request. Finally, implement JWT for session management.\" This structured dialogue is essential for managing complexity and debugging errors.\n\n3. **Adopting an Architectural Mindset:** The creator begins to think in terms of systems, not just components. They learn to design data flows, API contracts, and the overall architecture of an application. They are no longer just building pieces; they are orchestrating the assembly of a coherent whole.",
              "imageGroupIds": [
                "group_the-pathway-to-virtuosity_prompt-1"
              ]
            },
            {
              "pageId": "the-citizen-architect-the-end-state-of-virtuosity",
              "pageTitle": "The Citizen Architect: The End State of Virtuosity",
              "tldr": "The 'Citizen Architect' is the culmination of this pathwayan individual who can orchestrate AI to build sophisticated systems, making the distinction between 'coder' and 'non-coder' obsolete and unlocking a massive deflationary pressure on the value of traditional development teams.",
              "content": "The culmination of this pathway is the Citizen Architect. A Citizen Architect is an individual who has achieved this state of virtuosity. They can conceive, design, and orchestrate the construction of sophisticated digital systems, moving fluidly between high-level strategic vision and low-level implementation details, with AI as their tireless collaborator and force multiplier. [1.10] The creator of aiascent.game is the first case study of this new archetype.\n\nThe emergence of this pathway carries a profound implication. The traditional, rigid distinction between \"coder\" and \"non-coder\" is becoming obsolete. In its place is a new spectrum of technical literacy where the most valuable skill is not the mechanical act of writing code, but the cognitive act of *articulating intent* with sufficient precision for an AI to execute. This fundamentally changes the nature of technical work and dramatically broadens the pool of potential creators. If a single individual can build a system like aiascent.game in 120 days, it signals a massive deflationary pressure on the economic value of large, traditional software development teams and a corresponding inflationary pressure on the value of individual creativity, taste, and architectural vision. The age of the Citizen Architect has begun.",
              "imageGroupIds": [
                "group_the-citizen-architect-the-end-state-of-virtuosity_prompt-1"
              ]
            }
          ]
        }
      ]
    },
    {
      "sectionId": "part-ii-the-brittle-foundation",
      "sectionTitle": "Part II: The Brittle Foundation",
      "pages": [
        {
          "pageId": "part-ii-title",
          "pageTitle": "Part II: The Brittle Foundation - Anatomy of a Self-Inflicted Wound",
          "tldr": "This section dissects the flawed, exploitative labor model of the Western AI industry, arguing that it is a self-inflicted wound that guarantees poor data quality and makes AI systems brittle, unreliable, and unsafe.",
          "content": "While the potential for individual empowerment through AI is immense, the industrial foundation upon which the current AI revolution is being built is dangerously unstable. The dominant model for developing AI in the West is not one of empowerment, but of exploitation. This system, optimized for short-term cost reduction and liability evasion, has created a global 'ghost workforce' trapped in a cycle of precarity. This economic model is not merely an ethical failing; it is a critical strategic blunder. It actively engineers the conditions for its own failure by systematically degrading the cognitive capacity of its most essential human resource, leading directly to a crisis of data quality that makes AI systems brittle, unreliable, and unsafe. This is the anatomy of a self-inflicted wound. [2.1]",
          "imageGroupIds": [
            "group_part-ii-title_prompt-1"
          ]
        }
      ],
      "subSections": [
        {
          "subSectionId": "the-fissured-workplace-in-ai",
          "subSectionTitle": "The Fissured Workplace in AI",
          "pages": [
            {
              "pageId": "subsection-fissured-workplace-title",
              "pageTitle": "The Fissured Workplace in AI",
              "tldr": "The AI supply chain is a masterclass in obfuscation, deliberately fractured to distance valuable tech companies from the human labor that makes their products possible.",
              "content": "The architecture of the modern AI supply chain is a masterclass in obfuscation. It is a fissured workplace, deliberately fractured into layers of subcontracting to distance the world's most valuable technology companies from the human labor that makes their products possible. This labyrinthine structure is not an accident; it is a design choice intended to suppress wages, prevent worker organization, and shed legal and ethical liability. [2.2]",
              "imageGroupIds": [
                "group_subsection-fissured-workplace-title_prompt-1"
              ]
            },
            {
              "pageId": "the-architecture-of-obfuscation",
              "pageTitle": "The Architecture of Obfuscation",
              "tldr": "The AI supply chain is a 'fissured workplace,' a labyrinth of subcontractors designed to obscure accountability. This allows tech giants to profit from a global 'ghost workforce' while denying responsibility for their exploitative conditions.",
              "content": "The model typically begins with a household-name technology giantGoogle, Meta, Microsoft, OpenAIthat requires vast amounts of labeled data to train its AI models. [2.3] Rather than employing data workers directly, these companies outsource the work to large, multinational vendors like Sama, GlobalLogic (a subsidiary of Hitachi), Majorel, or Scale AI. [2.3] These primary contractors, in turn, often further subcontract the work to smaller, local firms in the Global South, creating a multi-layered system where accountability becomes almost impossible to trace. [2.3] When issues of exploitation arise, the tech giants can claim plausible deniability, stating that the workers are not their employees and that the responsibility lies with the subcontractor. [2.4]",
              "imageGroupIds": [
                "group_the-architecture-of-obfuscation_prompt-1"
              ]
            },
            {
              "pageId": "the-ghost-workforce",
              "pageTitle": "The Ghost Workforce",
              "tldr": "The 'ghost workforce,' primarily in the Global South, endures unconscionably low pay and psychologically damaging work, such as moderating traumatic content. In regions with high unemployment, this exploitation is tragically accepted as opportunity.",
              "content": "This system has given rise to a global **\"ghost workforce\"**an army of invisible, precarious laborers who perform the grueling, repetitive, and often psychologically damaging tasks of data annotation, content moderation, and AI training. [2.5] These workers are predominantly located in developing regions across Africa, Latin America, and Asia, where high unemployment rates create a large pool of vulnerable labor. [2.3] They are paid wages that are unconscionably low by any standard, often ranging from just $1.32 to $3 per hour, with no benefits, no paid time off, no job security, and no path for career advancement. [2.9] A 2022 report found that such contract workers make, on average, only 75 cents for every dollar earned by a direct employee. [2.10]",
              "imageGroupIds": [
                "group_the-ghost-workforce_prompt-1"
              ]
            },
            {
              "pageId": "the-human-cost",
              "pageTitle": "The Human Cost",
              "tldr": "The human cost of this model is staggering. 'Ghost workers' are forced to view a relentless stream of traumatic content to train AI filters, leading to severe and well-documented psychological harm, including PTSD and burnout.",
              "content": "The human cost of this model is staggering. The work is not just poorly compensated; it is frequently traumatic. To train AI to identify and filter toxic content, these ghost workers are forced to view a relentless stream of the most horrific material the internet has to offer, including graphic depictions of child sexual abuse, murder, suicide, and torture. [2.11] The psychological toll is severe and well-documented, with workers reporting high rates of post-traumatic stress disorder (PTSD), generalized anxiety disorder (GAD), and emotional burnout. [2.12] Yet, in regions with unemployment rates as high as 40%, the desperation for any income, especially in U.S. dollars, is so profound that people continue to seek out these jobs despite the clear warnings. As one former worker from Kenya noted, \"When unemployment hits 40% in Africa, people don't hear warnings, they hear salaries in USD. That's the calculus of late-stage capitalism: exploitation masquerades as opportunity\". [2.13] This is the brittle human foundation upon which the Western AI empire is built.",
              "imageGroupIds": [
                "group_the-human-cost_prompt-1"
              ]
            },
            {
              "pageId": "the-race-to-the-bottom",
              "pageTitle": "The Race to the Bottom",
              "tldr": "The fissured workplace model creates a 'responsibility void,' where the lead firm retains control and profit while pushing legal and financial responsibilities down to undercapitalized subcontractors forced to compete in a race to the bottom on labor costs.",
              "content": "The fissured workplace model creates a 'responsibility void,' where the lead firm retains control and profit while pushing legal and financial responsibilities down to undercapitalized subcontractors forced to compete in a race to the bottom on labor costs. This structure systemically drives down wages and working conditions, as subcontractors must cut corners to remain competitive and profitable under the immense cost pressure from the prime contractor and the apex client.",
              "imageGroupIds": [
                "group_the-race-to-the-bottom_prompt-1"
              ]
            }
          ]
        },
        {
          "subSectionId": "the-cognitive-consequence",
          "subSectionTitle": "The Cognitive Consequence",
          "pages": [
            {
              "pageId": "subsection-cognitive-consequence-title",
              "pageTitle": "The Cognitive Consequence: Scarcity vs. Abundance",
              "tldr": "The economic precarity engineered by the fissured workplace is a direct assault on the human cognitive function required to produce high-quality work.",
              "content": "The economic precarity engineered by the fissured workplace is not merely a social or ethical problem. It is a direct and measurable assault on the human cognitive function required to produce high-quality work. Decades of research in psychology and behavioral economics have demonstrated that financial stress and the constant mental burden of poverty impose what is known as a 'Cognitive Bandwidth Tax'. [2.14]",
              "imageGroupIds": [
                "group_subsection-cognitive-consequence-title_prompt-1"
              ]
            },
            {
              "pageId": "the-cognitive-tax",
              "pageTitle": "The Cognitive Tax",
              "tldr": "The 'Cognitive Bandwidth Tax' is a quantifiable reduction in mental capacity caused by financial stress. This 'scarcity mindset' impairs executive function, attention, and logical reasoning.",
              "content": "This \"tax\" is not a metaphor. It is a quantifiable reduction in an individual's cognitive capacitytheir ability to pay attention, solve problems, exert self-control, and engage in logical reasoning. [2.15] When a person's mind is constantly preoccupied with urgent, unmet needshow to pay the rent, where the next meal will come from, how to afford medical carea significant portion of their mental bandwidth is consumed by these worries. [2.16] This leaves fewer cognitive resources available for other tasks. A landmark study by researchers Sendhil Mullainathan and Eldar Shafir found that the cognitive load of poverty-related concerns could lead to a temporary drop in functional IQ of 13 to 14 pointsan effect comparable to losing a full night's sleep or the cognitive decline associated with chronic alcoholism. [2.17] A meta-analysis of 29 datasets confirmed a significant detrimental effect of financial scarcity on cognitive performance. [2.18]",
              "imageGroupIds": [
                "group_the-cognitive-tax_prompt-1"
              ]
            },
            {
              "pageId": "scarcity-vs-abundance-mindset",
              "pageTitle": "Scarcity vs. Abundance Mindset",
              "tldr": "A 'scarcity mindset' traps people in short-term survival thinking, which is incompatible with innovative knowledge work. The 'abundance mindset,' fostered by security, is the prerequisite for the creativity and focus needed to become a Citizen Architect.",
              "content": "This cognitive tax fosters a **\"scarcity mindset.\"** A person operating from a scarcity mindset is trapped in a state of short-term, survival-oriented thinking. [2.19] Their decisions are driven by fear of loss and the immediate need to secure limited resources. This psychological state is fundamentally incompatible with the requirements of high-quality, innovative knowledge work. Tasks like nuanced data annotation, which require sustained focus, critical judgment, and the ability to make consistent, subtle distinctions, are severely hampered when the worker's mind is heavily taxed. [2.20] In stark contrast, the prerequisite for creativity, innovation, and the kind of deep, focused work needed to become a Citizen Architect is an **\"abundance mindset\"**. [2.21] This mindset, which is fostered by psychological and financial security, is characterized by a belief in possibility, a focus on growth, and a willingness to collaborate and take calculated risks. [2.22] An abundance mindset frees up cognitive bandwidth, allowing individuals to engage in the higher-order thinking, problem-solving, and creative exploration that drives progress. [2.23] The Western AI industry has, through its labor practices, created a system that maximizes the cognitive tax on its foundational workforce. It has built an army of data workers operating in a state of scarcity, and then tasked them with performing cognitively demanding work that requires an abundance of mental resources. This is a recipe for systemic failure.",
              "imageGroupIds": [
                "group_scarcity-vs-abundance-mindset_prompt-1"
              ]
            },
            {
              "pageId": "an-assault-on-the-mind",
              "pageTitle": "An Assault on the Mind",
              "tldr": "Financial precarity is a direct assault on the human cognitive function required to produce high-quality work. It imposes a measurable 'Cognitive Bandwidth Tax' on its workforce.",
              "content": "The economic precarity engineered by the fissured workplace is not merely a social or ethical problem. It is a direct and measurable assault on the human cognitive function required to produce high-quality work. Decades of research in psychology and behavioral economics have demonstrated that financial stress and the constant mental burden of poverty impose what is known as a 'Cognitive Bandwidth Tax'.",
              "imageGroupIds": [
                "group_an-assault-on-the-mind_prompt-1"
              ]
            }
          ]
        },
        {
          "subSectionId": "institutionalized-gigo",
          "subSectionTitle": "Institutionalized GIGO",
          "pages": [
            {
              "pageId": "subsection-gigo-title",
              "pageTitle": "Institutionalized GIGO (Garbage In, Garbage Out)",
              "tldr": "The final link in the chain is 'Institutionalized GIGO'a systemic crisis where a cognitively taxed workforce guarantees the production of flawed data, making unreliable AI a structural feature, not a bug.",
              "content": "The final, fatal link in this causal chain connects the cognitively taxed, scarcity-driven workforce to a systemic crisis in data quality. The age-old principle of computing, 'Garbage In, Garbage Out' (GIGO), has been institutionalized at the very foundation of the AI development pipeline. The production of flawed, biased, and inconsistent AI models is not an occasional bug; it is a *structural feature* of the current labor model.",
              "imageGroupIds": [
                "group_subsection-gigo-title_prompt-1"
              ]
            },
            {
              "pageId": "an-architecture-of-self-sabotage",
              "pageTitle": "An Architecture of Self-Sabotage",
              "tldr": "The Western AI industry has built an architecture of self-sabotage, tasking a workforce operating in a state of scarcity with cognitively demanding work that requires an abundance of mental resources.",
              "content": "This cognitive tax fosters a **\"scarcity mindset.\"** A person operating from a scarcity mindset is trapped in a state of short-term, survival-oriented thinking. [2.10] Their decisions are driven by fear of loss and the immediate need to secure limited resources. This psychological state is fundamentally incompatible with the requirements of high-quality, innovative knowledge work. Tasks like nuanced data annotation, which require sustained focus, critical judgment, and the ability to make consistent, subtle distinctions, are severely hampered when the worker's mind is heavily taxed. [2.11] In stark contrast, the prerequisite for creativity, innovation, and the kind of deep, focused work needed to become a Citizen Architect is an **\"abundance mindset\"**. [2.12] This mindset, which is fostered by psychological and financial security, is characterized by a belief in possibility, a focus on growth, and a willingness to collaborate and take calculated risks. [2.13] An abundance mindset frees up cognitive bandwidth, allowing individuals to engage in the higher-order thinking, problem-solving, and creative exploration that drives progress. [2.14] The Western AI industry has, through its labor practices, created a system that maximizes the cognitive tax on its foundational workforce. It has built an army of data workers operating in a state of scarcity, and then tasked them with performing cognitively demanding work that requires an abundance of mental resources. This is a recipe for systemic failure.",
              "imageGroupIds": [
                "group_an-architecture-of-self-sabotage_prompt-1"
              ]
            },
            {
              "pageId": "institutionalized-gigo",
              "pageTitle": "Institutionalized GIGO",
              "tldr": "The 'Garbage In, Garbage Out' principle is no longer an occasional bug; it has been institutionalized at the foundation of the AI pipeline. The labor model itself is a structural feature that guarantees flawed output.",
              "content": "The final, fatal link in this causal chain connects the cognitively taxed, scarcity-driven workforce to a systemic crisis in data quality. The age-old principle of computing, \"Garbage In, Garbage Out\" (GIGO), has been institutionalized at the very foundation of the AI development pipeline. The production of flawed, biased, and inconsistent AI models is not an occasional bug; it is a *structural feature* of the current labor model.",
              "imageGroupIds": [
                "group_institutionalized-gigo_prompt-1"
              ]
            },
            {
              "pageId": "the-data-quality-crisis",
              "pageTitle": "The Data Quality Crisis",
              "tldr": "There is a full-blown data quality crisis eroding trust in AI. A 2025 survey showed only 36% of business leaders believe their data is accurate, a steep drop from 49% just two years prior.",
              "content": "A workforce that is burned-out, underpaid, suffering from high turnover, and operating under a significant cognitive load will inevitably produce low-quality data. [2.11] The repetitive and monotonous nature of the work, combined with grueling hours and intense pressure to meet quotas, leads to mental fatigue and burnout, which directly translates into inconsistent and inaccurate annotations. [2.11] When workers are treated as disposable, they have little incentive to invest the mental energy required for meticulous, high-quality work. The result is \"garbage\": datasets riddled with mislabeled images, inaccurate transcriptions, and biased classifications. [2.15] This is not a theoretical problem. There is mounting evidence of a full-blown **data quality crisis** that is eroding trust in AI across the enterprise. A recent Salesforce survey of business leaders, conducted in 2025, revealed a shocking collapse in confidence regarding the data that underpins their AI initiatives. Only 36% of leaders now believe their data is accurate, a precipitous drop from 49% just two years prior. Similarly, only 40% trust their data's reliability, down from 54% in 2023. [2.16] Executives understand that their data collection, cleansing, and curation processes are subpar, and they are rightly hesitant to trust decisions made by AI systems fed with this \"garbage\". [2.16] Over 90% of enterprise files contain at least one major inaccuracy, a quarter are outdated, and 33% are duplicates. [2.17]",
              "imageGroupIds": [
                "group_the-data-quality-crisis_prompt-1"
              ]
            },
            {
              "pageId": "the-ripple-effect-of-failure",
              "pageTitle": "The Ripple Effect of Failure",
              "tldr": "Bad data has severe consequences, from incorrect medical diagnoses and financial losses to catastrophic failures in autonomous systems. With AI agents that take action, the risks are exponentially higher.",
              "content": "The consequences of building AI on this foundation of poor-quality data are severe and far-reaching. Brittle and unreliable AI systems pose significant risks, especially in critical applications. In healthcare, an AI trained on mislabeled medical images can lead to incorrect diagnoses, such as misidentifying a benign tumor as malignant, resulting in ineffective or harmful patient care. [2.15] In finance, an AI fraud detection system trained on poorly annotated data will fail to catch fraudulent transactions while incorrectly flagging legitimate ones, causing financial loss and customer frustration. [2.15] In autonomous vehicles, mislabeled pedestrians or road signs in the training set can lead directly to catastrophic safety failures on the road. [2.11] The problem is exponentially magnified with the rise of AI agents, which are designed not just to answer questions but to *take autonomous actions*. As one industry expert noted, \"With AI agents, inaccurate data doesn't just produce bad responsesit produces bad actions\". [2.17] A single flawed document or a set of poorly curated data can create a ripple effect of failures across an entire network of interconnected agents.",
              "imageGroupIds": [
                "group_the-ripple-effect-of-failure_prompt-1"
              ]
            },
            {
              "pageId": "courting-disaster",
              "pageTitle": "Courting Disaster",
              "tldr": "As we delegate more critical societal functions to AI systems built on this brittle foundation of low-quality data, we are not just institutionalizing technical failure; we are actively courting disaster.",
              "content": "The Western AI industry's relentless pursuit of short-term cost savings through labor exploitation has engineered a system that guarantees low-quality data. This, in turn, undermines the long-term value, reliability, and safety of the very AI products the system is designed to build. It is an architecture of self-sabotage. As society delegates more critical functionsfrom medical diagnostics to infrastructure managementto AI systems built on this brittle foundation, we are not just institutionalizing technical failure; we are courting disaster.",
              "imageGroupIds": [
                "group_courting-disaster_prompt-1"
              ]
            },
            {
              "pageId": "the-negative-feedback-loop",
              "pageTitle": "The Negative Feedback Loop",
              "tldr": "The Western AI industry has created a perfect, self-perpetuating negative feedback loop where labor exploitation guarantees low-quality data, which in turn undermines the value and safety of the very AI products it builds.",
              "content": "The Western AI industry has created a perfect, self-perpetuating negative feedback loop. The relentless pursuit of short-term cost savings through labor exploitation engineers a workforce whose psychological and economic state guarantees the production of low-quality data. This low-quality data, in turn, undermines the long-term value, reliability, and safety of the very AI products the system is designed to build. This is an architecture of self-sabotage, a deep and festering wound inflicted by the industry upon itself.",
              "imageGroupIds": [
                "group_the-negative-feedback-loop_prompt-1"
              ]
            }
          ]
        }
      ]
    },
    {
      "sectionId": "part-iii-the-pacing-threat",
      "sectionTitle": "Part III: The Pacing Threat",
      "pages": [
        {
          "pageId": "part-iii-title",
          "pageTitle": "Part III: The Pacing Threat - China's Coherent Counter-Model",
          "tldr": "This section provides a net assessment of China's coherent, state-directed AI human capital strategy, framing it as a direct and superior counter-model to the flawed American approach.",
          "content": "While the Western AI industry grapples with the consequences of its self-inflicted wound, a formidable strategic competitor has adopted a fundamentally different and more coherent approach. This section analyzes the playbook of the People's Republic of China, which views its AI human capital as a core national asset to be cultivated, professionalized, and strategically weaponized. This divergence in approach is creating a dangerous and widening 'Cognitive Capital Gap,' representing a first-order strategic threat to the United States and its allies.",
          "imageGroupIds": [
            "group_part-iii-title_prompt-1"
          ]
        }
      ],
      "subSections": [
        {
          "subSectionId": "the-dragons-playbook",
          "subSectionTitle": "The Dragon's Playbook",
          "pages": [
            {
              "pageId": "subsection-dragons-playbook-title",
              "pageTitle": "The Dragon's Playbook",
              "tldr": "China's approach to AI is guided by clear, top-down strategic blueprints that frame AI dominance as a national destiny and a matter of international competition.",
              "content": "China's approach to AI is guided by clear, top-down strategic blueprints. The foundational document for its ambitions is the **'New Generation Artificial Intelligence Development Plan' (AIDP)**, issued by the State Council in July 2017. [3.1] This is not merely a policy paper but a detailed blueprint for making China the world's primary AI innovation center by 2030. [3.2]",
              "imageGroupIds": [
                "group_subsection-dragons-playbook-title_prompt-1"
              ]
            },
            {
              "pageId": "the-dragons-playbook",
              "pageTitle": "The Dragon's Playbook",
              "tldr": "China's state-directed AI human capital strategy is methodical, long-term, and built on three interconnected pillars designed to build a robust, resilient, and strategically aligned workforce.",
              "content": "The plan sets out clear, phased objectives with specific economic and technological targets, explicitly framing AI not merely as an economic opportunity but as a 'strategic technology' that is the 'focus of international competition.' [3.3] It calls for a whole-of-nation effort, leveraging the 'advantages of the socialist system that concentrates on doing things,' and ensuring the deep integration of AI with the economy, society, and, crucially, national defense. [3.4] China's state-directed AI human capital strategy is methodical, long-term, and built on three interconnected pillars. This playbook is designed to build a robust, resilient, and strategically aligned workforce that serves the nation's overarching goal of becoming the world's preeminent AI power by 2030; less than four years from now. [3.5]",
              "imageGroupIds": [
                "group_the-dragons-playbook_prompt-1"
              ]
            },
            {
              "pageId": "a-methodical-long-term-strategy",
              "pageTitle": "A Methodical, Long-Term Strategy",
              "tldr": "China's AI strategy is methodical and long-term, built on three pillars: inland-sourcing, national professionalization, and Military-Civil Fusion, all aimed at building a resilient and strategically aligned workforce.",
              "content": "China's state-directed AI human capital strategy is methodical, long-term, and built on three interconnected pillars. This playbook is designed to build a robust, resilient, and strategically aligned workforce that serves the nation's overarching goal of becoming the world's preeminent AI power by 2030; less than four years from now. [3.5]",
              "imageGroupIds": [
                "group_a-methodical-long-term-strategy_prompt-1"
              ]
            }
          ]
        },
        {
          "subSectionId": "pillar-1-inland-sourcing",
          "subSectionTitle": "Pillar 1: Inland Sourcing",
          "pages": [
            {
              "pageId": "subsection-inland-sourcing-title",
              "pageTitle": "Pillar 1: The 'Inland-Sourcing' Model",
              "tldr": "China's 'inland-sourcing' model is a dual-use policy that uses state-supported data labeling bases in interior provinces to both alleviate poverty and build a loyal, domestic AI data supply chain, insulating it from foreign influence.",
              "content": "A critical point of divergence from the Western model is China's strategy of 'inland-sourcing' for data annotation work. [3.6] While U.S. firms outsource globally, Chinese companies are directed to maintain data annotation activities in-house or send them to government-supported data labeling bases in 'third-tier' cities within China's interior provinces. [3.7]",
              "imageGroupIds": [
                "group_subsection-inland-sourcing-title_prompt-1"
              ]
            },
            {
              "pageId": "pillar-1-the-inland-sourcing-model-forging-a-loyal-data-army",
              "pageTitle": "The Inland-Sourcing Model",
              "tldr": "China's 'inland-sourcing' model is a deliberate industrial policy that uses data annotation for 'precision poverty alleviation,' creating a loyal, domestic data army and insulating its AI supply chain from foreign influence.",
              "content": "This is a deliberate, state-led industrial policy. The Chinese government is actively promoting the construction of national data annotation hubs, with seven already established to support the development of over 121 domestic large language models. [3.8] These data labeling factories are strategically established in remote and underdeveloped regions as a tool for 'precision poverty alleviation,' providing jobs for unskilled workers, women, and marginalized groups in areas with few other industrial resources. [3.9] The mountainous province of Guizhou, once one of China's poorest, has been systematically transformed into the country's 'big data hub' and a national comprehensive pilot zone through this strategy. [3.10]",
              "imageGroupIds": [
                "group_pillar-1-the-inland-sourcing-model-forging-a-loyal-data-army_prompt-1"
              ]
            },
            {
              "pageId": "data-annotation-as-poverty-alleviation",
              "pageTitle": "Data Annotation as Poverty Alleviation",
              "tldr": "China's strategy uses data annotation jobs as a tool for 'precision poverty alleviation' in its interior provinces, which simultaneously builds a massive, loyal, and secure domestic data workforce.",
              "content": "China's 'inland-sourcing' strategy is a dual-use policy: it uses data annotation jobs for poverty alleviation in its interior provinces, which simultaneously builds a massive, loyal, and secure domestic data workforce, a stark contrast to the West's risky global outsourcing.",
              "imageGroupIds": [
                "group_data-annotation-as-poverty-alleviation_prompt-1"
              ]
            },
            {
              "pageId": "insulating-the-supply-chain",
              "pageTitle": "Insulating the Supply Chain",
              "tldr": "By linking data jobs to state-led development, the CCP creates a loyal workforce, ensures social stability, and insulates its critical AI supply chain from foreign influence, providing a far more secure foundation for its national ambitions.",
              "content": "By linking data annotation jobs to state-led poverty alleviation and regional development, the Chinese Communist Party achieves multiple strategic goals simultaneously. It creates a loyal workforce that is economically dependent on the state, ensures social stability in underdeveloped regions, and, most importantly, insulates its critical AI data supply chain from foreign labor markets and external influence. This domestic 'data army' is loyal, insulated, and provides a far more secure and reliable foundation for its national AI ambitions than the West's fissured ghost workforce.",
              "imageGroupIds": [
                "group_insulating-the-supply-chain_prompt-1"
              ]
            }
          ]
        },
        {
          "subSectionId": "pillar-2-national-professionalization-of-ai-trainer",
          "subSectionTitle": "Pillar 2: National Professionalization of AI Trainer",
          "pages": [
            {
              "pageId": "subsection-professionalization-title",
              "pageTitle": "Pillar 2: National Professionalization of the 'AI Trainer'",
              "tldr": "With a 5.5-year head start, China has officially recognized 'AI Trainer' as a national profession, establishing standards and a career ladder that transforms data work from a low-skill gig into a respected, state-sanctioned career.",
              "content": "In a stark contrast to the uncredited 'ghost work' of the West, China is actively professionalizing its data workforce. In a clear signal of state intent, the Chinese government has officially recognized 'Artificial Intelligence (AI) Trainer' as a new national occupation. [3.12] This is not merely a symbolic gesture; it is part of a broader institutionalization process designed to formalize and standardize the skills of this workforce. [3.12]",
              "imageGroupIds": [
                "group_subsection-professionalization-title_prompt-1"
              ]
            },
            {
              "pageId": "a-5-5-year-head-start",
              "pageTitle": "A 5.5-Year Head Start",
              "tldr": "China's 2020 move to formalize 'data annotator' as an official profession gives it a 5.5-year head start on any comparable Western effort, transforming a low-skill gig into a recognized career.",
              "content": "Chinas move to formalize and elevate the status of data work transforms it from a low-skill gig into a recognized profession. In 2020, the Ministry of Human Resources and Social Security officially added 'data annotator' (and related titles like 'AI trainer') to the national occupational classification list, giving the job official recognition and legitimacy. [3.14] This is a 5.5-year head start on any comparable Western effort.",
              "imageGroupIds": [
                "group_a-5-5-year-head-start_prompt-1"
              ]
            },
            {
              "pageId": "a-tool-of-control",
              "pageTitle": "A Tool of Control",
              "tldr": "While professionalization offers benefits, it's a double-edged sword, also serving as a tool of managerial control to enforce 'precision labor'the hidden, excessive work required to meet arbitrary accuracy standards.",
              "content": "The government, in partnership with industry bodies, has established National Vocational Skills Standards for AI Trainers and sponsors national competitions based on these standards. [3.15] The standard defines job roles, skill levels (from Junior to Senior Technician), educational requirements, and mandatory training hours, formalizing a national talent pipeline led by major tech firms like Alibaba and Baidu. [3.16] This state-led professionalization promises workers greater visibility, recognition, and pathways to social mobility, with some provincial governments including qualified AI trainers in skill-based household registration (hukou) programs. [3.17]",
              "imageGroupIds": [
                "group_a-tool-of-control_prompt-1"
              ]
            },
            {
              "pageId": "precision-labor",
              "pageTitle": "Precision Labor",
              "tldr": "This national effort has even evolved to create high-paying roles for humanities graduates, tasked with training AI to align with Chinese cultural and ideological values, giving AI a 'human touch' that serves the state's interests.",
              "content": "This national effort has even evolved to create high-paying roles for humanities graduates, tasked with training AI to align with Chinese cultural and ideological values, giving AI a 'human touch' that serves the state's interests. [3.18] While this professionalization appears to offer benefits, it simultaneously serves as a tool of managerial control. It legitimizes what researchers term 'precision labor'the hidden, excessive, and often unpaid work demanded of annotators to meet extremely high and sometimes arbitrary accuracy standards set by clients. [3.12] This dynamic aligns with a broader trend in Chinese workplaces where the rapid, market-driven integration of AI has amplified the power imbalance between employers and employees. [3.21]",
              "imageGroupIds": [
                "group_precision-labor_prompt-1"
              ]
            },
            {
              "pageId": "a-national-talent-pipeline",
              "pageTitle": "A National Talent Pipeline",
              "tldr": "Through national standards, competitions, and professional education programs led by tech giants, China has formalized a national talent pipeline to ensure a steady supply of high-quality data for its AI models.",
              "content": "This recognition was followed by concrete policy action. In early 2025, the government issued new guidelines to accelerate the high-quality development of the data annotation sector. These guidelines set ambitious goals, including a projected average annual compound growth rate exceeding 20% by 2027 and the establishment of a comprehensive talent pool through professional education and training programs. The aim is to cultivate influential data annotation enterprises and improve the professional skill levels of the workforce, ensuring a supply of high-quality data for the nation's AI models.",
              "imageGroupIds": [
                "group_a-national-talent-pipeline_prompt-1"
              ]
            },
            {
              "pageId": "the-professionalized-ai-trainer",
              "pageTitle": "The Professionalized AI Trainer",
              "tldr": "The 'AI Trainer' was recognized as a bright prospect as early as 2021, with projections of over 200,000 trainers in China at the time and a global forecast of five million by 2022.",
              "content": "The profession of 'AI Trainer' was recognized as a bright prospect as early as 2021, with projections of over 200,000 trainers in China at the time and a global forecast of five million by 2022. [3.19] While this professionalization appears to offer benefits, it simultaneously serves as a tool of managerial control, legitimizing 'precision labor'the hidden, excessive, and often unpaid work demanded of annotators to meet extremely high and sometimes arbitrary accuracy standards set by clients.",
              "imageGroupIds": [
                "group_the-professionalized-ai-trainer_prompt-1"
              ]
            }
          ]
        },
        {
          "subSectionId": "pillar-3-the-doctrine-of-military-civil-fusion",
          "subSectionTitle": "Pillar 3: The Doctrine of Military-Civil Fusion",
          "pages": [
            {
              "pageId": "subsection-mcf-title",
              "pageTitle": "Pillar 3: The Doctrine of Military-Civil Fusion (MCF)",
              "tldr": "The capstone of China's strategy is 'Military-Civil Fusion,' an aggressive national doctrine that eliminates all barriers between the civilian tech sector and the military, ensuring that the professionalized 'data army' is a strategic military asset for achieving 'intelligentized warfare.'",
              "content": "The capstone of China's strategy is the **'Military-Civil Fusion' (MCF)** doctrine. This is an aggressive, top-down national strategy, personally overseen by Xi Jinping, designed to eliminate all barriers between China's civilian research and commercial sectors and its military and defense-industrial base. [3.22] The explicit goal of MCF is to develop the People's Liberation Army (PLA) into the world's most technologically advanced military by 2049. [3.23]",
              "imageGroupIds": [
                "group_subsection-mcf-title_prompt-1"
              ]
            },
            {
              "pageId": "military-civil-fusion",
              "pageTitle": "Military-Civil Fusion",
              "tldr": "Under MCF, AI is the key to achieving 'intelligentized warfare.' The professionalized 'data army' is not merely an economic resource; it is a strategic military asset, with the data they curate designed to be dual-use for both economic and warfighting capabilities.",
              "content": "Under MCF, AI is identified as the key technology that will drive the next revolution in military affairs, enabling a transition to **\"intelligentized warfare\" ()**. [3.24] This doctrine ensures that all national assetsincluding private companies, universities, research institutions, and the entire AI workforceare leveraged to advance military aims. The professionalized data army built through inland-sourcing is not merely an economic resource; it is a strategic military asset. The data they curate and the models they train are designed to be dual-use, advancing both economic development and the PLA's warfighting capabilities. [3.25]",
              "imageGroupIds": [
                "group_military-civil-fusion_prompt-1"
              ]
            },
            {
              "pageId": "a-weaponized-ecosystem",
              "pageTitle": "A Weaponized Ecosystem",
              "tldr": "This comprehensive, whole-of-nation approach weaponizes the entire AI ecosystem for geopolitical and military dominance, prioritizing cognitive warfare to gain asymmetric advantages.",
              "content": "This comprehensive, whole-of-nation approach weaponizes the entire AI ecosystem in service of a singular strategic objective: geopolitical and military dominance. The doctrine prioritizes cognitive warfare, which uses AI-driven psychological operations and big data analytics to manipulate an adversary's perceptions and degrade their decision-making. [3.26] The PLA views AI as the key to generating 'asymmetric advantages' against the United States, which it regards as a 'strong enemy.' [3.27]",
              "imageGroupIds": [
                "group_a-weaponized-ecosystem_prompt-1"
              ]
            },
          {
            "pageId": "fusion-in-practice-deepseek",
            "pageTitle": "Fusion in Practice: DeepSeek",
            "tldr": "DeepSeek exemplifies China's Military-Civil Fusion, operating as a state-championed asset integrated into the defense apparatus through personnel pipelines, reliance on sanctioned infrastructure, and direct PLA/PAP deployment. Its strategic GPU stockpiling, alleged sanctions evasion, and distribution of biased open-weight models highlight its role as a dual-use geopolitical tool.",
            "content": "The Military-Civil Fusion (MCF) doctrine systematically integrates China's leading AI companies into its military apparatus, rendering the Western distinction between 'civilian' and 'military' firms operationally irrelevant. DeepSeek, the Hangzhou-based AI firm known for its high-performing, low-cost open-source LLMs, exemplifies this fusion, functioning not as an independent vendor but as a systemic component of the state's defense and security apparatus.\n\nDeepSeek's integration is built upon a tangible pipeline of personnel and infrastructure. It draws human capital directly from the core of China's defense research ecosystem, recruiting heavily from the \"Seven Sons of National Defence\" (e.g., Harbin Institute of Technology, Beihang University)universities sanctioned by the U.S. for their military ties. Analysis indicates dozens of DeepSeek researchers have past or current affiliations with PLA laboratories. Furthermore, intelligence firm analysis found that DeepSeek-affiliated researchers participated in nearly 400 AI research projects funded by the PLA.\n\nWhile allegations of illicitly acquiring more powerful H100 chips persist, indicating a multi-pronged strategy to circumvent sanctions, DeepSeek's proven efficiency shows that a hardware advantage alone does not guarantee a perpetual lead. DeepSeek's operational capacity relies on infrastructure provided by entities deeply embedded in the military-industrial complex, including those designated by the U.S. as \"Chinese military companies\" (see table below).\n\n**Table: DeepSeek's Reliance on U.S.-Sanctioned and Military-Linked Suppliers**\n\n| Partner/Supplier Entity | State/Military Affiliation & U.S. Sanction Status | Role in DeepSeek's Operations |\n| :--- | :--- | :--- |\n| **Inspur ()** | State-run; Designated a \"Chinese Military Company\" by the U.S. DoD. | Cloud provider; Offers server solutions pre-loaded with DeepSeek models. |\n| **Sugon ()** | Sanctioned by the U.S. (2019) for supporting Chinese military/state security. | Provides GPU servers and cooling systems for DeepSeek's AI training centers. |\n| **China Mobile ()** | State-owned; Designated a \"Chinese Military Company\" by the U.S. DoD. | Provides backend infrastructure for data transmission. |\n\nThis connection translates into direct military and security application. OSINT confirms the rapid adoption of DeepSeek's technology by the People's Liberation Army (PLA) and the People's Armed Police (PAP). The PLA Central Theatre Command hospital deploys DeepSeek models for patient treatment planning. PAP units utilize the AI for training regimens and psychological counseling. A senior U.S. State Department official confirmed DeepSeek appears over 150 times in PLA procurement records, alleging the company provides direct technical services to military research institutions. Domestically, the models support state \"AI Governance\" initiatives, including law enforcement applications to \"predict crime trends.\"\n\nDeepSeek operates as a \"state-championed, privately-executed national asset.\" Its genesis was enabled by a calculated, multi-billion yuan investment by its parent company to stockpile approximately 10,000 high-end NVIDIA A100 GPUs *before* U.S. export controls, creating the \"Firefly\" supercomputer cluster. The company received unambiguous high-level endorsement when founder Liang Wenfeng met with Premier Li Qiang in January 2025, signaling alignment with national priorities. U.S. officials allege DeepSeek actively attempts to circumvent sanctions via shell companies and foreign data centersa risk tolerance characteristic of a state-directed operation.\n\nThis hybrid model poses significant geopolitical risks. Analysis reveals DeepSeek's models feature embedded, multi-layered censorship mechanisms and demonstrable pro-China bias. The company's \"open-weight\" strategy functions as a global distribution mechanism for this state-aligned technology. As developers worldwide integrate these powerful models, they risk unknowingly propagating the CCP's worldview, leveraging the open-source ethos as a sophisticated tool of soft power.",
            "imageGroupIds": [
              "group_fusion-in-practice-deepseek_prompt-1"
            ]
            },
          
            {
              "pageId": "intelligentized-warfare",
              "pageTitle": "Intelligentized Warfare: The Architecture of Cognitive Conflict",
              "tldr": "Intelligentized Warfare is built on the pillars of data, algorithms, and computing power, leveraged through Military-Civil Fusion. It aims to win by integrating autonomous systems and human-machine hybrid intelligence, expanding the battlefield to target the adversary's cognitionthe 'Brain Battlefield'to achieve strategic paralysis.",
              "content": "The PLA's doctrine of Intelligentized Warfare () is underpinned by a specific technological architecture designed to achieve cognitive dominance. This architecture rests on three foundational pillars: **Data, Algorithms, and Computing Power**. The PLA views data as the \"new oil\" and algorithms as the engine of future conflict. The national strategy of Military-Civil Fusion (MCF) is the critical enabler, allowing the PLA to rapidly leverage commercial advances in AI, big data, and cloud computing to build this foundation.\n\nThis foundation supports a shift toward **\"machine-led combat\" (, *jq zhzhn*)**. The PLA is investing heavily in unmanned and autonomous systems across all domains, viewing them not as auxiliary assets but as the primary combatants of the future. A key operational concept is **\"Swarm Warfare\" (, *fngqn zuzhn*)**, utilizing large numbers of low-cost, intelligent platforms to overwhelm sophisticated defenses through saturation and massan asymmetric logic described as \"ants gnawing an elephant.\"\n\nTo manage this high-speed, complex environment, the PLA emphasizes **\"Human-Machine Hybrid Intelligence\" (, *rn-j hnh zhnng*)**. This envisions AI as a \"digital staff\" (), analyzing data and optimizing plans at machine speed, fused with human creativity and strategic intuition. A specific model for this interaction is ***Rn Mu J Hu* ()\"Human plans, machine plots.\"** The human provides the strategy and intent (the \"why\"), while the AI handles the detailed optimization and execution (the \"how\"). The human soldier evolves into an \"intellect-warrior\" (, *zh sh*), supervising autonomous systems.\n\nCrucially, Intelligentized Warfare radically expands the concept of the battlefield. Beyond traditional multi-domain integration, it formalizes the cognitive domain as the primary theater of operations. PLA strategists identify the **\"Brain Battlefield\" (, *tuno zhnchng*)** as the new decisive combat space. The objective is to wage cognitive warfare to directly attack an opponent's perception, morale, and will to fight. Success in the cognitive domain can paralyze decision-making and potentially lead to victory before a major kinetic battle is fought.",
              "imageGroupIds": [
                "group_intelligentized-warfare_prompt-1"
              ]
            },
            {
              "pageId": "mcf-in-practice-the-national-champions",
              "pageTitle": "MCF in Practice: The National Champions",
              "tldr": "National champions in voice recognition (iFlytek) and computer vision (SenseTime, Megvii) are deeply integrated into the military apparatus, their technologies forming the backbone of advanced surveillance and defense systems.",
              "content": "iFlytek, a national leader in intelligent voice and speech recognition, has established joint laboratories and participated in MCF projects to adapt its advanced voice technology for defense applications, such as command and control systems. [3.30] SenseTime & Megvii, these computer vision giants have been officially designated as AI 'national champions.' Their facial and object recognition technologies are inherently dual-use, forming the backbone of advanced surveillance and public security systems. Their direct links to state security objectives have led to their inclusion on U.S. sanctions lists. [3.31]",
              "imageGroupIds": [
                "group_mcf-in-practice-the-national-champions_prompt-1"
              ]
            },
            {
              "pageId": "the-plas-ai-shopping-list",
              "pageTitle": "The PLA's AI Shopping List",
              "tldr": "Analysis of PLA procurement contracts reveals a pragmatic focus on near-term capabilities, with the majority of suppliers being private tech companies, confirming the success of the MCF strategy in fusing the commercial tech base with military objectives.",
              "content": "Analysis of hundreds of PLA AI-related procurement contracts reveals a clear focus on pragmatic, near-term capabilities. The most significant areas of investment are intelligent and autonomous vehicles (especially UAVs and drone swarms), Intelligence, Surveillance, and Reconnaissance (ISR), information warfare, predictive maintenance, and Automated Target Recognition (ATR). [3.32] The majority of the PLA's AI suppliers are not traditional state-owned defense conglomerates but private technology companies, confirming the success of the MCF strategy in fusing the commercial tech base with military objectives. [3.33]",
              "imageGroupIds": [
                "group_the-plas-ai-shopping-list_prompt-1"
              ]
            }
          ]
        },
        {
          "subSectionId": "net-assessment-the-cognitive-capital-gap",
          "subSectionTitle": "Net Assessment: The Cognitive Capital Gap",
          "pages": [
            {
              "pageId": "subsection-net-assessment-title",
              "pageTitle": "Net Assessment: The Cognitive Capital Gap",
              "tldr": "The U.S. treats its AI human capital as a disposable commodity; China treats it as a strategic resource. This philosophical divide is creating a 'Cognitive Capital Gap'a widening chasm in the quality, stability, and strategic alignment of the foundational human layer of the AI stack.",
              "content": "A direct comparison of the American and Chinese models reveals a stark and dangerous divergence. The United States and China are not just competing on algorithms and processing power; they are competing on two fundamentally different philosophies of human capital management. The U.S. approach treats the foundational human layer of AI as a disposable commodity, an externality to be managed for the lowest possible cost. China treats it as a strategic national resource, an asset to be cultivated, controlled, and directed. This philosophical divide is creating a 'Cognitive Capital Gap.'",
              "imageGroupIds": [
                "group_subsection-net-assessment-title_prompt-1"
              ]
            },
            {
              "pageId": "the-cognitive-capital-gap",
              "pageTitle": "The Cognitive Capital Gap",
              "tldr": "This is not merely a quantitative gap in the number of workers, but a qualitative chasm in the quality, stability, psychological well-being, and strategic alignment of the foundational human layer of the AI stack.",
              "content": "This is not merely a quantitative gap in the number of workers, but a qualitative chasm in the **quality, stability, psychological well-being, and strategic alignment** of the foundational human layer of the AI stack.",
              "imageGroupIds": [
                "group_the-cognitive-capital-gap_prompt-1"
              ]
            },
            {
              "pageId": "a-tale-of-two-systems",
              "pageTitle": "A Tale of Two Systems",
              "tldr": "The U.S. model is optimized for short-term corporate profit, leading to a precarious workforce and brittle AI. The Chinese model is optimized for long-term national power, producing a stable, controlled workforce and a more resilient data pipeline.",
              "content": "The U.S. model, built on the brittle foundation of a global ghost workforce, is optimized for short-term corporate profit and liability-shedding. It produces a workforce that is precarious, transient, underpaid, and operating under a significant cognitive tax. This inherently leads to lower-quality data, brittle AI systems, and a critical national security vulnerability. The Chinese model, built on a state-directed strategy of inland-sourcing and professionalization, is optimized for long-term national power. It produces a workforce that is stable, domestically controlled, professionalized, and strategically aligned with the state's objectives. While this system is authoritarian, it creates a more resilient and potentially higher-quality data pipeline for its national AI ambitions.",
              "imageGroupIds": [
                "group_a-tale-of-two-systems_prompt-1"
              ]
            },
            {
              "pageId": "the-enduring-vulnerability",
              "pageTitle": "The Enduring Vulnerability",
              "tldr": "While the U.S. may lead in frontier research and compute power, China is building a superior human capital foundation. Over time, China's AI systems may prove more robust and reliable, as a superpower cannot be sustained indefinitely on a brittle foundation.",
              "content": "While the United States currently maintains a lead in frontier model research and, critically, in overall access to high-performance computing power, this advantage is not guaranteed to last. China is rapidly closing the gap in model performance and is projected to continue narrowing it. [3.34] More importantly, it is building a superior human capital foundation. The Cognitive Capital Gap represents a long-term strategic vulnerability. An AI superpower cannot be sustained indefinitely on a brittle foundation. Over time, China's AI systems, particularly those dedicated to state and military functions, may prove to be more robust, reliable, and secure than their Western counterparts precisely because they are built on a foundation of more stable, better-supported, and more strategically aligned human cognitive capital. In the long-term strategic competition, a system deliberately designed for power has a distinct advantage over a system that has emerged from market logic optimized for short-term efficiency.",
              "imageGroupIds": [
                "group_the-enduring-vulnerability_prompt-1"
              ]
            },
            {
              "pageId": "an-unsustainable-superpower",
              "pageTitle": "An Unsustainable Superpower",
              "tldr": "An AI superpower cannot be sustained indefinitely on a brittle foundation of precarious labor. China's systems may prove more robust precisely because they are built on a more stable human foundation.",
              "content": "The Cognitive Capital Gap represents a long-term strategic vulnerability. An AI superpower cannot be sustained indefinitely on a brittle foundation. Over time, China's AI systems, particularly those dedicated to state and military functions, may prove to be more robust, reliable, and secure than their Western counterparts precisely because they are built on a foundation of more stable, better-supported, and more strategically aligned human cognitive capital.",
              "imageGroupIds": [
                "group_an-unsustainable-superpower_prompt-1"
              ]
            },
            {
              "pageId": "net-assessment-us-vs-china-ai-human-capital-models",
              "pageTitle": "Net Assessment: U.S. vs. China AI Human Capital Models",
              "tldr": "A direct comparison reveals a stark strategic asymmetry, with China's model showing advantages in stability, control, and strategic alignment, while the U.S. model is characterized by precarity and risk.",
              "content": "| Vector of Comparison | United States Model | People's Republic of China Model |\n| :---- | :---- | :---- |\n| **Labor Model** | Global outsourcing; \"ghost work\"; precarious gig economy. [2.11] | Domestic \"inland-sourcing\"; state-supported data bases. [3.14] |\n| **Compensation & Stability** | Low-wage ($1-3/hr); high turnover; no benefits or job security. [2.9] | Formalized profession; stable employment; state-backed career paths. |\n| **Training & Upskilling** | Ad-hoc; company-specific; minimal investment in human capital. | National priority; professional education pathways and certifications. [3.18] |\n| **Data & IP Control** | Diffuse; globally distributed; high risk of leakage and adversarial poisoning. [4.1] | Sovereign; centralized within national borders; state-controlled and monitored. |\n| **State Involvement** | Laissez-faire; reactive regulation focused on downstream harms. [2.2] | Directive; integrated into national strategy; proactive industrial policy. [3.5] |\n| **Strategic Goal** | Short-term corporate cost-minimization and liability-shedding. | Long-term national technological dominance and Military-Civil Fusion. [3.22] |",
              "imageGroupIds": [
                "group_net-assessment-us-vs-china-ai-human-capital-models_prompt-1"
              ]
            },
            {
              "pageId": "short-term-profit-vs-long-term-power",
              "pageTitle": "Short-Term Profit vs. Long-Term Power",
              "tldr": "The U.S. model is optimized for short-term corporate profit, leading to a precarious workforce and brittle AI. The Chinese model is optimized for long-term national power, producing a stable, controlled workforce and a more resilient data pipeline.",
              "content": "The U.S. model, built on the brittle foundation of a global ghost workforce, is optimized for short-term corporate profit and liability-shedding. It produces a workforce that is precarious, transient, underpaid, and operating under a significant cognitive tax. This inherently leads to lower-quality data, brittle AI systems, and a critical national security vulnerability. The Chinese model, built on a state-directed strategy of inland-sourcing and professionalization, is optimized for long-term national power. It produces a workforce that is stable, domestically controlled, professionalized, and strategically aligned with the state's objectives. While this system is authoritarian, it creates a more resilient and potentially higher-quality data pipeline for its national AI ambitions.",
              "imageGroupIds": [
                "group_short-term-profit-vs-long-term-power_prompt-1"
              ]
            },
            {
              "pageId": "the-tipping-point",
              "pageTitle": "The Tipping Point",
              "tldr": "The U.S. may maintain a temporary lead in frontier R&D, but China is winning the more important race to build the capacity for scaled integration. This gap will eventually reach a tipping point where our research lead becomes irrelevant.",
              "content": "While the United States currently maintains a lead in frontier model research and, critically, in overall access to high-performance computing power, this advantage is not guaranteed to last. China is rapidly closing the gap in model performance and is projected to continue narrowing it. [3.35] More importantly, it is building a superior human capital foundation. The Cognitive Capital Gap represents a long-term strategic vulnerability. An AI superpower cannot be sustained indefinitely on a brittle foundation.",
              "imageGroupIds": [
                "group_the-tipping-point_prompt-1"
              ]
            }
          ]
        }
      ]
    },
    {
      "sectionId": "part-iv-the-unseen-battlefield",
      "sectionTitle": "Part IV: The Unseen Battlefield",
      "pages": [
        {
          "pageId": "part-iv-title",
          "pageTitle": "Part IV: The Unseen Battlefield - The Cognitive Security Imperative",
          "tldr": "This section reframes the AI supply chain as a critical national security domain (COGSEC), arguing that the flawed labor model is not just an economic liability but a profound and unaddressed vulnerability to adversarial attack.",
          "content": "The brittle foundation of the Western AI labor model is more than an economic liability or an ethical failure; it is a profound and unaddressed national security vulnerability. The current discourse on AI safety, which is largely focused on abstract, long-term risks of unaligned superintelligence, is dangerously overlooking a clear and present danger that exists today. This threat does not require a sentient AI with its own malicious goals. It requires only a human adversary who understands how to exploit the systemic weaknesses we have built into our own AI supply chain. Reframing this problem through the lens of national security demands the recognition of a new strategic domain: Cognitive Security (COGSEC).",
          "imageGroupIds": [
            "group_part-iv-title_prompt-1"
          ]
        }
      ],
      "subSections": [
        {
          "subSectionId": "the-human-vector",
          "subSectionTitle": "The Human Vector",
          "pages": [
            {
              "pageId": "subsection-human-vector-title",
              "pageTitle": "The Human Vector",
              "tldr": "The most vulnerable point in the American AI ecosystem isn't a line of code; it's a human being. The precarious 'ghost workforce' constitutes the single greatest, and most easily exploited, attack surface.",
              "content": "In the complex architecture of AI systems, the most vulnerable point of entry for an adversary is often not a line of code or a network firewall, but a human being. The precarious, underpaid, and psychologically stressed 'ghost workforce' at the base of the AI supply chain constitutes the single greatest attack surface in the American AI ecosystem. This is the **human vector**, and it is wide open to exploitation.",
              "imageGroupIds": [
                "group_subsection-human-vector-title_prompt-1"
              ]
            },
            {
              "pageId": "the-human-vector",
              "pageTitle": "The Human Vector",
              "tldr": "The gig economy model is a security nightmare, with a staggering 87% of contract workers retaining access to sensitive data after a project ends and 76% having been hacked while working, making the entire AI data pipeline vulnerable.",
              "content": "The gig economy model, upon which much of the data annotation industry is built, is inherently fraught with cybersecurity risks. It involves a large, transient population of remote workers accessing corporate data and systems from personal devices over potentially unsecured networks. [4.1] This structure creates enormous challenges for security oversight. Research has shown that a staggering 87% of contract workers retain access to a previous client's sensitive accounts and data long after their gig has ended, and 76% have been hacked while working on a project. [4.2] This lax security posture makes the entire AI data pipeline vulnerable.",
              "imageGroupIds": [
                "group_the-human-vector_prompt-1"
              ]
            },
            {
              "pageId": "the-data-poisoning-threat",
              "pageTitle": "The Data Poisoning Threat",
              "tldr": "A financially desperate data annotator is an easy and inexpensive target for recruitment by adversaries. This makes data poisoningintentionally corrupting training datathe most feared threat in machine learning, as compromising the data compromises the entire model.",
              "content": "This vulnerable workforce is the perfect target for sophisticated **data poisoning attacks**. Data poisoning is an adversarial technique where an attacker intentionally injects false, biased, or malicious data into a training dataset to corrupt the resulting AI model. [4.3] A poisoned model can be manipulated to fail in specific ways, to exhibit hidden biases, or to contain \"backdoors\" that an attacker can trigger at a later time. [4.4] An adversary, such as a foreign intelligence service or a cybercriminal organization, does not need to execute a complex hack against a fortified corporate network. They only need to exploit the human vector. A disgruntled, financially desperate, or ideologically motivated data annotator in a low-wage country is an easy and inexpensive target for recruitment. For a small paymenta fraction of the cost of a traditional intelligence operationan adversary can persuade an insider to subtly alter data labels, inject malicious examples, or otherwise compromise the integrity of a dataset. [4.3] This is considered the most feared threat by companies working with machine learning, as compromising the training data compromises the entire model. [4.5]",
              "imageGroupIds": [
                "group_the-data-poisoning-threat_prompt-1"
              ]
            },
            {
              "pageId": "the-clean-label-attack",
              "pageTitle": "The Clean-Label Attack",
              "tldr": "Advanced 'clean-label' attacks use poisoned data that appears normal to human reviewers but still corrupts the AI. The low-wage ghost workforce provides a vast pool of potential insiders to inject this undetectable poison directly into the training pipeline.",
              "content": "The threat is magnified by the existence of advanced techniques like **\"clean-label\" poisoning attacks**. In a clean-label attack, the poisoned data is crafted so skillfully that it appears completely normal and correctly labeled to a human reviewer, yet it still carries the malicious payload that will corrupt the model's training process. [4.6] The most effective way to inject such data is through a trusted insider who can place it directly into the training pipeline, bypassing many standard validation checks. [4.4] The low-wage, high-turnover ghost workforce provides adversaries with a vast and continuously replenished pool of potential insiders to target for precisely this purpose. The West's AI labor model is not just producing low-quality data by accident; it is actively creating and expanding a critical national security vulnerability that adversaries can easily and cheaply exploit.",
              "imageGroupIds": [
                "group_the-clean-label-attack_prompt-1"
              ]
            },
            {
              "pageId": "a-security-nightmare",
              "pageTitle": "A Security Nightmare",
              "tldr": "The gig economy model, upon which much of the data annotation industry is built, is inherently fraught with cybersecurity risks, with a staggering 87% of contract workers retaining access to sensitive client data after their projects end.",
              "content": "The gig economy model, upon which much of the data annotation industry is built, is inherently fraught with cybersecurity risks. It involves a large, transient population of remote workers accessing corporate data and systems from personal devices over potentially unsecured networks. This structure creates enormous challenges for security oversight. Research has shown that a staggering 87% of contract workers retain access to a previous client's sensitive accounts and data long after their gig has ended, and 76% have been hacked while working on a project. This lax security posture makes the entire AI data pipeline vulnerable.",
              "imageGroupIds": [
                "group_a-security-nightmare_prompt-1"
              ]
            },
            {
              "pageId": "the-human-in-the-loophole",
              "pageTitle": "The Human in the Loophole",
              "tldr": "The most significant near-term risk is not that AI will spontaneously become malicious, but that a human adversary will deliberately *teach* our AI malicious behaviors by exploiting the very people we task with training them.",
              "content": "The current AI safety debate is focused on preventing a hypothetical future AI from spontaneously developing malicious intent. COGSEC forces us to confront a more immediate and plausible threat: that a human adversary will *deliberately teach* our AI systems malicious behaviors by exploiting the very people we have tasked with training them. The most significant near-term risk is not spontaneous AI malevolence, but weaponized human exploitation. This unseen battlefield of cognitive security must become a central focus of American AI strategy.",
              "imageGroupIds": [
                "group_the-human-in-the-loophole_prompt-1"
              ]
            }
          ]
        },
        {
          "subSectionId": "defining-cogsec",
          "subSectionTitle": "Defining COGSEC",
          "pages": [
            {
              "pageId": "subsection-cogsec-title",
              "pageTitle": "Defining Cognitive Security (COGSEC)",
              "tldr": "Cognitive Security (COGSEC) is the defense of human cognition and sensemaking from manipulation. It is about protecting the human mind as the foundational layer of any trustworthy system.",
              "content": "Addressing this vulnerability requires expanding our conception of security beyond the traditional boundaries of cybersecurity. We must establish and prioritize a new national security domain: **Cognitive Security (COGSEC)**. Cognitive Security is not simply about protecting computer networks or hardware. It is the practice of defending the entire socio-technical ecosystem of human cognition and sensemaking from intentional manipulation and disruption. [4.9]",
              "imageGroupIds": [
                "group_subsection-cogsec-title_prompt-1"
              ]
            },
            {
              "pageId": "defining-cogsec",
              "pageTitle": "Defining COGSEC",
              "tldr": "It is concerned with protecting against malicious influence at all scales, from the perception of a single individual to the collective 'intelligence' of a society or an AI model.",
              "content": "It is concerned with protecting against malicious influence at all scales, from the perception of a single individual to the collective 'intelligence' of a society or an AI model. [4.10] In its essence, COGSEC is about protecting the human mind as the foundational layer of any trustworthy system. [4.11]",
              "imageGroupIds": [
                "group_defining-cogsec_prompt-1"
              ]
            },
            {
              "pageId": "the-two-dimensions-of-cogsec",
              "pageTitle": "The Two Dimensions of COGSEC",
              "tldr": "COGSEC in AI has two dimensions: protecting the human cognitive supply chain and protecting AI models from manipulation. These are linked; the best way to manipulate an AI is to first exploit the vulnerabilities in the human workforce that trains it.",
              "content": "In the context of artificial intelligence, COGSEC has two primary dimensions:\n\n1. **Protecting the Human Cognitive Supply Chain:** This involves safeguarding the cognitive health, integrity, and reliability of the human beings who collect, create, label, and curate the data that AI systems learn from. A data annotator suffering from a high cognitive tax due to financial stress is a compromised cognitive asset. A workforce that is disaffected and economically vulnerable is a compromised cognitive supply chain.  \n2. **Protecting AI Models from Cognitive Manipulation:** This involves defending the AI models themselves from attacks like data poisoning and adversarial examples that are designed to manipulate their \"perception\" and decision-making processes.\n\nThis report argues that these two dimensions are inextricably linked. The most effective way to manipulate an AI model's cognition is by first exploiting the vulnerabilities in the human cognitive supply chain. Therefore, **securing the cognitive integrity of the data workforce is as vital to 21st-century national security as securing the semiconductor supply chain.**",
              "imageGroupIds": [
                "group_the-two-dimensions-of-cogsec_prompt-1"
              ]
            },
            {
              "pageId": "the-true-near-term-risk",
              "pageTitle": "The True Near-Term Risk",
              "tldr": "An AI-powered weapon system, intelligence analysis platform, or critical infrastructure controller that has been trained on poisoned data is a fundamentally compromised asset, regardless of how secure its hardware or network may be.",
              "content": "An AI-powered weapon system, intelligence analysis platform, or critical infrastructure controller that has been trained on poisoned data is a fundamentally compromised asset, regardless of how secure its hardware or network may be. The human vector is the weakest link in the chain, and our current labor practices have left it undefended. [4.12]",
              "imageGroupIds": [
                "group_the-true-near-term-risk_prompt-1"
              ]
            },
            {
              "pageId": "weaponized-human-exploitation",
              "pageTitle": "Weaponized Human Exploitation",
              "tldr": "The most significant near-term risk is not that AI will spontaneously become malicious, but that a human adversary will deliberately *teach* our AI malicious behaviors by exploiting the very people we task with training them.",
              "content": "The current AI safety debate is focused on preventing a hypothetical future AI from spontaneously developing malicious intent. COGSEC forces us to confront a more immediate and plausible threat: that a human adversary will *deliberately teach* our AI systems malicious behaviors by exploiting the very people we have tasked with training them. The most significant near-term risk is not spontaneous AI malevolence, but weaponized human exploitation. This unseen battlefield of cognitive security must become a central focus of American AI strategy.",
              "imageGroupIds": [
                "group_weaponized-human-exploitation_prompt-1"
              ]
            }
          ]
        },
        {
          "subSectionId": "the-strategic-boomerang",
          "subSectionTitle": "The Strategic Boomerang",
          "pages": [
            {
              "pageId": "subsection-strategic-boomerang-title",
              "pageTitle": "The Strategic Boomerang: The Great Cognitive Capital Transfer",
              "tldr": "By offshoring complex data work, the U.S. is funding a 'Great Cognitive Capital Transfer,' repeating the same fundamental error it made with manufacturing, but this time in the far more critical domain of cognitive production.",
              "content": "The flawed architecture of the fissured workplace does not merely result in poor data quality and domestic labor exploitation; it creates a profound and escalating national security vulnerability. The United States is repeating the same fundamental error it made with manufacturing in the late 20th century, but this time in the far more critical domain of cognitive production. The long-term consequences of this policy are predictable, severe, and represent a direct threat to American technological leadership and national security. [4.13][4.14]",
              "imageGroupIds": [
                "group_subsection-strategic-boomerang-title_prompt-1"
              ]
            },
            {
              "pageId": "the-strategic-boomerang",
              "pageTitle": "The Strategic Boomerang",
              "tldr": "The long-term consequences of this policy are predictable, severe, and represent a direct threat to American technological leadership and national security.",
              "content": "The long-term consequences of this policy are predictable, severe, and represent a direct threat to American technological leadership and national security. [4.13][4.14]",
              "imageGroupIds": [
                "group_the-strategic-boomerang_prompt-1"
              ]
            },
            {
              "pageId": "historys-warning-apple-in-china",
              "pageTitle": "History's Warning: Apple in China",
              "tldr": "The offshoring of U.S. manufacturing to China serves as a direct cautionary tale. A strategy that was immensely profitable for one company inadvertently turbocharged the technological development of a formidable geopolitical competitor like Huawei.",
              "content": "There is a direct historical parallel that serves as a cautionary tale: the offshoring of U.S. manufacturing and technology to China. For three decades, Apple, in pursuit of unparalleled efficiency and profitability, invested hundreds of billions of dollars to build a sophisticated manufacturing ecosystem in China. By 2015, Apple was investing $55 billion per year into China. This involved not just outsourcing assembly, but actively transferring technological know-how to over 28 million Chinese workers by embedding American engineers in Chinese facilities to co-design production processes. This strategy was immensely profitable for Apple, but it came at a significant geopolitical cost to the United States. The massive investment and knowledge transfer turbocharged China's own technological development, transforming the country from a low-cost labor hub into a formidable competitor. The very manufacturing expertise and supply chain infrastructure that Apple built is now leveraged by Chinese rivals like Huawei. [4.15]",
              "imageGroupIds": [
                "group_historys-warning-apple-in-china_prompt-1"
              ]
            },
            {
              "pageId": "the-great-cognitive-capital-transfer",
              "pageTitle": "The Great Cognitive Capital Transfer",
              "tldr": "By offshoring complex data work, the U.S. is funding a 'Great Cognitive Capital Transfer.' Each labeled dataset is a paid training session, upskilling a global workforce in foundational AI proficiencya far more vital capability than manufacturing.",
              "content": "Today, this same flawed logic is being applied to the AI supply chain. By offshoring the complex cognitive work of data annotation, curation, and moderation, the U.S. is not merely buying a service; it is actively funding the education of a global AI-skilled workforce. [4.16] Every dataset labeled by a worker in another country is a paid training session, honing skills in pattern recognition, data analysis, and the nuanced interpretation of complex informationthe very building blocks of AI proficiency. This constitutes a **\"Great Cognitive Capital Transfer,\"** a strategic boomerang where the short-term cost savings of today are directly financing the competitive capabilities of tomorrow's rivals. While manufacturing offshoring transferred the ability to *make things*, cognitive offshoring transfers the ability to *make sense of things*a far more foundational and strategically vital capability in the 21st century.",
              "imageGroupIds": [
                "group_the-great-cognitive-capital-transfer_prompt-1"
              ]
            }
          ]
        }
      ]
    },
    {
      "sectionId": "part-v-the-american-counter-strategy",
      "sectionTitle": "Part V: The American Counter-Strategy",
      "pages": [
        {
          "pageId": "part-v-title",
          "pageTitle": "Part V: The American Counter-Strategy - From Ghost Worker to Citizen Architect",
          "tldr": "This section outlines a hopeful, uniquely American solution to the problems identified, leveraging the nation's unique strengths: a culture of bottom-up innovation, a belief in individual empowerment, and the principles of democratic access.",
          "content": "The diagnosis is stark: the foundation of the Western AI industry is brittle, exploitative, and strategically vulnerable. The solution, however, cannot be to simply patch the cracks or to imitate China's authoritarian, top-down model. The American counter-strategy must be asymmetric, leveraging the nation's unique strengths: a culture of bottom-up innovation, a belief in individual empowerment, and the principles of democratic access. The path forward is not to build a bigger army of ghost workers, but to cultivate a nation of Citizen Architects. This requires a fundamental re-conceptualization of data work, from a low-skill task to a high-value profession, supported by a two-pronged strategy of elite professionalization and mass empowerment.",
          "imageGroupIds": [
            "group_part-v-title_prompt-1"
          ]
        }
      ],
      "subSections": [
        {
          "subSectionId": "the-hidden-curriculum",
          "subSectionTitle": "The Hidden Curriculum",
          "pages": [
            {
              "pageId": "subsection-hidden-curriculum-title",
              "pageTitle": "The Hidden Curriculum: The Rise of the 100x Data Curator",
              "tldr": "The solution begins by rejecting the premise that data annotation is low-skill work. It is a cognitively demanding act of knowledge architecture containing a 'hidden curriculum' of valuable skills.",
              "content": "The first step in this counter-strategy is to reject the flawed premise that data annotation is a low-skill, mechanical task. High-quality data curation is a cognitively demanding act of knowledge architecture. It requires domain expertise, critical thinking, nuanced judgment, and a deep understanding of potential biasesthe very skills that are suppressed by the current labor model. [5.1] The solution to the 'brittle foundation' is to transform the role of the data worker from a ghost in the machine into its most valued curator.",
              "imageGroupIds": [
                "group_subsection-hidden-curriculum-title_prompt-1"
              ]
            },
            {
              "pageId": "the-hidden-curriculum",
              "pageTitle": "The Hidden Curriculum",
              "tldr": "The '100x data curator' is a professional who uses AI tools to validate, clean, and secure datasets at a scale and quality 100 times greater than what is possible manually. They are not just labeling data; they are architecting knowledge.",
              "content": "This transformation follows the same 'Vibecoding to Virtuosity' pathway that enables the Citizen Architect. An entry-level annotator may start with simple, repetitive tasks. But through experience and upskilling, they can ascend to become a **\"100x data curator.\"** This is not an individual who simply labels 100 times more data points. This is a professional who uses AI-powered tools to validate, clean, structure, enrich, and secure datasets at a scale and quality level 100 times greater than what is possible through manual labor alone. [5.2] A 100x data curator is a master of the data pipeline. They use AI to detect anomalies and inconsistencies, to automatically identify and redact sensitive information, to generate synthetic data to cover edge cases, and to enforce governance policies across massive datasets. [5.1] They are, in essence, applying the skills of a Citizen Architect to the most foundational layer of the AI stack. They are not merely labeling data; they are architecting the knowledge upon which all reliable AI is built.",
              "imageGroupIds": [
                "group_the-hidden-curriculum_prompt-1"
              ]
            },
            {
              "pageId": "the-100x-data-curator-v2",
              "pageTitle": "The 100x Data Curator",
              "tldr": "The '100x data curator' is a professional who uses AI tools to validate, clean, and secure datasets at a scale and quality 100 times greater than what is possible manually. They are not just labeling data; they are architecting knowledge.",
              "content": "This transformation follows the same 'Vibecoding to Virtuosity' pathway that enables the Citizen Architect. An entry-level annotator may start with simple, repetitive tasks. But through experience and upskilling, they can ascend to become a **\"100x data curator.\"** This is not an individual who simply labels 100 times more data points. This is a professional who uses AI-powered tools to validate, clean, structure, enrich, and secure datasets at a scale and quality level 100 times greater than what is possible through manual labor alone. [5.2] A 100x data curator is a master of the data pipeline. They use AI to detect anomalies and inconsistencies, to automatically identify and redact sensitive information, to generate synthetic data to cover edge cases, and to enforce governance policies across massive datasets. [5.1] They are, in essence, applying the skills of a Citizen Architect to the most foundational layer of the AI stack. They are not merely labeling data; they are architecting the knowledge upon which all reliable AI is built.",
              "imageGroupIds": [
                "group_the-100x-data-curator_prompt-1"
              ]
            },
            {
              "pageId": "the-citizen-architect-pathway",
              "pageTitle": "The Citizen Architect Pathway",
              "tldr": "Recognizing and fostering the 'hidden curriculum' within data work reframes it as a valuable career path, creating the incentive structure needed to attract and retain the high-skill talent required to build trustworthy AI.",
              "content": "This new profession requires a new set of skills and a new mindset, moving from mechanical execution to strategic oversight. \n\n| Developmental Stage | Core Skills | Mindset & Approach | Typical Output |\n| :---- | :---- | :---- | :---- |\n| **Stage 1: Vibecoder / Annotator** | Intuitive prompting; basic data labeling; following explicit instructions. [5.3] | \"What is this?\" (Categorical) | Labeled data points; simple annotations. |\n| **Stage 2: AI Apprentice / Data Technician** | Structured prompting; use of annotation tools; basic quality checks; identifying simple inconsistencies. [5.4] | \"Is this correct?\" (Validational) | Cleaned datasets; verified annotations; basic quality reports. |\n| **Stage 3: Journeyman Developer / Data Steward** | System design for data pipelines; use of AI for automated data cleaning and validation; RAG implementation; bias detection. [5.5] | \"How does this data fit into the larger system?\" (Integrative) | Well-structured, validated, and documented datasets; data governance frameworks. |\n| **Stage 4: Citizen Architect / 100x Data Curator** | Strategic oversight of data ecosystems; complex system orchestration; COGSEC principles; adversarial data testing; synthetic data generation. [5.6] | \"What data should exist and why? How can it be secured?\" (Architectural & Strategic) | Robust, secure, high-quality, AI-ready knowledge bases; resilient data pipelines. |\n\n*Table 2: The Citizen Architect Pathway: From Vibecoding to Virtuosity*\n\nRecognizing and fostering this \"hidden curriculum\" is the first step toward fixing the brittle foundation. It reframes data work as a valuable career path, creating the incentive structure needed to attract and retain the high-skill talent required to build trustworthy AI.",
              "imageGroupIds": [
                "group_the-citizen-architect-pathway_prompt-1"
              ]
            },
            {
              "pageId": "a-valuable-career-path",
              "pageTitle": "A Valuable Career Path",
              "tldr": "Recognizing and fostering this 'hidden curriculum' reframes data work as a valuable career path, creating the incentive structure needed to attract and retain the high-skill talent required to build trustworthy AI.",
              "content": "Recognizing and fostering this 'hidden curriculum' is the first step toward fixing the brittle foundation. It reframes data work as a valuable career path, creating the incentive structure needed to attract and retain the high-skill talent required to build trustworthy AI.",
              "imageGroupIds": [
                "group_a-valuable-career-path_prompt-1"
              ]
            }
          ]
        },
        {
          "subSectionId": "the-human-firewall",
          "subSectionTitle": "The Human Firewall",
          "pages": [
            {
              "pageId": "subsection-human-firewall-title",
              "pageTitle": "A New Professional Cadre - The Human Firewall",
              "tldr": "To protect its most sensitive AI applications, the U.S. must build a 'human firewall'a dedicated, government-controlled, and highly skilled workforce composed of the National Security Annotation Corps (NSAC) and the Data Curator Intelligence Analyst (DCIA).",
              "content": "While foundational reform can stabilize the commercial data ecosystem, it cannot provide the absolute trust and security required for the nation's most sensitive AI applications. For data related to intelligence collection, military operations, and critical infrastructure protection, the commercial modeleven when reformedpresents an unacceptable level of risk from insider threats and foreign intelligence exploitation. To counter this, the United States must build its own human firewall: a dedicated, government-controlled, and highly skilled workforce for its most critical data needs. This is not a call to nationalize the entire industry, but to create a specialized corps of professionals capable of safeguarding the data that underpins national security.",
              "imageGroupIds": [
                "group_subsection-human-firewall-title_prompt-1"
              ]
            },
            {
              "pageId": "the-human-firewall",
              "pageTitle": "The Human Firewall",
              "tldr": "This human firewall is composed of two interlocking initiatives: the National Security Annotation Corps (NSAC), the organizational structure providing a cleared and trusted workforce; and the Data Curator Intelligence Analyst (DCIA), the new professional cadre with the hybrid skills to lead it.",
              "content": "This human firewall is composed of two interlocking initiatives: the **National Security Annotation Corps (NSAC)**, the organizational structure providing a cleared and trusted workforce; and the **Data Curator Intelligence Analyst (DCIA)**, the new professional cadre with the hybrid skills to lead it.",
              "imageGroupIds": [
                "group_the-human-firewall_prompt-1"
              ]
            }
          ]
        },
        {
          "subSectionId": "nsac",
          "subSectionTitle": "The National Security Annotation Corps (NSAC)",
          "pages": [
            {
              "pageId": "subsection-nsac-title",
              "pageTitle": "The National Security Annotation Corps (NSAC)",
              "tldr": "The NSAC is a proposed corps of security-cleared, U.S. citizen data curators who would handle the most sensitive AI projects for the DoD and Intelligence Community, directly closing the vulnerability of the commercial supply chain and tapping into underutilized domestic talent pools like military spouses.",
              "content": "The U.S. government should establish the National Security Annotation Corps (NSAC). The NSAC's mission would be to serve as a dedicated, security-cleared, U.S. citizen workforce for performing high-stakes data annotation, labeling, validation, and curation for the most sensitive AI projects within the Department of Defense (DoD) and the Intelligence Community (IC).",
              "imageGroupIds": [
                "group_subsection-nsac-title_prompt-1"
              ]
            },
            {
              "pageId": "nsac",
              "pageTitle": "NSAC",
              "tldr": "The rationale for the NSAC is to close the unacceptable risk of adversaries compromising military AI by simply bribing an underpaid data annotator. The NSAC re-shores and professionalizes this critical task.",
              "content": "**Mission and Rationale:** The rationale for the NSAC is rooted in the unacceptable risks of the current system. An adversary does not need to execute a complex cyberattack to compromise a critical US military AI; they can simply pay an underpaid data annotator to subtly mislabel a handful of key data points, creating a latent backdoor that can be exploited at a time of their choosing. The NSAC is designed to directly close this vulnerability by re-shoring and professionalizing the most critical segment of the AI data supply chain. The creation of such a corps is consistent with historical precedent and contemporary strategic thinking. The National Security Act of 1947 established the NSC to coordinate policy, and subsequent reforms have sought to create a more integrated community of national security professionals. The Hart-Rudman Commission, for example, proposed a 'National Security Service Corps' to develop leaders skilled in integrative problem-solving, applying the 'joint' spirit of the Goldwater-Nichols Act to the interagency world. The NSAC would apply this same principle to the digital age, creating a dedicated cadre of professionals for the foundational work of AI.",
              "imageGroupIds": [
                "group_nsac_prompt-1"
              ]
            },
            {
              "pageId": "nsac-structure-and-operations",
              "pageTitle": "NSAC: Structure and Operations",
              "tldr": "The NSAC would be structured under the ODNI or CDAO, with all members being cleared U.S. citizens working in secure facilities. A key recruitment strategy would be to tap into underutilized domestic talent pools like the military spouse community.",
              "content": "**Structure and Operations:** The NSAC could be structured as a new component within the Office of the Director of National Intelligence (ODNI) or as a joint organization under the DoD's Chief Digital and Artificial Intelligence Office (CDAO), which is already tasked with accelerating AI adoption. Key operational characteristics would include:\n\n* **Personnel:** All NSAC members would be U.S. citizens who have undergone rigorous background checks and hold security clearances appropriate to the classification of the data they handle (e.g., Secret, Top Secret/SCI).  \n* **Facilities:** All annotation work would be conducted in secure, government-accredited facilities, eliminating the risks of data exfiltration and foreign surveillance inherent in the remote, global commercial model.  \n* **Recruitment:** A key strategic opportunity for building this workforce lies in a loyal, domestic talent pool that is currently vastly underutilized: the military spouse community. This highly educated and motivated demographic suffers from an exceptionally high unemployment rate of 21-24% due to the exigencies of military life. Targeting this and other underutilized domestic talent pools (e.g., in economically distressed regions) would be a core recruitment strategy.  \n* **Funding:** The NSAC should be funded as a national security priority, recognizing that the quality of its work is as critical to mission success as the hardware on which AI models are run.\n\nThe establishment of the NSAC would directly address the severe counterintelligence vulnerabilities identified in this report. It would replace the opaque, insecure, and easily exploitable commercial supply chain with a closed-loop, trusted system for the nation's most critical AI data needs.",
              "imageGroupIds": [
                "group_nsac-structure-and-operations_prompt-1"
              ]
            }
          ]
        },
        {
          "subSectionId": "the-dcia",
          "subSectionTitle": "The Data Curator Intelligence Analyst (DCIA)",
          "pages": [
            {
              "pageId": "subsection-dcia-title",
              "pageTitle": "The Data Curator Intelligence Analyst (DCIA): Architect of the AI's Worldview",
              "tldr": "The era of 'prompt engineering' is over. Building secure and reliable AI demands a new disciplineContext Engineeringand a new professional cadre to master it: the Data Curator Intelligence Analyst (DCIA).",
              "content": "The initial excitement surrounding 'prompt engineering'the craft of coaxing AI with clever phrasesis rapidly fading. It is an unreliable, unscalable, and insecure tactic insufficient for mission-critical systems. The future belongs to a more rigorous, architectural discipline: **Context Engineering**. This is the science of designing, structuring, and securing the AI's entire information environmentits worldview. The realization that an AI's 'worldview' is an engineered artifact carries immense strategic implications: he who controls the context, controls the AI. This new discipline demands a new type of hybrid professional, one who bridges the divide between data science, cybersecurity, and human-AI systems design. This professional is the **Data Curator Intelligence Analyst (DCIA)**, the architect of AI cognition and the guardian of its ground truth.",
              "imageGroupIds": [
                "group_subsection-dcia-title_prompt-1"
              ]
            },
            {
              "pageId": "from-prompt-to-context-engineering",
              "pageTitle": "The End of Prompting, The Rise of Context Engineering",
              "tldr": "Prompt engineering is a fragile art, reliant on 'voodoo' and trial-and-error. Context Engineering is the architectural science that replaces it, shifting the focus from crafting the perfect instruction to building the perfect information environment.",
              "content": "Prompt engineering, in practice, is more akin to 'voodoo' or 'black magic' than a true engineering discipline. It relies on unscientific trial-and-error, lacks deterministic control, and is inherently brittle; techniques that work for one model often fail for another, or even for the same model after an update. This fragility makes it unsuitable for scalable, high-stakes applications.\n\n**Context Engineering** represents a fundamental paradigm shift. The goal is no longer to craft the perfect, complex instruction for an AI in an information vacuum. Instead, the goal is to **build the perfect information environment** for the AI to operate within, such that even a simple instruction becomes profoundly effective. It is the architecture of the AI's 'working memory.'\n\n| Dimension | Prompt Engineering (The Art of Conversation) | Context Engineering (The Science of Architecture) |\n| :---- | :---- | :---- |\n| **Core Function** | Crafting a specific instruction for a one-off response. | Designing a dynamic information ecosystem for consistent performance. |\n| **Mindset** | \"How can I phrase this question perfectly?\" | \"What does this AI need to *know* to answer perfectly?\" |\n| **Scope** | A single input-output pair. The prompt itself. | The entire context window: memory, documents, tools, history, instructions. |\n| **Scalability** | Low. Brittle and requires manual tweaking. | High. Designed for consistency and reuse across users and tasks. |\n| **Key Skills** | Language creativity, intuition, trial-and-error. | Systems thinking, data architecture, information retrieval, security. |\n| **Primary Tools** | Text editors, AI chat interfaces. | Vector DBs, knowledge graphs, RAG frameworks, data curation platforms. |",
              "imageGroupIds": [
                "group_from-prompt-to-context-engineering_prompt-1"
              ]
            },
            {
              "pageId": "the-architecture-of-context",
              "pageTitle": "The Architecture of Context: The DCIA's Toolkit",
              "tldr": "The DCIA masters the three pillars of Context Engineering: Grounding the AI in reality with RAG, Structuring its knowledge in vector databases and knowledge graphs, and Governing its behavior with advanced system prompts and tools.",
              "content": "A DCIA does not merely talk to an AI; they design its reality. This is achieved through the systematic integration of three technical pillars that construct a governable and grounded worldview for the AI system.\n\n**1. Grounding (What the AI Knows):** The foundation is **Retrieval-Augmented Generation (RAG)**. RAG connects the AI to external, authoritative knowledge bases in real-time, grounding it in verifiable facts and dramatically reducing hallucinations. This ensures the AI's knowledge is current, domain-specific, and accurate.\n\n**2. Structuring (How the AI Understands):** For RAG to work, knowledge must be structured for efficient retrieval. **Vector Databases** enable rapid semantic search by storing data based on its meaning (embeddings), acting as the AI's long-term memory. **Knowledge Graphs** provide explicit structure by mapping entities and their relationships, enabling complex, multi-hop reasoning and explainability.\n\n**3. Governing (How the AI Behaves):** The final pillar dictates the AI's behavior. **Advanced System Prompts** act as the AI's constitution, defining its persona, rules, ethical boundaries, and operational protocols using structured formats and role-based definitions. **Tooling (Function Calling)** transforms the AI from a passive oracle into an active agent, allowing it to interact with external APIs and systems in a controlled manner.",
              "imageGroupIds": [
                "group_the-architecture-of-context_prompt-1"
              ]
            },
            {
              "pageId": "the-dcia-skill-matrix",
              "pageTitle": "The DCIA Skill Matrix: A Hybrid Professional",
              "tldr": "The DCIA is a 'new collar' professional embodying the convergence of three distinct skill sets: the rigorous stewardship of the 100x Data Curator, the adversarial mindset of the Intelligence Analyst, and the creative systems thinking of the Virtuoso Vibecoder.",
              "content": "The DCIA is a 'new collar' professional who embodies the convergence of three distinct, yet synergistic, skill sets. They are the architects of the AI's cognitive environment, mastering the integrated skills required to build and defend trustworthy AI.\n\n**1. The 100x Data Curator (Stewardship & Order):** The master of the source. They ensure data integrity, quality, and provenance (FAIR principles). Their focus is **Validation over Generation**, treating the context package as a curated dataset. This is the first line of defense against data-centric attacks.\n\n**2. The Intelligence Analyst (Skepticism & Adversarial Thinking):** The proactive security mindset. They think like an adversary to anticipate threats, employ threat modeling and red teaming, and hunt for anomalies and deception. They approach the data ecosystem with professional skepticism.\n\n**3. The Virtuoso Vibecoder (Creativity & Systems Thinking):** The creative partner and systems architect. They translate complex human intent into structured logic and agentic workflows. They possess AI-native fluency, enabling them to rapidly prototype and orchestrate complex context environments and on-the-fly tooling.\n\n| Characteristic | The 100x Data Curator | The Intelligence Analyst | The Virtuoso Vibecoder |\n| :---- | :---- | :---- | :---- |\n| **Core Discipline** | Data Governance & Management | Threat Analysis & Risk Mitigation | Human-AI Systems Design |\n| **Key Responsibilities** | Ensuring data is FAIR; Implementing data governance; Validating sources. | Threat modeling; Red teaming pipelines; Detecting anomalies and poisoning. | Designing context architectures; Authoring complex system prompts; Building agentic workflows. |\n| **Contribution to AI Trust** | Guarantees the *integrity* of the AI's knowledge. | Guarantees the *security* of the AI's knowledge. | Guarantees the *usability and alignment* of the AI's knowledge. |",
              "imageGroupIds": [
                "group_the-dcia-skill-matrix_prompt-1"
              ]
            },
            {
              "pageId": "the-professionalized-human-firewall",
              "pageTitle": "The Professionalized Human Firewall: Securing the Cognitive Domain",
              "tldr": "The DCIA is the professionalized 'Human Firewall,' uniquely qualified to defend against the primary threat to modern AIdata poisoning and 'reality hacking'by actively architecting a resilient cognitive environment.",
              "content": "In the AI era, the primary threats are attacks on the AI's cognitive foundations. This demands a new defense: the DCIA as the professionalized human firewall. The most potent threat is **data poisoning**the adversarial manipulation of an AI's contextual data to corrupt its behavior from within. This is 'reality hacking,' manipulating the AI's perception of the world.\n\nThe DCIA's entire skill set is a direct countermeasure. Their **Data Curation** expertise (auditing sources, tracking provenance) is the primary defense. Their **Intelligence Analyst** identity provides the adversarial mindset to anticipate novel attacks that automated tools miss. Their **Vibecoding** skills allow them to build the defenses they design, such as adversarial training routines.\n\nIn the context of national security, this role is vital to **Cognitive Security (COGSEC)**. By safeguarding the foundational data, the DCIA acts as a **'Guardian of the Ground Truth,'** ensuring critical decisions are based on an uncorrupted view of reality. They close the dangerous **'human-in-the-loophole,'** transforming the human role from the weakest link into the most formidable line of defense.",
              "imageGroupIds": [
                "group_the-professionalized-human-firewall_prompt-1"
              ]
            },
            {
              "pageId": "the-strategic-imperative-quality-as-advantage",
              "pageTitle": "The Strategic Imperative: Quality as the Ultimate Advantage",
              "tldr": "The DCIA is the true 100x multiplier, transforming 'Garbage In, Garbage Out' to 'Quality In, Virtuosity Out.' Cultivating this cadre is the key to an asymmetric American advantage based on trust and reliability, not commoditized labor.",
              "content": "The true and sustainable 100x productivity multiplier in the AI era is the DCIA. A simple prompt directed at a brilliantly engineered context will consistently outperform a brilliant prompt directed at an information vacuum. The DCIA transforms the fundamental equation from 'Garbage In, Garbage Out' (GIGO) to **'Quality In, Virtuosity Out.'**\n\nIn the global AI race, this focus on quality provides a powerful asymmetric strategy. An AI model of moderate size, guided by a meticulously curated context, can outperform a larger, more expensive model fed 'garbage' context. This creates a defensible **'quality chokepoint.'** An adversary may possess the largest model, but if they cannot match the quality of the context, their results will remain inferior.\n\nThe DCIA is the definitive American counter-narrative to the exploitative 'ghost worker' model. It is a high-skill, high-dignity profession that 'on-shores' the most critical component of the AI supply chain: trust. By choosing to compete not on the commoditization of labor but on the professionalization of trust, the United States can secure a decisive and enduring advantage.",
              "imageGroupIds": [
                "group_the-strategic-imperative-quality-as-advantage_prompt-1"
              ]
            }
          ]
        },
        {
          "subSectionId": "from-vibecoding-to-virtuosity",
          "subSectionTitle": "From 'Vibecoding' to 'Virtuosity'",
          "pages": [
            {
              "pageId": "subsection-vibecoding-virtuosity-title",
              "pageTitle": "The 'Vibecoding to Virtuosity' Pathway: Cultivating the 100x Analyst",
              "tldr": "The V2V pathway is a structured pedagogical model, grounded in Cognitive Apprenticeship, designed to transform intuitive AI interaction ('vibecoding') into the architectural mastery required by the DCIA.",
              "content": "The cultivation of the 100x DCIA requires a new approach to training. Traditional models fail to impart the 'hidden curriculum' of *how* an expert thinks. The **'Vibecoding to Virtuosity' (V2V)** pathway provides a structured framework to bridge this gap.\n\n'Vibecoding'the intuitive use of AI to generate code from natural languageoffers unprecedented speed but introduces significant risks: the illusion of competence, technical debt, and security vulnerabilities. Unstructured vibecoding can lead to fragile, insecure systems built by developers who don't fully understand their own creations.\n\nThe V2V pathway addresses this paradox by grounding the learning process in the established principles of **Cognitive Apprenticeship**. It is a four-stage developmental model designed to systematically guide a learner from a novice prompter to an expert architect, transforming intuitive interaction into deep, resilient mastery. This is the formalized curriculum for developing the DCIA.",
              "imageGroupIds": [
                "group_subsection-vibecoding-virtuosity-title_prompt-1"
              ]
            },
            {
              "pageId": "the-pedagogical-engine-cam",
              "pageTitle": "The Pedagogical Engine: Cognitive Apprenticeship in the AI Era",
              "tldr": "Cognitive Apprenticeship (CAM) is the core pedagogical engine of the V2V pathway, designed to make the invisible 'hidden curriculum' of expert thinking visible and learnable, supercharged by AI.",
              "content": "The central challenge in training expert knowledge workers is that their most critical skillsproblem-solving heuristics, diagnostic strategies, self-correctionare internal and invisible. **Cognitive Apprenticeship (CAM)** is designed to make this 'hidden curriculum' visible and learnable by adapting traditional apprenticeship methods to cognitive skills.\n\nCAM is implemented through six core methods: **Modeling** (expert thinks aloud), **Coaching** (context-specific feedback), **Scaffolding & Fading** (gradual removal of support), **Articulation** (learner explains reasoning), **Reflection** (comparing performance to expert), and **Exploration** (autonomous problem-solving).\n\nHistorically, apprenticeship was hard to scale due to the expert's limited time. AI fundamentally breaks this constraint. AI can serve as a tireless, personalized **Coach**, provide dynamic, intelligent **Scaffolding** that adapts in real-time, and generate infinite realistic scenarios for **Modeling** and **Exploration**. This integration transforms CAM into a scalable engine for cultivating expertise.",
              "imageGroupIds": [
                "group_the-pedagogical-engine-cam_prompt-1"
              ]
            },
            {
              "pageId": "v2v-stages-1-and-2",
              "pageTitle": "Stages 1 & 2: Building the Foundation (Annotator & Toolmaker)",
              "tldr": "The pathway begins by developing critical analysis (Cognitive Annotator) and then shifts to active creation (Adaptive Toolmaker), fostering agency and practical problem-solving.",
              "content": "**Stage 1: The Cognitive Annotator (Deconstructing the Vibe).** The learner is not a 'coder' but a critical analyst. The goal is to dismantle the flawed model of AI infallibility. Activities focus on rigorous analysis: decomposing problems into precise prompts, and critically reviewing AI output for correctness, security, and style. They learn to be skeptical of the AI, identifying bugs and vulnerabilities. AI acts as a **'Scaffolded Solution Space'** providing examples for deconstruction and analysis.\n\n**Stage 2: The Adaptive Toolmaker (On-the-Fly Scaffolding).** The learner shifts from consumer to creator. The goal is to solve authentic, contextual problems by building simple tools. Activities include identifying workflow inefficiencies and building 'on-the-fly' scripts, automations, and API integrations. This fosters agency and develops skills in abstraction and systems thinking. AI acts as an **'Adaptive Component Library,'** providing functions and snippets for the learner to assemble.",
              "imageGroupIds": [
                "group_v2v-stages-1-and-2_prompt-1"
              ]
            },
            {
              "pageId": "v2v-stages-3-and-4",
              "pageTitle": "Stages 3 & 4: Achieving Mastery (Recursive Learner & Virtuoso)",
              "tldr": "The advanced stages focus on engineering one's own expertise (Recursive Learner) and culminating in fluid, intuitive mastery (Virtuoso), characterized by the apex skill of 'On-the-Fly Tooling.'",
              "content": "**Stage 3: The Recursive Learner (Building the Engine of Expertise).** The learner turns their skills inward to engineer their own expertise (a human version of Recursive Self-Improvement). Activities involve deep metacognitive analysis of learning gaps and building personalized 'Learning Accelerators' (e.g., custom tutors, specialized AI agents, targeted quiz generators) to address weaknesses. AI acts as a **'Meta-Tool'** used to build tools that enhance the learner's cognition.\n\n**Stage 4: The Virtuoso (The 100x DCIA).** The culmination of the pathway. Core principles are internalized, leading to adaptive expertise. Activities involve fluid human-AI collaboration (coding at the speed of thought), complex system architecture, governance, and mentorship. The defining apex skill is **'On-the-Fly Tooling'**: the expert improvisation of using AI as a 'foundry' to instantly create bespoke tools for novel challenges. AI acts as a **'Cognitive Exoskeleton,'** augmenting the expert's intent and reach.",
              "imageGroupIds": [
                "group_v2v-stages-3-and-4_prompt-1"
              ]
            },
            {
              "pageId": "the-v2v-framework-consolidated",
              "pageTitle": "The 'Vibecoding to Virtuosity' Framework",
              "tldr": "A consolidated matrix detailing the roles, skills, activities, and function of AI across the four stages of the developmental pathway.",
              "content": "| Stage | Learner's Role | Core Activities | Key Cognitive Skills Developed | Function of AI |\n| :---- | :---- | :---- | :---- | :---- |\n| **1. Cognitive Annotator** | A critical analyst of problems and solutions. | Decomposing problems into precise prompts; Critically reviewing AI-generated code for correctness, security, and style; Iterative refinement. | Pattern Recognition, Logical Decomposition, Attention to Detail, Bias Detection, Critical Thinking. | A \"Scaffolded Solution Space\" providing complete examples for deconstruction and analysis. |\n| **2. Adaptive Toolmaker** | A practical problem-solver and creator. | Identifying workflow inefficiencies; Building \"on-the-fly\" scripts and automations; Integrating tools with external APIs. | Abstraction, Encapsulation, System Thinking, Agency and Self-Efficacy. | An \"Adaptive Component Library\" providing functions and snippets for the learner to assemble. |\n| **3. Recursive Learner** | An engineer of one's own expertise. | Metacognitive analysis of personal learning gaps; Building personalized \"learning accelerators\" (e.g., custom tutors, quiz generators). | Advanced Metacognition, Recursive Thinking, Expertise Modeling, Self-Regulated Learning. | A \"Meta-Tool\" used to construct personalized tools that enhance the learner's own cognitive capabilities. |\n| **4. Virtuoso (DCIA)** | A master practitioner and mentor. | Fluid, intuitive human-AI collaboration; 'On-the-Fly Tooling'; Designing complex systems; Mentorship and Governance. | True Intuition (Adaptive Expertise), Strategic Foresight, Effortless Execution. | A \"Cognitive Exoskeleton\" that augments the expert's intent, speed, and reach. |",
              "imageGroupIds": [
                "group_the-v2v-framework-consolidated_prompt-1"
              ]
            },
            {
                  "pageId": "the-accelerator-deliberate-practice",
                  "pageTitle": "The Accelerator: Deliberate Practice and the AI Coach",
                  "tldr": "Progression is accelerated by Deliberate Practicefocused training at the edge of one's ability. The AI Coach is the ideal engine for implementing this rigorous practice at scale, providing personalized challenges and instant feedback.",
                  "content": "Progression through the stages is not passive. It can be dramatically accelerated by **Deliberate Practice**: highly structured training specifically designed to improve performance. The journey from Competence to Proficiency is the 'great filter' where many professionals plateau. Deliberate Practice is the mechanism for breaking through, forging the deep, pattern-based intuition of the expert.\n\nCore principles include:\n*   **Focused Goals:** Breaking complex skills into components and setting specific improvement goals.\n*   **Pushing the Comfort Zone:** Consistently attempting tasks at the edge of one's current abilities.\n*   **Immediate Feedback:** Receiving instant, informative feedback to identify errors and adjust.\n\nThe **AI Co-pilot** is the ideal engine for implementing Deliberate Practice at scale, a task traditionally too intensive for human coaches. The AI can generate infinite problems tailored to the learner's skill 'edge' and provide instant, objective feedback. The synergy is powerful: the Dreyfus model provides the *map*, Deliberate Practice provides the *vehicle*, and the AI Coach provides the *engine*.",
                  "imageGroupIds": [
                        "group_the-accelerator-deliberate-practice_prompt-1"
                  ]
            },
            {
                  "pageId": "the-apex-skill-on-the-fly-tooling",
                  "pageTitle": "The Apex Skill: On-the-Fly Tooling",
                  "tldr": "The culmination of the pathway is 'On-the-Fly Tooling'the ability to use AI not as a tool, but as a 'foundry' to create bespoke solutions in real-time. This is the definitive marker of the 100x DCIA.",
                  "content": "The culmination of the pathway is the emergence of the apex skill: **'On-the-Fly Tooling.'** This is an act of expert improvisation where the analyst transcends the role of tool user and becomes a tool creator in real-time.\n\nIt is the ability to leverage the AI's core generative capabilities as a **'foundry'** to instantly create a bespoke toola Python function, a validation script, a custom API callin the moment it is needed. The cognitive shift is profound: The competent user asks the AI, 'How do I solve problem X?' The expert *commands* the AI, 'Build me a tool that solves problem X.'\n\nThis is not a conversation; it is an act of creation. The DCIA no longer sees the AI as a fixed set of capabilities, but as a plastic, generative mediuman extension of their own analytical will. This skill, analogous to a jazz musician improvising a melody or a special forces operator adapting gear in the field, is the definitive behavioral marker of the 100x DCIA and the ultimate expression of expert-level human-AI symbiosis.",
                  "imageGroupIds": [
                        "group_the-apex-skill-on-the-fly-tooling_prompt-1"
                  ]
            }
          ]
        },
{
            "subSectionId": "mass-empowerment-uba",
            "subSectionTitle": "Mass Empowerment: Universal Basic Access (UBA)",
            "pages": [
                  {
                        "pageId": "subsection-mass-empowerment-title",
                        "pageTitle": "Mass Empowerment: The Production Divide and the UBA Imperative",
                        "tldr": "A new 'production divide'access to AI toolsthreatens American dynamism. Universal Basic Access (UBA) is the imperative to close this gap, providing the fuel for the 'Vibecoding to Virtuosity' pathway and unleashing nationwide innovation.",
                        "content": "The elite DCIA initiative secures the nation's core AI infrastructure. But to truly out-innovate a state-directed competitor, America must unleash the creative potential of its entire population. The immense computational resources required for frontier AI are concentrating power in a few corporations, creating a dangerous **'production divide'**: a gap in access to the fundamental tools of economic creation.\n\nThis concentration stifles the permissionless innovation that fuels American prosperity. The solution is **Universal Basic Access (UBA)**: a policy of mass empowerment designed to equip all citizens with the tools to become active creators, not merely passive consumers, in the new economy.\n\nTo enable the 'Vibecoding to Virtuosity' pathway at a national scale, we must provide the fuel. UBA is that fuel. It is a national security imperative, fostering a distributed and resilient innovation base that provides the most potent and uniquely American response to the strategic challenges of the AI era.",
                        "imageGroupIds": [
                              "group_subsection-mass-empowerment-title_prompt-1"
                        ]
                  },
                  {
                        "pageId": "the-ubi-fallacy-the-uba-alternative",
                        "pageTitle": "The UBI Fallacy and the UBA Alternative: Agency vs. Dependency",
                        "tldr": "Universal Basic Income (UBI) is a flawed, consumptive policy that fosters dependency. Universal Basic Access (UBA) is a productive alternative, providing access to the means of production (AI tools) to foster agency and empowerment.",
                        "content": "The debate over managing the AI transition has been dominated by Universal Basic Income (UBI)unconditional cash payments to offset job displacement. While well-intentioned, UBI is a flawed paradigm.\n\nUBI is a **consumptive policy**. It addresses the symptoms of displacement, tacitly accepting a future where many are economically superfluous, surviving on transfers. It is fiscally staggering, potentially inflationary, and risks fostering dependency, diminishing the agency and purpose derived from productive contribution.\n\n**Universal Basic Access (UBA)** represents a radical departure. It is the unconditional provision of access to the new means of production: frontier AI models and the compute required to run them. UBA is an **essential infrastructure policy**, not a welfare program. It is a 'hand-up,' not a 'hand-out.'\n\nThe distinction is philosophical. UBI manages obsolescence; UBA invests in human capital and ingenuity. It provides the foundation for millions to become Citizen Architects.\n\n| Feature | Universal Basic Income (UBI) | Universal Basic Access (UBA) |\n| :--- | :--- | :--- |\n| **Core Concept** | Unconditional Cash Payment | Unconditional Access to Productive Tools (AI Compute) |\n| **Economic Logic** | Consumptive (Stimulates Demand) | Productive (Expands Supply & Innovation) |\n| **Inflationary Impact** | High Risk (Demand-Pull Inflation) | Low Risk / Deflationary (Increases Supply) |\n| **Work Incentive** | Contested (Potential to Disincentivize Labor) | Pro-Work/Pro-Creation (Enables Entrepreneurship) |\n| **Primary Goal** | Poverty Alleviation via Income Support | Mass Empowerment via Access to Production |\n| **Citizen Role** | Recipient / Consumer | Creator / Producer / Architect |",
                        "imageGroupIds": [
                              "group_the-ubi-fallacy-the-uba-alternative_prompt-1"
                        ]
                  },
                  {
                        "pageId": "the-economics-of-empowerment",
                        "pageTitle": "The Economics of Empowerment: The Appreciating AI Credit",
                        "tldr": "AI costs are hyper-deflationary due to Wright's Law. UBA leverages this by issuing 'AI Credits'an appreciating citizen-asset whose productive power grows exponentially over time, unlike inflationary UBI cash.",
                        "content": "A central challenge for any large-scale policy is fiscal sustainability. Here, UBA presents a paradigm shift, made possible by the unique economics of AI.\n\nThe cost of AI intelligence is in freefall, a phenomenon of **hyper-deflation**. Empirical data shows costs plummeting by orders of magnitude (e.g., a 240x drop in 18 months for GPT-4 level intelligence), driven by fierce competition, efficiency gains, and the rise of smaller, smarter models.\n\nThis dynamic is governed by **Wright's Law**: costs decline by a constant percentage with every cumulative doubling of units produced. As global AI computation increases, the cost per unit of intelligence plummets exponentially.\n\nThe core mechanism of UBA is the **AI Credit**: an annual, non-transferable allotment for purchasing compute. The revolutionary nature of the AI Credit lies in its interaction with hyper-deflation. Because costs are falling rapidly, a fixed allotment buys exponentially more productive power each year. This transforms the AI Credit into an **appreciating citizen-asset**.\n\nUBI cash is eroded by inflation. The AI Credit's productive value grows at the speed of technological progress. This makes UBA uniquely sustainable; the government's cost can remain stable while the value delivered to citizens skyrockets.\n\n| The Appreciating AI Credit vs. Depreciating UBI Cash | | | | | | |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| *Assumptions:* | *3% annual inflation for UBI; 40% annual AI compute cost deflation for UBA.* | | | | | |\n| **Year** | **1** | **2** | **3** | **4** | **5** | **10** |\n| **UBI Cash Purchasing Power ($100 base)** | $100.00 | $97.00 | $94.09 | $91.27 | $88.53 | $73.74 |\n| **UBA Credit Productive Power (100 units base)** | 100 | 167 | 278 | 463 | 771 | 5,949 |",
                        "imageGroupIds": [
                              "group_the-economics-of-empowerment_prompt-1"
                        ]
                  },
                  {
                        "pageId": "a-proven-blueprint",
                        "pageTitle": "A Proven Blueprint: The 21st Century Rural Electrification Act",
                        "tldr": "UBA is the modern application of the Rural Electrification Act (REA) of 1936. The REA's success in overcoming market failure through decentralized, citizen-owned cooperatives provides the blueprint for democratizing access to AI compute.",
                        "content": "UBA is not a leap into the unknown. It is the modern application of a proven, successful, and quintessentially American policy model: the **Rural Electrification Act (REA) of 1936**. [5.13]\n\nIn the 1930s, only 11% of U.S. farms had electricity. Private utilities refused to extend lines to rural areas, citing high costs and low profitsa classic market failure. This mirrors today's AI compute divide, where large firms control the 'grid' and find it unprofitable to provide affordable, frontier-level access to the public.\n\nThe REA's response was not nationalization, but a market-catalyzing infrastructure project. It provided low-interest loans, not grants. Crucially, 90% of these loans went to **non-profit, member-owned electric cooperatives** organized by the citizens themselves.\n\nThe government acted as an enabler, providing financing and technical assistance, while the citizens built and owned the infrastructure. This decentralized, bottom-up approach was the key to its success. By 1953, over 90% of farms were electrified, unleashing decades of productivity growth with a loan default rate of less than 1%. [5.14]\n\nThe REA provides the blueprint for UBA: the most effective way to spread a transformative technology is not to impose it from above, but to give people the tools and the framework to adopt it from the ground up.",
                        "imageGroupIds": [
                              "group_a-proven-blueprint_prompt-1"
                        ]
                  },
                  {
                        "pageId": "implementation-the-cooperative-model",
                        "pageTitle": "Implementation: The Cooperative Model and Permissionless Innovation",
                        "tldr": "UBA implementation must be decentralized. A two-tier governance structureCommunity Data Trusts (CDTs) for ethical oversight and Tech Worker Cooperatives (TWCs) for operationswill ensure local accountability and unleash permissionless innovation.",
                        "content": "The implementation of UBA must avoid monolithic bureaucracy and embrace a decentralized model inspired by the REA. A two-tier governance structure separates ethical oversight from operational execution.\n\n**Tier 1: Community Data Trusts (CDTs).** Non-profit entities governed by the community. CDTs serve as the ethical conscience, responsible for data stewardship, privacy policies, and benefit sharing. They answer the 'why' and 'for whom.'\n\n**Tier 2: Tech Worker Cooperatives (TWCs).** The 21st-century equivalent of electric co-ops. Owned and controlled by their employees, TWCs handle the operations: procuring wholesale compute, maintaining local infrastructure, and providing 'last-mile' services like training and support.\n\nThis model fosters a localized market for high-road technology jobs across the country. Initial funding would come from low-interest federal loans, mirroring the REA mechanism.\n\nThis structure fosters **permissionless innovation**. The engine of the digital economy has been the freedom to build without approval from a central gatekeeper. UBA democratizes this freedom. By providing compute to all, it transforms a nation of consumers into a nation of creators, unleashing grassroots innovation far from traditional tech hubs.",
                        "imageGroupIds": [
                              "group_implementation-the-cooperative-model_prompt-1"
                        ]
                  },
                  {
                        "pageId": "the-strategic-choice",
                        "pageTitle": "The Strategic Choice: A Democratic Alternative to Digital Authoritarianism",
                        "tldr": "UBA offers a democratic, decentralized alternative to China's state-controlled AI model. By unleashing the distributed genius of the populace, UBA provides a superior asymmetric strategy for long-term geopolitical competition.",
                        "content": "The geopolitical competition of the 21st century is a contest between two models of AI development.\n\n**China's Model** is top-down, centralized, and state-controlled. Beijing directs resources to 'national champions,' aligning innovation with state priorities and leveraging AI for social control and geopolitical influence.\n\n**The American Model, enabled by UBA,** is the antithesis: bottom-up, decentralized, and democratic. Instead of concentrating resources, it distributes the fundamental assetcomputeto 330 million citizens.\n\nThis decentralized approach is inherently more adaptable, innovative, and antifragile than any centrally planned system. UBA is the superior asymmetric counter-strategy. The U.S. cannot win by imitating China's top-down system. The winning strategy must focus on supercharging the American model.\n\nUBA is a declaration of technological independence for the citizen. It positions the U.S. to win this contest by demonstrating that true strength lies not in control, but in the empowerment and freedom of the individualleveraging the distributed genius of its people.",
                        "imageGroupIds": [
                              "group_the-strategic-choice_prompt-1"
                        ]
                  }
            ]
      },
        {
          "subSectionId": "the-new-collar-compact",
          "subSectionTitle": "The New Collar Compact",
          "pages": [            
            {
              "pageId": "subsection-new-collar-compact-title",
              "pageTitle": "The New Collar Compact: A National Framework",
              "tldr": "The 'New Collar Compact' is the comprehensive national strategy unifying the DCIA and UBA initiatives. It is founded on principles of skills-first hiring, public-private partnership, equity, and a recognition of human capital as a critical national security imperative.",
              "content": "The American counter-strategy requires a unifying national commitment: **The New Collar Compact**. This is a comprehensive initiative designed to build the workforce of the AI era, secure the nation's digital supply chains, and ensure shared prosperity. It integrates the top-down security imperative of the DCIA/NSAC with the bottom-up empowerment of Universal Basic Access.\n\nThe Compact is founded on four core principles derived from historical lessons and the demands of the AI economy:\n\n1. **Skills-First, Not Degree-First:** Prioritizing verifiable, in-demand competencies over traditional academic credentials, opening pathways for a broader segment of the population.\n2. **Deep Public-Private Partnership:** Ensuring training programs are demand-driven, aligned with real-world employer needs, and lead directly to high-quality jobs.\n3. **Equity and Accessibility:** Designed from the ground up with equity as a central goal, including 'wrap-around' services (childcare, transportation) to remove barriers to participation.\n4. **A National Strategic Imperative:** Framed, funded, and executed not as a social program, but as a critical investment in national security and economic competitiveness, on par with the strategic initiatives of competitors like China.\n\nThe New Collar Compact provides the actionable framework to transition from the precarious 'ghost work' model to the high-value profession of the Citizen Architect. It is the mechanism for operationalizing the 'Vibecoding to Virtuosity' pathway at a national scale.",
              "imageGroupIds": [
                "group_subsection-new-collar-compact-title_prompt-1"
              ]
            },
            {
              "pageId": "the-trillion-dollar-billion-worker-opportunity",
              "pageTitle": "The Trillion-Dollar, Billion-Worker Opportunity",
              "tldr": "The AI economy is exploding, powered by a 'hidden workforce' potentially numbering in the hundreds of millions. This massive scale presents the central challenge: transforming this precarious labor pool into a high-skill engine of prosperity through a national 'New Collar' strategy.",
              "content": "The AI revolution is generating economic activity on a scale that defies historical precedent. The data annotation market alonethe foundational layer of the AI economyis expanding at a staggering 25-35% CAGR, projected to become a multi-trillion-dollar ecosystem. This growth is fueled by the insatiable demand for high-quality data, the essential fuel for AI models.\n\nThis immense economic engine is powered by an equally immense human workforce. Landmark research from the World Bank estimates the global online gig economy, the primary labor pool for AI data work, already comprises between 154 million and 435 million individuals. As AI adoption accelerates, projections suggest this 'hidden workforce' could expand dramatically, leading to the provocative concept of a 'Billion-Person Workforce.'\n\nThis workforce represents the largest shift in the global labor market of the 21st century. Currently, it is characterized by the 'ghost work' model analyzed in Part II: low wages, high precarity, and significant strategic risks. The central challenge facing the nation is how to transform this massive, precarious workforce into a stable, high-skill engine of prosperity and security.\n\nThe emergence of 'New Collar' jobs provides the pathway. These are roles defined not by traditional degrees, but by demonstrable, in-demand technical skills in high-growth sectors like data curation, cybersecurity, and AI management. The scale of the opportunity is immense; the majority of new jobs in the coming decade are projected to fall into this category.\n\nThe United States stands at a crossroads. We can continue the current trajectory, allowing this vast human capital to languish in digital sweatshops, creating economic stagnation and national vulnerability. Or, we can make a strategic national investment to upskill this workforce, transforming the 'ghost worker' into the 'Citizen Architect.' This requires a national mobilization on a scale not seen since World War II.",
              "imageGroupIds": [
                "group_the-trillion-dollar-billion-worker-opportunity_prompt-1"
              ]
            },
            {
              "pageId": "a-blueprint-from-history",
              "pageTitle": "A Blueprint from History: The G.I. Bill for the AI Era",
              "tldr": "The G.I. Bill provides a proven historical blueprint for navigating technological transition. Its massive investment in human capital yielded a 10x ROI and built the middle class, offering a clear, American-made formula for success in the AI era.",
              "content": "To comprehend the transformative potential of such an investment, we need only look to American history. The Servicemen's Readjustment Act of 1944the G.I. Billstands as the most successful workforce development program in the nation's history. It provides a proven blueprint for navigating the current technological transition.\n\nIn 1944, facing the return of 15 million veterans, policymakers feared mass unemployment and a return to the Depression. The G.I. Bill was a proactive investment in human capital designed to transform this crisis into an opportunity. It provided tuition support, living stipends, and loan guarantees, enabling 8 million veterans to attend college or vocational training.\n\nThe economic return was staggering. The program cost approximately $14.5 billion, but generated an estimated **ten times that amount in increased tax revenue** alone, as educated veterans earned significantly higher wages. The G.I. Bill is widely credited with fueling the post-war boom and creating the modern American middle class. It demonstrated that large-scale investments in human capital are not expenditures, but high-yield national investments.\n\nHowever, an honest appraisal must acknowledge the G.I. Bill's failure to ensure equitable implementation, as discriminatory local practices systematically excluded many Black veterans, widening the racial wealth gap. A modern initiative must learn from this history, ensuring strong federal oversight and explicit equity goals.\n\nThe historical precedent provides a clear, American-made formula for success. We must adapt this proven model to the challenges of the AI era, transforming the threat of displacement into an engine of national renewal.",
              "imageGroupIds": [
                "group_a-blueprint-from-history_prompt-1"
              ]
            },
            {
              "pageId": "pillar-1-national-certification-and-skills-infrastructure",
              "pageTitle": "Pillar 1: National Certification and Skills Infrastructure",
              "tldr": "The Compact will establish a national infrastructure for the digital workforce, featuring a tiered competency model, leveraging existing educational institutions, and emphasizing industry-driven curricula and apprenticeships to build a sustainable talent pipeline.",
              "content": "The foundation of any profession is a shared understanding of required competencies and a trusted mechanism for validating them. The Compact will establish a national infrastructure for training and certifying the new digital workforce, particularly the Data Curator and DCIA roles.\n\n**A National Competency Model:** In partnership with industry and academia, a federal body will develop and maintain a national competency model. This model will feature multiple tierse.g., Associate, Professional, and Master/Specialistto create a clear career ladder. Certification will validate skills across Technical, Analytical, and Governance/Ethical domains.\n\n**Leveraging Existing Institutions:** Rather than creating a new bureaucracy, the Compact will deliver training primarily through the nation's existing network of community colleges, vocational schools, and university extension programs. These institutions are agile, locally embedded, and experienced in delivering skills-based education.\n\n**Industry-Driven Curriculum and Apprenticeships:** Federal funding will be contingent on sectoral partnerships, where curricula are co-designed and continuously updated with industry partners. The initiative will strongly emphasize 'Earn and Learn' models, such as Registered Apprenticeships, allowing trainees to gain paid, on-the-job experience while studying.\n\nThis infrastructure ensures that the supply of newly skilled workers is met with robust demand, creating a sustainable and scalable talent pipeline aligned with the strategic needs of the nation.",
              "imageGroupIds": [
                "group_pillar-1-national-certification-and-skills-infrastructure_prompt-1"
              ]
            },
            {
              "pageId": "pillar-2-the-citizen-architect-grant",
              "pageTitle": "Pillar 2: The 'Citizen Architect' Grant",
              "tldr": "Modeled on the G.I. Bill, the 'Citizen Architect' Grant provides tuition and living stipends for certified training. This investment is designed to generate a significant economic multiplier effect and is self-financing through increased tax revenue.",
              "content": "To enable millions of Americans to participate in full-time training and utilize the tools provided by UBA, the Compact will provide direct financial support, modeled directly on the most successful elements of the G.I. Bill. This is the 'Citizen Architect' Grant.\n\n**Tuition Grants and Stipends:** Individuals accepted into a nationally certified training program (such as the V2V pathway) will receive a federal grant covering the full cost of tuition, fees, and required materials. This removes the burden of student debt for a new generation of skilled workers.\n\n**Living Allowance:** Recognizing that trainees cannot work full-time while studying, the Compact will provide a monthly living allowance. This stipend, similar to the G.I. Bill's original allowance, provides the financial stability necessary for individuals, especially those with families, to commit to reskilling.\n\n**The Economic Multiplier:** This investment is designed to generate a significant Keynesian multiplier effect. By transitioning workers into high-wage New Collar careers, the initiative increases disposable income, driving consumer demand and creating jobs across the economy.\n\n**Self-Financing Investment:** The program will be funded through direct federal appropriation, justified as a national security and economic development investment. As demonstrated by the G.I. Bill's 10-to-1 return, this investment is designed to be self-financing over the long term through the increased tax revenue generated by a higher-earning workforce.",
              "imageGroupIds": [
                "group_pillar-2-the-citizen-architect-grant_prompt-1"
              ]
            },
            {
              "pageId": "a-uniquely-american-solution",
              "pageTitle": "A Uniquely American Solution",
              "tldr": "The New Collar Compact rejects the false choice between authoritarian control and exploitative markets. It leverages strategic public investment to empower citizens, ensuring the U.S. can out-compete any rival by being both more secure at its core and more innovative at its edges.",
              "content": "The New Collar Compact represents a uniquely American solution to a global challenge. It rejects the false choice between China's authoritarian, state-controlled model and the West's current unfettered, exploitative market logic.\n\nInstead, it leverages strategic public investment to empower private citizens and secure the public good. It operationalizes the core American belief that the strength of the nation lies in the ingenuity and empowerment of the individual.\n\nIt is a whole-of-nation strategy that ensures the United States can out-compete any rival by being simultaneously more secure at its core (through the professionalized DCIA cadre) and more dynamically innovative at its edges (through the mass empowerment of UBA).\n\nBy investing in our own cognitive capital, we build a future where technology serves humanity, where opportunity is broadly accessible, and where the nation's strategic posture is resilient and enduring.",
              "imageGroupIds": [
                "group_a-uniquely-american-solution_prompt-1"
              ]
            }
          ]
        }
      ]
    },
    {
      "sectionId": "conclusion-rise-to-meet-the-machine",
      "sectionTitle": "Conclusion: Rise to Meet the Machine",
      "pages": [
        {
          "pageId": "conclusion-title",
          "pageTitle": "Conclusion: Rise to Meet the Machine",
          "tldr": "This report concludes with a synthesis of the crisis and the solution. The game is the proof of a new paradigm; the analysis provides the urgent context. The forces reshaping our world demand a transformation in our national strategy.",
          "content": "This report began with an artifact: the game in your hands. It serves as the proof that a new paradigm of creationthe 100x productivity of the Citizen Architectis a present reality. The analysis that followed detailed the urgent context for this transformation: a global AI ecosystem built on a brittle foundation of exploitation, a coherent strategic competitor capitalizing on our vulnerabilities, and the imperative of securing the cognitive domain.\n\nThe entire analysis converges on a single, fundamental decision point for our society. The forces reshaping our worldthe rise of artificial intelligence, the restructuring of the global labor market, and the intensification of geopolitical competitiondemand a commensurate transformation in our national strategy.\n\nWe have detailed the path forward: the professionalization of the 100x Data Curator, the creation of the elite DCIA cadre, the mass empowerment of Universal Basic Access, unified under the New Collar Compact. This is the American counter-strategy.",
          "imageGroupIds": [
            "group_conclusion-title_prompt-1"
          ]
        },
        {
          "pageId": "the-choice",
          "pageTitle": "The Choice: Ghost or Architect",
          "tldr": "The current system asks people to be disposable 'ghosts,' a path to stagnation and vulnerability. The alternative is to rise to meet the machineto become 'Citizen Architects,' the empowered collaborators of our intelligent systems and the engine of national renewal.",
          "content": "The current system, optimized for short-term efficiency and liability evasion, asks people to be invisible, interchangeable, and disposable cogs in a vast machine. It asks them to be **ghosts**, haunting the data centers and digital supply chains that power our world, their cognitive vitality drained in exchange for a poverty wage.\n\nThis path leads to brittle technology, a vulnerable nation, and a squandered human potential. It is a path of stagnation and strategic decay, characterized by a scarcity mindset and a widening cognitive capital gap. It is a dead end.\n\nThe alternative is to **rise up to meet the machine**. This is the path of the **Citizen Architect**. It is a path that rejects the notion that human beings are a cost to be minimized and instead re-imagines them as the source of all valuethe architects, the curators, the guardians, and the strategic collaborators of our intelligent systems. It is a path of abundance, empowerment, and national renewal.",
          "imageGroupIds": [
            "group_the-choice_prompt-1"
          ]
        },
        {
          "pageId": "the-intersection-of-progress",
          "pageTitle": "The Intersection of Progress",
          "tldr": "The exponential improvement of AI is a descending line, while human skill is an ascending one. The intersection point is the moment of 100x transformation. The V2V pathway is the mechanism to raise the human line and accelerate that intersection.",
          "content": "The exponential improvement of artificial intelligence can be visualized as a descending line on a graph, representing the ever-decreasing cost and ever-increasing capability of the technology. A human's technological knowledge and skill is an ascending line.\n\nThe point where these two lines intersect is the moment of transformationthe point at which an individual, armed with AI, becomes a 100x force multiplier, capable of achieving what was once the exclusive domain of large organizations.\n\nThe 'Vibecoding to Virtuosity' pathway is the mechanism for raising that human line. The more a person learns, the faster their line rises. The sooner their line rises, the sooner that intersection happens, and the greater the productive power they unlock.",
          "imageGroupIds": [
            "group_the-intersection-of-progress_prompt-1"
          ]
        },
        {
          "pageId": "a-national-project-of-ascent",
          "pageTitle": "A National Project of Ascent",
          "tldr": "The American counter-strategy is a national project to accelerate the 100x transformation for the entire population, rooted in the understanding that our greatest strategic asset is the collective cognitive capital of the American people.",
          "content": "The American counter-strategy proposed in this report is a national project to help every single citizen raise their line. It is a strategy to accelerate that moment of intersection for an entire population.\n\nIt is a strategy rooted in the understanding that in the 21st-century technology competition, the nation that invests in the cognitive security, economic stability, and professional dignity of its people will build the most resilient, innovative, and powerful AI ecosystem.\n\nIt is a strategy that recognizes that our greatest strategic asset is not silicon or algorithms, but the collective cognitive capital of the American people.",
          "imageGroupIds": [
            "group_a-national-project-of-ascent_prompt-1"
          ]
        },
        {
          "pageId": "a-call-to-action-start-your-ascent",
          "pageTitle": "A Call to Action: Start Your Ascent",
          "tldr": "This report is a call to action. The game is a training ground. The skills you acquire are the tools needed to build a better future. The future is unwritten. It is time to build. The choice is yours: be a ghost, or be an architect.",
          "content": "This report is therefore a call to action. The game you are playing is not just a game. It is the proof that this ascent is possible. It is a training ground for the skills that matter now.\n\nThe choice is yours. Start your own journey from vibecoding to virtuosity. Find a project that matters to you. Ask AI to help you build it. Fail, learn, debug, and build again.\n\nThe skills you acquire are not just for a game; they are the tools needed to build a better, more prosperous, and more secure future for yourself, your community, and your country. The future is unwritten. It is time to build.\n\nThe choice is yours: be a ghost, or be an architect.",
          "imageGroupIds": [
            "group_a-call-to-action-start-your-ascent_prompt-1"
          ]
        }
      ]
    },
    {
      "sectionId": "end-matter",
      "sectionTitle": "End Matter",
      "pages": [
        {
          "pageId": "end-page",
          "pageTitle": "End of Report",
          "tldr": "Thank you for exploring The Ascent Report. The future is unwritten. It is time to build.",
          "content": "You have reached the end of the report. The analysis presented here is a diagnosis of a critical challenge and a proposal for a hopeful path forward. The choice between being a ghost in the machine or an architect of the future is now yours.",
          "imageGroupIds": [
            "group_end-page_prompt-1"
          ]
        }
      ]
    }
  ]
}
</file_artifact>

<file path="src/Artifacts/A113. AI Ascent Dev - Universal Task Checklist.md">
# Artifact A113: AI Ascent Dev - Universal Task Checklist
# Date Created: C117
# Author: AI Model & Curator

## 1. Purpose

This artifact provides a structured checklist for the initial development tasks for the new `aiascent.dev` website project. It organizes the work required to set up the project shell, port over relevant components, and build the core features like the interactive whitepaper.

## Task List for `aiascent.dev` - Phase 1

## T-1: Project Setup and Scaffolding
- **Files Involved:**
    - `package.json`
    - `.gitignore`
    - Next.js project structure (from `automationsaas` shell)
    - `src/Artifacts/` (All newly generated `aiascent-dev-A*.md` files)
- **Total Tokens:** ~5,000
- **More than one cycle?** No
- **Status:** To Do

- [ ] **Task (T-ID: 1.1):** Initialize the `aiascent-dev` project folder.
- [ ] **Task (T-ID: 1.2):** Copy the shell of the `automationsaas` project into the new directory.
- [ ] **Task (T-ID: 1.3):** Initialize a Git repository and create the first commit, following the `A9. GitHub Repository Setup Guide`.
- [ ] **Task (T-ID: 1.4):** Create the `src/Artifacts` directory and place all the `aiascent-dev-A*.md` planning documents inside it.
- [ ] **Task (T-ID: 1.5):** Clean out any `automationsaas`-specific logic, leaving only the Next.js/React/TailwindCSS shell.

### Verification Steps
1.  Run `npm install` and `npm run dev` in the new project directory.
2.  **Expected:** A blank or minimal starter page should be viewable at `http://localhost:3000`. The project should have no compilation errors.

## T-2: Port and Adapt Report Viewer
- **Files Involved:**
    - `aiascent.game/src/components/ReportViewer.tsx` (and its dependencies)
    - `aiascent-dev/src/components/InteractiveWhitepaper.tsx` (New)
    - `aiascent-dev/src/pages/whitepaper.tsx` (New)
- **Total Tokens:** ~10,000+ (depending on dependencies)
- **More than one cycle?** Yes
- **Status:** To Do

- [ ] **Task (T-ID: 2.1):** Analyze the `ReportViewer` component from `aiascent.game` and identify all its child components and dependencies.
- [ ] **Task (T-ID: 2.2):** Copy the component and its dependencies into the `aiascent-dev` project.
- [ ] **Task (T-ID: 2.3):** Refactor the copied components to remove any `aiascent.game`-specific logic, styling, or state management. Rename `ReportViewer` to `InteractiveWhitepaper`.
- [ ] **Task (T-ID: 2.4):** Create a new page at `/whitepaper` that renders the `InteractiveWhitepaper` component.
- [ ] **Task (T-ID: 2.5):** Adapt the component to load its content from a local JSON file (e.g., the content from `A78. DCE - Whitepaper - Process as Asset.md`).

### Verification Steps
1.  Navigate to `/whitepaper` in the browser.
2.  **Expected:** The interactive report viewer should render, displaying the content of the DCE whitepaper, complete with page navigation and section breakdowns.

## T-3: Build Main Website Shell
- **Files Involved:**
    - `aiascent-dev/src/pages/index.tsx`
    - `aiascent-dev/src/components/Header.tsx`
    - `aiascent-dev/src/components/Footer.tsx`
- **Total Tokens:** ~3,000
- **More than one cycle?** No
- **Status:** To Do

- [ ] **Task (T-ID: 3.1):** Design and implement the main landing page (`index.tsx`).
- [ ] **Task (T-ID: 3.2):** Create a reusable `Header` component with navigation links (e.g., Home, Whitepaper, Tutorials, GitHub).
- [ ] **Task (T-ID: 3.3):** Create a reusable `Footer` component.

### Verification Steps
1.  View the home page in the browser.
2.  **Expected:** A professional-looking landing page is displayed with a functional header and footer.

## T-4: Plan for Next Cycle
- **Files Involved:**
    - `src/Artifacts/A113. AI Ascent Dev - Universal Task Checklist.md`
- **Total Tokens:** ~1,000
- **More than one cycle?** No
- **Status:** To Do

- [ ] **Task (T-ID: 4.1):** Update this checklist based on the progress made and create a new checklist for the next phase of development (e.g., creating tutorial content).
</file_artifact>

<file path="src/Artifacts/A114. AI Ascent - Dual Domain Hosting Guide.md">
# Artifact A114: AI Ascent - Dual Domain Hosting Guide
# Date Created: C117
# Author: AI Model & Curator

- **Key/Value for A0:**
- **Description:** A guide explaining how to host multiple domains (e.g., `aiascent.game` and `aiascent.dev`) on a single server using a reverse proxy like Caddy.
- **Tags:** guide, networking, hosting, reverse proxy, caddy, dns

## 1. Overview & Goal

You have asked if it's possible to host both `aiascent.game` and the new `aiascent.dev` on the same server that is currently hosting the game and the vLLM instance. The answer is **yes**, and this is a standard and efficient way to manage multiple websites on a single machine.

The goal of this guide is to explain the technical concept of a **reverse proxy** and provide a concrete example of how to configure it using Caddy, which you are already using.

## 2. The Core Concept: Reverse Proxy with Virtual Hosts

The magic that makes this work is a **reverse proxy** that uses **virtual hosts**. Here's how the pieces fit together:

1.  **DNS Records:** You will configure the DNS "A" records for both `aiascent.game` and `aiascent.dev` to point to the **same public IP address**the one for your home server.

2.  **Port Forwarding:** Your AT&T router will continue to forward all web traffic (ports 80 for HTTP and 443 for HTTPS) to the single PC in your closet that acts as the server.

3.  **The Reverse Proxy (Caddy):** This is the traffic controller. Caddy will be the only process listening on ports 80 and 443. When a request comes in, Caddy inspects the `Host` header to see which domain the user was trying to reach.
    *   If the `Host` is `aiascent.game`, Caddy forwards the request to the Node.js process running your game.
    *   If the `Host` is `aiascent.dev`, Caddy forwards the request to the *different* Node.js process running your new website.

4.  **Backend Applications:** Each of your applications (the game server, the new website server) will run on its own, separate, internal-only port (e.g., 3001 for the game, 3002 for the new website). They don't need to know anything about HTTPS or the public domains.

This architecture is secure, efficient, and makes adding more websites in the future very simple.

## 3. Example Caddyfile Configuration

Your existing `Caddyfile` (from `A91`) is already set up to handle `aiascent.game`. To add the new `aiascent.dev` site, you simply need to add another block to the file.

Let's assume:
*   Your `aiascent.game` Node.js server runs on `localhost:3001`.
*   Your new `aiascent-dev` Next.js server will run on `localhost:3002`.

Your new `Caddyfile` would look like this:

```caddy
# Caddyfile for dual domain hosting

aiascent.game {
    # Caddy will automatically handle HTTPS for this domain.
    encode zstd gzip
    log {
        output file /var/log/caddy/aiascent_game.log
    }

    # Reverse proxy all requests for aiascent.game to the game server on port 3001.
    reverse_proxy localhost:3001 {
        header_up Host {host}
        header_up X-Real-IP {remote_ip}
        header_up X-Forwarded-For {remote_ip}
        header_up X-Forwarded-Proto {scheme}
        header_up Connection {>Connection}
        header_up Upgrade {>Upgrade}
    }
}

aiascent.dev {
    # Caddy will automatically handle HTTPS for this domain as well.
    encode zstd gzip
    log {
        output file /var/log/caddy/aiascent_dev.log
    }

    # Reverse proxy all requests for aiascent.dev to the new website server on port 3002.
    reverse_proxy localhost:3002
}

# Optional: Redirect www versions to the main domains
www.aiascent.game {
    redir https://aiascent.game{uri} permanent
}
www.aiascent.dev {
    redir https://aiascent.dev{uri} permanent
}
```

### 4. Action Steps

1.  **DNS:** Point the `aiascent.dev` A record to your server's public IP address.
2.  **Application Ports:** Ensure your two applications are configured to run on different ports (e.g., 3001 and 3002).
3.  **Caddyfile:** Update your `Caddyfile` with the new block for `aiascent.dev`.
4.  **Reload Caddy:** Run `caddy reload` in your server's terminal to apply the new configuration.

Caddy will automatically obtain the SSL certificate for `aiascent.dev` and begin routing traffic to the correct application based on the domain name.
</file_artifact>

<file path="src/Artifacts/A115. DCE - Porting Guide for aiascent.dev.md">
# Artifact A115: DCE - Porting Guide for aiascent.dev
# Date Created: C117
# Author: AI Model & Curator

- **Key/Value for A0:**
- **Description:** A list of recommended documentation artifacts to port from the DCE project to the new `aiascent.dev` project to bootstrap its development process.
- **Tags:** guide, documentation, project setup, aiascent-dev

## 1. Overview

To effectively bootstrap the `aiascent.dev` project using the Data Curation Environment (DCE), it is highly recommended to port over a set of existing documentation artifacts from the DCE project itself. These artifacts codify the development process, workflow, and interaction patterns that will be essential for building the new website.

This guide lists the specific artifacts you should copy from your main `DCE/src/Artifacts` directory into the `aiascent-dev/context/dce/` directory.

## 2. Recommended Artifacts to Port

The following artifacts provide the "source of truth" for the DCE-driven development process. They will be invaluable as context when prompting the AI to build the `aiascent.dev` website.

### Core Process & Workflow
*   **`A0. DCE Master Artifact List.md`**: Provides the structure and concept of the master list.
*   **`A9. DCE - GitHub Repository Setup Guide.md`**: Essential for initializing the new project's version control.
*   **`A65. DCE - Universal Task Checklist.md`**: The template and philosophy for organizing work in cycles.
*   **`A69. DCE - Animated UI Workflow Guide.md`**: Documents the "perfect loop" of the DCE workflow, which is a key concept to showcase and teach.
*   **`A70. DCE - Git-Integrated Testing Workflow Plan.md`**: The baseline/restore workflow is a core feature of the development process that should be used for the new project.
*   **`A72. DCE - README for Artifacts.md`**: Explains the purpose of the artifacts directory to both the user and the AI.

### Interaction & Parsing
*   **`A52.1 DCE - Parser Logic and AI Guidance.md`**: Provides the AI with the literal parser code, enabling metainterpretability.
*   **`A52.2 DCE - Interaction Schema Source.md`**: The canonical rules for how the AI should structure its responses to be parsed correctly by the DCE.

### Content & Showcase
*   **`A77. DCE - Whitepaper Generation Plan.md`**: The original plan for generating the whitepaper.
*   **`A78. DCE - Whitepaper - Process as Asset.md`**: The full content of the whitepaper that you intend to display in the interactive report viewer.
*   **`reportContent.json`**: The structured JSON data from `aiascent.game`'s report viewer, which can be used as the data source for the new `InteractiveWhitepaper` component.

### 3. Procedure

1.  Navigate to your `C:\Projects\DCE\src\Artifacts` directory.
2.  Copy the files listed above.
3.  Paste them into the `C:\Projects\aiascent-dev\context\dce\` directory.
4.  You can now use these files as part of the context when generating prompts for the `aiascent.dev` project within the DCE.
</file_artifact>

<file path="src/Artifacts/aiascent-dev-A0-Master-Artifact-List.md">
# Artifact A0: aiascent.dev - Master Artifact List
# Date Created: C0
# Author: AI Model & Curator

## 1. Purpose

This file serves as the definitive, parseable list of all documentation artifacts for the `aiascent.dev` website project. This project aims to create a promotional website for the Data Curation Environment (DCE) VS Code Extension, featuring an interactive whitepaper as a primary showcase.

## 2. Formatting Rules for Parsing

*   Lines beginning with `#` are comments and are ignored.
*   `##` denotes a major category header and is ignored.
*   `###` denotes an artifact entry. The text following it is the artifact's full name and ID.
*   Lines beginning with `- **Description:**` provide context for the project.
*   Lines beginning with `- **Tags:**` provide keywords for Inference.

## 3. Artifacts List

## I. Project Planning & Design

### A1. aiascent.dev - Project Vision and Goals
- **Description:** High-level overview of the `aiascent.dev` website, its purpose to promote the DCE, and the phased development plan.
- **Tags:** project vision, goals, scope, dce, whitepaper, promotional website

### A2. aiascent.dev - Phase 1 - Requirements & Design
- **Description:** Detailed functional and technical requirements for Phase 1, focusing on building the static site shell and porting the interactive report viewer.
- **Tags:** requirements, design, phase 1, report viewer, nextjs

### A3. aiascent.dev - Technical Scaffolding Plan
- **Description:** Outlines the proposed file structure and technologies, leveraging the `automationsaas` project shell and components from `aiascent.game`.
- **Tags:** technical plan, scaffolding, file structure, nextjs, react, tailwindcss

### A7. aiascent.dev - Development and Testing Guide
- **Description:** A step-by-step guide explaining how to run, debug, and test the `aiascent.dev` website locally.
- **Tags:** development, testing, debugging, workflow, nextjs

### A9. aiascent.dev - GitHub Repository Setup Guide
- **Description:** A step-by-step guide with the necessary git commands to initialize the project as a local repository and push it to a new remote repository on GitHub.
- **Tags:** git, github, version control, setup, repository
</file_artifact>

<file path="src/Artifacts/aiascent-dev-A1-Project-Vision-and-Goals.md">
# Artifact A1: aiascent.dev - Project Vision and Goals
# Date Created: C0
# Author: AI Model & Curator

- **Key/Value for A0:**
- **Description:** High-level overview of the `aiascent.dev` website, its purpose to promote the DCE, and the phased development plan.
- **Tags:** project vision, goals, scope, dce, whitepaper, promotional website

## 1. Project Vision

The vision of **aiascent.dev** is to create a professional and engaging promotional website for the **Data Curation Environment (DCE) VS Code Extension**. The website will serve as the primary public-facing hub for the DCE project, explaining its value proposition and demonstrating its power. It aims to be more than a static landing page; it will be a living testament to the capabilities of the DCE by showcasing complex, interactive components that were themselves built using the extension.

## 2. High-Level Goals & Phases

The project will be developed in distinct phases to ensure an iterative and manageable workflow.

### Phase 1: Core Website and Interactive Whitepaper

The goal of this phase is to establish the foundational website and deliver the primary showcase content.
-   **Core Functionality:**
    -   Build a static website shell based on the `automationsaas` project, including a landing page, header, and footer.
    -   Port the "Report Viewer" component from `aiascent.game` and refactor it into a reusable "Interactive Whitepaper" component.
    -   Integrate the content of the DCE whitepaper (`A78`) into the interactive viewer.
-   **Outcome:** A functional website at `aiascent.dev` where visitors can learn about the DCE and explore the full interactive whitepaper, demonstrating a key product built with the tool.

### Phase 2: Vibe Coding Tutorials and Blog

This phase will build upon the foundation by adding educational content to foster a community and teach the "vibe coding" methodology.
-   **Core Functionality:**
    -   Create a new section on the website for tutorials.
    -   Develop the first set of interactive tutorials explaining the "Vibecoding to Virtuosity" pathway.
    -   Implement a simple blog or articles section for development updates and conceptual deep-dives.
-   **Outcome:** The website becomes an educational resource for users wanting to master AI-assisted development with the DCE.

### Phase 3: Community and Integration Features

This phase focuses on community building and deeper integration with the DCE ecosystem.
-   **Core Functionality:**
    -   Potentially add a community forum or Discord integration.
    -   Explore features like a showcase of projects built with the DCE.
    -   Provide direct download links for the DCE extension's `.vsix` file.
-   **Outcome:** `aiascent.dev` becomes the central community hub for the Data Curation Environment project.
</file_artifact>

<file path="src/Artifacts/aiascent-dev-A2-Phase1-Requirements.md">
# Artifact A2: aiascent.dev - Phase 1 Requirements & Design
# Date Created: C0
# Author: AI Model & Curator

- **Key/Value for A0:**
- **Description:** Detailed functional and technical requirements for Phase 1, focusing on building the static site shell and porting the interactive report viewer.
- **Tags:** requirements, design, phase 1, report viewer, nextjs

## 1. Overview

This document outlines the detailed requirements for Phase 1 of the `aiascent.dev` project. The primary goal of this phase is to launch the core website and implement the interactive whitepaper showcase.

## 2. Functional Requirements

| ID | Requirement | User Story | Acceptance Criteria |
|---|---|---|---|
| FR-01 | **Static Website Shell** | As a visitor, I want to land on a professional homepage that explains what the DCE is, so that I can quickly understand its purpose. | - The website has a main landing page (`/`). <br> - A persistent header provides navigation to "Home" and "Whitepaper". <br> - A persistent footer contains standard links (e.g., GitHub). |
| FR-02 | **Interactive Whitepaper** | As a visitor, I want to navigate to an interactive whitepaper, so that I can read the "Process as Asset" report in an engaging way. | - A page exists at `/whitepaper`. <br> - This page renders the "Interactive Whitepaper" component. <br> - The component loads its content from a structured JSON file. <br> - Users can navigate between pages and sections of the report. |
| FR-03 | **Content Integration** | As a project owner, I want the content of the DCE whitepaper to be displayed in the interactive viewer. | - The textual and structural content from `A78. DCE - Whitepaper - Process as Asset.md` is converted into the JSON format required by the viewer component. |

## 3. Non-Functional Requirements

| ID | Requirement | Description |
|---|---|---|
| NFR-01 | **Performance** | The website should load quickly and be responsive. It will be a statically generated site. |
| NFR-02 | **Reusability** | The "Interactive Whitepaper" component should be designed to be reusable for future reports or tutorials. |

## 4. High-Level Design

-   **Framework:** The project will use the Next.js/React framework from the `automationsaas` shell.
-   **Component Porting:** The `ReportViewer` component and its dependencies will be copied from the `aiascent.game` project. It will be refactored to remove game-specific styling and state, and renamed to `InteractiveWhitepaper`.
-   **Data Source:** The `InteractiveWhitepaper` component will be modified to fetch its data from a local JSON file (`src/data/whitepaperContent.json`), which will be a structured version of the content from the DCE artifacts.
</file_artifact>

<file path="src/Artifacts/aiascent-dev-A3-Technical-Scaffolding-Plan.md">
# Artifact A3: aiascent.dev - Technical Scaffolding Plan
# Date Created: C0
# Author: AI Model & Curator

- **Key/Value for A0:**
- **Description:** Outlines the proposed technical scaffolding and file structure, leveraging the `automationsaas` project shell and components from `aiascent.game`.
- **Tags:** technical plan, scaffolding, file structure, nextjs, react, tailwindcss

## 1. Overview

This document outlines the proposed technical scaffolding and file structure for the `aiascent.dev` project. This plan leverages existing assets to accelerate development, ensuring a clean and scalable architecture from the start.

## 2. Technology Stack

-   **Language:** TypeScript
-   **Framework:** Next.js (from `automationsaas` shell)
-   **UI Library:** React (from `automationsaas` shell)
-   **Styling:** TailwindCSS (from `automationsaas` shell)
-   **Deployment:** The project will be deployed as a static site, hosted on the existing server infrastructure and managed by Caddy.

## 3. Proposed File Structure

The project will start with the file structure from the `automationsaas` project and will be adapted as follows:

```
aiascent-dev/
 src/
    components/
       layout/
          Header.tsx
          Footer.tsx
       whitepaper/
           InteractiveWhitepaper.tsx  # Ported & refactored from aiascent.game
           PageContent.tsx            # Dependency of the viewer
   
    pages/
       _app.tsx
       index.tsx                  # The main landing page
       whitepaper.tsx             # Page to host the interactive whitepaper
   
    styles/
       globals.css
   
    data/
        whitepaperContent.json     # Data source for the whitepaper

 public/
    ... (images, fonts)

 package.json
 tsconfig.json
 ... (Next.js config files)
```

## 4. Key Architectural Concepts

-   **Leverage Existing Assets:** The core strategy is to reuse and adapt existing, proven components and project structures to accelerate development.
    -   The Next.js/React/TailwindCSS foundation from `automationsaas` provides a modern and efficient web development stack.
    -   The `ReportViewer` from `aiascent.game` provides the complex logic for the interactive document experience.
-   **Component-Based Architecture:** The UI will be built by composing reusable React components.
-   **Static Site Generation (SSG):** Next.js will be used to generate a static site, ensuring maximum performance and security.
-   **Data Decoupling:** The content for the whitepaper will be stored in a separate JSON file, decoupling the data from the presentation layer and making it easy to update or add new reports in the future.
</file_artifact>

<file path="src/Artifacts/aiascent-dev-A7-Development-and-Testing-Guide.md">
# Artifact A7: aiascent.dev - Development and Testing Guide
# Date Created: C0
# Author: AI Model & Curator

- **Key/Value for A0:**
- **Description:** A step-by-step guide explaining how to run, debug, and test the `aiascent.dev` website locally.
- **Tags:** template, cycle 0, documentation, project setup, nextjs

## 1. Purpose

This guide provides the standard procedure for running, debugging, and testing the **aiascent.dev** website locally.

## 2. Development Workflow

### Step 1: Install Dependencies

Ensure all project dependencies are installed using npm. Navigate to the project root (`C:\Projects\aiascent-dev`) in your terminal and run:
```bash
npm install
```

### Step 2: Start the Development Server

To compile the code and watch for changes with hot-reloading, run the following command:
```bash
npm run dev
```
This will start the Next.js development server.

### Step 3: Running the Application

Once the development server is running, you will see a message in your terminal, typically:
```
- ready started server on 0.0.0.0:3000, url: http://localhost:3000
```
Open a web browser and navigate to **`http://localhost:3000`** to view the application.

### Step 4: Debugging

You can use the browser's developer tools to debug the frontend application. You can set breakpoints directly in your source code within the "Sources" tab of the developer tools.

## 3. Testing

The project will be configured with a testing framework (e.g., Jest and React Testing Library). To run the test suite, use the following command:
```bash
npm run test
```
This will execute all test files located in the project and report the results to the console.
</file_artifact>

<file path="src/Artifacts/aiascent-dev-A9-GitHub-Repository-Setup-Guide.md">
# Artifact A9: aiascent.dev - GitHub Repository Setup Guide
# Date Created: C0
# Author: AI Model & Curator

- **Key/Value for A0:**
- **Description:** A step-by-step guide with the necessary git commands to initialize the project as a local repository and push it to a new remote repository on GitHub.
- **Tags:** git, github, version control, setup, repository, workflow

## 1. Overview

This guide provides the necessary commands to turn your local `aiascent-dev` project folder into a Git repository and link it to a new, empty repository on GitHub.

## 2. Prerequisites

*   You have `git` installed on your machine.
*   You have a GitHub account.

## 3. Step-by-Step Setup

### Step 1: Create a New Repository on GitHub

1.  Go to [github.com](https://github.com) and log in.
2.  In the top-right corner, click the `+` icon and select **"New repository"**.
3.  **Repository name:** `aiascent-dev`.
4.  **Description:** "Promotional and educational website for the Data Curation Environment (DCE) VS Code Extension."
5.  Choose **"Private"** or **"Public"**.
6.  **IMPORTANT:** Do **not** initialize the repository with a `README`, `.gitignore`, or `license`. We will be pushing our existing files.
7.  Click **"Create repository"**.

GitHub will now show you a page with command-line instructions. We will use the section titled **"...or push an existing repository from the command line"**.

### Step 2: Initialize Git in Your Local Project

Open a terminal and navigate to your project's root directory (`C:\Projects\aiascent-dev`). Then, run the following commands one by one.

1.  **Initialize the repository:**
    ```bash
    git init
    ```

2.  **Add all existing files:**
    ```bash
    git add .
    ```

3.  **Create the first commit:**
    ```bash
    git commit -m "Initial commit: Project setup and Cycle 0 artifacts"
    ```

4.  **Rename the default branch to `main`:**
    ```bash
    git branch -M main
    ```

### Step 3: Link and Push to GitHub

1.  **Add the remote repository:** Replace the placeholder URL with the one from your new GitHub repository page.
    ```bash
    git remote add origin https://github.com/YOUR_USERNAME/aiascent-dev.git
    ```

2.  **Push your local `main` branch to GitHub:**
    ```bash
    git push -u origin main
    ```

Your new project is now set up with version control and linked to GitHub. You can now use the DCE's Git-integrated features like "Baseline" and "Restore" as you develop the website.
</file_artifact>

<file path="src/Artifacts/A117. DCE - FAQ for aiascent.dev Knowledge Base.md">
# Artifact A117: DCE - FAQ for aiascent.dev Knowledge Base
# Date Created: C118
# Author: AI Model & Curator

- **Key/Value for A0:**
- **Description:** A comprehensive, consolidated Frequently Asked Questions (FAQ) document to serve as the primary knowledge base for the `aiascent.dev` website's RAG chatbot, Ascentia.
- **Tags:** documentation, faq, knowledge base, rag, user guide

## 1. Purpose

This document provides a comprehensive list of frequently asked questions about the Data Curation Environment (DCE). It is intended to be the primary source of information for new and existing users, and will be used to create an embedding for the AI-powered chatbot on the `aiascent.dev` website.

---

## **I. General & Philosophy**

### **Q: What is the Data Curation Environment (DCE)?**

**A:** The Data Curation Environment (DCE) is a VS Code extension designed to streamline and enhance the workflow of AI-assisted development. It provides an integrated toolset for selecting, managing, and packaging the context (code files, documents, etc.) you provide to Large Language Models (LLMs), and for managing the multiple responses you get back. Its primary goal is to solve the "context problem" by automating the tedious and error-prone process of manually preparing prompts for an AI.

### **Q: What problem does DCE solve?**

**A:** DCE solves two main problems:
1.  **Context Management:** Manually copying and pasting files, tracking which files you've included, and managing the size of your prompt is cumbersome. DCE automates this with a user-friendly interface.
2.  **Single-Threaded Interaction:** Standard AI chats are linear. DCE's "Parallel Co-Pilot Panel" allows you to manage, compare, and test multiple, parallel AI responses to the same prompt, dramatically speeding up the iterative process of finding the best solution.

### **Q: Who is DCE for?**

**A:** DCE is for any developer, project manager, researcher, or "Citizen Architect" who uses LLMs as part of their workflow. It's particularly powerful for those working on complex, multi-file projects who want a more structured, efficient, and auditable process for collaborating with AI.

### **Q: Is DCE free? Do I need an API key?**

**A:** Yes, the DCE extension is free. The default "Manual Mode" does not require any API keys. It's a "bring your own AI" workflow where DCE helps you generate a `prompt.md` file, which you can then copy and paste into any AI service you prefer, including free services like Google's AI Studio. This allows you to leverage powerful models without incurring API costs.

### **Q: What is the "Process as Asset" philosophy?**

**A:** This is the core idea that the *process* of developing with AIthe curated context, the prompts, the multiple AI responses, and the developer's final choiceis itself a valuable, auditable, and reusable asset. DCE is built to capture this process in a structured way through its "Cycle" system, creating a persistent knowledge graph of your project's evolution.

### **Q: What is "Vibecoding"?**

**A:** "Vibecoding" is a term for the intuitive, conversational, and iterative process of collaborating with an AI to create something new. It starts with a high-level goal or "vibe" and progressively refines it into a functional product through a human-machine partnership. DCE is the professional toolset for serious vibecoding.

---

## **II. Installation & Setup**

### **Q: How do I install the DCE extension?**

**A:** The DCE is not currently available on the VS Code Marketplace. It is distributed as a `.vsix` file from the `aiascent.dev` website. To install it, follow these steps:
1.  Download the `.vsix` file.
2.  Open VS Code and go to the **Extensions** view in the Activity Bar (or press `Ctrl+Shift+X`).
3.  Click the **...** (More Actions) button at the top-right of the Extensions view.
4.  Select **"Install from VSIX..."** from the dropdown menu.
5.  In the file dialog that opens, navigate to and select the `.vsix` file you downloaded.
6.  VS Code will install the extension and prompt you to reload the window.

### **Q: What are the prerequisites?**

**A:** You need to have Visual Studio Code and `git` installed on your machine. The extension works best when your project is a Git repository, as this enables the powerful "Baseline" and "Restore" features for safe code testing.

### **Q: How do I start a new project with DCE?**

**A:** Simply open a new, empty folder in VS Code. The DCE panel will automatically open to an "Onboarding" view. Describe your project's goal in the "Project Scope" text area and click "Generate Initial Artifacts Prompt." This will create a `prompt.md` file and a starter set of planning documents (called "Artifacts") to bootstrap your project.

### **Q: Why does DCE create documentation first instead of code?**

**A:** This is part of the "Documentation First" philosophy. By establishing a clear plan, vision, and set of requirements in documentation artifacts, you provide a stable "source of truth" that guides all subsequent code generation. This leads to more coherent and aligned results from the AI and creates a valuable, auditable history of your project's design decisions.

---

## **III. The Core Workflow**

### **Q: What is the recommended "perfect loop" workflow?**

**A:** The ideal workflow is a guided, iterative process that DCE facilitates:
1.  **Curate & Prompt:** Use the Context Chooser to select files, write your instructions in the "Cycle Context," and generate a `prompt.md`.
2.  **Paste & Parse:** Get multiple AI responses and paste them into the Parallel Co-Pilot Panel (PCPP), then use "Parse All".
3.  **Select:** Review the parsed responses and click "Select This Response" on the best one.
4.  **Baseline:** Create a `git commit` restore point with the "Baseline" button.
5.  **Accept & Test:** In the "Associated Files" list, check the files you want to apply and click "Accept Selected". Then, test the changes in your application.
6.  **(If needed) Restore:** If the changes are bad, click "Restore Baseline" to revert everything instantly.
7.  **Finalize & Repeat:** Once you're happy, write your notes for the next task in the "Cycle Context" and "Cycle Title" fields, then start the next cycle.

### **Q: What is an "Artifact"?**

**A:** An "Artifact" is a formal, written document (like a project plan, this FAQ, or a requirements doc) that serves as a "source of truth" for your project. They are stored in the `src/Artifacts` directory and are the blueprints that guide development.

### **Q: What are "Cycles"?**

**A:** A "Cycle" represents one full loop of the development process. The DCE organizes your entire project history into these numbered cycles, allowing you to use the Cycle Navigator in the PCPP to move back and forth in time, reviewing the exact context and AI suggestions from any point in your project's history.

### **Q: What is the difference between "Cycle Context" and "Ephemeral Context"?**

**A:**
*   **Cycle Context:** This is for your main instructions and goals for the current cycle. This content is saved and becomes part of the permanent history of your project.
*   **Ephemeral Context:** This is for temporary information that is only relevant for the *current* prompt generation, such as error logs or a snippet of code you want the AI to analyze. This content is **not** saved in the cycle history to keep it clean.

---

## **IV. Features: Context Curation (File Tree View)**

### **Q: How do I select files to include in the context for the AI?**

**A:** You use the File Tree View (FTV), which is the panel with the spiral icon. It shows your entire workspace with checkboxes next to each file and folder. Simply check the items you want to include. The FTV also shows you token counts, file counts, and Git status for your project.

### **Q: What does "Flatten Context" do?**

**A:** "Flattening" is the process of taking all the files you've selected (checked) and concatenating their content into a single file, `flattened_repo.md`. This file, along with your cycle history and instructions, becomes part of the `prompt.md` that you send to the AI.

### **Q: Can DCE handle different file types like PDFs or Excel sheets?**

**A:** Yes. DCE has built-in extractors for various file types. When you check a `.pdf`, `.docx` (Word), or `.xlsx`/`.csv` (Excel) file, DCE automatically extracts the textual content and converts it into a readable format (like Markdown for tables) to be included in the flattened context.

### **Q: Why are some folders or files grayed out and un-selectable?**

**A:** The DCE automatically excludes common directories that shouldn't be included in an AI's context, such as `node_modules`, `.git`, `.vscode`, and build output folders like `dist`. This is to keep your context focused, reduce token count, and prevent errors.

---

## **V. Features: The Parallel Co-Pilot Panel (PCPP)**

### **Q: Why should I use multiple responses?**

**A:** LLMs are non-deterministic; asking the same question multiple times can yield vastly different solutions. The Parallel Co-Pilot Panel is designed to manage this. It allows you to generate and compare 4, 8, or more responses at once to find the most elegant, efficient, or creative solution.

### **Q: What does the "Parse All" button do?**

**A:** After you paste raw AI responses into the tabs, the "Parse All" button processes them. It automatically identifies the AI's summary, its plan, and any code blocks, transforming the raw text into a structured, easy-to-read view with syntax highlighting and file association.

### **Q: What are "Associated Files" and how does the diffing work?**

**A:** When a response is parsed, DCE lists all the files the AI intended to modify under "Associated Files." You can click the "Open Changes" icon next to any file to open VS Code's built-in, side-by-side diff viewer, showing a precise comparison between your current file and the version suggested by the AI.

### **Q: What do the "Baseline (Commit)" and "Restore Baseline" buttons do?**

**A:** These buttons integrate DCE with Git to provide a safe testing loop. "Baseline" creates a Git commit of your current work, creating a restore point. After you "Accept" an AI's changes, you can test them. If they're buggy, one click on "Restore Baseline" instantly discards all those changes and reverts your workspace, allowing you to test a different response without manual cleanup.

---

## **VI. Local LLM & Demo Mode**

### **Q: Can I use DCE with a local LLM?**

**A:** Yes. DCE supports connecting to any OpenAI-compatible API endpoint. You can run a model locally using a tool like vLLM, Ollama, or LM Studio, and then enter its URL (e.g., `http://localhost:8000/v1`) in the DCE settings panel to have the extension communicate directly with your local model.

### **Q: What is "Demo Mode"?**

**A:** "Demo Mode" is a pre-configured setting that connects the DCE extension to a specific, high-performance vLLM instance. When in this mode, the "Generate prompt.md" button is replaced with a "Generate responses" button, which fully automates the process of sending the prompt and streaming the responses back into the UI in real-time.

### **Q: What is the Response Progress UI?**

**A:** When using an automated connection mode like "Demo Mode," a special UI appears during generation. It shows real-time progress bars for each parallel response, token-per-second metrics, status indicators ("Thinking," "Generating," "Complete"), and timers. This gives you full visibility into the generation process.

---

## **VII. Troubleshooting**

### **Q: My file tree is flashing or constantly refreshing. How do I fix it?**

**A:** This is almost always caused by the DCE's auto-save feature writing to the `.vscode/dce_history.json` file, which then triggers the file watcher to refresh the tree. To fix this, you must add `.vscode/` to your project's `.gitignore` file.

### **Q: Parsing failed or looks incorrect. What can I do?**

**A:** Parsing failures can happen if the AI doesn't format its response correctly. You can click "Un-Parse All" to return to the raw text view. Often, you can fix the issue by manually adding a missing tag (like `<summary>...</summary>`) or correcting a malformed file tag (`<file path="...">...
</file_artifact>

<file path="webpack.config.js">
const path = require('path');
const CopyPlugin = require("copy-webpack-plugin");
const webpack = require('webpack');
const MiniCssExtractPlugin = require('mini-css-extract-plugin');

/** @type {import('webpack').Configuration} */
const baseConfig = {
    mode: 'none',
    resolve: {
        extensions: ['.ts', '.js', '.tsx', '.jsx'],
        alias: {
            "@": path.resolve(__dirname, 'src'),
        }
    },
    module: {
        rules: [
            {
                test: /\.ts$/,
                exclude: /node_modules/,
                use: [{ loader: 'ts-loader' }]
            },
            {
                test: /\.?ts.?(x)$/,
                exclude: /node_modules/,
                use: {
                    loader: "babel-loader",
                    options: {
                        presets: ['@babel/preset-react', '@babel/preset-typescript']
                    }
                }
            },
        ]
    },
    devtool: 'nosources-source-map',
    infrastructureLogging: {
        level: "log",
    },
};

/** @type {import('webpack').Configuration} */
const extensionConfig = {
    ...baseConfig,
    target: 'node',
    entry: {
        extension: './src/extension.ts',
    },
    output: {
        path: path.resolve(__dirname, 'dist'),
        filename: 'extension.js',
        libraryTarget: 'commonjs2'
    },
    externals: {
        vscode: 'commonjs vscode',
        'better-sqlite3': 'commonjs better-sqlite3'
    },
};

/** @type {import('webpack').Configuration} */
const webviewConfig = {
    ...baseConfig,
    target: 'web',
    entry: {
        contextChooserView: './src/client/views/context-chooser.view/view.tsx',
        parallelCopilotView: './src/client/views/parallel-copilot.view/view.tsx',
        settingsView: './src/client/views/settings.view/view.tsx',
    },
    output: {
        path: path.resolve(__dirname, 'dist'),
        filename: '[name].js',
        libraryTarget: 'commonjs2',
    },
    module: {
        ...baseConfig.module,
        rules: [
            ...baseConfig.module.rules,
            {
                test: /\.s[ac]ss$/i,
                use: [MiniCssExtractPlugin.loader, "css-loader", "sass-loader"],
            },
			{
				test: /\.css$/,
				use: [MiniCssExtractPlugin.loader, 'css-loader']
			},
			{
				test: /\.ttf$/,
				type: 'asset/resource'
			}
        ]
    },
    resolve: {
        ...baseConfig.resolve,
        fallback: {
            "path": require.resolve("path-browserify")
        }
    },
    plugins: [
        new MiniCssExtractPlugin({
            filename: '[name].css'
        }),
        new CopyPlugin({
            patterns: [
                { from: "public", to: "public" },
                { from: "node_modules/@wooorm/starry-night/style/both.css", to: "starry-night.css" },
                { from: "src/Artifacts", to: "Artifacts" }
            ],
        }),
        new webpack.ProvidePlugin({
            process: 'process/browser',
        }),
    ],
};

module.exports = [extensionConfig, webviewConfig];
</file_artifact>

<file path="tsconfig.json">
{
    "compilerOptions": {
        "module": "esnext",
        "moduleResolution": "bundler",
        "target": "ESNext",
        "lib": ["ES2022", "DOM"],
        "jsx": "react",
        "sourceMap": true,
        "rootDir": "src",
        "strict": false,
        "baseUrl": "./",
        "paths": {
            "@/*": ["src/*"]
        },
        "experimentalDecorators": true,
        "allowSyntheticDefaultImports": true
    },
    "include": [
        "src/**/*.ts",
        "src/**/*.tsx"
    ],
    "exclude": [
        "node_modules",
        ".vscode-test",
        "The-Creator-AI-main"
    ]
}
</file_artifact>

<file path="README.md">
# Data Curation Environment (DCE)

The Data Curation Environment (DCE) is a VS Code extension designed to streamline the workflow of interacting with large language models (LLMs) for software development and other complex tasks. It provides an integrated toolset for selecting, packaging, and managing the context (code files, documents, etc.) required for effective AI-assisted development.

## Core Features

### Phase 1: The Context Chooser
- **File Tree with Checkboxes:** An intuitive UI to select files and folders for your AI context directly within a custom VS Code panel.
- **Context Flattening:** A one-click button to "flatten" all selected files into a single, portable `flattened_repo.md` file, ready to be used in a prompt.
- **Advanced File Handling:** On-demand text extraction for complex file types like PDF, Word, and Excel, converting them to Markdown and including them in the context without creating temporary files in your workspace.
- **Feature Parity:** Aims to replicate the core usability features of the native VS Code Explorer, including file operations (rename, delete, copy/paste), keyboard navigation, and drag-and-drop.

### Phase 2: The Parallel Co-Pilot Panel
- **Multi-Response Management:** A dedicated panel with a multi-tabbed interface to manage, compare, and test multiple AI-generated responses to a single prompt.
- **Integrated Diffing:** A built-in diff viewer to compare an AI's suggested changes against your current workspace files.
- **Cycle Navigator:** A persistent, navigable history of your development cycles. Each cycle stores the context, prompt, and all AI responses, creating a "knowledge graph" of your project's evolution.
- **Git-Integrated Testing:** "Baseline" and "Restore" buttons that leverage Git to allow for rapid, safe testing of AI-generated code.

### Phase 3: Advanced AI & Local LLM Integration
- **Direct API Calls:** Future support for making API calls directly to various LLM providers from within the extension.
- **Local LLM Support:** The ability to configure an endpoint for a locally hosted LLM, enabling fully offline and private AI-assisted development.

## Development

To run the extension locally for development:
1.  Run `npm install` to install dependencies.
2.  Run `npm run watch` to start the Webpack compiler in watch mode.
3.  Press `F5` in VS Code to launch the **Extension Development Host**, a new VS Code window with the DCE extension installed and running.
</file_artifact>

<file path="package.json">
{
    "name": "data-curation-environment",
    "publisher": "DCE-Developer",
    "displayName": "Data Curation Environment",
    "description": "A VS Code extension for curating context for Large Language Models.",
    "version": "1.2.0",
    "icon": "public/spiral.svg",
    "repository": {
        "type": "git",
        "url": "https://github.com/dgerabagi/data-curation-environment.git"
    },
    "engines": {
        "vscode": "^1.90.0"
    },
    "categories": [
        "Other"
    ],
    "activationEvents": [
        "onCommand:dce.showParallelCopilot"
    ],
    "main": "./dist/extension.js",
    "contributes": {
        "configuration": {
            "title": "Data Curation Environment",
            "properties": {
                "dce.connectionMode": {
                    "type": "string",
                    "default": "manual",
                    "description": "The LLM connection mode (manual, demo, url, key)."
                }
            }
        },
        "commands": [
            {
                "command": "dce.saveCurrentSelection",
                "title": "DCE: Save Current Selection Set",
                "category": "DCE"
            },
            {
                "command": "dce.loadSelectionSet",
                "title": "DCE: Load Selection Set",
                "category": "DCE"
            },
            {
                "command": "dce.manageSelectionSets",
                "title": "DCE: Manage Selection Sets",
                "category": "DCE"
            },
            {
                "command": "dce.refreshTree",
                "title": "DCE: Refresh Explorer",
                "category": "DCE"
            },
            {
                "command": "dce.openParallelCopilot",
                "title": "DCE: Open Parallel Co-Pilot",
                "category": "DCE",
                "icon": "$(multiple-windows)"
            },
            {
                "command": "dce.showParallelCopilot",
                "title": "DCE: Show Parallel Co-Pilot"
            },
            {
                "command": "dce.openSettingsPanel",
                "title": "DCE: Open Settings & Help",
                "category": "DCE",
                "icon": "$(settings-gear)"
            },
            {
                "command": "dce.gitInit",
                "title": "DCE: Initialize Git Repository"
            }
        ],
        "viewsContainers": {
            "activitybar": [
                {
                    "id": "data-curation-environment",
                    "title": "Data Curation",
                    "icon": "public/spiral.svg"
                },
                {
                    "id": "dce-parallel-copilot-container",
                    "title": "DCE Parallel Co-Pilot",
                    "icon": "public/copilot.svg"
                }
            ]
        },
        "views": {
            "data-curation-environment": [
                {
                    "type": "webview",
                    "id": "viewType.sidebar.contextChooser",
                    "name": "Data Curation"
                }
            ]
        },
        "menus": {
            "view/title": [
                {
                    "command": "dce.openParallelCopilot",
                    "when": "view == viewType.sidebar.contextChooser",
                    "group": "navigation"
                },
                {
                    "command": "dce.openSettingsPanel",
                    "when": "view == viewType.sidebar.contextChooser",
                    "group": "navigation@2"
                }
            ],
            "activityBar/view/title": [
                {
                    "command": "dce.showParallelCopilot",
                    "when": "viewContainer == dce-parallel-copilot-container"
                }
            ]
        }
    },
    "scripts": {
        "vscode:prepublish": "npm run package",
        "compile": "webpack",
        "watch": "webpack --watch",
        "package": "webpack --mode production --devtool hidden-source-map",
        "lint": "eslint src --ext ts",
        "rebuild": "electron-rebuild"
    },
    "devDependencies": {
        "@babel/preset-react": "^7.24.7",
        "@babel/preset-typescript": "^7.24.7",
        "@electron/rebuild": "^3.6.0",
        "@types/better-sqlite3": "^7.6.10",
        "@types/node": "18.x",
        "@types/path-browserify": "^1.0.2",
        "@types/prismjs": "^1.26.4",
        "@types/react-dom": "^18.3.0",
        "@types/vscode": "^1.90.0",
        "@typescript-eslint/eslint-plugin": "^7.7.1",
        "@typescript-eslint/parser": "^7.7.1",
        "babel-loader": "^9.1.3",
        "copy-webpack-plugin": "^12.0.2",
        "css-loader": "^7.1.2",
        "electron": "^33.0.0",
        "eslint": "^8.57.0",
        "mini-css-extract-plugin": "^2.9.0",
        "path-browserify": "^1.0.1",
        "postcss-loader": "^8.1.1",
        "process": "^0.11.10",
        "sass": "^1.78.0",
        "sass-loader": "^16.0.1",
        "style-loader": "^4.0.0",
        "ts-loader": "^9.5.1",
        "typescript": "^5.4.5",
        "webpack": "^5.91.0",
        "webpack-cli": "^5.1.4"
    },
    "dependencies": {
        "@types/diff": "^5.2.1",
        "@wooorm/starry-night": "^3.8.0",
        "agentkeepalive": "^4.5.0",
        "better-sqlite3": "^11.5.0",
        "diff": "^5.2.0",
        "hast-util-to-html": "^9.0.1",
        "mammoth": "^1.8.0",
        "node-fetch": "^2.6.7",
        "pdf-parse": "^1.1.1",
        "react": "^18.3.1",
        "react-dom": "^18.3.1",
        "react-icons": "^5.3.0",
        "react-markdown": "^9.0.1",
        "reflect-metadata": "^0.2.2",
        "rxjs": "^7.8.1",
        "xlsx": "^0.18.5"
    }
}
</file_artifact>

<file path="LICENSE">
MIT License

Copyright (c) 2025 Catalyst AI, LLC

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
</file_artifact>

<file path="CHANGELOG.md">
# DCE Changelog

All notable changes to the "Data Curation Environment" extension will be documented in this file.

## [1.2.0] - Q4 2025

### Added
- **SQLite Integration:** Replaced the brittle `dce_history.json` file storage with a robust SQLite database (`.vscode/dce.db`) for managing cycle history. This resolves the data loss issues caused by race conditions during autosave.
- **Markdown Preview:** Added an "Open Preview" button to Markdown files in the Parallel Co-Pilot's "Associated Files" list, allowing users to view rendered documentation directly within VS Code.

### Fixed
- **Similarity Score Ghost Data:** Fixed a bug where similarity scores were incorrectly shared across different response tabs for the same file. Metrics are now correctly scoped to the specific response tab.
- **Associated Files Mismatch:** Added enhanced logging and path normalization to diagnose and fix issues where files in the parsed response were incorrectly marked as missing.
- **Native Module Build Issues:** Consolidated and updated documentation for troubleshooting ABI mismatches when building native modules like `better-sqlite3` for different Electron versions.

## [0.1.10] - Q3 2025

### Fixed
- **Cost Calculation Display:** Fixed an issue where the estimated prompt cost was not being correctly displayed on the frontend, often remaining at $0.00 despite changes in context. The calculation is now correctly triggered and displayed.

## [0.1.9] - Q3 2025

### Added
- **Native Diff Viewer:** Replaced the custom, in-panel diff viewer with an integration of VS Code's native diffing functionality (`vscode.diff`). This provides a much richer, more stable, and familiar user experience for comparing AI-generated code with workspace files.

### Fixed
- **File Duplication:** Resolved several bugs that could cause duplicate files to appear in the flattened context, particularly during the onboarding workflow and when using the "auto-add new files" feature.
- **Data Loss Prevention:** Implemented a more robust, UI-driven autosave status indicator with navigation locking. This prevents race conditions when switching between cycles, significantly reducing the chance of data loss.
- **Auto-Add Logic:** Fixed a race condition in the "auto-add new files" feature that caused newly created files to be "stuck" in the selection state and unable to be removed.

## [0.1.2] - Q3 2025

### Added
- **Similarity Score:** The PCPP now displays a similarity score for associated files and uses a color gradient to indicate the degree of change.
- **Robust Autosave:** Implemented a more robust autosave with navigation locking to prevent data loss when switching cycles.
- **Settings Panel:** Created a new settings panel to display the README and Changelog.
- **Auto-Tab on Paste:** The PCPP now automatically advances to the next empty response tab after pasting in a large response.
- **Smarter Restore:** The "Restore Baseline" button now correctly deletes newly created files that were part of the accepted response.

## [0.1.1] - Q3 2025

### Added
- **Git-Integrated Testing:** Added "Baseline (Commit)" and "Restore Baseline" buttons to the PCPP for a rapid test-and-revert workflow.
- **Undo/Redo for File Operations:** Implemented `Ctrl+Z` and `Ctrl+Y` in the File Tree View to undo/redo file moves.
- **Tab Persistence:** The active response tab in the PCPP is now saved and restored across sessions.

### Fixed
- **Command Registration:** Fixed a critical activation error caused by a command being registered twice.
- **Exclusion List:** `tsconfig.tsbuildinfo` and `dist` directories are now correctly excluded from selection and the flattened context.
</file_artifact>

<file path="src/Artifacts/A118. DCE - Database Integration Plan.md">
# Artifact A118: DCE - Database Integration Plan
# Date Created: C118
# Author: AI Model & Curator
# Updated on: C123 (Add troubleshooting for ABI mismatch)

- **Key/Value for A0:**
- **Description:** A plan to transition from the brittle `dce_history.json` file to a robust SQLite database for managing cycle history, solving data loss issues.
- **Tags:** plan, architecture, database, sqlite, persistence, data integrity

## 1. Problem Statement

The current persistence mechanism relies on a single, monolithic JSON file (`.vscode/dce_history.json`). As the project history grows, this file becomes large (potentially 100MB+). The "autosave" feature writes this entire file to disk on every significant change (debounced). This approach has critical flaws:

1.  **Race Conditions:** Rapid navigation or edits can trigger multiple writes, leading to data loss if a write is interrupted or if the in-memory state is stale when a write occurs.
2.  **Performance:** Serializing and writing a huge JSON string is CPU and I/O intensive, causing UI freezes (flashing) and lag.
3.  **Fragility:** A single write error can corrupt the entire history.

## 2. The Solution: SQLite Database

We will replace the live `dce_history.json` with a local SQLite database (`.vscode/dce.db`). SQLite is transactional, atomic, and efficient for partial updates. This ensures that saving a single response or updating a cycle title does not require rewriting the entire history.

The `dce_history.json` format will be retained solely for **Import/Export** functionality, allowing users to share or backup their projects.

## 3. Technical Architecture

### 3.1. Database Technology
-   **Library:** `better-sqlite3`. This library provides a synchronous API that is highly performant and fits well with the VS Code extension architecture (running in the Node.js Extension Host).
-   **File Location:** `.vscode/dce.db` (inside the user's workspace).
-   **Build Configuration (C119):** Because `better-sqlite3` is a native Node.js module, it **must** be excluded from the Webpack bundle. We will add it to the `externals` section of `webpack.config.js`.
-   **Native Module Compatibility (C122):** `better-sqlite3` must be compiled against the specific Electron version used by VS Code.
    -   **Dependency:** Add `@electron/rebuild` and `electron` (matching the target ABI, e.g., `^33.0.0`) to `devDependencies`.
    -   **Script:** Add `"rebuild": "electron-rebuild"` to `package.json`.
    -   **Action:** Run `npm install` followed by `npm run rebuild` whenever native dependencies are added or updated.
    -   **Troubleshooting (C123):** If `NODE_MODULE_VERSION` errors persist, check the "Data Curation Environment" output channel for the `[Env]` log. This log reveals the *exact* Electron version the extension is running in. Run `npm run rebuild -- -v <VERSION> -f` to force a build for that specific version.

### 3.2. Schema Design

**Table: `key_value_store`**
Stores global project settings and state.
| Column | Type | Constraints | Description |
| :--- | :--- | :--- | :--- |
| `key` | TEXT | PRIMARY KEY | E.g., 'project_scope', 'last_viewed_cycle_id' |
| `value` | TEXT | | JSON stringified value |

**Table: `cycles`**
Stores the metadata for each development cycle.
| Column | Type | Constraints | Description |
| :--- | :--- | :--- | :--- |
| `id` | INTEGER | PRIMARY KEY | The Cycle ID (0, 1, 2...) |
| `title` | TEXT | | |
| `timestamp` | TEXT | | ISO string |
| `cycle_context` | TEXT | | |
| `ephemeral_context` | TEXT | | |
| `tab_count` | INTEGER | | |
| `active_tab` | INTEGER | | |
| `is_parsed_mode` | INTEGER | | Boolean (0/1) |
| `is_sorted_by_tokens` | INTEGER | | Boolean (0/1) |
| `selected_response_id` | TEXT | | |
| `left_pane_width` | INTEGER | | |
| `status` | TEXT | | 'generating' | 'complete' |
| `connection_mode` | TEXT | | 'manual' | 'demo' | 'url' |
| `active_workflow_step` | TEXT | | |
| `is_ephemeral_context_collapsed` | INTEGER | | Boolean (0/1) |

**Table: `responses`**
Stores the AI responses associated with each cycle.
| Column | Type | Constraints | Description |
| :--- | :--- | :--- | :--- |
| `cycle_id` | INTEGER | | Foreign Key -> cycles.id |
| `tab_id` | TEXT | | '1', '2', etc. |
| `content` | TEXT | | Raw response content |
| `status` | TEXT | | 'pending' | 'generating' | 'complete' | ... |
| `start_time` | INTEGER | | Timestamp |
| `end_time` | INTEGER | | Timestamp |
| `thinking_tokens` | INTEGER | | |
| `response_tokens` | INTEGER | | |
| PRIMARY KEY | (`cycle_id`, `tab_id`) | | Composite Key |

### 3.3. Migration Strategy

1.  **Detection:** On startup, the `DatabaseService` checks for `.vscode/dce.db`.
2.  **Import:** If the DB is missing but `dce_history.json` exists, it reads the JSON and populates the DB tables.
3.  **Archive:** After successful import, it renames `dce_history.json` to `dce_history.json.bak`.
4.  **Initialization:** If neither exists, it initializes an empty DB with the schema.

## 4. Implementation Plan

1.  **Install Dependencies:** `npm install better-sqlite3`, `npm install --save-dev @electron/rebuild electron`.
2.  **Configure Webpack:** Update `webpack.config.js` to add `better-sqlite3` to `externals`.
3.  **Create `DatabaseService`:** Implement the connection, schema creation, migration logic, and CRUD operations.
4.  **Refactor `HistoryService`:**
    *   Remove file system calls for `.json`.
    *   Inject `DatabaseService`.
    *   Replace `_readHistoryFile` with a method that queries the DB and reconstructs the `PcppHistoryFile` object (to maintain compatibility with `PromptService`).
    *   Replace `saveCycleData` with atomic DB updates (`UPSERT`).
    *   Implement `handleExportHistory` to dump the DB back to JSON format.
    *   Implement `handleImportHistory` to wipe the DB and load from JSON.
5.  **Update `Services`:** Register the new service.
</file_artifact>

<file path="src/backend/services/database.service.ts">
// src/backend/services/database.service.ts
// Updated on: C126 (Add schema migration for is_cycle_collapsed)
import * as vscode from 'vscode';
import * as path from 'path';
import * as fs from 'fs';
import Database from 'better-sqlite3';
import { Services } from './services';
import { PcppCycle, PcppResponse } from '@/common/types/pcpp.types';

export class DatabaseService {
    private db: Database.Database | null = null;
    private dbPath: string | undefined;

    constructor() {}

    public initialize() {
        const workspaceFolders = vscode.workspace.workspaceFolders;
        if (!workspaceFolders || workspaceFolders.length === 0) {
            Services.loggerService.warn("No workspace open, database cannot be initialized.");
            return;
        }

        const vscodeDir = path.join(workspaceFolders[0].uri.fsPath, '.vscode');
        if (!fs.existsSync(vscodeDir)) {
            fs.mkdirSync(vscodeDir);
        }
        this.dbPath = path.join(vscodeDir, 'dce.db');

        // Log environment details to help debug native module mismatches
        Services.loggerService.log(`[Env] Node: ${process.versions.node}, Electron: ${process.versions['electron'] || 'N/A'}, ABI: ${process.versions.modules}`);

        try {
            this.db = new Database(this.dbPath);
            this.db.pragma('journal_mode = WAL');
            this.createTables();
            this.migrateSchema(); // Run migrations after table creation
            this.migrateFromLegacyJson();
            Services.loggerService.log(`Database initialized at ${this.dbPath}`);
        } catch (error) {
            Services.loggerService.error(`Failed to initialize database: ${error}`);
        }
    }

    private createTables() {
        if (!this.db) return;

        this.db.exec(`
            CREATE TABLE IF NOT EXISTS key_value_store (
                key TEXT PRIMARY KEY,
                value TEXT
            );

            CREATE TABLE IF NOT EXISTS cycles (
                id INTEGER PRIMARY KEY,
                title TEXT,
                timestamp TEXT,
                cycle_context TEXT,
                ephemeral_context TEXT,
                tab_count INTEGER,
                active_tab INTEGER,
                is_parsed_mode INTEGER,
                is_sorted_by_tokens INTEGER,
                selected_response_id TEXT,
                left_pane_width INTEGER,
                status TEXT,
                connection_mode TEXT,
                active_workflow_step TEXT,
                is_ephemeral_context_collapsed INTEGER,
                is_cycle_collapsed INTEGER, -- Added in C126
                selected_files_for_replacement TEXT -- Added in C126 Fix
            );

            CREATE TABLE IF NOT EXISTS responses (
                cycle_id INTEGER,
                tab_id TEXT,
                content TEXT,
                status TEXT,
                start_time INTEGER,
                thinking_end_time INTEGER,
                end_time INTEGER,
                thinking_tokens INTEGER,
                response_tokens INTEGER,
                parsed_content TEXT, -- JSON string
                PRIMARY KEY (cycle_id, tab_id),
                FOREIGN KEY (cycle_id) REFERENCES cycles(id) ON DELETE CASCADE
            );
        `);
    }

    private migrateSchema() {
        if (!this.db) return;
        try {
            const tableInfo = this.db.pragma('table_info(cycles)') as any[];
            
            // Check for is_cycle_collapsed (C126)
            const hasIsCycleCollapsed = tableInfo.some(col => col.name === 'is_cycle_collapsed');
            if (!hasIsCycleCollapsed) {
                this.db.exec('ALTER TABLE cycles ADD COLUMN is_cycle_collapsed INTEGER DEFAULT 0');
                Services.loggerService.log('Migrated database: Added is_cycle_collapsed to cycles table.');
            }

            // Check for is_ephemeral_context_collapsed (C118/C126 catch-up)
            const hasIsEphemeralContextCollapsed = tableInfo.some(col => col.name === 'is_ephemeral_context_collapsed');
            if (!hasIsEphemeralContextCollapsed) {
                this.db.exec('ALTER TABLE cycles ADD COLUMN is_ephemeral_context_collapsed INTEGER DEFAULT 0');
                Services.loggerService.log('Migrated database: Added is_ephemeral_context_collapsed to cycles table.');
            }
            
            // Check for selected_files_for_replacement (C126 Fix)
            const hasSelectedFiles = tableInfo.some(col => col.name === 'selected_files_for_replacement');
            if (!hasSelectedFiles) {
                this.db.exec('ALTER TABLE cycles ADD COLUMN selected_files_for_replacement TEXT DEFAULT "[]"');
                Services.loggerService.log('Migrated database: Added selected_files_for_replacement to cycles table.');
            }

        } catch (error) {
            Services.loggerService.error(`Schema migration failed: ${error}`);
        }
    }

    private migrateFromLegacyJson() {
        if (!this.db || !this.dbPath) return;
        
        const jsonPath = path.join(path.dirname(this.dbPath), 'dce_history.json');
        if (!fs.existsSync(jsonPath)) return;

        // Check if DB is empty
        const row = this.db.prepare('SELECT count(*) as count FROM cycles').get() as { count: number };
        if (row.count > 0) return; // Already populated

        Services.loggerService.log("Migrating legacy dce_history.json to SQLite...");
        
        try {
            const content = fs.readFileSync(jsonPath, 'utf-8');
            const history = JSON.parse(content);

            if (history.projectScope) {
                this.setGlobalValue('project_scope', history.projectScope);
            }

            const insertCycle = this.db.prepare(`
                INSERT INTO cycles (id, title, timestamp, cycle_context, ephemeral_context, tab_count, active_tab, is_parsed_mode, is_sorted_by_tokens, selected_response_id, left_pane_width, status, connection_mode, active_workflow_step, is_ephemeral_context_collapsed, is_cycle_collapsed, selected_files_for_replacement)
                VALUES (@id, @title, @timestamp, @cycleContext, @ephemeralContext, @tabCount, @activeTab, @isParsedMode, @isSortedByTokens, @selectedResponseId, @leftPaneWidth, @status, @connectionMode, @activeWorkflowStep, @isEphemeralContextCollapsed, @isCycleCollapsed, @selectedFilesForReplacement)
            `);

            const insertResponse = this.db.prepare(`
                INSERT INTO responses (cycle_id, tab_id, content, status, start_time, thinking_end_time, end_time, thinking_tokens, response_tokens, parsed_content)
                VALUES (@cycleId, @tabId, @content, @status, @startTime, @thinkingEndTime, @endTime, @thinkingTokens, @responseTokens, @parsedContent)
            `);

            const transaction = this.db.transaction((cycles: PcppCycle[]) => {
                for (const cycle of cycles) {
                    insertCycle.run({
                        id: cycle.cycleId,
                        title: cycle.title,
                        timestamp: cycle.timestamp,
                        cycleContext: cycle.cycleContext,
                        ephemeralContext: cycle.ephemeralContext,
                        tabCount: cycle.tabCount || 4,
                        activeTab: cycle.activeTab || 1,
                        isParsedMode: cycle.isParsedMode ? 1 : 0,
                        isSortedByTokens: cycle.isSortedByTokens ? 1 : 0,
                        selectedResponseId: cycle.selectedResponseId || null,
                        leftPaneWidth: cycle.leftPaneWidth || 33,
                        status: cycle.status || 'complete',
                        connectionMode: (cycle as any).connectionMode || null,
                        activeWorkflowStep: cycle.activeWorkflowStep || null,
                        isEphemeralContextCollapsed: cycle.isEphemeralContextCollapsed ? 1 : 0,
                        isCycleCollapsed: cycle.isCycleCollapsed ? 1 : 0,
                        selectedFilesForReplacement: JSON.stringify(cycle.selectedFilesForReplacement || [])
                    });

                    for (const [tabId, resp] of Object.entries(cycle.responses)) {
                        insertResponse.run({
                            cycleId: cycle.cycleId,
                            tabId: tabId,
                            content: resp.content,
                            status: resp.status,
                            startTime: resp.startTime || null,
                            thinkingEndTime: resp.thinkingEndTime || null,
                            endTime: resp.endTime || null,
                            thinkingTokens: resp.thinkingTokens || 0,
                            responseTokens: resp.responseTokens || 0,
                            parsedContent: resp.parsedContent ? JSON.stringify(resp.parsedContent) : null
                        });
                    }
                }
            });

            transaction(history.cycles);
            
            fs.renameSync(jsonPath, jsonPath + '.bak');
            Services.loggerService.log("Migration complete. Legacy file renamed to .bak");

        } catch (error) {
            Services.loggerService.error(`Migration failed: ${error}`);
        }
    }

    public setGlobalValue(key: string, value: any) {
        if (!this.db) return;
        const stmt = this.db.prepare(`INSERT INTO key_value_store (key, value) VALUES (?, ?) ON CONFLICT(key) DO UPDATE SET value = ?`);
        const strVal = JSON.stringify(value);
        stmt.run(key, strVal, strVal);
    }

    public getGlobalValue<T>(key: string): T | undefined {
        if (!this.db) return undefined;
        const row = this.db.prepare('SELECT value FROM key_value_store WHERE key = ?').get(key) as { value: string } | undefined;
        if (row) return JSON.parse(row.value);
        return undefined;
    }

    public getCycle(id: number): PcppCycle | null {
        if (!this.db) return null;
        const cycleRow = this.db.prepare('SELECT * FROM cycles WHERE id = ?').get(id) as any;
        if (!cycleRow) return null;

        const responseRows = this.db.prepare('SELECT * FROM responses WHERE cycle_id = ?').all(id) as any[];
        const responses: { [key: string]: PcppResponse } = {};
        
        responseRows.forEach(r => {
            responses[r.tab_id] = {
                content: r.content,
                status: r.status,
                startTime: r.start_time,
                thinkingEndTime: r.thinking_end_time,
                endTime: r.end_time,
                thinkingTokens: r.thinking_tokens,
                responseTokens: r.response_tokens,
                parsedContent: r.parsed_content ? JSON.parse(r.parsed_content) : null
            };
        });

        return {
            cycleId: cycleRow.id,
            title: cycleRow.title,
            timestamp: cycleRow.timestamp,
            cycleContext: cycleRow.cycle_context,
            ephemeralContext: cycleRow.ephemeral_context,
            tabCount: cycleRow.tab_count,
            activeTab: cycleRow.active_tab,
            isParsedMode: !!cycleRow.is_parsed_mode,
            isSortedByTokens: !!cycleRow.is_sorted_by_tokens,
            selectedResponseId: cycleRow.selected_response_id,
            leftPaneWidth: cycleRow.left_pane_width,
            status: cycleRow.status,
            activeWorkflowStep: cycleRow.active_workflow_step,
            isEphemeralContextCollapsed: !!cycleRow.is_ephemeral_context_collapsed,
            isCycleCollapsed: !!cycleRow.is_cycle_collapsed,
            selectedFilesForReplacement: cycleRow.selected_files_for_replacement ? JSON.parse(cycleRow.selected_files_for_replacement) : [],
            responses
        };
    }

    public getAllCycles(): PcppCycle[] {
        if (!this.db) return [];
        const cycleRows = this.db.prepare('SELECT id FROM cycles ORDER BY id ASC').all() as { id: number }[];
        return cycleRows.map(row => this.getCycle(row.id)!);
    }

    public saveCycle(cycle: PcppCycle) {
        if (!this.db) return;
        
        const upsertCycle = this.db.prepare(`
            INSERT INTO cycles (id, title, timestamp, cycle_context, ephemeral_context, tab_count, active_tab, is_parsed_mode, is_sorted_by_tokens, selected_response_id, left_pane_width, status, connection_mode, active_workflow_step, is_ephemeral_context_collapsed, is_cycle_collapsed, selected_files_for_replacement)
            VALUES (@id, @title, @timestamp, @cycleContext, @ephemeralContext, @tabCount, @activeTab, @isParsedMode, @isSortedByTokens, @selectedResponseId, @leftPaneWidth, @status, @connectionMode, @activeWorkflowStep, @isEphemeralContextCollapsed, @isCycleCollapsed, @selectedFilesForReplacement)
            ON CONFLICT(id) DO UPDATE SET
                title=@title, cycle_context=@cycleContext, ephemeral_context=@ephemeralContext, tab_count=@tabCount, active_tab=@activeTab, is_parsed_mode=@isParsedMode,
                is_sorted_by_tokens=@isSortedByTokens, selected_response_id=@selectedResponseId, left_pane_width=@leftPaneWidth, status=@status,
                connection_mode=@connectionMode, active_workflow_step=@activeWorkflowStep, is_ephemeral_context_collapsed=@isEphemeralContextCollapsed, is_cycle_collapsed=@isCycleCollapsed, selected_files_for_replacement=@selectedFilesForReplacement
        `);

        const upsertResponse = this.db.prepare(`
            INSERT INTO responses (cycle_id, tab_id, content, status, start_time, thinking_end_time, end_time, thinking_tokens, response_tokens, parsed_content)
            VALUES (@cycleId, @tabId, @content, @status, @startTime, @thinkingEndTime, @endTime, @thinkingTokens, @responseTokens, @parsedContent)
            ON CONFLICT(cycle_id, tab_id) DO UPDATE SET
                content=@content, status=@status, start_time=@startTime, thinking_end_time=@thinkingEndTime, end_time=@endTime,
                thinking_tokens=@thinkingTokens, response_tokens=@responseTokens, parsed_content=@parsedContent
        `);

        const transaction = this.db.transaction(() => {
            upsertCycle.run({
                id: cycle.cycleId,
                title: cycle.title,
                timestamp: cycle.timestamp,
                cycleContext: cycle.cycleContext,
                ephemeralContext: cycle.ephemeralContext,
                tabCount: cycle.tabCount || 4,
                activeTab: cycle.activeTab || 1,
                isParsedMode: cycle.isParsedMode ? 1 : 0,
                isSortedByTokens: cycle.isSortedByTokens ? 1 : 0,
                selectedResponseId: cycle.selectedResponseId || null,
                leftPaneWidth: cycle.leftPaneWidth || 33,
                status: cycle.status || 'complete',
                connectionMode: (cycle as any).connectionMode || null,
                activeWorkflowStep: cycle.activeWorkflowStep || null,
                isEphemeralContextCollapsed: cycle.isEphemeralContextCollapsed ? 1 : 0,
                isCycleCollapsed: cycle.isCycleCollapsed ? 1 : 0,
                selectedFilesForReplacement: JSON.stringify(cycle.selectedFilesForReplacement || [])
            });

            for (const [tabId, resp] of Object.entries(cycle.responses)) {
                upsertResponse.run({
                    cycleId: cycle.cycleId,
                    tabId: tabId,
                    content: resp.content,
                    status: resp.status,
                    startTime: resp.startTime || null,
                    thinkingEndTime: resp.thinkingEndTime || null,
                    endTime: resp.endTime || null,
                    thinkingTokens: resp.thinkingTokens || 0,
                    responseTokens: resp.responseTokens || 0,
                    parsedContent: resp.parsedContent ? JSON.stringify(resp.parsedContent) : null
                });
            }
        });

        transaction();
    }

    public deleteCycle(id: number) {
        if (!this.db) return;
        this.db.prepare('DELETE FROM cycles WHERE id = ?').run(id);
        this.db.prepare('DELETE FROM responses WHERE cycle_id = ?').run(id);
    }

    public reset() {
        if (!this.db) return;
        this.db.exec('DELETE FROM cycles; DELETE FROM responses; DELETE FROM key_value_store;');
    }
}
</file_artifact>

<file path="src/Artifacts/A119. DCE - Universal Task Checklist for Cycle 122+.md">
# Artifact A119: DCE - Universal Task Checklist for Cycle 122+
# Date Created: C121
# Author: AI Model & Curator
# Updated on: C123 (Update status)

## 1. Purpose

This artifact provides a structured checklist for the next phase of development, focusing on stabilizing the new SQLite database integration and resolving the remaining data migration and UI issues.

## Task List

## T-1: Stabilize SQLite Integration
- **Files Involved:**
    - `src/backend/services/database.service.ts`
    - `src/backend/services/history.service.ts`
    - `package.json`
- **Total Tokens:** ~5,000
- **More than one cycle?** No
- **Status:** **In Progress (Blocked by Build Environment)**

- [x] **Task (T-ID: 1.1):** Verify that `npm run rebuild` correctly compiles `better-sqlite3` for the Electron environment. (User attempted, but runtime mismatch persists).
- [ ] **Task (T-ID: 1.2):** Confirm that `DatabaseService` correctly initializes and creates the `.vscode/dce.db` file. (Pending successful build).
- [ ] **Task (T-ID: 1.3):** Verify that the migration logic in `DatabaseService` correctly imports data from an existing `dce_history.json` and renames it to `.bak`.
- [ ] **Task (T-ID: 1.4):** Ensure that `HistoryService` correctly reads and writes to the database, and that the UI reflects the persisted state (e.g., cycle count, responses).

### Verification Steps
1.  Open a workspace with an existing `dce_history.json`.
2.  Run the extension.
3.  **Expected:** A `.vscode/dce.db` file is created. `dce_history.json` is renamed to `dce_history.json.bak`. The PCPP loads with the correct cycle history.
4.  Make a change (e.g., edit cycle context) and navigate to another cycle.
5.  **Expected:** The change is persisted and visible when navigating back.

## T-2: Plan for Next Cycle
- **Files Involved:**
    - `src/Artifacts/A120-New-Checklist.md`
- **Total Tokens:** ~500
- **More than one cycle?** No

- [ ] **Task (T-ID: 2.1):** Create the Universal Task Checklist for the next cycle based on current progress and backlog.
</file_artifact>

<file path="src/Artifacts/A120. DCE - Database Maintenance Guide.md">
# Artifact A120: DCE - Database Maintenance Guide
# Date Created: C126
# Author: AI Model & Curator

- **Key/Value for A0:**
- **Description:** A guide for developers on how to maintain, migrate, and debug the SQLite database used by the DCE extension.
- **Tags:** guide, database, sqlite, maintenance, migration, debugging

## 1. Overview

The Data Curation Environment (DCE) uses a local SQLite database (`.vscode/dce.db`) to store project history, cycles, and responses. This ensures data integrity and performance. This guide outlines the procedures for maintaining this database, including schema migrations, debugging, and manual editing.

## 2. Database Location

The database is located in the user's workspace:
*   **Path:** `.vscode/dce.db`
*   **WAL File:** `.vscode/dce.db-wal` (Write-Ahead Log - do not delete while DB is open)
*   **SHM File:** `.vscode/dce.db-shm` (Shared Memory - do not delete while DB is open)

## 3. Schema Management & Migrations

As the extension evolves, the database schema will need to change (e.g., adding new columns for new features).

### 3.1. Adding a New Column
To add a new column to an existing table (e.g., `cycles`):

1.  **Modify `pcpp.types.ts`:** Update the TypeScript interface (e.g., `PcppCycle`) to include the new property.
2.  **Update `DatabaseService.ts`:**
    *   **`createTables()`:** Update the `CREATE TABLE` statement to include the new column for *new* databases.
    *   **`migrateSchema()` (New Method):** Implement a migration check.
        ```typescript
        private migrateSchema() {
            // Example: Check if 'is_cycle_collapsed' exists
            const tableInfo = this.db.pragma('table_info(cycles)') as any[];
            const hasColumn = tableInfo.some(col => col.name === 'is_cycle_collapsed');
            
            if (!hasColumn) {
                this.db.exec('ALTER TABLE cycles ADD COLUMN is_cycle_collapsed INTEGER DEFAULT 0');
                Services.loggerService.log('Migrated database: Added is_cycle_collapsed to cycles table.');
            }
        }
        ```
    *   **`initialize()`:** Call `this.migrateSchema()` after `createTables()`.
3.  **Update `HistoryService.ts`:** Ensure the `saveCycle` and `getCycle` methods map the new TypeScript property to the new database column.

### 3.2. Breaking Changes
If a change requires a complete schema restructure (rare), it is often safer to:
1.  Rename the existing table (e.g., `cycles_v1`).
2.  Create the new table (`cycles`).
3.  Run a migration script to copy/transform data from `cycles_v1` to `cycles`.
4.  Drop `cycles_v1`.

## 4. Debugging & Inspection

To inspect the database contents during development:

1.  **VS Code Extensions:** Use an extension like "SQLite" or "SQLite Viewer" to open `.vscode/dce.db` directly within VS Code.
2.  **CLI:** Use the `sqlite3` command-line tool:
    ```bash
    sqlite3 .vscode/dce.db "SELECT id, title, status FROM cycles ORDER BY id DESC LIMIT 5;"
    ```
3.  **Logs:** The `DatabaseService` logs all major operations and errors to the "Data Curation Environment" output channel.

## 5. Backup & Recovery

*   **Automatic Backup:** The legacy `dce_history.json` is renamed to `dce_history.json.bak` upon migration.
*   **Manual Export:** Users can export their history to JSON via the "Export History" button in the PCPP. This JSON can be re-imported to rebuild the database.
</file_artifact>

<file path="src/Artifacts/A121. DCE - Master Artifact List Automation Plan.md">
# Artifact A121: DCE - Master Artifact List Automation Plan
# Date Created: C126
# Author: AI Model & Curator

- **Key/Value for A0:**
- **Description:** A plan to automate the maintenance of the Master Artifact List (A0) by programmatically scanning artifact files for metadata tags.
- **Tags:** plan, automation, documentation, maintenance, a0

## 1. Vision & Goal

The Master Artifact List (`A0`) is the central index of the project's documentation. Currently, it is maintained manually, which is error-prone and tedious. The goal is to automate the generation and update of `A0` by scanning the `src/Artifacts` directory.

We will treat the individual artifact files as the "Source of Truth." Each artifact will contain a standardized metadata header. The system will read these headers and compile the `A0` list dynamically.

## 2. Metadata Schema

Every artifact file MUST start with a metadata block formatted as YAML-like comments or specific Markdown lines that are easily regex-parseable.

**Standard Header Format:**
```markdown
# Artifact A[ID]: [Title]
# Date Created: [Cycle]
# Author: [Author]
# Updated on: [Cycle] ([Change Log])

- **Key/Value for A0:**
- **Description:** [A concise description for A0]
- **Tags:** [comma, separated, tags]
```

## 3. Technical Implementation Plan

### 3.1. New Service: `ArtifactService`
We will create a new backend service, `ArtifactService`, responsible for managing documentation artifacts.

**Responsibilities:**
1.  **Scan:** Read all `.md` files in `src/Artifacts`.
2.  **Parse:** Extract ID, Title, Description, and Tags from the header of each file.
3.  **Generate:** Construct the `A0. DCE Master Artifact List.md` content.
4.  **Update:** Write the new `A0` content to disk.

### 3.2. State Awareness (Selection Sync)
The user expressed a desire for the `A0` list to be "state-aware" regarding selected files.
*   **Concept:** If a user deselects an artifact in the File Tree View (FTV), should it be removed from `A0`?
*   **Analysis:** `A0` serves as a global index. Removing items from `A0` just because they aren't currently selected for the *prompt* might degrade its utility as a map.
*   **Refined Approach:** `A0` should list *all* available artifacts. However, we can add a dynamic "Status" or "Included" indicator to the `A0` generation if it's being generated for a prompt context.

### 3.3. Automation Triggers
*   **On Command:** A command `dce.refreshMasterArtifactList` to manually trigger the rebuild.
*   **On Save:** A file watcher on `src/Artifacts/*.md` could trigger a rebuild (debounced) whenever a documentation file is modified.

## 4. Implementation Steps (Future Cycle)
1.  Create `ArtifactService.ts`.
2.  Implement regex parsers for the standard header.
3.  Implement the `generateA0` method.
4.  Register the command and watcher.
</file_artifact>

<file path="external_context/personal-project/altered-galaxy/scripts/fix-shared-imports.js">
/**
 * SCRIPT: fix-shared-imports.js
 * PURPOSE: Fixes circular dependency issues in @ag/shared where internal files import from '@ag/shared'
 *          instead of relative paths. This resolves TS5055 "Overwrite input file" errors.
 */

const fs = require('fs');
const path = require('path');

const sharedDataDir = path.resolve(__dirname, '../packages/ag-shared/src/data/items');

function processDirectory(dir) {
    if (!fs.existsSync(dir)) {
        console.warn(`Directory not found: ${dir}`);
        return;
    }

    const entries = fs.readdirSync(dir, { withFileTypes: true });

    for (const entry of entries) {
        const fullPath = path.join(dir, entry.name);
        if (entry.isDirectory()) {
            processDirectory(fullPath);
        } else if (entry.name.endsWith('.ts')) {
            fixImport(fullPath);
        }
    }
}

function fixImport(filePath) {
    let content = fs.readFileSync(filePath, 'utf-8');
    let changed = false;

    // Calculate relative path to 'src/types/item.types'
    // We assume the structure packages/ag-shared/src/data/items/...
    // and types are in packages/ag-shared/src/types/item.types.ts
    
    // Logic:
    // 1. Get dir of current file.
    // 2. Find relative path from dir to 'packages/ag-shared/src/types/item.types'
    
    const typesPath = path.resolve(__dirname, '../packages/ag-shared/src/types/item.types');
    const fileDir = path.dirname(filePath);
    
    // Get relative path, remove extension for import
    let relativePath = path.relative(fileDir, typesPath).replace(/\\/g, '/');
    if (!relativePath.startsWith('.')) relativePath = './' + relativePath;

    // Regex to find: import { ... } from '@ag/shared';
    const regex = /from\s+['"]@ag\/shared['"];/g;

    if (regex.test(content)) {
        content = content.replace(regex, `from '${relativePath}';`);
        changed = true;
    }

    if (changed) {
        fs.writeFileSync(filePath, content, 'utf-8');
        console.log(`Fixed imports in: ${filePath}`);
    }
}

console.log('Starting Shared Import Fix...');
processDirectory(sharedDataDir);
console.log('Finished.');
</file_artifact>

<file path="external_context/personal-project/altered-galaxy/scripts/generate-d-info.js">
/*
 * SCRIPT: generate-d-info.js
 * AUTHOR: AI Model & Curator
 * DATE: C80
 * UPDATED: C101 (Fixed command-line argument parsing)
 * PURPOSE: To recursively scan a directory and generate `d-info.md` summary files.
 *          This is used to consolidate thousands of small `.png.txt` files into a few
 *          summary files to reduce the token count for AI context.
 *
 * USAGE: 
 * 1. Run the script from the project root directory.
 * 2. Pass the target directory as an argument.
 * 3. Example: `npm run script:generate-d-info -- packages/ag-client/public/assets/icons/items`
 *          `npm run script:generate-d-info -- packages/ag-server/maps`
 *          `npm run script:generate-d-info -- C:\Projects\altered-galaxy\packages\ag-client\public\assets\audio\sfx\weapons
 *          `npm run script:generate-d-info -- packages\ag-client\public\assets\audio\sfx\weapons`
 *          `npm run script:generate-d-info -- packages\ag-client\public\assets\sprites\units\npc\xylos\boss\effects`
 */

const fs = require('fs');
const path = require('path');

// --- CONFIGURATION ---
const rootDirectoryArg = process.argv[2];
const outputFileName = 'd-info.md';
// -------------------

if (!rootDirectoryArg) {
    console.error('Error: Please provide a target directory path as an argument.');
    console.error('Example: npm run script:generate-d-info -- path/to/your/assets');
    process.exit(1);
}

const rootDirectory = path.resolve(process.cwd(), rootDirectoryArg);


/**
 * Recursively processes a directory to generate d-info.md files.
 * @param {string} dir - The directory path to process.
 */
function processDirectory(dir) {
  try {
    const entries = fs.readdirSync(dir, { withFileTypes: true });
    const files = [];
    const subdirectories = [];

    for (const entry of entries) {
      if (entry.isDirectory()) {
        subdirectories.push(entry.name);
      } else {
        // Exclude the output file itself and any other unwanted files from the list
        if (entry.name !== outputFileName && !entry.name.startsWith('.')) {
          files.push(entry.name);
        }
      }
    }

    // Only create a d-info.md file if there are other files present
    if (files.length > 0) {
      const relativeDir = path.relative(path.join(rootDirectory, '..', '..'), dir); // Make path more readable
      
      let content = `<d-info.md (directory info)>\n`;
      content += `File Count: ${files.length}\n`;
      content += `Directory Located at: ${relativeDir.replace(/\\/g, '/')}/\n`;
      content += `Files:\n`;
      
      files.sort().forEach((file, index) => {
        content += `${index + 1}. ${file}\n`;
      });
      content += `</d-info.md (directory info)>`;

      const outputPath = path.join(dir, outputFileName);
      fs.writeFileSync(outputPath, content);
      console.log(`Generated: ${outputPath}`);
    }

    // Recurse into subdirectories
    for (const subdir of subdirectories) {
      processDirectory(path.join(dir, subdir));
    }
  } catch (error) {
    console.error(`Error processing directory ${dir}:`, error);
  }
}

console.log(`Starting directory info generation in: ${rootDirectory}`);
console.log('---');

if (fs.existsSync(rootDirectory)) {
  processDirectory(rootDirectory);
} else {
  console.error(`Error: Root directory not found at ${rootDirectory}`);
}

console.log('---');
console.log('Finished generating directory info files.');
</file_artifact>

<file path="external_context/personal-project/altered-galaxy/scripts/migrate-items.js">
const fs = require('fs');
const path = require('path');

const projectRoot = path.resolve(__dirname, '..');
const clientItemsDir = path.join(projectRoot, 'packages', 'ag-client', 'src', 'data', 'items');
const serverItemsDir = path.join(projectRoot, 'packages', 'ag-server', 'src', 'data', 'items');
const sharedDataDir = path.join(projectRoot, 'packages', 'ag-shared', 'src', 'data');
const sharedItemsDir = path.join(sharedDataDir, 'items');

function copyRecursiveSync(src, dest) {
    const exists = fs.existsSync(src);
    const stats = exists && fs.statSync(src);
    const isDirectory = exists && stats.isDirectory();

    if (isDirectory) {
        if (!fs.existsSync(dest)) {
            fs.mkdirSync(dest, { recursive: true });
        }
        fs.readdirSync(src).forEach((childItemName) => {
            copyRecursiveSync(path.join(src, childItemName), path.join(dest, childItemName));
        });
    } else {
        if (!fs.existsSync(path.dirname(dest))) {
            fs.mkdirSync(path.dirname(dest), { recursive: true });
        }
        fs.copyFileSync(src, dest);
    }
}

console.log('Starting Item Data Migration...');

// 1. Create Shared Directory
if (!fs.existsSync(sharedItemsDir)) {
    console.log(`Creating ${sharedItemsDir}...`);
    fs.mkdirSync(sharedItemsDir, { recursive: true });
}

// 2. Copy from Client (Source of Truth for most files)
if (fs.existsSync(clientItemsDir)) {
    console.log(`Copying items from Client to Shared...`);
    copyRecursiveSync(clientItemsDir, sharedItemsDir);
} else {
    console.warn(`Client items directory not found: ${clientItemsDir}`);
}

// 3. Update Shared index.ts to export data
const sharedIndex = path.join(projectRoot, 'packages', 'ag-shared', 'src', 'index.ts');
let indexContent = fs.readFileSync(sharedIndex, 'utf-8');
if (!indexContent.includes("export * from './data/items'")) {
    console.log(`Updating Shared index.ts...`);
    indexContent += "\nexport * from './data/items';\n";
    fs.writeFileSync(sharedIndex, indexContent);
}

console.log('Migration of files complete.');
console.log('ACTION REQUIRED: Please update client and server imports to use @ag/shared and delete old data directories manually to ensure safety.');
</file_artifact>

<file path="external_context/personal-project/altered-galaxy/scripts/README.md">
# Scripts Directory

This directory contains utility scripts for project maintenance and workflow optimization.

## `rename-files.js`

**Purpose:** To recursively find files in a directory and remove a specific suffix from their names. This is useful for batch-cleaning files downloaded from services that add their own branding to filenames.

**Usage:**
1.  **COPY** this script to the root of the directory you want to clean up (e.g., `C:\Users\YourUser\Downloads\my-images`).
2.  Open a terminal or command prompt in that same directory.
3.  Run the script with the command: `node rename-files.js`

The script is pre-configured to remove `-Photoroom` from filenames. You can change the `suffixToRemove` variable inside the script if needed.

## `generate-d-info.js` (Updated C100)

**Purpose:** To recursively scan a specified directory and generate a `d-info.md` summary file in each subdirectory that contains assets.

**Usage:**
1.  Run this script from the **project root directory**.
2.  Use the configured npm script and pass the target directory as an argument.
    ```bash
    # Note the '--' is important for passing arguments to the script via npm
    npm run script:generate-d-info -- packages/ag-client/public/assets/icons/items
    ```
3.  This script is a key part of our token management strategy. It consolidates thousands of small `.png.txt` files into a few summary files, which dramatically reduces the token count required for providing context to the AI.

## `truncate-data-files.js` (New C100)

**Purpose:** To recursively scan a directory and create truncated `.local.ts` versions of large `*Data.ts` files. The `.local` version contains only the first and last entries of a data array, preserving the file's structure while reducing token count for AI context.

**Usage:**
1.  Run this script from the **project root directory**.
2.  Use the configured npm script and pass the target directory as an argument.
    ```bash
    npm run script:truncate-data -- packages/ag-server/src/data
</file_artifact>

<file path="external_context/personal-project/altered-galaxy/scripts/rename-files.js">
/*
 * SCRIPT: rename-files.js
 * AUTHOR: AI Model & Curator
 * DATE: C80
 * PURPOSE: To recursively scan a directory and remove a specific suffix from filenames.
 *
 * USAGE:
 * 1. COPY this script to the root of the directory you want to clean up (e.g., your main downloads folder).
 * 2. Open a terminal/command prompt in that directory.
 * 3. Run the script with the command: `node rename-files.js`
 *
 * NOTE: This script performs file operations directly. It's always a good idea to have a backup.
 */

const fs = require('fs');
const path = require('path');

// --- CONFIGURATION ---
const directoryToScan = process.cwd(); // This makes the script run in the directory it's placed in.
const suffixToRemove = '-Photoroom';
// -------------------

/**
 * Recursively walks a directory, renaming files that match the criteria.
 * @param {string} dir - The directory path to scan.
 */
function walkAndRename(dir) {
  try {
    const files = fs.readdirSync(dir);
    
    files.forEach((file) => {
      const filePath = path.join(dir, file);
      try {
        const stat = fs.statSync(filePath);
        if (stat.isDirectory()) {
          walkAndRename(filePath); // Recurse into subdirectory
        } else if (file.includes(suffixToRemove)) {
          const newFileName = file.replace(suffixToRemove, '');
          const newFilePath = path.join(dir, newFileName);
          
          fs.renameSync(filePath, newFilePath);
          console.log(`Renamed: ${filePath} -> ${newFilePath}`);
        }
      } catch (statError) {
        console.error(`Could not stat file ${filePath}:`, statError);
      }
    });
  } catch (readError) {
    console.error(`Could not read directory ${dir}:`, readError);
  }
}

console.log(`Starting file rename process...`);
console.log(`Target directory: ${directoryToScan}`);
console.log(`Suffix to remove: "${suffixToRemove}"`);
console.log('---');

walkAndRename(directoryToScan);

console.log('---');
console.log('Finished renaming files.');
</file_artifact>

<file path="external_context/personal-project/altered-galaxy/scripts/requirements.txt">
requests
beautifulsoup4
</file_artifact>

<file path="external_context/personal-project/altered-galaxy/scripts/scrape_wiki.py">
import requests
from bs4 import BeautifulSoup
import re
import time
import os

def scrape_fandom_page(page_title):
    # Handle known redirects or corrections observed in the fandom wiki
    original_title = page_title
    if page_title == "Galery":
        page_title = "Gallery"
    if page_title == "Specture":
        page_title = "Spectre"
    if page_title == "Planets & Ressources":
         page_title = "Planets & Resources"
    if page_title == "Super-Organics":
        page_title = "Super Organics"

    base_url = "https://shattered-galaxy.fandom.com/wiki/"
    # Basic URL encoding for titles
    url_title = page_title.replace(" ", "_")
    # Use requests.utils.quote to handle special characters like '&' correctly
    url = base_url + requests.utils.quote(url_title)

    headers = {
        # Use a generic User-Agent to avoid being blocked
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.0.0 Safari/537.36'}

    try:
        # allow_redirects=True handles cases where the wiki normalizes the URL (e.g., capitalization)
        response = requests.get(url, headers=headers, timeout=15, allow_redirects=True)

        if response.status_code == 200:
            soup = BeautifulSoup(response.content, 'html.parser')
            # The main content area in MediaWiki/Fandom
            content_div = soup.find('div', class_='mw-parser-output')

            if content_div:
                # Remove known noisy elements (TOC, edit links, navigation boxes, sidebars, etc.)
                # This improves the signal-to-noise ratio of the scraped text.
                for noisy_element in content_div.find_all(['div', 'span', 'aside'], class_=['toc', 'editsection', 'navbox', 'metadata', 'mw-editsection', 'portable-infobox', 'page-header__actions', 'WikiaBar']):
                     if noisy_element:
                        noisy_element.decompose()

                # Extract text, using newline as a separator to preserve some structure (like lists/paragraphs)
                text = content_div.get_text(separator='\n', strip=True)

                # Basic cleanup
                text = re.sub(r'\[\d+\]', '', text) # Remove citations like [1]
                text = re.sub(r'(\n\s*){3,}', '\n\n', text) # Collapse excessive newlines

                return text.strip()
            else:
                return f"Could not find main content area (mw-parser-output) on page: {response.url}"
        elif response.status_code == 404:
             return f"Page not found (404): {url}"
        else:
            return f"Failed to fetch page: {url} (Status code: {response.status_code})"
    except requests.RequestException as e:
        return f"Error fetching page: {url} ({e})"

def main():
    # The raw list provided in the Cycle 1 context
    page_list = [
        "Ability Glossary", "Abomination", "Albatross", "Apparition", "Arbalest",
        "Army & Skill-Points", "Aviation Advanced", "Aviation Bonus & Misc", "Aviation Prime",
        "Ballista", "Banshee", "Basic Equipment", "Battles", "Behemoth",
        "Biodirves & Engines", "Charise", "Charnal", "Chimera", "Clout Table", "Condor",
        "Daeva", "Defense", "Dythe", "Eagle", "Equipment", "Falcon", "Galery", "Gallery",
        "Gear-Doc", "Ghast", "Gryphon", "Hawk", "Hotkeys & Chat-Commands", "Hydra", "Imp",
        "Infantry Advanced", "Infantry Bonus & Misc", "Infantry I", "Infantry Misc",
        "Infantry Prime", "Informative Links", "Jorias", "Larva, Scave, Knell", "Leviathan",
        "Liche", "Lithubik", "Main Page", "Mamos, Momos, Mamos", "Manta, Onnir", "Manticore",
        "Mantlet", "Max. Skill-Units", "Medic", "Mephit", "Miasam", "Miasmal",
        "Mobile Advanced", "Mobile Bonus & Misc", "Mobile Prime", "Offense",
        "Oizys, Boreas, Eris, Lyssa", "Orbus", "Organic", "Organic Bonus & Misc", "Organic Misc",
        "Owl", "Pegasus", "Pelican", "Phantom", "Phoenix", "Planets & Resources",
        "Planets & Ressources", "Poda, Kritsk, Mlortha", "Quorg", "Rayoks", "Red-Eye",
        "Reincarnation", "Remakes, Private Servers, and Spiritual Successors", "Revenant",
        "Roc", "Sapper", "Shade", "Shattered Galaxy Wiki", "Slanth, Crudgin, Rouke",
        "Spectre", "Specture", "Spirit", "Super-Organics", "Super Organics", "Trebuchet",
        "Triage", "Ubik, Tyr, Haltyr", "Virus", "Volte", "Vulture", "Vytyr", "War Pigeon",
        "Weapon & Armor", "Wight", "Wraith"
    ]

    # Normalize and deduplicate the list based on known corrections
    unique_pages = []
    seen = set()
    for page in page_list:
        normalized = page
        if normalized == "Galery":
            normalized = "Gallery"
        if normalized == "Specture":
            normalized = "Spectre"
        if normalized == "Planets & Ressources":
            normalized = "Planets & Resources"
        if normalized == "Super-Organics":
            normalized = "Super Organics"

        if normalized not in seen:
            # We use the normalized name for scraping and organization
            unique_pages.append(normalized)
            seen.add(normalized)

    scraped_data = {}
    start_time = time.time()
    print(f"Starting scrape of {len(unique_pages)} unique pages...")

    for i, page in enumerate(unique_pages):
        print(f"Scraping page {i+1}/{len(unique_pages)}: {page}")
        content = scrape_fandom_page(page)
        scraped_data[page] = content
        time.sleep(0.2) # Be polite to the server

    end_time = time.time()
    print(f"Scraping finished in {end_time - start_time:.2f} seconds.")

    # Define the output path for the consolidated artifact
    # Assuming the script is run from the project root
    output_dir = os.path.join("src", "Artifacts")
    os.makedirs(output_dir, exist_ok=True)
    output_file = os.path.join(output_dir, "AlteredGalaxy-A25-Wiki-Scrape-C1.md")

    # Write the results to the artifact file
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("# Artifact A25: Altered Galaxy - Shattered Galaxy Wiki Scrape (C1)\n")
        f.write("# Date Created: C1\n")
        f.write("# Author: AI Model (Scraper Script) & Curator\n")
        f.write("\n- **Key/Value for A0:**\n")
        f.write(f"- **Description:** The raw text content scraped from the Shattered Galaxy Fandom Wiki ({len(scraped_data)} pages) in Cycle 1, providing essential data on units, items, and mechanics.\n")
        f.write("- **Tags:** research, data sourcing, raw data, shattered galaxy, wiki scrape\n")
        f.write("\n## 1. Overview\n\n")
        f.write("This artifact contains the raw text scraped from the Shattered Galaxy Fandom Wiki (https://shattered-galaxy.fandom.com/). This data is crucial for filling the content gaps identified in A18 and A19.\n\n")
        f.write(f"Total Pages Scraped: {len(scraped_data)}\n\n")
        f.write("## 2. Scraped Content\n")

        # Write the content of each page into the consolidated file
        for title, content in scraped_data.items():
            clean_title = title.replace("#", "").strip()
            # Ensure the URL in the markdown is correctly formatted
            url_segment = requests.utils.quote(title.replace(" ", "_"))
            f.write(f"\n---\n\n### Page: {clean_title}\n\n")
            f.write(f"Source: https://shattered-galaxy.fandom.com/wiki/{url_segment}\n\n")
            f.write("```text\n")
            if content:
                f.write(content)
            else:
                f.write("No content scraped (see scraper logs for details).")
            f.write("\n```\n")

    print(f"\nSuccessfully wrote consolidated scraped data to {output_file}")

if __name__ == "__main__":
    main()
</file_artifact>

<file path="external_context/personal-project/altered-galaxy/scripts/simulate-movement.js">
/**
 * SCRIPT: simulate-movement.js
 * PURPOSE: To simulate and debug movement logic for Carriers and Fleets without running the full server.
 *          Diagnoses overshoot issues and acceleration spikes using a rectangular path.
 * USAGE: npm run script:simulate
 */

// Mock Entity
let fleet = { 
    x: 0, 
    y: 0, 
    vx: 0, 
    vy: 0, 
    targetX: 0, 
    targetY: 0, 
    maxSpeed: 400, // Matches server MAX_SPEED
    path: [
        {x: 1000, y: 0},
        {x: 1000, y: 1000},
        {x: 0, y: 1000},
        {x: 0, y: 0}
    ] 
};

const TICK_RATE = 30;
const DT = 1 / TICK_RATE;
const MAX_ACCEL = 150; // Matches server MAX_ACCEL
const ARRIVAL_RADIUS = 50;
const DECEL_RADIUS = 300;
const STOP_THRESHOLD = 4;

// Initialize first target
let next = fleet.path.shift();
fleet.targetX = next.x;
fleet.targetY = next.y;

console.log("--- SIMULATION START: RECTANGLE LAP ---");
console.log(`Route: (0,0) -> (1000,0) -> (1000,1000) -> (0,1000) -> (0,0)`);

for (let i = 0; i < 600; i++) { // Run for 20 seconds (600 ticks)
    const dx = fleet.targetX - fleet.x;
    const dy = fleet.targetY - fleet.y;
    const dist = Math.sqrt(dx * dx + dy * dy);
    
    // Waypoint Passing Logic (Lookahead)
    const vecToTarget = { x: dx, y: dy };
    const vel = { x: fleet.vx, y: fleet.vy };
    const dot = vecToTarget.x * vel.x + vecToTarget.y * vel.y;
                            
    if ((dist < ARRIVAL_RADIUS || (dist < ARRIVAL_RADIUS * 2 && dot < 0)) && fleet.path.length > 0) {
        console.log(`[Tick ${i}] *** WAYPOINT REACHED (${fleet.targetX}, ${fleet.targetY}) ***`);
        const nextPoint = fleet.path.shift();
        fleet.targetX = nextPoint.x;
        fleet.targetY = nextPoint.y;
        // Note: We do NOT zero velocity here, preserving momentum for the turn
    } else if (dist < STOP_THRESHOLD && fleet.path.length === 0) {
        console.log(`[Tick ${i}] *** FINAL DESTINATION REACHED (${fleet.targetX}, ${fleet.targetY}) ***`);
        break;
    }

    let ax = 0;
    let ay = 0;
    const applyAccel = (fx, fy) => {
        ax = Math.max(-MAX_ACCEL * 2, Math.min(MAX_ACCEL * 2, fx));
        ay = Math.max(-MAX_ACCEL * 2, Math.min(MAX_ACCEL * 2, fy));
    };

    // Physics Logic (Mirrors physicsSystem.ts)
    const isFinalWaypoint = fleet.path.length === 0;
    
    // Calculate turn angle for Cornering Logic
    let decelRadius = DECEL_RADIUS;
    let targetSpeedMultiplier = 1.0;
    
    if (!isFinalWaypoint && fleet.path.length > 0) {
            const nextPoint = fleet.path[0];
            const vecCurrent = { x: fleet.targetX - fleet.x, y: fleet.targetY - fleet.y };
            const vecNext = { x: nextPoint.x - fleet.targetX, y: nextPoint.y - fleet.targetY };
            
            const magCurrent = Math.sqrt(vecCurrent.x*vecCurrent.x + vecCurrent.y*vecCurrent.y);
            const magNext = Math.sqrt(vecNext.x*vecNext.x + vecNext.y*vecNext.y);
            
            if (magCurrent > 0 && magNext > 0) {
                // Dot product
                const dot = (vecCurrent.x * vecNext.x + vecCurrent.y * vecNext.y) / (magCurrent * magNext);
                const angle = Math.acos(Math.max(-1, Math.min(1, dot))); // radians
                
                const angleDeg = angle * (180 / Math.PI);
                
                // Straight Shot (0-20 deg)
                if (angleDeg < 20) {
                    decelRadius = 0; // Do not brake
                } 
                // Standard Turn (20-90 deg)
                else if (angleDeg < 90) {
                    decelRadius = DECEL_RADIUS * 0.5; // Brake slightly
                    targetSpeedMultiplier = 0.75;
                }
                // Hairpin (> 90 deg)
                else {
                    decelRadius = DECEL_RADIUS * 1.5; // Brake earlier
                    targetSpeedMultiplier = 0.2; // Brake harder
                }
            }
    }
    
    if (isFinalWaypoint) {
         if (dist < DECEL_RADIUS) {
            // Arrival Damping
            const desiredSpeed = fleet.maxSpeed * (dist / DECEL_RADIUS);
            const nx = dx / dist;
            const ny = dy / dist;
            const desiredVx = nx * desiredSpeed;
            const desiredVy = ny * desiredSpeed;
            applyAccel((desiredVx - fleet.vx)*2, (desiredVy - fleet.vy)*2);
         } else {
             const nx = dx / dist;
             const ny = dy / dist;
             const desiredVx = nx * fleet.maxSpeed;
             const desiredVy = ny * fleet.maxSpeed;
             applyAccel(desiredVx - fleet.vx, desiredVy - fleet.vy);
         }
    } else {
         // Cruising / Turning
         const nx = dx / dist;
         const ny = dy / dist;
         
         let targetSpeed = fleet.maxSpeed;
         
         // Apply Cornering Brake
         if (decelRadius > 0 && dist < decelRadius) {
                targetSpeed = fleet.maxSpeed * targetSpeedMultiplier + (fleet.maxSpeed * (1-targetSpeedMultiplier) * (dist / decelRadius));
         }

         const desiredVx = nx * targetSpeed;
         const desiredVy = ny * targetSpeed;
         
         const forceMult = targetSpeed < fleet.maxSpeed ? 2 : 1;
         applyAccel((desiredVx - fleet.vx) * forceMult, (desiredVy - fleet.vy) * forceMult);
    }

    fleet.vx += ax * DT;
    fleet.vy += ay * DT;
    
    // Clamp Max Speed
    const speed = Math.sqrt(fleet.vx*fleet.vx + fleet.vy*fleet.vy);
    if (speed > fleet.maxSpeed) {
        fleet.vx = (fleet.vx / speed) * fleet.maxSpeed;
        fleet.vy = (fleet.vy / speed) * fleet.maxSpeed;
    }
    
    fleet.x += fleet.vx * DT;
    fleet.y += fleet.vy * DT;

    // Log every 5 ticks to reduce noise, but keep granularity high enough
    if (i % 5 === 0) {
        console.log(`Tick ${i}: Pos(${fleet.x.toFixed(0)},${fleet.y.toFixed(0)}) Speed=${speed.toFixed(0)} Dist=${dist.toFixed(0)} Target=(${fleet.targetX},${fleet.targetY})`);
    }
}

console.log("--- SIMULATION END ---");
</file_artifact>

<file path="external_context/personal-project/altered-galaxy/scripts/truncate-data-files.js">
/*
 * SCRIPT: truncate-data-files.js
 * AUTHOR: AI Model & Curator
 * DATE: C100
 * UPDATED: C102 (Enhanced to handle object-based data files like chassisSpecData)
 * PURPOSE: To recursively scan a directory and create truncated `.local.ts` versions
 *          of large data files. The local version contains only the first
 *          and last entries of a data array/object to reduce token count for AI context
 *          while preserving the file's structure.
 *
 * USAGE:
 * 1. Run the script from the project root directory.
 * 2. Pass the target directory as an argument.
 * 3. Example: `npm run script:truncate-data -- packages\ag-shared\src\data\items`
 */

const fs = require('fs');
const path = require('path');

const targetDirArg = process.argv[2];

if (!targetDirArg) {
  console.error('Error: Please provide a target directory path as an argument.');
  console.error('Example: npm run script:truncate-data -- packages/ag-server/src/data');
  process.exit(1);
}

const absoluteTargetDir = path.resolve(process.cwd(), targetDirArg);

function processDirectory(dir) {
  if (!fs.existsSync(dir)) {
    console.error(`Directory not found: ${dir}`);
    return;
  }

  const entries = fs.readdirSync(dir, { withFileTypes: true });

  for (const entry of entries) {
    const fullPath = path.join(dir, entry.name);
    if (entry.isDirectory()) {
      processDirectory(fullPath);
    } else if ((entry.name.endsWith('Data.ts') || entry.name.endsWith('Weapons.ts')) && !entry.name.endsWith('.local.ts')) {
      createLocalVersion(fullPath);
    }
  }
}

function createLocalVersion(filePath) {
  try {
    const content = fs.readFileSync(filePath, 'utf-8');
    
    // Try matching array structure first
    let match = content.match(/(const\s+\w+\s*:\s*[^=\[]+\[\]\s*=\s*)\[([\s\S]*)\];/);
    if (match && match[2]) {
      const arrayContent = match[2].trim();
      if (arrayContent === '') {
        console.log(`Skipping ${filePath}: Array is empty.`);
        return;
      }
      const objects = arrayContent.match(/\{[\s\S]*?\}(?=\s*,|\s*$)/g);
      if (!objects || objects.length < 2) {
        console.log(`Skipping ${filePath}: Contains fewer than 2 array objects.`);
        return;
      }

      const header = match[1];
      const newContent = `${header}[\n  ${objects[0]},\n  // [...]\n  ${objects[objects.length - 1]}\n];`;
      const finalContent = content.replace(match[0], newContent);
      const newFilePath = filePath.replace('.ts', '.local.ts');
      fs.writeFileSync(newFilePath, finalContent);
      console.log(`Generated: ${newFilePath}`);
      return;
    }

    // Fallback to matching object structure (for chassisSpecData, etc.)
    match = content.match(/(export const \w+\s*:\s*Record<string, \w+>\s*=\s*)\{([\s\S]*)\};/);
    if (match && match[2]) {
      const objectContent = match[2].trim();
      if (objectContent === '') {
        console.log(`Skipping ${filePath}: Object is empty.`);
        return;
      }
      
      // This regex is designed to capture top-level properties like "Key": { ... }
      const properties = objectContent.match(/"[^"]+"\s*:\s*\{[\s\S]*?\}(?=,?\s*\n)/g);

      if (!properties || properties.length < 2) {
        console.log(`Skipping ${filePath}: Contains fewer than 2 object properties.`);
        return;
      }

      const header = match[1];
      const newContent = `${header}{\n  ${properties[0]},\n  // [...]\n  ${properties[properties.length - 1]}\n};`;
      const finalContent = content.replace(match[0], newContent);
      const newFilePath = filePath.replace('.ts', '.local.ts');
      fs.writeFileSync(newFilePath, finalContent);
      console.log(`Generated: ${newFilePath}`);
      return;
    }

    console.log(`Skipping ${filePath}: No recognized data array or object found.`);

  } catch (error) {
    console.error(`Error processing file ${filePath}:`, error);
  }
}

console.log(`Starting data file truncation process in: ${absoluteTargetDir}`);
console.log('---');
processDirectory(absoluteTargetDir);
console.log('---');
console.log('Finished truncation process.');
</file_artifact>

<file path="src/Artifacts/A122. DCE - Directory Summarization & Large Data Strategy.md">
# Artifact A122: DCE - Directory Summarization & Large Data Strategy
# Date Created: C127
# Author: AI Model & Curator

- **Key/Value for A0:**
- **Description:** A strategy to manage token bloat by summarizing large asset directories and truncating massive data files.
- **Tags:** strategy, optimization, tokens, d-info, truncation, large files

## 1. Problem Statement

As projects grow, they often accumulate large numbers of asset files (images, audio) or massive data definition files. Including these in the AI context "raw" leads to significant token bloat.
1.  **Asset Directories:** A folder with 2,000 images generates 2,000 entries in the flattened context. Even if the content is skipped, the file paths and metadata headers consume thousands of tokens.
2.  **Data Files:** Large TypeScript data files (e.g., item definitions, RPG stats) can consume tens of thousands of tokens while providing low "structural" value to the AI, which often only needs to know the *shape* of the data.

## 2. Strategy 1: Directory Summarization (`d-info`)

**Goal:** Replace the verbose listing of hundreds of individual files with a concise summary of the directory's contents.

**Mechanism:**
*   **Trigger:** When the Flattener Service processes the selected files, it groups them by their parent directory. If the number of selected files in a single directory exceeds a threshold (e.g., **50 files**), the "Summarization Mode" is triggered for that directory.
*   **Action:** The individual file entries are removed from the flattening queue. They are replaced by a single, virtual file entry named `d-info.md` within that directory.
*   **Content:** The virtual `d-info.md` file contains:
    *   Total file count.
    *   Directory location relative to the project root.
    *   A concise list of the filenames.

**Output Format:**
```markdown
<d-info.md (directory info)>
File Count: 150
Directory Located at: packages/ag-client/public/assets/icons/items/
Files:
1. icon_001.png
2. icon_002.png
...
</d-info.md (directory info)>
```

## 3. Strategy 2: Large Data Truncation (Planned)

**Goal:** Provide the AI with the *structure* (schema) of large data files without burdening it with the *volume* of the data.

**Mechanism (Future Implementation):**
*   **Detection:** Identify large `.ts` or `.json` files that primarily contain arrays of objects or large dictionaries.
*   **Truncation:** Generate a temporary `.local.ts` version of the file.
*   **Logic:**
    *   Keep the file header (imports, variable declarations).
    *   Keep the first entry of the array/object (to show the schema/structure).
    *   Insert a comment `// ... [X items truncated] ...`.
    *   Keep the last entry (to show the closing syntax).
*   **Context:** The system will prefer the `.local.ts` version for the context window, while the original file remains untouched on disk.

## 4. Benefits

*   **Token Efficiency:** Drastically reduces the overhead of asset-heavy projects.
*   **Context Clarity:** Reduces noise, allowing the AI to focus on code logic rather than file lists.
*   **Performance:** Faster flattening and prompt generation.
</file_artifact>

